{"id": "4146", "revid": "43282988", "url": "https://en.wikipedia.org/wiki?curid=4146", "title": "Bus", "text": "A bus (contracted from omnibus, with variants multibus, motorbus, autobus, etc.) is a motor vehicle that carries significantly more passengers than an average car or van, but fewer than the average rail transport. It is most commonly used in public transport, but is also in use for charter purposes, or through private ownership. Although the average bus carries between 30 and 100 passengers, some buses have a capacity of up to 300 passengers. The most common type is the single-deck rigid bus, with double-decker and articulated buses carrying larger loads, and midibuses and minibuses carrying smaller loads. Coaches are used for longer-distance services. Many types of buses, such as city transit buses and inter-city coaches, charge a fare. Other types, such as elementary or secondary school buses or shuttle buses within a post-secondary education campus, are free. In many jurisdictions, bus drivers require a special large vehicle licence above and beyond a regular driving license.\nBuses may be used for scheduled bus transport, scheduled coach transport, school transport, private hire, or tourism; promotional buses may be used for political campaigns and others are privately operated for a wide range of purposes, including rock and pop band tour vehicles.\nHorse-drawn buses were used from the 1820s, followed by steam buses in the 1830s, and electric trolleybuses in 1882. The first internal combustion engine buses, or motor buses, were used in 1895. Recently, interest has been growing in hybrid electric buses, fuel cell buses, and electric buses, as well as buses powered by compressed natural gas or biodiesel. As of the 2010s, bus manufacturing is increasingly globalised, with the same designs appearing around the world.\nName.\nThe word \"bus\" is a shortened form of the Latin adjectival form (\"for all\"), the dative plural of (\"all\"). The theoretical full name is in French (\"vehicle for all\"). The name originates from a mass-transport service started in 1823 by a French corn-mill owner named in Richebourg, a suburb of Nantes. A by-product of his mill was hot water, and thus next to it he established a spa business. In order to encourage customers he started a horse-drawn transport service from the city centre of Nantes to his establishment. The first vehicles stopped in front of the shop of a hatter named Omn\u00e9s, which displayed a large sign inscribed \"Omnes Omnibus\", a pun on his Latin-sounding surname, being the male and female nominative, vocative and accusative form of the Latin adjective (\"all\"), combined with \"omnibus\", the dative plural form meaning \"for all\", thus giving his shop the name \"Omn\u00e9s for all\", or \"everything for everyone\".\nHis transport scheme was a huge success, although not as he had intended as most of his passengers did not visit his spa. He turned the transport service into his principal lucrative business venture and closed the mill and spa. Nantes citizens soon gave the nickname \"omnibus\" to the vehicle. Having invented the successful concept Baudry moved to Paris and launched the first omnibus service there in April 1828. A similar service was introduced in Manchester in 1824 and in London in 1829.\nHistory.\nSteam buses.\nRegular intercity bus services by steam-powered buses were pioneered in England in the 1830s by Walter Hancock and by associates of Sir Goldsworthy Gurney, among others, running reliable services over road conditions which were too hazardous for horse-drawn transportation.\nThe first mechanically propelled omnibus appeared on the streets of London on 22 April 1833. Steam carriages were much less likely to overturn, they travelled faster than horse-drawn carriages, they were much cheaper to run, and caused much less damage to the road surface due to their wide tyres.\nHowever, the heavy road tolls imposed by the turnpike trusts discouraged steam road vehicles and left the way clear for the horse bus companies, and from 1861 onwards, harsh legislation virtually eliminated mechanically propelled vehicles from the roads of Great Britain for 30 years, the Locomotive Act 1861 imposing restrictive speed limits on \"road locomotives\" of in towns and cities, and in the country.\nTrolleybuses.\nIn parallel to the development of the bus was the invention of the electric trolleybus, typically fed through trolley poles by overhead wires. The Siemens brothers, William in England and Ernst Werner in Germany, collaborated on the development of the trolleybus concept. Sir William first proposed the idea in an article to the \"Journal of the Society of Arts\" in 1881 as an \"...arrangement by which an ordinary omnibus...would have a suspender thrown at intervals from one side of the street to the other, and two wires hanging from these suspenders; allowing contact rollers to run on these two wires, the current could be conveyed to the tram-car, and back again to the dynamo machine at the station, without the necessity of running upon rails at all.\"\nThe first such vehicle, the Electromote, was made by his brother Ernst Werner von Siemens and presented to the public in 1882 in Halensee, Germany. Although this experimental vehicle fulfilled all the technical criteria of a typical trolleybus, it was dismantled in the same year after the demonstration.\nMax Schiemann opened a passenger-carrying trolleybus in 1901 near Dresden, in Germany. Although this system operated only until 1904, Schiemann had developed what is now the standard trolleybus current collection system. In the early days, a few other methods of current collection were used. Leeds and Bradford became the first cities to put trolleybuses into service in Great Britain on 20 June 1911.\nMotor buses.\nIn Siegerland, Germany, two passenger bus lines ran briefly, but unprofitably, in 1895 using a six-passenger motor carriage developed from the 1893 Benz Viktoria. Another commercial bus line using the same model Benz omnibuses ran for a short time in 1898 in the rural area around Llandudno, Wales.\nGermany's Daimler Motors Corporation also produced one of the earliest motor-bus models in 1898, selling a double-decker bus to the Motor Traction Company which was first used on the streets of London on 23 April 1898. The vehicle had a maximum speed of and accommodated up to 20 passengers, in an enclosed area below and on an open-air platform above. With the success and popularity of this bus, DMG expanded production, selling more buses to companies in London and, in 1899, to Stockholm and Speyer. Daimler Motors Corporation also entered into a partnership with the British company Milnes and developed a new double-decker in 1902 that became the market standard.\nThe first mass-produced bus model was the B-type double-decker bus, designed by Frank Searle and operated by the London General Omnibus Company\u2014it entered service in 1910, and almost 3,000 had been built by the end of the decade. Hundreds of them saw military service on the Western Front during the First World War.\nThe Yellow Coach Manufacturing Company, which rapidly became a major manufacturer of buses in the US, was founded in Chicago in 1923 by John D. Hertz. General Motors purchased a majority stake in 1925 and changed its name to the Yellow Truck and Coach Manufacturing Company. GM purchased the balance of the shares in 1943 to form the GM Truck and Coach Division.\nModels expanded in the 20th century, leading to the widespread introduction of the contemporary recognizable form of full-sized buses from the 1950s. The AEC Routemaster, developed in the 1950s, was a pioneering design and remains an icon of London to this day. The innovative design used lightweight aluminium and techniques developed in aircraft production during World War II. As well as a novel weight-saving integral design, it also introduced for the first time on a bus independent front suspension, power steering, a fully automatic gearbox, and power-hydraulic braking.\nTypes.\nFormats include single-decker bus, double-decker bus (both usually with a rigid chassis) and articulated bus (or 'bendy-bus') the prevalence of which varies from country to country. High-capacity bi-articulated buses are also manufactured, and passenger-carrying trailers\u2014either towed behind a rigid bus (a bus trailer) or hauled as a trailer by a truck (a trailer bus). Smaller midibuses have a lower capacity and open-top buses are typically used for leisure purposes. In many new fleets, particularly in local transit systems, a shift to low-floor buses is occurring, primarily for easier accessibility. Coaches are designed for longer-distance travel and are typically fitted with individual high-backed reclining seats, seat belts, toilets, and audio-visual entertainment systems, and can operate at higher speeds with more capacity for luggage. Coaches may be single- or double-deckers, articulated, and often include a separate luggage compartment under the passenger floor. Guided buses are fitted with technology to allow them to run in designated guideways, allowing the controlled alignment at bus stops and less space taken up by guided lanes than conventional roads or bus lanes.\nBus manufacturing may be by a single company (an integral manufacturer), or by one manufacturer's building a bus body over a chassis produced by another manufacturer.\nDesign.\nAccessibility.\nTransit buses used to be mainly high-floor vehicles. However, they are now increasingly of low-floor design and optionally also 'kneel' air suspension and have ramps to provide access for wheelchair users and people with baby carriages, sometimes as electrically or hydraulically extended under-floor constructs for level access. Prior to more general use of such technology, these wheelchair users could only use specialist para-transit mobility buses.\nAccessible vehicles also have wider entrances and interior gangways and space for wheelchairs. Interior fittings and destination displays may also be designed to be usable by the visually impaired. Coaches generally use wheelchair lifts instead of low-floor designs. In some countries, vehicles are required to have these features by disability discrimination laws.\nConfiguration.\nBuses were initially configured with an engine in the front and an entrance at the rear. With the transition to one-man operation, many manufacturers moved to mid- or rear-engined designs, with a single door at the front or multiple doors. The move to the low-floor design has all but eliminated the mid-engined design, although some coaches still have mid-mounted engines. Front-engined buses still persist for niche markets such as American school buses, some minibuses, and buses in less developed countries, which may be derived from truck chassis, rather than purpose-built bus designs. Most buses have two axles, while articulated buses have three.\nGuidance.\nGuided buses are fitted with technology to allow them to run in designated guideways, allowing the controlled alignment at bus stops and less space taken up by guided lanes than conventional roads or bus lanes. Guidance can be mechanical, optical, or electromagnetic. Extensions of the guided technology include the Guided Light Transit and Translohr systems, although these are more often termed 'rubber-tyred trams' as they have limited or no mobility away from their guideways.\nLiveries.\nTransit buses are normally painted to identify the operator or a route, function, or to demarcate low-cost or premium service buses. Liveries may be painted onto the vehicle, applied using adhesive vinyl technologies, or using decals. Vehicles often also carry bus advertising or part or all of their visible surfaces (as mobile billboard). Campaign buses may be decorated with key campaign messages; these can be to promote an event or initiative.\nPropulsion.\nThe most common power source since the 1920s has been the diesel engine. Early buses, known as trolleybuses, were powered by electricity supplied from overhead lines. Nowadays, electric buses often carry their own battery, which is sometimes recharged on stops/stations to keep the size of the battery small/lightweight. Currently, interest exists in hybrid electric buses, fuel cell buses, electric buses, and ones powered by compressed natural gas or biodiesel. Gyrobuses, which are powered by the momentum stored by a flywheel, were tried in the 1940s.\nDimensions.\nUnited Kingdom and European Union:\nUnited States, Canada and Mexico:\nManufacture.\nEarly bus manufacturing grew out of carriage coach building, and later out of automobile or truck manufacturers. Early buses were merely a bus body fitted to a truck chassis. This body+chassis approach has continued with modern specialist manufacturers, although there also exist integral designs such as the Leyland National where the two are practically inseparable. Specialist builders also exist and concentrate on building buses for special uses or modifying standard buses into specialised products.\nIntegral designs have the advantages that they have been well-tested for strength and stability, and also are off-the-shelf. However, two incentives cause use of the chassis+body model. First, it allows the buyer and manufacturer both to shop for the best deal for their needs, rather than having to settle on one fixed design\u2014the buyer can choose the body and the chassis separately. Second, over the lifetime of a vehicle (in constant service and heavy traffic), it will likely get minor damage now and again, and being able easily to replace a body panel or window etc. can vastly increase its service life and save the cost and inconvenience of removing it from service.\nAs with the rest of the automotive industry, into the 20th century, bus manufacturing increasingly became globalized, with manufacturers producing buses far from their intended market to exploit labour and material cost advantages. A typical city bus costs almost US$450,000.\nUses.\nPublic transport.\nTransit buses, used on public transport bus services, have utilitarian fittings designed for efficient movement of large numbers of people, and often have multiple doors. Coaches are used for longer-distance routes. High-capacity bus rapid transit services may use the bi-articulated bus or tram-style buses such as the Wright StreetCar and the Irisbus Civis.\nBuses and coach services often operate to a predetermined published public transport timetable defining the route and the timing, but smaller vehicles may be used on more flexible demand responsive transport services.\nTourism.\nBuses play a major part in the tourism industry. Tour buses around the world allow tourists to view local attractions or scenery. These are often open-top buses, but can also be regular buses or coaches.\nIn local sightseeing, City Sightseeing is the largest operator of local tour buses, operating on a franchised basis all over the world. Specialist tour buses are also often owned and operated by safari parks and other theme parks or resorts. Longer-distance tours are also carried out by bus, either on a turn up and go basis or through a tour operator, and usually allow disembarkation from the bus to allow touring of sites of interest on foot. These may be day trips or longer excursions incorporating hotel stays. Tour buses often carry a tour guide, although the driver or a recorded audio commentary may also perform this function. The tour operator may be a subsidiary of a company that operates buses and coaches for other uses or an independent company that charters buses or coaches. Commuter transport operators may also use their coaches to conduct tours within the target city between the morning and evening commuter transport journey.\nBuses and coaches are also a common component of the wider package holiday industry, providing private airport transfers (in addition to general airport buses) and organised tours and day trips for holidaymakers on the package.\nTour buses can also be hired as chartered buses by groups for sightseeing at popular holiday destinations. These private tour buses may offer specific stops, such as all the historical sights, or allow the customers to choose their own itineraries. Tour buses come with professional and informed staff and insurance, and maintain state governed safety standards. Some provide other facilities like entertainment units, luxurious reclining seats, large scenic windows, and even lavatories.\nPublic long-distance coach networks are also often used as a low-cost method of travel by students or young people travelling the world. Some companies such as Topdeck Travel were set up specifically to use buses to drive the hippie trail or travel to places such as North Africa.\nIn many tourist or travel destinations, a bus is part of the tourist attraction, such as the North American tourist trolleys, London's AEC Routemaster heritage routes, or the customised buses of Malta, Asia, and the Americas. Another example of tourist stops is the homes of celebrities, such as tours based near Hollywood. There are several such services between 6000 and 7000 Hollywood Boulevard in Los Angeles.\nStudent transport.\nIn some countries, particularly the US and Canada, buses used to transport schoolchildren have evolved into a specific design with specified mandatory features. American states have also adopted laws regarding motorist conduct around school buses, including large fines and possibly prison for passing a stopped school bus in the process of loading or offloading children passengers. These school buses may have school bus yellow livery and crossing guards. Other countries may mandate the use of seat belts. As a minimum, many countries require a bus carrying students to display a , and may also adopt yellow liveries. Student transport often uses older buses cascaded from service use, retrofitted with more seats or seatbelts. Student transport may be operated by local authorities or private contractors. Schools may also own and operate their own buses for other transport needs, such as class field trips or transport to associated sports, music, or other school events.\nPrivate charter.\nDue to the costs involved in owning, operating, and driving buses and coaches, much bus and coach use comes from the private hire of vehicles from charter bus companies, either for a day or two or on a longer contract basis, where the charter company provides the vehicles and qualified drivers.\nCharter bus operators may be completely independent businesses, or charter hire may be a subsidiary business of a public transport operator that might maintain a separate fleet or use surplus buses, coaches, and dual-purpose coach-seated buses. Many private taxicab companies also operate larger minibus vehicles to cater for group fares. Companies, private groups, and social clubs may hire buses or coaches as a cost-effective method of transporting a group to an event or site, such as a group meeting, racing event, or organised recreational activity such as a summer camp. Schools often hire charter bus services on regular basis for transportation of children to and from their homes. Chartered buses are also used by education institutes for transport to conventions, exhibitions, and field trips. Entertainment or event companies may also hire temporary shuttles buses for transport at events such as festivals or conferences. Party buses are used by companies in a similar manner to limousine hire, for luxury private transport to social events or as a touring experience. Sleeper buses are used by bands or other organisations that tour between entertainment venues and require mobile rest and recreation facilities. Some couples hire preserved buses for their wedding transport, instead of the traditional car. Buses are often hired for parades or processions. Victory parades are often held for triumphant sports teams, who often tour their home town or city in an open-top bus. Sports teams may also contract out their transport to a team bus, for travel to away games, to a competition or to a final event. These buses are often specially decorated in a livery matching the team colours. Private companies often contract out private shuttle bus services, for transport of their customers or patrons, such as hotels, amusement parks, university campuses, or private airport transfer services. This shuttle usage can be as transport between locations, or to and from parking lots. High specification luxury coaches are often chartered by companies for executive or VIP transport. Charter buses may also be used in tourism and for promotion (See Tourism and Promotion sections).\nPrivate ownership.\nMany organisations, including the police, not for profit, social or charitable groups with a regular need for group transport may find it practical or cost-effective to own and operate a bus for their own needs. These are often minibuses for practical, tax and driver licensing reasons, although they can also be full-size buses. Cadet or scout groups or other youth organizations may also own buses. Companies such as railroads, construction contractors, and agricultural firms may own buses to transport employees to and from remote job sites. Specific charities may exist to fund and operate bus transport, usually using specially modified mobility buses or otherwise accessible buses (See Accessibility section). Some use their contributions to buy vehicles and provide volunteer drivers.\nAirport operators make use of special airside airport buses for crew and passenger transport in the secure airside parts of an airport. Some public authorities, police forces, and military forces make use of armoured buses where there is a special need to provide increased passenger protection. The United States Secret Service acquired two in 2010 for transporting dignitaries needing special protection. Police departments make use of police buses for a variety of reasons, such as prisoner transport, officer transport, temporary detention facilities, and as command and control vehicles. Some fire departments also use a converted bus as a command post while those in cold climates might retain a bus as a heated shelter at fire scenes. Many are drawn from retired school or service buses.\nPromotion.\nBuses are often used for advertising, political campaigning, , public relations, or promotional purposes. These may take the form of temporary charter hire of service buses, or the temporary or permanent conversion and operation of buses, usually of second-hand buses. Extreme examples include converting the bus with displays and decorations or awnings and fittings. Interiors may be fitted out for exhibition or information purposes with special equipment or audio visual devices.\nBus advertising takes many forms, often as interior and exterior adverts and all-over advertising liveries. The practice often extends into the exclusive private hire and use of a bus to promote a brand or product, appearing at large public events, or touring busy streets. The bus is sometimes staffed by promotions personnel, giving out free gifts. Campaign buses are often specially decorated for a political campaign or other social awareness information campaign, designed to bring a specific message to different areas, or used to transport campaign personnel to local areas/meetings. Exhibition buses are often sent to public events such as fairs and festivals for purposes such as recruitment campaigns, for example by private companies or the armed forces. Complex urban planning proposals may be organised into a mobile exhibition bus for the purposes of public consultation.\nGoods transport.\nIn some sparsely populated areas, it is common to use brucks, buses with a cargo area to transport both passengers and cargo at the same time. They are especially common in the Nordic countries.\nAround the world.\nHistorically, the types and features of buses have developed according to local needs. Buses were fitted with technology appropriate to the local climate or passenger needs, such as air conditioning in Asia, or cycle mounts on North American buses. The bus types in use around the world where there was little mass production were often sourced secondhand from other countries, such as the Malta bus, and buses in use in Africa. Other countries such as Cuba required novel solutions to import restrictions, with the creation of the \"camellos\" (camel bus), a specially manufactured trailer bus.\nAfter the Second World War, manufacturers in Europe and the Far East, such as Mercedes-Benz buses and Mitsubishi Fuso expanded into other continents influencing the use of buses previously served by local types. Use of buses around the world has also been influenced by colonial associations or political alliances between countries. Several of the Commonwealth nations followed the British lead and sourced buses from British manufacturers, leading to a prevalence of double-decker buses. Several Eastern Bloc countries adopted trolleybus systems, and their manufacturers such as Trolza exported trolleybuses to other friendly states. In the 1930s, Italy designed the world's only triple decker bus for the busy route between Rome and Tivoli that could carry eighty-eight passengers. It was unique not only in being a triple decker but having a separate smoking compartment on the third level.\nThe buses to be found in countries around the world often reflect the quality of the local road network, with high-floor resilient truck-based designs prevalent in several less developed countries where buses are subject to tough operating conditions. Population density also has a major impact, where dense urbanisation such as in Japan and the far east has led to the adoption of high capacity long multi-axle buses, often double-deckers while South America and China are implementing large numbers of articulated buses for bus rapid transit schemes.\nBus expositions.\nEuro Bus Expo is a trade show, which is held biennially at the UK's National Exhibition Centre in Birmingham. As the official show of the Confederation of Passenger Transport, the UK's trade association for the bus, coach and light rail industry, the three-day event offers visitors from Europe and beyond the chance to see and experience the very latest vehicles and product and service innovations right across the industry.\nBusworld Kortrijk in Kortrijk, Belgium, is the leading bus trade fair in Europe. It is also held biennially.\nUse of retired buses.\nMost public or private buses and coaches, once they have reached the end of their service with one or more operators, are sent to the wrecking yard for breaking up for scrap and spare parts. Some buses which are not economical to keep running as service buses are often converted for use other than revenue-earning transport. Much like old cars and trucks, buses often pass through a dealership where they can be bought privately or at auction.\nBus operators often find it economical to convert retired buses to use as permanent training buses for driver training, rather than taking a regular service bus out of use. Some large operators have also converted retired buses into tow bus vehicles, to act as tow trucks. With the outsourcing of maintenance staff and facilities, the increase in company health and safety regulations, and the increasing curb weights of buses, many operators now contract their towing needs to a professional vehicle recovery company.\nSome buses that have reached the end of their service that are still in good condition are sent for export to other countries.\nSome retired buses have been converted to static or mobile caf\u00e9s, often using historic buses as a tourist attraction. There are also catering buses: buses converted into a mobile canteen and break room. These are commonly seen at external filming locations to feed the cast and crew, and at other large events to feed staff. Another use is as an emergency vehicle, such as high-capacity ambulance bus or mobile command centre.\nSome organisations adapt and operate playbuses or learning buses to provide a playground or learning environments to children who might not have access to proper play areas. An ex-London AEC Routemaster bus has been converted to a mobile theatre and catwalk fashion show.\nSome buses meet a destructive end by being entered in banger races or at demolition derbies. A larger number of old retired buses have also been converted into mobile holiday homes and campers.\nBus preservation.\nRather than being scrapped or converted for other uses, sometimes retired buses are saved for preservation. This can be done by individuals, volunteer preservation groups or charitable trusts, museums, or sometimes by the operators themselves as part of a heritage fleet. These buses often need to be restored to their original condition and will have their livery and other details such as internal notices and rollsigns restored to be authentic to a specific time in the bus's history. Some buses that undergo preservation are rescued from a state of great disrepair, but others enter preservation with very little wrong with them. As with other historic vehicles, many preserved buses either in a working or static state form part of the collections of transport museums. Additionally, some buses are preserved so they can appear alongside other period vehicles in television and film. Working buses will often be exhibited at rallies and events, and they are also used as charter buses. While many preserved buses are quite old or even vintage, in some cases relatively new examples of a bus type can enter restoration. In-service examples are still in use by other operators. This often happens when a change in design or operating practice, such as the switch to one person operation or low floor technology, renders some buses redundant while still relatively new."}
{"id": "4147", "revid": "48546149", "url": "https://en.wikipedia.org/wiki?curid=4147", "title": "Bali", "text": " \nBali (; ) is a province of Indonesia and the westernmost of the Lesser Sunda Islands. East of Java and west of Lombok, the province includes the island of Bali and a few smaller offshore islands, notably Nusa Penida, Nusa Lembongan, and Nusa Ceningan to the southeast. The provincial capital, Denpasar, is the most populous city in the Lesser Sunda Islands and the second-largest, after Makassar, in Eastern Indonesia. Denpasar metropolitan area is the extended metropolitan area around Denpasar. The upland town of Ubud in Greater Denpasar is considered Bali's cultural centre. The province is Indonesia's main tourist destination, with a significant rise in tourism since the 1980s, and becoming an Indonesian area of overtourism. Tourism-related business makes up 80% of the Bali economy.\nBali is the only Hindu-majority province in Indonesia, with 86.9% of the population adhering to Balinese Hinduism. It is renowned for its highly developed arts, including traditional and modern dance, sculpture, painting, leather, metalworking, and music. The Indonesian International Film Festival is held every year in Bali. Other international events that have been held in Bali include Miss World 2013, the 2018 Annual Meetings of the International Monetary Fund and the World Bank Group and the 2022 G20 summit. In March 2017, TripAdvisor named Bali as the world's top destination in its Traveller's Choice award, which it also earned in January 2021.\nBali is part of the Coral Triangle, the area with the highest biodiversity of marine species, especially fish and turtles. In this area alone, over 500 reef-building coral species can be found. For comparison, this is about seven times as many as in the entire Caribbean. Bali is the home of the Subak irrigation system, a UNESCO World Heritage Site. It is also home to a unified confederation of kingdoms composed of 10 traditional royal Balinese houses, each house ruling a specific geographic area. The confederation is the successor of the Bali Kingdom. The royal houses, which originated before Dutch colonisation, are not recognised by the government of Indonesia.\nHistory.\nAncient.\nBali was inhabited around 2000 BC by Austronesian people who migrated originally from the island of Taiwan to Southeast Asia and Oceania through Maritime Southeast Asia. Culturally and linguistically, the Balinese are closely related to the people of the Indonesian archipelago, Malaysia, Brunei, the Philippines, and Oceania. Stone tools dating from this time have been found near the village of Cekik in the island's west.\nIn ancient Bali, nine Hindu sects existed, the Pasupata, Bhairawa, Siwa Shidanta, Vaishnava, Bodha, Brahma, Resi, Sora and Ganapatya. Each sect revered a specific deity as its personal Godhead.\nInscriptions from 896 and 911 do not mention a king, until 914, when Sri Kesarivarma is mentioned. They also reveal an independent Bali, with a distinct dialect, where Buddhism and Shaivism were practised simultaneously. Mpu Sindok's great-granddaughter, Mahendradatta (Gunapriyadharmapatni), married the Bali king Udayana Warmadewa (Dharmodayanavarmadeva) around 989, giving birth to Airlangga around 1001. This marriage also brought more Hinduism and Javanese culture to Bali. Princess Sakalendukirana appeared in 1098. Suradhipa reigned from 1115 to 1119, and Jayasakti from 1146 until 1150. Jayapangus appears on inscriptions between 1178 and 1181, while Adikuntiketana and his son Paramesvara in 1204.\nBalinese culture was strongly influenced by Indian, Chinese, and particularly Hindu culture, beginning around the 1st century AD. The name \"Bali dwipa\" (\"Bali island\") has been discovered from various inscriptions, including the Blanjong pillar inscription written by Sri Kesari Warmadewa in 914 AD and mentioning Walidwipa. It was during this time that the people developed their complex irrigation system \"subak\" to grow rice in wet-field cultivation. Some religious and cultural traditions still practised today can be traced to this period.\nThe Hindu-Buddhist Majapahit Empire (1293\u20131520 AD) on eastern Java founded a Balinese colony in 1343. The uncle of Hayam Wuruk is mentioned in the charters of 1384\u201386. Mass Javanese immigration to Bali occurred in the next century when the Majapahit Empire fell in 1520. Bali's government then became an independent collection of Hindu kingdoms which led to a Balinese national identity and major enhancements in culture, arts, and economy. The nation with various kingdoms became independent for up to 386 years until 1906 when the Dutch subjugated and repulsed the natives for economic control and took it over.\nPortuguese contacts.\nThe first known European contact with Bali is thought to have been made in 1512, when a Portuguese expedition led by Antonio Abreu and Francisco Serr\u00e3o sighted its northern shores. It was the first expedition of a series of bi-annual fleets to the Moluccas, that throughout the 16th century travelled along the coasts of the Sunda Islands. Bali was also mapped in 1512, in the chart of Francisco Rodrigues, aboard the expedition. In 1585, a ship foundered off the Bukit Peninsula and left a few Portuguese in the service of Dewa Agung.\nDutch East Indies.\nIn 1597, the Dutch merchant-explorer Cornelis de Houtman arrived at Bali, and the Dutch East India Company was established in 1602. The Dutch government expanded its control across the Indonesian archipelago during the second half of the 19th century. Dutch political and economic control over Bali began in the 1840s on the island's north coast when the Dutch pitted various competing Balinese realms against each other. In the late 1890s, struggles between Balinese kingdoms on the island's south were exploited by the Dutch to increase their control.\nIn June 1860, the famous Welsh naturalist, Alfred Russel Wallace, travelled to Bali from Singapore, landing at Buleleng on the north coast of the island. Wallace's trip to Bali was instrumental in helping him devise his Wallace Line theory. The Wallace Line is a faunal boundary that runs through the strait between Bali and Lombok. It is a boundary between species. In his travel memoir \"The Malay Archipelago,\" Wallace wrote of his experience in Bali, which has a strong mention of the unique Balinese irrigation methods:\nI was astonished and delighted; as my visit to Java was some years later, I had never beheld so beautiful and well-cultivated a district out of Europe. A slightly undulating plain extends from the seacoast about inland, where it is bounded by a fine range of wooded and cultivated hills. Houses and villages, marked out by dense clumps of coconut palms, tamarind and other fruit trees, are dotted about in every direction; while between them extend luxurious rice grounds, watered by an elaborate system of irrigation that would be the pride of the best-cultivated parts of Europe. \nThe Dutch mounted large naval and ground assaults at the Sanur region in 1906 and were met by the thousands of members of the royal family and their followers who rather than yield to the superior Dutch force committed ritual suicide (\"puputan\") to avoid the humiliation of surrender. Despite Dutch demands for surrender, an estimated 200 Balinese killed themselves rather than surrender. In the Dutch intervention in Bali, a similar mass suicide occurred in the face of a Dutch assault in Klungkung. Afterwards, the Dutch governours exercised administrative control over the island, but local control over religion and culture generally remained intact. Dutch rule over Bali came later and was never as well established as in other parts of Indonesia such as Java and Maluku.\nIn the 1930s, anthropologists Margaret Mead and Gregory Bateson, artists Miguel Covarrubias and Walter Spies, and musicologist Colin McPhee all spent time here. Their accounts of the island and its peoples created a western image of Bali as \"an enchanted land of aesthetes at peace with themselves and nature\". Western tourists began to visit the island. The sensuous image of Bali was enhanced in the West by a quasi-pornographic 1932 documentary \"Virgins of Bali\" about a day in the lives of two teenage Balinese girls whom the film's narrator Deane Dickason notes in the first scene \"bathe their shamelessly nude bronze bodies\". Under the looser version of the Hays code that existed up to 1934, nudity involving \"civilised\" (i.e. white) women was banned, but permitted with \"uncivilised\" (i.e. all non-white women), a loophole that was exploited by the producers of \"Virgins of Bali\". The film, which mostly consisted of scenes of topless Balinese women was a great success in 1932, and almost single-handedly made Bali into a popular spot for tourists.\nImperial Japan occupied Bali during World War II. It was not originally a target in their Netherlands East Indies Campaign, but as the airfields on Borneo were inoperative due to heavy rains, the Imperial Japanese Army decided to occupy Bali, which did not suffer from comparable weather. The island had no regular Royal Netherlands East Indies Army (KNIL) troops. There was only a Native Auxiliary Corps \"Prajoda\" (Korps Prajoda) consisting of about 600 native soldiers and several Dutch KNIL officers under the command of KNIL Lieutenant Colonel W.P. Roodenburg. On 19 February 1942, the Japanese forces landed near the town of Sanoer (Sanur). The island was quickly captured.\nDuring the Japanese occupation, a Balinese military officer, I Gusti Ngurah Rai, formed a Balinese 'freedom army'. The harshness of Japanese occupation forces made them more resented than the Dutch colonial rulers.\nIndependence from the Dutch.\nIn 1945, Bali was liberated by the British 5th infantry Division under the command of Major-General Robert Mansergh who took the Japanese surrender. Once Japanese forces had been repatriated the island was handed over to the Dutch the following year.\nIn 1946, the Dutch constituted Bali as one of the 13 administrative districts of the newly proclaimed State of East Indonesia, a rival state to the Republic of Indonesia, which was proclaimed and headed by Sukarno and Hatta. Bali was included in the \"Republic of the United States of Indonesia\" when the Netherlands recognised Indonesian independence on 29 December 1949. The first governor of Bali, Anak Agung Bagus Suteja, was appointed by President Sukarno in 1958, when Bali became a province.\nContemporary.\nThe 1963 eruption of Mount Agung killed thousands, created economic havoc, and forced many displaced Balinese to be transmigrated to other parts of Indonesia. Mirroring the widening of social divisions across Indonesia in the 1950s and early 1960s, Bali saw conflict between supporters of the traditional caste system, and those rejecting this system. Politically, the opposition was represented by supporters of the Indonesian Communist Party (PKI) and the Indonesian Nationalist Party (PNI), with tensions and ill-feeling further increased by the PKI's land reform programmes. A purported coup attempt in Jakarta was averted by forces led by General Suharto.\nThe army became the dominant power as it instigated a violent anti-communist purge, in which the army blamed the PKI for the coup. Most estimates suggest that at least 500,000 people were killed across Indonesia, with an estimated 80,000 killed in Bali, equivalent to 5% of the island's population. With no Islamic forces involved as in Java and Sumatra, upper-caste PNI landlords led the extermination of PKI members.\nAs a result of the 1965\u201366 upheavals, Suharto was able to manoeuvre Sukarno out of the presidency. His \"New Order\" government re-established relations with Western countries. The pre-War Bali as \"paradise\" was revived in a modern form. The resulting large growth in tourism has led to a dramatic increase in Balinese standards of living and significant foreign exchange earned for the country.\nA bombing in 2002 by militant Islamists in the tourist area of Kuta killed 202 people, mostly foreigners. This attack, and another in 2005, severely reduced tourism, producing much economic hardship on the island.\nOn 27 November 2017, Mount Agung erupted five times, causing the evacuation of thousands, disrupting air travel and causing much environmental damage. Further eruptions also occurred between 2018 and 2019.\nOn 15\u201316 November 2022, the 2022 G20 Bali summit, the seventeenth meeting of the Group of Twenty (G20) was held in Nusa Dua.\nGeography.\nThe island of Bali lies east of Java, and is approximately 8 degrees south of the equator. Bali and Java are separated by the Bali Strait. East to west, the island is approximately wide and spans approximately north to south; administratively it covers , or excluding offshore Nusa Penida District, which comprises three small islands off the southeast coast of Bali. Its population density was roughly in mid 2023.\nBali's central mountains include several peaks over in elevation and active volcanoes such as Mount Batur. The highest is Mount Agung (), known as the \"mother mountain\", which is an active volcano rated as one of the world's most likely sites for a massive eruption within the next 100 years. In late 2017 Mount Agung started erupting and large numbers of people were evacuated, temporarily closing the island's airport. Mountains range from centre to the eastern side, with Mount Agung the easternmost peak. Bali's volcanic nature has contributed to its exceptional fertility and its tall mountain ranges provide the high rainfall that supports the highly productive agriculture sector. South of the mountains is a broad, steadily descending area where most of Bali's large rice crop is grown. The northern side of the mountains slopes more steeply to the sea and is the main coffee-producing area of the island, along with rice, vegetables, and cattle. The longest river, Ayung River, flows approximately (see List of rivers of Bali).\nThe island is surrounded by coral reefs. Beaches in the south tend to have white sand while those in the north and west have black sand. Bali has no major waterways, although the Ho River is navigable by small \"sampan\" boats. Black sand beaches between Pasut and Klatingdukuh are being developed for tourism, but apart from the seaside temple of Tanah Lot, they are not yet used for significant tourism.\nThe largest city is the provincial capital, Denpasar, near the southern coast. Its population is around 748,400 (mid 2023). Bali's second-largest city is the old colonial capital, Singaraja, which is located on the north coast and is home to around 150,000 people in 2020. Other important cities include the beach resort, Kuta, which is practically part of Denpasar's urban area, and Ubud, situated at the north of Denpasar, is the island's cultural centre.\nThree small islands lie to the immediate south-east and all are administratively part of the Klungkung regency of Bali: Nusa Penida, Nusa Lembongan and Nusa Ceningan. These islands are separated from Bali by the Badung Strait.\nTo the east, the Lombok Strait separates Bali from Lombok and marks the biogeographical division between the fauna of the Indomalayan realm and the distinctly different fauna of Australasia. The transition is known as the Wallace Line, named after Alfred Russel Wallace, who first proposed a transition zone between these two major biomes. When sea levels dropped during the Pleistocene ice age, Bali was connected to Java and Sumatra and to the mainland of Asia and shared the Asian fauna, but the deep water of the Lombok Strait continued to keep Lombok Island and the Lesser Sunda archipelago isolated.\nClimate.\nBeing just 8 degrees south of the equator, Bali has a fairly even climate all year round. Average year-round temperature stands at around with a humidity level of about 85%.\nDaytime temperatures at low elevations vary between , but the temperatures decrease significantly with increasing elevation.\nThe west monsoon is in place from approximately October to April, and this can bring significant rain, particularly from December to March. During the rainy season, there are comparatively fewer tourists seen in Bali. During the Easter and Christmas holidays, the weather is very unpredictable. Outside of the monsoon period, humidity is relatively low and any rain is unlikely in lowland areas.\nFlora and Fauna.\nBali lies just to the west of the Wallace Line, and thus has a fauna that is Asian in character, with very little Australasian influence, and has more in common with Java than with Lombok. An exception is the yellow-crested cockatoo, a member of a primarily Australasian family. There are around 280 species of birds, including the critically endangered Bali myna, which is endemic. Others include barn swallow, black-naped oriole, black racket-tailed treepie, crested serpent-eagle, crested treeswift, dollarbird, Java sparrow, lesser adjutant, long-tailed shrike, milky stork, Pacific swallow, red-rumped swallow, sacred kingfisher, sea eagle, woodswallow, savanna nightjar, stork-billed kingfisher, yellow-vented bulbul and great egret.\nUntil the early 20th century, Bali was possibly home to several large mammals: banteng, leopard and the endemic Bali tiger. The banteng still occurs in its domestic form, whereas leopards are found only in neighbouring Java, and the Bali tiger is extinct. The last definite record of a tiger on Bali dates from 1937 when one was shot, though the subspecies may have survived until the 1940s or 1950s. Pleistocene and Holocene megafaunas include banteng and giant tapir (based on speculations that they might have reached up to the Wallace Line), and rhinoceros.\nSquirrels are quite commonly encountered, less often is the Asian palm civet, which is also kept in coffee farms to produce kopi luwak. Bats are well represented, perhaps the most famous place to encounter them remaining is the Goa Lawah (Temple of the Bats) where they are worshipped by the locals and also constitute a tourist attraction. They also occur in other cave temples, for instance at Gangga Beach. Two species of monkey occur. The crab-eating macaque, known locally as \"kera\", is quite common around human settlements and temples, where it becomes accustomed to being fed by humans, particularly in any of the three \"monkey forest\" temples, such as the popular one in the Ubud area. They are also quite often kept as pets by locals. The second monkey, endemic to Java and some surrounding islands such as Bali, is far rarer and more elusive and is the Javan langur, locally known as \"lutung\". They occur in a few places apart from the West Bali National Park. They are born an orange colour, though they would have already changed to a more blackish colouration by their first year. In Java, however, there is more of a tendency for this species to retain its juvenile orange colour into adulthood, and a mixture of black and orange monkeys can be seen together as a family. Other rarer mammals include the Sunda leopard cat, Sunda pangolin and black giant squirrel. Snakes include the king cobra and reticulated python. The water monitor can grow to at least in length and and can move quickly.\nThe rich coral reefs around the coast, particularly around popular diving spots such as Tulamben, Amed, Menjangan or neighbouring Nusa Penida, host a wide range of marine life, for instance hawksbill turtle, giant sunfish, giant manta ray, giant moray eel, bumphead parrotfish, hammerhead shark, reef shark, barracuda, and sea snakes. Dolphins are commonly encountered on the north coast near Singaraja and Lovina.\nA team of scientists surveyed from 29 April 2011, to 11 May 2011, at 33 sea sites around Bali. They discovered 952 species of reef fish of which 8 were new discoveries at Pemuteran, Gilimanuk, Nusa Dua, Tulamben and Candidasa, and 393 coral species, including two new ones at Padangbai and between Padangbai and Amed. The average coverage level of healthy coral was 36% (better than in Raja Ampat and Halmahera by 29% or in Fakfak and Kaimana by 25%) with the highest coverage found in Gili Selang and Gili Mimpang in Candidasa, Karangasem Regency. Among the larger trees the most common are: banyan trees, jackfruit, coconuts, bamboo species, acacia trees and also endless rows of coconuts and banana species. Numerous flowers can be seen: hibiscus, frangipani, bougainvillea, poinsettia, oleander, jasmine, water lily, lotus, roses, begonias, orchids and hydrangeas exist. On higher grounds that receive more moisture, for instance, around Kintamani, certain species of fern trees, mushrooms and even pine trees thrive well. Rice comes in many varieties. Other plants with agricultural value include: salak, mangosteen, corn, Kintamani orange, coffee and water spinach.\nEnvironment.\nOver-exploitation by the tourist industry has led to 200 out of 400 rivers on the island drying up. Research suggests that the southern part of Bali would face a water shortage. To ease the shortage, the central government plans to build a water catchment and processing facility at Petanu River in Gianyar. The 300 litres capacity of water per second will be channelled to Denpasar, Badung and Gianyar in 2013.\nA 2010 Environment Ministry report on its environmental quality index gave Bali a score of 99.65, which was the highest score of Indonesia's 33 provinces. The score considers the level of total suspended solids, dissolved oxygen, and chemical oxygen demand in water.\nErosion at Lebih Beach has seen of land lost every year. Decades ago, this beach was used for holy pilgrimages with more than 10,000 people, but they have now moved to Masceti Beach.\nIn 2017, a year when Bali received nearly 5.7\u00a0million tourists, government officials declared a \"garbage emergency\" in response to the covering of 3.6-mile stretch of coastline in plastic waste brought in by the tide, amid concerns that the pollution could dissuade visitors from returning. Indonesia is one of the world's worst plastic polluters, with some estimates suggesting the country is the source of around 10 per cent of the world's plastic waste.\nGovernment.\nPolitics.\nIn the national legislature, Bali is represented by nine members, with a single electoral district covering the whole province. The Bali Regional People's Representative Council, the provincial legislature, has 55 members. The province's politics has historically been dominated by the Indonesian Democratic Party of Struggle (PDI-P), which has won by far the most votes in every election in Bali since the first free elections in 1999.\nAdministrative divisions.\nThe province is divided into eight regencies (\"kabupaten\") and one city (\"kota\"); all the regencies were originally inaugurated on 9 August 1958, while the city of Denpasar were created from part of Badung Regency on 15 January 1992. They are tabulated below with their areas and their populations at the 2010 census and the 2020 census, together with the official estimates as at mid 2023 and the Human Development Index for each regency and city.\nThe province forms one of Indonesia's 84 national electoral districts to elect members to the People's Representative Council. The Bali Electoral District consists of all of the 8 regencies in the province, together with the city of Denpasar, and elects 9 members to the People's Representative Council.\nEconomy.\nIn the 1970s, the Balinese economy was largely agriculture-based in terms of both output and employment. Tourism is now the largest single industry in terms of income, and as a result, Bali is one of Indonesia's wealthiest regions. In 2003, around 80% of Bali's economy was tourism related. By the end of June 2011, the rate of non-performing loans of all banks in Bali were 2.23%, lower than the average of Indonesian banking industry non-performing loan rates (about 5%). The economy, however, suffered significantly as a result of the terrorist bombings in 2002 and 2005. The tourism industry has since recovered from these events.\nAgriculture.\nAlthough tourism produces the GDP's largest output, agriculture is still the island's biggest employer. Fishing also provides a significant number of jobs. Bali is also famous for its artisans who produce a vast array of handicrafts, including batik and ikat cloth and clothing, wooden carvings, stone carvings, painted art and silverware. Notably, individual villages typically adopt a single product, such as wind chimes or wooden furniture.\nThe Arabica coffee production region is the highland region of Kintamani near Mount Batur. Generally, Balinese coffee is processed using the wet method. This results in a sweet, soft coffee with good consistency. Typical flavours include lemon and other citrus notes. Many coffee farmers in Kintamani are members of a traditional farming system called Subak Abian, which is based on the Hindu philosophy of \"Tri Hita Karana\". According to this philosophy, the three causes of happiness are good relations with God, other people, and the environment. The Subak Abian system is ideally suited to the production of fair trade and organic coffee production. Arabica coffee from Kintamani is the first product in Indonesia to request a geographical indication.\nTourism.\nIn 1963 the Bali Beach Hotel in Sanur was built by Sukarno and boosted tourism in Bali. Before the Bali Beach Hotel construction, there were only three significant tourist-class hotels on the island. Construction of hotels and restaurants began to spread throughout Bali. Tourism further increased in Bali after the Ngurah Rai International Airport opened in 1970. The Buleleng regency government encouraged the tourism sector as one of the mainstays for economic progress and social welfare.\nThe tourism industry is primarily focused in the south, while also significant in the other parts of the island. The prominent tourist locations are the town of Kuta (with its beach), and its outer suburbs of Legian and Seminyak (which were once independent townships), the east coast town of Sanur (once the only tourist hub), Ubud towards the centre of the island, to the south of the Ngurah Rai International Airport, Jimbaran and the newer developments of Nusa Dua and Pecatu.\nThe United States government lifted its travel warnings in 2008. The Australian government issued an advisory on Friday, 4 May 2012, with the overall level of this advisory lowered to 'Exercise a high degree of caution'. The Swedish government issued a new warning on Sunday, 10 June 2012, because of one tourist who died from methanol poisoning. Australia last issued an advisory on Monday, 5 January 2015, due to new terrorist threats.\nAn offshoot of tourism is the growing real estate industry. Bali's real estate has been rapidly developing in the main tourist areas of Kuta, Legian, Seminyak, and Oberoi. Most recently, high-end 5-star projects are under development on the Bukit peninsula, on the island's south side. Expensive villas are being developed along the cliff sides of south Bali, with commanding panoramic ocean views. Foreign and domestic, many Jakarta individuals and companies are fairly active, and investment into other areas of the island also continues to grow. Land prices, despite the worldwide economic crisis, have remained stable.\nIn the last half of 2008, Indonesia's currency had dropped approximately 30% against the US dollar, providing many overseas visitors with improved value for their currencies.\nBali's tourism economy survived the Islamist terrorist bombings of 2002 and 2005, and the tourism industry has slowly recovered and surpassed its pre-terrorist bombing levels; the long-term trend has been a steady increase in visitor arrivals. In 2010, Bali received 2.57\u00a0million foreign tourists, which surpassed the target of 2.0\u20132.3\u00a0million tourists. The average occupancy of starred hotels achieved 65%, so the island still should be able to accommodate tourists for some years without any addition of new rooms/hotels, although at the peak season some of them are fully booked.\nBali received the Best Island award from Travel and Leisure in 2010. Bali won because of its attractive surroundings (both mountain and coastal areas), diverse tourist attractions, excellent international and local restaurants, and the friendliness of the local people. The Balinese culture and its religion are also considered the main factor of the award. One of the most prestigious events that symbolize a strong relationship between a god and its followers is Kecak dance. According to BBC Travel released in 2011, Bali is one of the World's Best Islands, ranking second after Santorini, Greece.\nIn 2006, Elizabeth Gilbert's memoir \"Eat, Pray, Love\" was published, and in August 2010 it was adapted into the film \"Eat Pray Love\". It took place at Ubud and Padang-Padang Beach in Bali. Both the book and the film fuelled a boom in tourism in Ubud, the hill town and cultural and tourist centre that was the focus of Gilbert's quest for balance and love through traditional spirituality and healing.\nIn January 2016, after musician David Bowie died, it was revealed that in his will, Bowie asked for his ashes to be scattered in Bali, conforming to Buddhist rituals. He had visited and performed in several Southeast Asian cities early in his career, including Bangkok and Singapore.\nSince 2011, China has displaced Japan as the second-largest supplier of tourists to Bali, while Australia still tops the list while India has also emerged as a greater supply of tourists.\nChinese tourists increased by 17% in 2011 from 2010 due to the impact of ACFTA and new direct flights to Bali.\nIn January 2012, Chinese tourists increased by 222.18% compared to January 2011, while Japanese tourists declined by 23.54% year on year.\nBali authorities reported the island had 2.88\u00a0million foreign tourists and 5\u00a0million domestic tourists in 2012, marginally surpassing the expectations of 2.8\u00a0million foreign tourists.\nBased on a Bank Indonesia survey in May 2013, 34.39 per cent of tourists are upper-middle class, spending between $1,286 and $5,592, and are dominated by Australia, India, France, China, Germany and the UK. Some Chinese tourists have increased their levels of spending from previous years. 30.26 per cent of tourists are middle class, spending between $662 and $1,285. In 2017 it was expected that Chinese tourists would outnumber Australian tourists.\nIn January 2020, 10,000 Chinese tourists cancelled trips to Bali due to the COVID-19 pandemic. Because of the COVID-19 pandemic travel restrictions, Bali welcomed 1.07\u00a0million international travelers in 2020, most of them between January and March, which is -87% compared to 2019. In the first half of 2021, they welcomed 43 international travelers. The pandemic presented a major blow on Bali's tourism-dependent economy. On 3 February 2022, Bali reopened again for the first foreign tourists after 2 years of being closed due to the pandemic.\nIn 2022 Indonesia's Minister of Health, Budi Sadikin, stated that the tourism industry in Bali will be complemented by the medical industry.\nAt the beginning of 2023, the governor of Bali demanded a ban on the use of motorcycles by tourists. This happened after a series of accidents. Wayan Koster proposed to cancel the violators' visas. The move sparked widespread outrage on social media.\nTransportation.\nThe Ngurah Rai International Airport is located near Jimbaran, on the isthmus at the southernmost part of the island. Lt. Col. Wisnu Airfield is in northwest Bali.\nA coastal road circles the island, and three major two-lane arteries cross the central mountains at passes reaching 1,750\u00a0m in height (at Penelokan). The Ngurah Rai Bypass is a four-lane expressway that partly encircles Denpasar. Bali has no railway lines. There is a car ferry between Gilimanuk on the west coast of Bali to Ketapang on Java.\nIn December 2010 the Government of Indonesia invited investors to build a new Tanah Ampo Cruise Terminal at Karangasem, Bali with a projected worth of $30\u00a0million. On 17 July 2011, the first cruise ship (Sun Princess) anchored about away from the wharf of Tanah Ampo harbour. The current pier is only but will eventually be extended to to accommodate international cruise ships. The harbour is safer than the existing facility at Benoa and has a scenic backdrop of east Bali mountains and green rice fields. The tender for improvement was subject to delays, and as of July 2013 the situation was unclear with cruise line operators complaining and even refusing to use the existing facility at Tanah Ampo.\nA memorandum of understanding was signed by two ministers, Bali's governor and Indonesian Train Company to build of railway along the coast around the island. As of July 2015, no details of these proposed railways have been released. In 2019 it was reported in \"Gapura Bali\" that Wayan Koster, governor of Bali, \"is keen to improve Bali's transportation infrastructure and is considering plans to build an electric rail network across the island\".\nOn 16 March 2011 (Tanjung) Benoa port received the \"Best Port Welcome 2010\" award from London's \"Dream World Cruise Destination\" magazine. Government plans to expand the role of Benoa port as export-import port to boost Bali's trade and industry sector. In 2013, The Tourism and Creative Economy Ministry advised that 306 cruise liners were scheduled to visit Indonesia, an increase of 43 per cent compared to the previous year.\nIn May 2011, an integrated Area Traffic Control System (ATCS) was implemented to reduce traffic jams at four crossing points: Ngurah Rai statue, Dewa Ruci Kuta crossing, Jimbaran crossing and Sanur crossing. ATCS is an integrated system connecting all traffic lights, CCTVs and other traffic signals with a monitoring office at the police headquarters. It has successfully been implemented in other ASEAN countries and will be implemented at other crossings in Bali.\nOn 21 December 2011, construction started on the Nusa Dua-Benoa-Ngurah Rai International Airport toll road, which will also provide a special lane for motorcycles. This has been done by seven state-owned enterprises led by PT Jasa Marga with 60% of the shares. PT Jasa Marga Bali Tol will construct the toll road (totally with access road). The construction is estimated to cost Rp.2.49\u00a0trillion ($273.9\u00a0million). The project goes through of mangrove forest and through of beach, both within area. The elevated toll road is built over the mangrove forest on 18,000 concrete pillars that occupied two hectares of mangrove forest. This was compensated by the planting of 300,000 mangrove trees along the road. On 21 December 2011, the Dewa Ruci underpass has also started on the busy Dewa Ruci junction near Bali Kuta Galeria with an estimated cost of Rp136\u00a0billion ($14.9\u00a0million) from the state budget. On 23 September 2013, the Bali Mandara Toll Road was opened, with the Dewa Ruci Junction underpass being opened previously.\nTo solve chronic traffic problems, the province will also build a toll road connecting Serangan with Tohpati, a toll road connecting Kuta, Denpasar, and Tohpati, and a flyover connecting Kuta and Ngurah Rai Airport.\nDemographics.\nThe population of Bali was 3,890,757 as of the 2010 census, and 4,317,404 at the 2020 census; the official estimate as at mid 2023 was 4,404,300. In 2021, the Indonesian Ministry of Justice estimated that there were 109,801 foreigners living on Bali, with most originating from Russia, the US, Australia, the UK, Germany, Japan, France, Italy, and the Netherlands.\nEthnic origins.\nA DNA study in 2005 by Karafet et al. found that 12% of Balinese Y-chromosomes are of likely Austroasiasic origin, while 84% are of likely Austronesian origin, and 2% of likely Melanesian origin.\nCaste system.\nPre-modern Bali had four castes, as Jeff Lewis and Belinda Lewis state, but with a \"very strong tradition of communal decision-making and interdependence\". The four castes have been classified as Sudra (Shudra), Wesia (Vaishyas), Satria (Kshatriyas) and Brahmana (Brahmin).\nThe 19th-century scholars such as Crawfurd and Friederich suggested that the Balinese caste system had Indian origins, but Helen Creese states that scholars such as Brumund who had visited and stayed on the island of Bali suggested that his field observations conflicted with the \"received understandings concerning its Indian origins\". In Bali, the Shudra (locally spelt \"Soedra\") has typically been the temple priests, though depending on the demographics, a temple priest may also be from the other three castes. In most regions, it has been the Shudra who typically make offerings to the gods on behalf of the Hindu devotees, chant prayers, recite \"meweda\" (Vedas), and set the course of Balinese temple festivals.\nReligion.\nAbout 87.91% of Bali's population adheres to Balinese Hinduism, formed as a combination of existing local beliefs and Hindu influences from mainland Southeast Asia and South Asia. Minority religions include Islam (8.10%), Christianity (3.30%), and Buddhism (0.68%) as for 2022.\nThe general beliefs and practices of \"Agama Hindu Dharma\" mix ancient traditions and contemporary pressures placed by Indonesian laws that permit only monotheist belief under the national ideology of \"Pancasila\". Traditionally, Hinduism in Indonesia had a pantheon of deities and that tradition of belief continues in practice; further, Hinduism in Indonesia granted freedom and flexibility to Hindus as to when, how and where to pray. However, officially, the Indonesian government considers and advertises Indonesian Hinduism as a monotheistic religion with certain officially recognised beliefs that comply with its national ideology. Indonesian school textbooks describe Hinduism as having one supreme being, Hindus offering three daily mandatory prayers, and Hinduism as having certain common beliefs that in part parallel those of Islam. Some scholars contest whether these Indonesian government recognised and assigned beliefs to reflect the traditional beliefs and practices of Hindus in Indonesia before Indonesia gained independence from Dutch colonial rule.\nBalinese Hinduism has roots in Indian Hinduism and Buddhism, which arrived through Java. Hindu influences reached the Indonesian Archipelago as early as the first century. Historical evidence is unclear about the diffusion process of cultural and spiritual ideas from India. Java legends refer to Saka-era, traced to 78 AD. Stories from the Mahabharata Epic have been traced in Indonesian islands to the 1st century; however, the versions mirror those found in the southeast Indian peninsular region (now Tamil Nadu and southern Karnataka and Andhra Pradesh).\nThe Bali tradition adopted the pre-existing animistic traditions of the indigenous people. This influence strengthened the belief that the gods and goddesses are present in all things. Every element of nature, therefore, possesses its power, which reflects the power of the gods. A rock, tree, dagger, or woven cloth is a potential home for spirits whose energy can be directed for good or evil. Balinese Hinduism is deeply interwoven with art and ritual. Ritualising states of self-control are a notable feature of religious expression among the people, who for this reason have become famous for their graceful and decorous behaviour.\nApart from the majority of Balinese Hindus, there also exist Chinese immigrants whose traditions have melded with that of the locals. As a result, these Sino-Balinese embrace their original religion, which is a mixture of Buddhism, Christianity, Taoism, and Confucianism, and find a way to harmonise it with the local traditions. Hence, it is not uncommon to find local Sino-Balinese during the local temple's \"odalan\". Moreover, Balinese Hindu priests are invited to perform rites alongside a Chinese priest in the event of the death of a Sino-Balinese. Nevertheless, the Sino-Balinese claim to embrace Buddhism for administrative purposes, such as their Identity Cards. The Roman Catholic community has a diocese, the Diocese of Denpasar that encompasses the province of Bali and West Nusa Tenggara and has its cathedral located in Denpasar.\nLanguage.\nBalinese and Indonesian are the most widely spoken languages in Bali, and the vast majority of Balinese people are bilingual or trilingual. The most common spoken language around the tourist areas is Indonesian, as many people in the tourist sector are not solely Balinese, but migrants from Java, Lombok, Sumatra, and other parts of Indonesia. The Balinese language is heavily stratified due to the Balinese caste system. Kawi and Sanskrit are also commonly used by some Hindu priests in Bali, as Hindu literature was mostly written in Sanskrit.\nEnglish and Chinese are the next most common languages (and the primary foreign languages) of many Balinese, owing to the requirements of the tourism industry, as well as the English-speaking community and huge Chinese-Indonesian population. Other foreign languages, such as Japanese, Korean, French, Russian or German are often used in multilingual signs for foreign tourists.\nCulture.\n \nBali is renowned for its diverse and sophisticated art forms, such as painting, sculpture, woodcarving, handcrafts, and performing arts. Balinese cuisine is also distinctive, and unlike the rest of Indonesia, pork is commonly found in Balinese dishes such as Babi Guling. Balinese percussion orchestra music, known as \"gamelan\", is highly developed and varied. Balinese performing arts often portray stories from Hindu epics such as the Ramayana but with heavy Balinese influence. Famous Balinese dances include \"pendet\", \"legong\", \"baris\", \"topeng\", \"barong\", \"gong keybar\", and \"kecak\" (the monkey dance). Bali boasts one of the most diverse and innovative performing arts cultures in the world, with paid performances at thousands of temple festivals, private ceremonies, and public shows.\nIn 2018 Governor I Wayan Koster issued Bali Governor's Regulation No. 79 of 2018 which mandated that city officials wear traditional Balinese dress, such as that made of \"songket\". This was followed by Circular No. 4 of 2021 which specified the use of Endek fabrics, and was expanded to high-ranking individuals in the private sector and other institutions.\nArchitecture.\n\"Kaja\" and \"kelod\" are the Balinese equivalents of North and South, which refer to one's orientation between the island's largest mountain Gunung Agung (\"kaja\"), and the sea (\"kelod\"). In addition to spatial orientation, \"kaja\" and \"kelod\" have the connotation of good and evil; gods and ancestors are believed to live on the mountain whereas demons live in the sea. Buildings such as temples and residential homes are spatially oriented by having the most sacred spaces closest to the mountain and the unclean places nearest to the sea.\nMost temples have an inner courtyard and an outer courtyard which are arranged with the inner courtyard furthest \"kaja\". These spaces serve as performance venues since most Balinese rituals are accompanied by any combination of music, dance, and drama. The performances that take place in the inner courtyard are classified as \"wali\", the most sacred rituals which are offerings exclusively for the gods, while the outer courtyard is where \"bebali\" ceremonies are held, which are intended for gods and people. Lastly, performances meant solely for the entertainment of humans take place outside the temple's walls and are called \"bali-balihan\". This three-tiered system of classification was standardised in 1971 by a committee of Balinese officials and artists to better protect the sanctity of the oldest and most sacred Balinese rituals from being performed for a paying audience.\nDances.\nTourism, Bali's chief industry, has provided the island with a foreign audience that is eager to pay for entertainment, thus creating new performance opportunities and more demand for performers. The impact of tourism is controversial since before it became integrated into the economy, the Balinese performing arts did not exist as a capitalist venture, and were not performed for entertainment outside of their respective ritual context. Since the 1930s sacred rituals such as the \"barong\" dance have been performed both in their original contexts, as well as exclusively for paying tourists. This has led to new versions of many of these performances that have developed according to the preferences of foreign audiences; some villages have a \"barong\" mask specifically for non-ritual performances and an older mask that is only used for sacred performances.\nFestivals.\nThroughout the year, there are many festivals celebrated locally or island-wide according to the traditional calendars. The Hindu New Year, \"Nyepi\", is celebrated in the spring by a day of silence. On this day everyone stays at home and tourists are encouraged (or required) to remain in their hotels. On the day before New Year, large and colourful sculptures of \"Ogoh-ogoh\" monsters are paraded and burned in the evening to drive away evil spirits. Other festivals throughout the year are specified by the Balinese \"pawukon\" calendrical system.\nCelebrations are held for many occasions such as a tooth-filing (coming-of-age ritual), cremation or \"odalan\" (temple festival). One of the most important concepts that Balinese ceremonies have in common is that of \"d\u00e9sa kala patra\", which refers to how ritual performances must be appropriate in both the specific and general social context. Many ceremonial art forms such as \"wayang kulit\" and \"topeng\" are highly improvisatory, providing flexibility for the performer to adapt the performance to the current situation. Many celebrations call for a loud, boisterous atmosphere with much activity, and the resulting aesthetic, \"ram\u00e9\", is distinctively Balinese. Often two or more \"gamelan\" ensembles will be performing well within earshot, and sometimes compete with each other to be heard. Likewise, the audience members talk amongst themselves, get up and walk around, or even cheer on the performance, which adds to the many layers of activity and the liveliness typical of \"ram\u00e9\".\nTradition.\nBalinese society continues to revolve around each family's ancestral village, to which the cycle of life and religion is closely tied. Coercive aspects of traditional society, such as customary law sanctions imposed by traditional authorities such as village councils (including \"kasepekang\", or shunning) have risen in importance as a consequence of the democratisation and decentralisation of Indonesia since 1998.\nOther than Balinese sacred rituals and festivals, the government presents Bali Arts Festival to showcase Bali's performing arts and various artworks produced by the local talents that they have. It is held once a year, from the second week of June until the end of July. Southeast Asia's biggest annual festival of words and ideas Ubud Writers and Readers Festival is held at Ubud in October, which is participated by the world's most celebrated writers, artists, thinkers, and performers.\nOne unusual tradition is the naming of children in Bali. In general, Balinese people name their children depending on the order they are born, and the names are the same for both males and females.\nBeauty pageant.\nBali was the host of Miss World 2013 (63rd edition of the Miss World pageant). It was the first time Indonesia hosted an international beauty pageant. In 2022, Bali also co-hosted Miss Grand International 2022 along with Jakarta, West Java, and Banten.\nSports.\nBali is a major world surfing destination with popular breaks dotted across the southern coastline and around the offshore island of Nusa Lembongan.\nAs part of the Coral Triangle, Bali, including Nusa Penida, offers a wide range of dive sites with varying types of reefs, and tropical aquatic life.\nBali was the host of 2008 Asian Beach Games. It was the second time Indonesia hosted an Asia-level multi-sport event, after Jakarta held the 1962 Asian Games.\nIn 2023, Bali was the location for a major eSports event, the Dota 2 Bali Major, the third and final Major of the Dota Pro Circuit season. The event was held at the Ayana Estate and the Champa Garden, and it was the first time that a Dota Pro Circuit Major was held in Indonesia.\nIn football, Bali is home to Bali United football club, which plays in Liga 1.\nThe team was relocated from Samarinda, East Kalimantan to Gianyar, Bali. Harbiansyah Hanafiah, the main commissioner of Bali United explained that he changed the name and moved the home base because there was no representative from Bali in the highest football tier in Indonesia. Another reason was due to local fans in Samarinda preferring to support Pusamania Borneo F.C. rather than Persisam.\nHeritage sites.\nIn June 2012, Subak, the irrigation system for paddy fields in Jatiluwih, central Bali was listed as a Natural UNESCO World Heritage Site."}
{"id": "4149", "revid": "1224855", "url": "https://en.wikipedia.org/wiki?curid=4149", "title": "Bulgarian language", "text": "Bulgarian (, ; , ) is an Eastern South Slavic language spoken in Southeast Europe, primarily in Bulgaria. It is the language of the Bulgarians.\nAlong with the closely related Macedonian language (collectively forming the East South Slavic languages), it is a member of the Balkan sprachbund and South Slavic dialect continuum of the Indo-European language family. The two languages have several characteristics that set them apart from all other Slavic languages, including the elimination of case declension, the development of a suffixed definite article, and the lack of a verb infinitive. They retain and have further developed the Proto-Slavic verb system (albeit analytically). One such major development is the innovation of evidential verb forms to encode for the source of information: witnessed, inferred, or reported.\nIt is the official language of Bulgaria, and since 2007 has been among the official languages of the European Union. It is also spoken by the Bulgarian historical communities in North Macedonia, Ukraine, Moldova, Serbia, Romania, Hungary, Albania and Greece.\nHistory.\nOne can divide the development of the Bulgarian language into several periods.\n\"Bulgarian\" was the first Slavic language attested in writing. As Slavic linguistic unity lasted into late antiquity, the oldest manuscripts initially referred to this language as \u0467\u0437\ua651\u043a\u044a \u0441\u043b\u043e\u0432\u0463\u043d\u044c\u0441\u043a\u044a, \"the Slavic language\". In the Middle Bulgarian period this name was gradually replaced by the name \u0467\u0437\ua651\u043a\u044a \u0431\u043b\u044a\u0433\u0430\u0440\u044c\u0441\u043a\u044a, the \"Bulgarian language\". In some cases, this name was used not only with regard to the contemporary Middle Bulgarian language of the copyist but also to the period of Old Bulgarian. A most notable example of anachronism is the Service of Saint Cyril from Skopje (\u0421\u043a\u043e\u043f\u0441\u043a\u0438 \u043c\u0438\u043d\u0435\u0439), a 13th-century Middle Bulgarian manuscript from northern Macedonia according to which St. Cyril preached with \"Bulgarian\" books among the Moravian Slavs. The first mention of the language as the \"Bulgarian language\" instead of the \"Slavonic language\" comes in the work of the Greek clergy of the Archbishopric of Ohrid in the 11th century, for example in the Greek hagiography of Clement of Ohrid by Theophylact of Ohrid (late 11th century).\nDuring the Middle Bulgarian period, the language underwent dramatic changes, losing the Slavonic case system, but preserving the rich verb system (while the development was exactly the opposite in other Slavic languages) and developing a definite article. It was influenced by its non-Slavic neighbors in the Balkan language area (mostly grammatically) and later also by Turkish, which was the official language of the Ottoman Empire, in the form of the Ottoman Turkish language, mostly lexically. The damaskin texts mark the transition from Middle Bulgarian to New Bulgarian, which was standardized in the 19th century.\nAs a national revival occurred toward the end of the period of Ottoman rule (mostly during the 19th century), a modern Bulgarian literary language gradually emerged that drew heavily on Church Slavonic/Old Bulgarian (and to some extent on literary Russian, which had preserved many lexical items from Church Slavonic) and later reduced the number of Turkish and other Balkan loans. Today one difference between Bulgarian dialects in the country and literary spoken Bulgarian is the significant presence of Old Bulgarian words and even word forms in the latter. Russian loans are distinguished from Old Bulgarian ones on the basis of the presence of specifically Russian phonetic changes, as in \u043e\u0431\u043e\u0440\u043e\u0442 (turnover, rev), \u043d\u0435\u043f\u043e\u043d\u044f\u0442\u0435\u043d (incomprehensible), \u044f\u0434\u0440\u043e (nucleus) and others. Many other loans from French, English and the classical languages have subsequently entered the language as well.\nModern Bulgarian was based essentially on the Eastern dialects of the language, but its pronunciation is in many respects a compromise between East and West Bulgarian (see especially the phonetic sections below). Following the efforts of some figures of the National awakening of Bulgaria (most notably Neofit Rilski and Ivan Bogorov), there had been many attempts to codify a standard Bulgarian language; however, there was much argument surrounding the choice of norms. Between 1835 and 1878 more than 25 proposals were put forward and \"linguistic chaos\" ensued. Eventually the eastern dialects prevailed,\nand in 1899 the Bulgarian Ministry of Education officially codified a standard Bulgarian language based on the Drinov-Ivanchev orthography.\nGeographic distribution.\nBulgarian is the official language of Bulgaria, where it is used in all spheres of public life. As of 2011, it is spoken as a first language by about 6million people in the country, or about four out of every five Bulgarian citizens.\nThere is also a significant Bulgarian diaspora abroad. One of the main historically established communities are the Bessarabian Bulgarians, whose settlement in the Bessarabia region of nowadays Moldova and Ukraine dates mostly to the early 19th century. There were Bulgarian speakers in Ukraine at the 2001 census, in Moldova as of the 2014 census (of which were habitual users of the language), and presumably a significant proportion of the 13,200 ethnic Bulgarians residing in neighbouring Transnistria in 2016.\nAnother community abroad are the Banat Bulgarians, who migrated in the 17th century to the Banat region now split between Romania, Serbia and Hungary. They speak the Banat Bulgarian dialect, which has had its own written standard and a historically important literary tradition.\nThere are Bulgarian speakers in neighbouring countries as well. The regional dialects of Bulgarian and Macedonian form a dialect continuum, and there is no well-defined boundary where one language ends and the other begins. Within the limits of the Republic of North Macedonia a strong separate Macedonian identity has emerged since the Second World War, even though there still are a small number of citizens who identify their language as Bulgarian. Beyond the borders of North Macedonia, the situation is more fluid, and the pockets of speakers of the related regional dialects in Albania and in Greece variously identify their language as Macedonian or as Bulgarian. In Serbia, there were speakers as of 2011, mainly concentrated in the so-called Western Outlands along the border with Bulgaria. Bulgarian is also spoken in Turkey: natively by Pomaks, and as a second language by many Bulgarian Turks who emigrated from Bulgaria, mostly during the \"Big Excursion\" of 1989.\nThe language is also represented among the diaspora in Western Europe and North America, which has been steadily growing since the 1990s. Countries with significant numbers of speakers include Germany, Spain, Italy, the United Kingdom ( speakers in England and Wales as of 2011), France, the United States, and Canada ( in 2011).\nDialects.\nThe language is mainly split into two broad dialect areas, based on the different reflexes of the Proto-Slavic yat vowel (\u0462). This split, which occurred at some point during the Middle Ages, led to the development of Bulgaria's:\nThe literary language norm, which is generally based on the Eastern dialects, also has the Eastern alternating reflex of \"yat\". However, it has not incorporated the general Eastern umlaut of \"all\" synchronic or even historic \"ya\" sounds into \"e\" before front vowels \u2013 e.g. \u043f\u043e\u043b\u044f\u043d\u0430 (\"polyana\") vs. \u043f\u043e\u043b\u0435\u043d\u0438 (\"poleni\") \"meadow \u2013 meadows\" or even \u0436\u0430\u0431\u0430 (\"zhaba\") vs. \u0436\u0435\u0431\u0438 (\"zhebi\") \"frog \u2013 frogs\", even though it co-occurs with the yat alternation in almost all Eastern dialects that have it (except a few dialects along the yat border, e.g. in the Pleven region).\nMore examples of the \"yat\" umlaut in the literary language are:\nUntil 1945, Bulgarian orthography did not reveal this alternation and used the original Old Slavic Cyrillic letter \"yat\" (\u0462), which was commonly called \u0434\u0432\u043e\u0439\u043d\u043e \u0435 (\"dvoyno e\") at the time, to express the historical \"yat\" vowel or at least root vowels displaying the \"ya \u2013 e\" alternation. The letter was used in each occurrence of such a root, regardless of the actual pronunciation of the vowel: thus, both \"mlyako\" and \"mlekar\" were spelled with (\u0462). Among other things, this was seen as a way to \"reconcile\" the Western and the Eastern dialects and maintain language unity at a time when much of Bulgaria's Western dialect area was controlled by Serbia and Greece, but there were still hopes and occasional attempts to recover it. With the 1945 orthographic reform, this letter was abolished and the present spelling was introduced, reflecting the alternation in pronunciation.\nThis had implications for some grammatical constructions:\nSometimes, with the changes, words began to be spelled as other words with different meanings, e.g.:\nIn spite of the literary norm regarding the yat vowel, many people living in Western Bulgaria, including the capital Sofia, will fail to observe its rules. While the norm requires the realizations \"vidyal\" vs. \"videli\" (he has seen; they have seen), some natives of Western Bulgaria will preserve their local dialect pronunciation with \"e\" for all instances of \"yat\" (e.g. \"videl\", \"videli\"). Others, attempting to adhere to the norm, will actually use the \"ya\" sound even in cases where the standard language has \"e\" (e.g. \"vidyal\", \"vidyali\"). The latter hypercorrection is called \u0441\u0432\u0440\u044a\u0445\u044f\u043a\u0430\u043d\u0435 (\"svrah-yakane\" \u2248\"over-\"ya\"-ing\").\nBulgarian is the only Slavic language whose literary standard does not naturally contain the iotated \"e\" (or its variant, \"e\" after a palatalized consonant , except in non-Slavic foreign-loaned words). This sound combination is common in all modern Slavic languages (e.g. Czech \"medv\u011bd\" \"bear\", Polish \"pi\u0119\u0107\" \"five\", Serbo-Croatian jelen\" \"deer\", Ukrainian \"\u043d\u0435\u043c\u0430\u0454 \"there is not...\", Macedonian \"\u043f\u0438\u0448\u0443\u0432\u0430\u045a\u0435\" \"writing\", etc.), as well as some Western Bulgarian dialectal forms \u2013 e.g. \"\u043e\u0440\u0430\u0300\u043d\u2019\u0435\" (standard Bulgarian: \"\u043e\u0440\u0430\u043d\u0435\" , \"ploughing\"), however it is not represented in standard Bulgarian speech or writing. Even where occurs in other Slavic words, in Standard Bulgarian it is usually transcribed and pronounced as pure \u2013 e.g. Boris Yeltsin is \"Eltsin\" (), Yekaterinburg is \"Ekaterinburg\" () and Sarajevo is \"Saraevo\" (), although \u2013 because of the stress and the beginning of the word \u2013 Jelena Jankovi\u0107 is \"Yelena Yankovich\" ().\nRelationship to Macedonian.\nUntil the period immediately following the Second World War, all Bulgarian and the majority of foreign linguists referred to the South Slavic dialect continuum spanning the area of modern Bulgaria, North Macedonia and parts of Northern Greece as a group of Bulgarian dialects. In contrast, Serbian sources tended to label them \"south Serbian\" dialects. Some local naming conventions included \"bolg\u00e1rski\", \"bug\u00e1rski\" and so forth. The codifiers of the standard Bulgarian language, however, did not wish to make any allowances for a pluricentric \"Bulgaro-Macedonian\" compromise. In 1870 Marin Drinov, who played a decisive role in the standardization of the Bulgarian language, rejected the proposal of Parteniy Zografski and Kuzman Shapkarev for a mixed eastern and western Bulgarian/Macedonian foundation of the standard Bulgarian language, stating in his article in the newspaper \"Makedoniya\": \"Such an artificial assembly of written language is something impossible, unattainable and never heard of.\"\nAfter 1944 the People's Republic of Bulgaria and the Socialist Federal Republic of Yugoslavia began a policy of making Macedonia into the connecting link for the establishment of a new Balkan Federative Republic and stimulating here a development of distinct Macedonian consciousness. With the proclamation of the Socialist Republic of Macedonia as part of the Yugoslav federation, the new authorities also started measures that would overcome the pro-Bulgarian feeling among parts of its population and in 1945 a separate Macedonian language was codified. After 1958, when the pressure from Moscow decreased, Sofia reverted to the view that the Macedonian language did not exist as a separate language. Nowadays, Bulgarian and Greek linguists, as well as some linguists from other countries, still consider the various Macedonian dialects as part of the broader Bulgarian pluricentric dialectal continuum. Outside Bulgaria and Greece, Macedonian is generally considered an autonomous language within the South Slavic dialect continuum. Sociolinguists agree that the question whether Macedonian is a dialect of Bulgarian or a language is a political one and cannot be resolved on a purely linguistic basis, because dialect continua do not allow for either/or judgements.\nPhonology.\nBulgarian possesses a phonology similar to that of the rest of the South Slavic languages, notably lacking Serbo-Croatian's phonemic vowel length and tones and alveo-palatal affricates. There is a general dichotomy between Eastern and Western dialects, with Eastern ones featuring consonant palatalization before front vowels ( and ) and substantial vowel reduction of the low vowels , and in unstressed position, sometimes leading to neutralisation between and , and , and and . Both patterns have partial parallels in Russian, leading to partially similar sounds. In turn, the Western dialects generally do not have any allophonic palatalization and exhibit minor, if any, vowel reduction.\nStandard Bulgarian keeps a middle ground between the macrodialects. It allows palatalizaton only before central and back vowels and only partial reduction of and . Reduction of , consonant palatalisation before front vowels and depalatalization of palatalized consonants before central and back vowels is strongly discouraged and labelled as provincial.\nBulgarian has six vowel phonemes, but at least eight distinct phones can be distinguished when reduced allophones are taken into consideration. There is currently no consensus on the number of Bulgarian consonants, with one school of thought advocating for the existence of only 22 consonant phonemes and another one claiming that there are not fewer than 39 consonant phonemes. The main bone of contention is how to treat palatalized consonants: as separate phonemes or as allophones of their respective plain counterparts.\nThe 22-consonant model is based on a general consensus reached by all major Bulgarian linguists in the 1930s and 1940s. In turn, the 39-consonant model was launched in the beginning of the 1950s under the influence of the ideas of Russian linguist Nikolai Trubetzkoy. \nDespite frequent objections, the support of the Bulgarian Academy of Sciences has ensured Trubetzkoy's model virtual monopoly in state-issued phonologies and grammars since the 1960s. However, its reception abroad has been lukewarm, with a number of authors either calling the model into question or outright rejecting it. Thus, the Handbook of the International Phonetic Association only lists 22 consonants in Bulgarian's consonant inventory.\nAlphabet.\nIn 886 AD, the Bulgarian Empire introduced the Glagolitic alphabet which was devised by the Saints Cyril and Methodius in the 850s. The Glagolitic alphabet was gradually superseded in later centuries by the Cyrillic script, developed around the Preslav Literary School, Bulgaria in the late 9th century.\nSeveral Cyrillic alphabets with 28 to 44 letters were used in the beginning and the middle of the 19th century during the efforts on the codification of Modern Bulgarian until an alphabet with 32 letters, proposed by Marin Drinov, gained prominence in the 1870s. The alphabet of Marin Drinov was used until the orthographic reform of 1945, when the letters yat (uppercase \u0462, lowercase \u0463) and yus (uppercase \u046a, lowercase \u046b) were removed from its alphabet, reducing the number of letters to 30.\nWith the accession of Bulgaria to the European Union on 1 January 2007, Cyrillic became the third official script of the European Union, following the Latin and Greek scripts.\nGrammar.\nThe parts of speech in Bulgarian are divided in ten types, which are categorized in two broad classes: mutable and immutable. The difference is that mutable parts of speech vary grammatically, whereas the immutable ones do not change, regardless of their use. The five classes of mutables are: \"nouns\", \"adjectives\", \"numerals\", \"pronouns\" and \"verbs\". Syntactically, the first four of these form the group of the noun or the nominal group. The immutables are: \"adverbs\", \"prepositions\", \"conjunctions\", \"particles\" and \"interjections\". Verbs and adverbs form the group of the verb or the verbal group.\nNominal morphology.\nNouns and adjectives have the categories grammatical gender, number, case (only vocative) and definiteness in Bulgarian. Adjectives and adjectival pronouns agree with nouns in number and gender. Pronouns have gender and number and retain (as in nearly all Indo-European languages) a more significant part of the case system.\nNominal inflection.\nGender.\nThere are three grammatical genders in Bulgarian: \"masculine\", \"feminine\" and \"neuter\". The gender of the noun can largely be inferred from its ending: nouns ending in a consonant (\"zero ending\") are generally masculine (for example, 'city', 'son', 'man'; those ending in\u00a0\u2013\u0430/\u2013\u044f (-a/-ya) ( 'woman', 'daughter', 'street') are normally feminine; and nouns ending in\u00a0\u2013\u0435,\u00a0\u2013\u043e are almost always neuter ( 'child', 'lake'), as are those rare words (usually loanwords) that end in\u00a0\u2013\u0438,\u00a0\u2013\u0443, and\u00a0\u2013\u044e ( 'tsunami', 'taboo', 'menu'). Perhaps the most significant exception from the above are the relatively numerous nouns that end in a consonant and yet are feminine: these comprise, firstly, a large group of nouns with zero ending expressing quality, degree or an abstraction, including all nouns ending on\u00a0\u2013\u043e\u0441\u0442/\u2013\u0435\u0441\u0442 -{ost/est} ( 'wisdom', 'vileness', 'loveliness', 'sickness', 'love'), and secondly, a much smaller group of irregular nouns with zero ending which define tangible objects or concepts ( 'blood', 'bone', 'evening', 'night'). There are also some commonly used words that end in a vowel and yet are masculine: 'father', 'grandfather', / 'uncle', and others.\nThe plural forms of the nouns do not express their gender as clearly as the singular ones, but may also provide some clues to it: the ending (-i) is more likely to be used with a masculine or feminine noun ( 'facts', 'sicknesses'), while one in belongs more often to a neuter noun ( 'lakes'). Also, the plural ending occurs only in masculine nouns.\nNumber.\nTwo numbers are distinguished in Bulgarian\u2013singular and plural. A variety of plural suffixes is used, and the choice between them is partly determined by their ending in singular and partly influenced by gender; in addition, irregular declension and alternative plural forms are common. Words ending in (which are usually feminine) generally have the plural ending , upon dropping of the singular ending. Of nouns ending in a consonant, the feminine ones also use , whereas the masculine ones usually have for polysyllables and for monosyllables (however, exceptions are especially common in this group). Nouns ending in (most of which are neuter) mostly use the suffixes (both of which require the dropping of the singular endings) and .\nWith cardinal numbers and related words such as ('several'), masculine nouns use a special count form in , which stems from the Proto-Slavonic dual: ('two/three chairs') versus ('these chairs'); cf. feminine ('two/three/these books') and neuter ('two/three/these beds'). However, a recently developed language norm requires that count forms should only be used with masculine nouns that do not denote persons. Thus, ('two/three students') is perceived as more correct than , while the distinction is retained in cases such as ('two/three pencils') versus ('these pencils').\nCase.\nCases exist only in the personal and some other pronouns (as they do in many other modern Indo-European languages), with nominative, accusative, dative and vocative forms. Vestiges are present in a number of phraseological units and sayings. The major exception are vocative forms, which are still in use for masculine (with the endings -\u0435, -\u043e and -\u044e) and feminine nouns (-[\u044c/\u0439]\u043e and -\u0435) in the singular.\nDefiniteness (article).\nIn modern Bulgarian, definiteness is expressed by a definite article which is postfixed to the noun, much like in the Scandinavian languages or Romanian (indefinite: , 'person'; definite: , \"\"the\" person\") or to the first nominal constituent of definite noun phrases (indefinite: , 'a good person'; definite: , \"\"the\" good person\"). There are four singular definite articles. Again, the choice between them is largely determined by the noun's ending in the singular. Nouns that end in a consonant and are masculine use \u2013\u044a\u0442/\u2013\u044f\u0442, when they are grammatical subjects, and \u2013\u0430/\u2013\u044f elsewhere. Nouns that end in a consonant and are feminine, as well as nouns that end in \u2013\u0430/\u2013\u044f (most of which are feminine, too) use \u2013\u0442\u0430. Nouns that end in \u2013\u0435/\u2013\u043e use \u2013\u0442\u043e.\nThe plural definite article is \u2013\u0442\u0435 for all nouns except for those whose plural form ends in \u2013\u0430/\u2013\u044f; these get \u2013\u0442\u0430 instead. When postfixed to adjectives the definite articles are \u2013\u044f\u0442/\u2013\u044f for masculine gender (again, with the longer form being reserved for grammatical subjects), \u2013\u0442\u0430 for feminine gender, \u2013\u0442\u043e for neuter gender, and \u2013\u0442\u0435 for plural.\nAdjective and numeral inflection.\nBoth groups agree in gender and number with the noun they are appended to. They may also take the definite article as explained above.\nPronouns.\nPronouns may vary in gender, number, and definiteness, and are the only parts of speech that have retained case inflections. Three cases are exhibited by some groups of pronouns \u2013 nominative, accusative and dative. The distinguishable types of pronouns include the following: personal, relative, reflexive, interrogative, negative, indefinitive, summative and possessive.\nVerbal morphology and grammar.\nA Bulgarian verb has many distinct forms, as it varies in person, number, voice, aspect, mood, tense and in some cases gender.\nFinite verbal forms.\nFinite verbal forms are \"simple\" or \"compound\" and agree with subjects in person (first, second and third) and number (singular, plural). In addition to that, past compound forms using participles vary in gender (masculine, feminine, neuter) and voice (active and passive) as well as aspect (perfective/aorist and imperfective).\nAspect.\nBulgarian verbs express lexical aspect: perfective verbs signify the completion of the action of the verb and form past perfective (aorist) forms; imperfective ones are neutral with regard to it and form past imperfective forms. Most Bulgarian verbs can be grouped in perfective-imperfective pairs (imperfective/perfective: \"come\", \"arrive\"). Perfective verbs can be usually formed from imperfective ones by suffixation or prefixation, but the resultant verb often deviates in meaning from the original. In the pair examples above, aspect is stem-specific and therefore there is no difference in meaning.\nIn Bulgarian, there is also grammatical aspect. Three grammatical aspects are distinguishable: neutral, perfect and pluperfect. The neutral aspect comprises the three simple tenses and the future tense. The pluperfect is manifest in tenses that use double or triple auxiliary \"be\" participles like the past pluperfect subjunctive. Perfect constructions use a single auxiliary \"be\".\nMood.\nThe traditional interpretation is that in addition to the four moods (\u043d\u0430\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u044f ) shared by most other European languages \u2013 indicative (\u0438\u0437\u044f\u0432\u0438\u0442\u0435\u043b\u043d\u043e, ) imperative (\u043f\u043e\u0432\u0435\u043b\u0438\u0442\u0435\u043b\u043d\u043e ), subjunctive ( ) and conditional (\u0443\u0441\u043b\u043e\u0432\u043d\u043e, ) \u2013 in Bulgarian there is one more to describe a general category of unwitnessed events \u2013 the inferential (\u043f\u0440\u0435\u0438\u0437\u043a\u0430\u0437\u043d\u043e ) mood. However, most contemporary Bulgarian linguists usually exclude the subjunctive mood and the inferential mood from the list of Bulgarian moods (thus placing the number of Bulgarian moods at a total of 3: indicative, imperative and conditional) and do not consider them to be moods but view them as verbial morphosyntactic constructs or separate gramemes of the verb class. The possible existence of a few other moods has been discussed in the literature. Most Bulgarian school grammars teach the traditional view of 4 Bulgarian moods (as described above, but excluding the subjunctive and including the inferential).\nTense.\nThere are three grammatically distinctive positions in time \u2013 present, past and future \u2013 which combine with aspect and mood to produce a number of formations. Normally, in grammar books these formations are viewed as separate tenses \u2013 i. e. \"past imperfect\" would mean that the verb is in past tense, in the imperfective aspect, and in the indicative mood (since no other mood is shown). There are more than 40 different tenses across Bulgarian's two aspects and five moods.\nIn the indicative mood, there are three simple tenses:\nIn the indicative there are also the following compound tenses:\nThe four perfect constructions above can vary in aspect depending on the aspect of the main-verb participle; they are in fact pairs of imperfective and perfective aspects. Verbs in forms using past participles also vary in voice and gender.\nThere is only one simple tense in the imperative mood, the present, and there are simple forms only for the second-person singular, -\u0438/-\u0439 (-i, -y/i), and plural, -\u0435\u0442\u0435/-\u0439\u0442\u0435 (-ete, -yte), e.g. \u0443\u0447\u0430 ('to study'): , sg., , pl.; 'to play': , . There are compound imperative forms for all persons and numbers in the present compound imperative (, ), the present perfect compound imperative (, ) and the rarely used present pluperfect compound imperative (, ).\nThe conditional mood consists of five compound tenses, most of which are not grammatically distinguishable. The present, future and past conditional use a special past form of the stem \u0431\u0438- (bi \u2013 \"be\") and the past participle (, , 'I would study'). The past future conditional and the past future perfect conditional coincide in form with the respective indicative tenses.\nThe subjunctive mood is rarely documented as a separate verb form in Bulgarian, (being, morphologically, a sub-instance of the quasi-infinitive construction with the particle \u0434\u0430 and a normal finite verb form), but nevertheless it is used regularly. The most common form, often mistaken for the present tense, is the present subjunctive ( , 'I had better go'). The difference between the present indicative and the present subjunctive tense is that the subjunctive can be formed by \"both\" perfective and imperfective verbs. It has completely replaced the infinitive and the supine from complex expressions (see below). It is also employed to express opinion about \"possible\" future events. The past perfect subjunctive ( , 'I'd had better be gone') refers to \"possible\" events in the past, which \"did not\" take place, and the present pluperfect subjunctive ( ), which may be used about both past and future events arousing feelings of incontinence, suspicion, etc.\nThe inferential mood has five pure tenses. Two of them are simple \u2013 \"past aorist inferential\" and \"past imperfect inferential\" \u2013 and are formed by the past participles of perfective and imperfective verbs, respectively. There are also three compound tenses \u2013 \"past future inferential\", \"past future perfect inferential\" and \"past perfect inferential\". All these tenses' forms are gender-specific in the singular. There are also conditional and compound-imperative crossovers. The existence of inferential forms has been attributed to Turkic influences by most Bulgarian linguists. Morphologically, they are derived from the perfect.\nNon-finite verbal forms.\nBulgarian has the following participles:\nThe participles are inflected by gender, number, and definiteness, and are coordinated with the subject when forming compound tenses (see tenses above). When used in an attributive role, the inflection attributes are coordinated with the noun that is being attributed.\nReflexive verbs.\nBulgarian uses reflexive verbal forms (i.e. actions which are performed by the agent onto him- or herself) which behave in a similar way as they do in many other Indo-European languages, such as French and Spanish. The reflexive is expressed by the invariable particle se, originally a clitic form of the accusative reflexive pronoun. Thus \u2013\nWhen the action is performed on others, other particles are used, just like in any normal verb, e.g. \u2013\nSometimes, the reflexive verb form has a similar but not necessarily identical meaning to the non-reflexive verb \u2013\nIn other cases, the reflexive verb has a completely different meaning from its non-reflexive counterpart \u2013\nWhen the action is performed on an indirect object, the particles change to si and its derivatives \u2013\nIn some cases, the particle \"si\" is ambiguous between the indirect object and the possessive meaning \u2013\nThe difference between transitive and intransitive verbs can lead to significant differences in meaning with minimal change, e.g. \u2013\nThe particle \"si\" is often used to indicate a more personal relationship to the action, e.g. \u2013\nAdverbs.\nThe most productive way to form adverbs is to derive them from the neuter singular form of the corresponding adjective\u2014e.g. (fast), (hard), (strange)\u2014but adjectives ending in use the masculine singular form (i.e. ending in ), instead\u2014e.g. (heroically), (bravely, like a man), (skillfully). The same pattern is used to form adverbs from the (adjective-like) ordinal numerals, e.g. (firstly), (secondly), (thirdly), and in some cases from (adjective-like) cardinal numerals, e.g. (twice as/double), (three times as), (five times as).\nThe remaining adverbs are formed in ways that are no longer productive in the language. A small number are original (not derived from other words), for example: (here), (there), (inside), (outside), (very/much) etc. The rest are mostly fossilized case forms, such as:\nAdverbs can sometimes be reduplicated to emphasize the qualitative or quantitative properties of actions, moods or relations as performed by the subject of the sentence: \"\" (\"rather slowly\"), \"\" (\"with great difficulty\"), \"\" (\"quite\", \"thoroughly\").\nOther features.\nQuestions.\nQuestions in Bulgarian which do not use a question word (such as who? what? etc.) are formed with the particle after the verb; a subject is not necessary, as the verbal conjugation suggests who is performing the action:\nWhile the particle generally goes after the verb, it can go after a noun or adjective if a contrast is needed:\nA verb is not always necessary, e.g. when presenting a choice:\nRhetorical questions can be formed by adding to a question word, thus forming a \"double interrogative\" \u2013\nThe same construction ('no') is an emphasized positive \u2013\nSignificant verbs.\nBe (\"\u0421\u044a\u043c\").\nThe verb \u2013 'to be' is also used as an auxiliary for forming the perfect, the passive and the conditional:\nTwo alternate forms of exist:\nWill (\"\u0429\u0435\").\nThe impersonal verb (lit. 'it wants') is used to for forming the (positive) future tense:\nThe negative future is formed with the invariable construction (see below):\nThe past tense of this verb \u2013 \u0449\u044f\u0445 is conjugated to form the past conditional ('would have' \u2013 again, with \u0434\u0430, since it is \"irrealis\"):\nHave/Don't have (\"\u0418\u043c\u0430\u043c and \u043d\u044f\u043c\u0430\u043c\").\nThe verbs ('to have') and ('to not have'):\nConjunctions and particles.\nBut.\nIn Bulgarian, there are several conjunctions all translating into English as \"but\", which are all used in distinct situations. They are (), (), (), (), and () (and () \u2013 \"however\", identical in use to ).\nWhile there is some overlapping between their uses, in many cases they are specific. For example, is used for a choice \u2013 \u2013 \"not this one, but that one\" (compare Spanish ), while is often used to provide extra information or an opinion \u2013 \u2013 \"I said it, but I was wrong\". Meanwhile, provides contrast between two situations, and in some sentences can even be translated as \"although\", \"while\" or even \"and\" \u2013 \u2013 \"I'm working, and he's daydreaming\".\nVery often, different words can be used to alter the emphasis of a sentence \u2013 e.g. while and both mean \"I smoke, but I shouldn't\", the first sounds more like a statement of fact (\"...but I mustn't\"), while the second feels more like a \"judgement\" (\"...but I oughtn't\"). Similarly, and both mean \"I don't want to, but he does\", however the first emphasizes the fact that \"he\" wants to, while the second emphasizes the \"wanting\" rather than the person.\n is interesting in that, while it feels archaic, it is often used in poetry and frequently in children's stories, since it has quite a moral/ominous feel to it.\nSome common expressions use these words, and some can be used alone as interjections:\nVocative particles.\nBulgarian has several abstract particles which are used to strengthen a statement. These have no precise translation in English. The particles are strictly informal and can even be considered rude by some people and in some situations. They are mostly used at the end of questions or instructions.\nModal particles.\nThese are \"tagged\" on to the beginning or end of a sentence to express the mood of the speaker in relation to the situation. They are mostly interrogative or slightly imperative in nature. There is no change in the grammatical mood when these are used (although they may be expressed through different grammatical moods in other languages).\nIntentional particles.\nThese express intent or desire, perhaps even pleading. They can be seen as a sort of cohortative side to the language. (Since they can be used by themselves, they could even be considered as verbs in their own right.) They are also highly informal.\nThese particles can be combined with the vocative particles for greater effect, e.g. (let me see), or even exclusively in combinations with them, with no other elements, e.g. (come on!); (I told you not to!).\nPronouns of quality.\nBulgarian has several pronouns of quality which have no direct parallels in English \u2013 (what sort of); (this sort of); (that sort of \u2013 colloq.); (some sort of); (no sort of); (every sort of); and the relative pronoun (the sort of ... that ... ). The adjective (\"the same\") derives from the same radical.\nExample phrases include:\nAn interesting phenomenon is that these can be strung along one after another in quite long constructions, e.g.\nAn extreme, albeit colloquial, example with almost no intrinsic lexical meaning \u2013 yet which is meaningful to the Bulgarian ear \u2013 would be :\nThe subject of the sentence is simply the pronoun \"\" (lit. \"this one here\"; colloq. \"she\").\nAnother interesting phenomenon that is observed in colloquial speech is the use of (neuter of ) not only as a substitute for an adjective, but also as a substitute for a verb. In that case the base form is used as the third person singular in the present indicative and all other forms are formed by analogy to other verbs in the language. Sometimes the \"verb\" may even acquire a derivational prefix that changes its meaning. Examples:\nAnother use of in colloquial speech is the word , which can be used as a substitution for a noun, but also, if the speaker does not remember or is not sure how to say something, they might say and then pause to think about it:\nAs a result of this versatility, the word can readily be used as a euphemism for taboo subjects. It is commonly used to substitute, for example, words relating to reproductive organs or sexual acts:\nSimilar \"meaningless\" expressions are extremely common in spoken Bulgarian, especially when the speaker is finding it difficult to describe or express something.\nSyntax.\nBulgarian employs clitic doubling, mostly for emphatic purposes. For example, the following constructions are common in colloquial Bulgarian:\nThe phenomenon is practically obligatory in the spoken language in the case of inversion signalling information structure (in writing, clitic doubling may be skipped in such instances, with a somewhat bookish effect):\nSometimes, the doubling signals syntactic relations, thus:\nThis is contrasted with:\nIn this case, clitic doubling can be a colloquial alternative of the more formal or bookish passive voice, which would be constructed as follows:\nClitic doubling is also fully obligatory, both in the spoken and in the written norm, in clauses including several special expressions that use the short accusative and dative pronouns such as \"\" (I feel like playing), \u0441\u0442\u0443\u0434\u0435\u043d\u043e \u043c\u0438 \u0435 (I am cold), and \u0431\u043e\u043b\u0438 \u043c\u0435 \u0440\u044a\u043a\u0430\u0442\u0430 (my arm hurts):\nExcept the above examples, clitic doubling is considered inappropriate in a formal context.\nVocabulary.\nMost of the vocabulary of modern Bulgarian consists of terms inherited from Proto-Slavic and local Bulgarian innovations and formations of those through the mediation of Old and Middle Bulgarian. The native terms in Bulgarian account for 70% to 80% of the lexicon.\nThe remaining 20% to 30% are loanwords from a number of languages, as well as derivations of such words. Bulgarian adopted also a few words of Thracian and Bulgar origin. The languages which have contributed most to Bulgarian as a way of foreign vocabulary borrowings are:\nThe classical languages Latin and Greek are the source of many words, used mostly in international terminology. Many Latin terms entered Bulgarian during the time when present-day Bulgaria was part of the Roman Empire and also in the later centuries through Romanian, Aromanian, and Megleno-Romanian during Bulgarian Empires. The loanwords of Greek origin in Bulgarian are a product of the influence of the liturgical language of the Orthodox Church. Many of the numerous loanwords from another Turkic language, Ottoman Turkish and, via Ottoman Turkish, from Arabic were adopted into Bulgarian during the long period of Ottoman rule, but have been replaced with native Bulgarian terms. Furthermore, after the independence of Bulgaria from the Ottoman Empire in 1878, Bulgarian intellectuals imported many French language vocabulary. In addition, both specialized (usually coming from the field of science) and commonplace English words (notably abstract, commodity/service-related or technical terms) have also penetrated Bulgarian since the second half of the 20th century, especially since 1989. A noteworthy portion of this English-derived terminology has attained some unique features in the process of its introduction to native speakers, and this has resulted in peculiar derivations that set the newly formed loanwords apart from the original words (mainly in pronunciation), although many loanwords are completely identical to the source words. A growing number of international neologisms are also being widely adopted, causing controversy between younger generations who, in general, are raised in the era of digital globalization, and the older, more conservative educated purists.\nSample text.\nArticle 1 of the \"Universal Declaration of Human Rights\" in Bulgarian:\nThe romanization of the text into Latin alphabet:\nBulgarian pronunciation transliterated in broad IPA:\nArticle 1 of the \"Universal Declaration of Human Rights\" in English:\nExternal links.\nLinguistic reports\nDictionaries\nCourses"}
{"id": "4151", "revid": "1168457624", "url": "https://en.wikipedia.org/wiki?curid=4151", "title": "Brainfuck programming language/Examples", "text": ""}
{"id": "4153", "revid": "1262307509", "url": "https://en.wikipedia.org/wiki?curid=4153", "title": "Bipyramid", "text": "In geometry, a bipyramid, dipyramid, or double pyramid is a polyhedron formed by fusing two pyramids together base-to-base. The polygonal base of each pyramid must therefore be the same, and unless otherwise specified the base vertices are usually coplanar and a bipyramid is usually \"symmetric\", meaning the two pyramids are mirror images across their common base plane. When each apex (, the off-base vertices) of the bipyramid is on a line perpendicular to the base and passing through its center, it is a \"right\" bipyramid; otherwise it is \"oblique\". When the base is a regular polygon, the bipyramid is also called \"regular\".\nDefinition and properties.\nA bipyramid is a polyhedron constructed by fusing two pyramids which share the same polygonal base; a pyramid is in turn constructed by connecting each vertex of its base to a single new vertex (the apex) not lying in the plane of the base, for an gonal base forming triangular faces in addition to the base face. An gonal bipyramid thus has faces, edges, and vertices. More generally, a right pyramid is a pyramid where the apices are on the perpendicular line through the centroid of an arbitrary polygon or the incenter of a tangential polygon, depending on the source. Likewise, a \"right bipyramid\" is a polyhedron constructed by attaching two symmetrical right bipyramid bases; bipyramids whose apices are not on this line are called \"oblique bipyramids\".\nWhen the two pyramids are mirror images, the bipyramid is called \"symmetric\". It is called \"regular\" if its base is a regular polygon. When the base is a regular polygon and the apices are on the perpendicular line through its center (a \"regular right bipyramid\") then all of its faces are isosceles triangles; sometimes the name \"bipyramid\" refers specifically to symmetric regular right bipyramids, Examples of such bipyramids are the triangular bipyramid, octahedron (square bipyramid) and pentagonal bipyramid. If all their edges are equal in length, these shapes consist of equilateral triangle faces, making them deltahedra; the triangular bipyramid and the pentagonal bipyramid are Johnson solids, and the regular octahedron is a Platonic solid.\nThe symmetric regular right bipyramids have prismatic symmetry, with dihedral symmetry group of order : they are unchanged when rotated of a turn around the axis of symmetry, reflected across any plane passing through both apices and a base vertex or both apices and the center of a base edge, or reflected across the mirror plane. Because their faces are transitive under these symmetry transformations, they are isohedral. They are the dual polyhedra of prisms and the prisms are the dual of bipyramids as well; the bipyramids vertices correspond to the faces of the prism, and the edges between pairs of vertices of one correspond to the edges between pairs of faces of the other, and vice versa. The prisms share the same symmetry as the bipyramids. The regular octahedron is more symmetric still, as its base vertices and apices are indistinguishable and can be exchanged by reflections or rotations; the regular octahedron and its dual, the cube, have octahedral symmetry.\nThe volume of a symmetric bipyramid is\nformula_1\nwhere is the area of the base and the perpendicular distance from the base plane to either apex. In the case of a regular sided polygon with side length and whose altitude is , the volume of such a bipyramid is:\nformula_2\nRelated and other types of bipyramid.\nConcave bipyramids.\nA \"concave bipyramid\" has a concave polygon base, and one example is a concave tetragonal bipyramid or an irregular concave octahedron. A bipyramid with an arbitrary polygonal base could be considered a \"right\" bipyramid if the apices are on a line perpendicular to the base passing through the base's centroid.\nAsymmetric bipyramids.\nAn \"asymmetric bipyramid\" has apices which are not mirrored across the base plane; for a right bipyramid this only happens if each apex is a different distance from the base.\nThe dual of an asymmetric right -gonal bipyramid is an -gonal frustum.\nA regular asymmetric right -gonal bipyramid has symmetry group , of order .\nScalene triangle bipyramids.\nAn isotoxal right (symmetric) di--gonal bipyramid is a right (symmetric) -gonal bipyramid with an \"isotoxal\" flat polygon base: its basal vertices are coplanar, but alternate in two radii.\nAll its faces are congruent scalene triangles, and it is isohedral. It can be seen as another type of a right symmetric di--gonal \"scalenohedron\", with an isotoxal flat polygon base.\nAn isotoxal right (symmetric) di--gonal bipyramid has two-fold rotation axes through opposite basal vertices, reflection planes through opposite apical edges, an -fold rotation axis through apices, a reflection plane through base, and an -fold rotation-reflection axis through apices, representing symmetry group of order . (The reflection about the base plane corresponds to the rotation-reflection. If is even, then there is an inversion symmetry about the center, corresponding to the rotation-reflection.)\nExample with :\nExample with :\nDouble example:\nIn crystallography, isotoxal right (symmetric) didigonal (8-faced), ditrigonal (12-faced), ditetragonal (16-faced), and dihexagonal (24-faced) bipyramids exist.\nScalenohedra.\nA scalenohedron is similar to a bipyramid; the difference is that the scalenohedra has a zig-zag pattern in the middle edges.\nIt has two apices and basal vertices, faces, and edges; it is topologically identical to a -gonal bipyramid, but its basal vertices alternate in two rings above and below the center.\nAll its faces are congruent scalene triangles, and it is isohedral. It can be seen as another type of a right symmetric di--gonal bipyramid, with a regular zigzag skew polygon base.\nA regular right symmetric di--gonal scalenohedron has two-fold rotation axes through opposite basal mid-edges, reflection planes through opposite apical edges, an -fold rotation axis through apices, and a -fold rotation-reflection axis through apices (about which rotations-reflections globally preserve the solid), representing symmetry group of order . (If is odd, then there is an inversion symmetry about the center, corresponding to the rotation-reflection.)\nExample with :\nExample with :\nFor at most two particular values of formula_11 the faces of such a scalenohedron may be isosceles.\nDouble example:\nIn crystallography, regular right symmetric didigonal (-faced) and ditrigonal (-faced) scalenohedra exist.\nThe smallest geometric scalenohedra have eight faces, and are topologically identical to the regular octahedron. In this case (), in crystallography, a regular right symmetric didigonal (-faced) scalenohedron is called a \"tetragonal scalenohedron\".\nLet us temporarily focus on the regular right symmetric -faced scalenohedra with i.e. \nformula_20\nTheir two apices can be represented as and their four basal vertices as : \nformula_21\nwhere is a parameter between and .\nAt , it is a regular octahedron; at , it has four pairs of coplanar faces, and merging these into four congruent isosceles triangles makes it a disphenoid; for , it is concave.\nIf the -gon base is both isotoxal in-out and zigzag skew, then not all faces of the isotoxal right symmetric scalenohedron are congruent.\nExample with five different edge lengths:\nFor some particular values of , half the faces of such a scalenohedron may be isosceles or equilateral.\nExample with three different edge lengths:\nStar bipyramids.\nA \"star\" bipyramid has a star polygon base, and is self-intersecting.\nA regular right symmetric star bipyramid has congruent isosceles triangle faces, and is isohedral.\nA -bipyramid has Coxeter diagram .\n4-polytopes with bipyramidal cells.\nThe dual of the rectification of each convex regular 4-polytopes is a cell-transitive 4-polytope with bipyramidal cells. In the following:\nThe bipyramid 4-polytope will have vertices where the apices of bipyramids meet. It will have vertices where the type vertices of bipyramids meet. \nAs cells must fit around an edge,\nformula_30\nOther dimensions.\nA generalized -dimensional \"bipyramid\" is any -polytope constructed from an -polytope \"base\" lying in a hyperplane, with every base vertex connected by an edge to two \"apex\" vertices. If the -polytope is a regular polytope and the apices are equidistant from its center along the line perpendicular to the base hyperplane, it will have identical pyramidal facets.\nA 2-dimensional analog of a right symmetric bipyramid is formed by joining two congruent isosceles triangles base-to-base to form a rhombus. More generally, a kite is a 2-dimensional analog of a (possibly asymmetric) right bipyramid, and any quadrilateral is a 2-dimensional analog of a general bipyramid."}
{"id": "4154", "revid": "33618156", "url": "https://en.wikipedia.org/wiki?curid=4154", "title": "Beast of Bodmin Moor", "text": ""}
{"id": "4157", "revid": "11308236", "url": "https://en.wikipedia.org/wiki?curid=4157", "title": "Brown University", "text": "Brown University is a private Ivy League research university in Providence, Rhode Island, United States. It is the seventh-oldest institution of higher education in the US, founded in 1764 as the \"College in the English Colony of Rhode Island and Providence Plantations\". One of nine colonial colleges chartered before the American Revolution, it was the first US college to codify that admission and instruction of students was to be equal regardless of the religious affiliation of students.\nThe university is home to the oldest applied mathematics program in the country and oldest engineering program in the Ivy League. It was one of the early doctoral-granting institutions in the U.S., adding masters and doctoral studies in 1887. In 1969, it adopted its Open Curriculum after student lobbying, which eliminated mandatory general education distribution requirements. In 1971, Brown's coordinate women's institution, Pembroke College, was fully merged into the university.\nThe university comprises the College, the Graduate School, Alpert Medical School, the School of Engineering, the School of Public Health and the School of Professional Studies. Its international programs are organized through the Watson Institute for International and Public Affairs, and it is academically affiliated with the Marine Biological Laboratory and the Rhode Island School of Design, which offers undergraduate and graduate dual degree programs. Brown's main campus is in the College Hill neighborhood of Providence. The university is surrounded by a federally listed architectural district with a concentration of Colonial-era buildings. Benefit Street has one of America's richest concentrations of 17th- and 18th-century architecture. Undergraduate admissions are among the most selective in the country, with an acceptance rate of 5% for the class of 2026.\n, 11 Nobel Prize winners have been affiliated with Brown as alumni, faculty, or researchers, 1 Fields Medalist, 7 National Humanities Medalists, and 11 National Medal of Science laureates. Alumni include 27 Pulitzer Prize winners, 21 billionaires, 4 U.S. Secretaries of State, over 100 members of the United States Congress, 58 Rhodes Scholars, 22 MacArthur Genius Fellows, and 38 Olympic medalists.\nHistory.\nFoundation and charter.\nIn 1761, three residents of Newport, Rhode Island, drafted a petition to the colony's General Assembly:\nThe three petitioners were Ezra Stiles, pastor of Newport's Second Congregational Church and future president of Yale University; William Ellery Jr., future signer of the United States Declaration of Independence; and Josias Lyndon, future governor of the colony. Stiles and Ellery later served as co-authors of the college's charter two years later. The editor of Stiles's papers observes, \"This draft of a petition connects itself with other evidence of Dr. Stiles's project for a Collegiate Institution in Rhode Island, before the charter of what became Brown University.\"\nThe Philadelphia Association of Baptist Churches was also interested in establishing a college in Rhode Island, which was home of the mother church of their denomination. At the time, the Baptists were unrepresented among the colonial colleges; the Congregationalists had Harvard University and Yale University, the Presbyterians had the College of New Jersey, which later became Princeton University, and the Episcopalians had the College of William &amp; Mary and King's College, which later became Columbia University. The local University of Pennsylvania in their native Philadelphia was founded by Benjamin Franklin without direct association with any particular denomination. Isaac Backus, a historian of the New England Baptists and an inaugural trustee of Brown, wrote of the October 1762 resolution taken at Philadelphia:\nJames Manning arrived at Newport in July 1763 and was introduced to Stiles, who agreed to write the charter for the college. Stiles' first draft was read to the General Assembly in August 1763, and rejected by Baptist members who worried that their denomination would be underrepresented in the College Board of Fellows. A revised charter written by Stiles and Ellery was adopted by the Rhode Island General Assembly on March 3, 1764, in East Greenwich.\nIn September 1764, the inaugural meeting of the corporation\u2014the college's governing body\u2014was held in Newport's Old Colony House. Governor Stephen Hopkins was chosen chancellor, former and future governor Samuel Ward vice chancellor, John Tillinghast treasurer, and Thomas Eyres secretary. The charter stipulated that the board of trustees should be composed of 22 Baptists, five Quakers, five Episcopalians, and four Congregationalists. Of the 12 Fellows, eight should be Baptists\u2014including the college president\u2014\"and the rest indifferently of any or all Denominations.\"\nAt the time of its creation, Brown's charter was a uniquely progressive document. Other colleges had curricular strictures against opposing doctrines, while Brown's charter asserted, \"Sectarian differences of opinions, shall not make any Part of the Public and Classical Instruction.\" The document additionally \"recognized more broadly and fundamentally than any other [university charter] the principle of denominational cooperation.\" The oft-repeated statement that Brown's charter alone prohibited a religious test for College membership is inaccurate; other college charters were similarly liberal in that particular.\nThe college was founded as Rhode Island College, at the site of the First Baptist Church in Warren, Rhode Island. Manning was sworn in as the college's first president in 1765 and remained in the role until 1791. In 1766, the college authorized the Reverend Morgan Edwards to travel to Europe to \"solicit Benefactions for this Institution\". During his year-and-a-half stay in the British Isles, Edwards secured funding from benefactors including Thomas Penn and Benjamin Franklin.\nIn 1770, the college moved from Warren to Providence. To establish a campus, John and Moses Brown purchased a four-acre lot on the crest of College Hill on behalf of the school. The majority of the property fell within the bounds of the original home lot of Chad Brown, an ancestor of the Browns and one of the original proprietors of Providence Plantations. After the college was relocated to the city, work began on constructing its first building.\nA building committee, organized by the corporation, developed plans for the college's first purpose-built edifice, finalizing a design on February 9, 1770. The subsequent structure, referred to as \"The College Edifice\" and later as University Hall, may have been modeled on Nassau Hall, built 14 years prior at the College of New Jersey. President Manning, an active member of the building process, was educated at Princeton and might have suggested that Brown's first building resemble that of his alma mater.\nBrown family.\nNicholas Brown, John Brown, Joseph Brown, and Moses Brown were instrumental in moving the college to Providence, constructing its first building, and securing its endowment. Joseph became a professor of natural philosophy at the college; John served as its treasurer from 1775 to 1796; and Nicholas Sr's son Nicholas Brown Jr. succeeded his uncle as treasurer from 1796 to 1825.\nOn September 8, 1803, the corporation voted, \"That the donation of $5,000, if made to this College within one Year from the late Commencement, shall entitle the donor to name the College.\" The following year, the appeal was answered by College Treasurer Nicholas Brown Jr. In a letter dated September 6, 1804, Brown committed \"a donation of Five Thousand Dollars to Rhode Island College, to remain in perpetuity as a fund for the establishment of a Professorship of Oratory and Belles Letters.\" In recognition of the gift, the corporation on the same day voted, \"That this College be called and known in all future time by the Name of Brown University.\" Over the years, the benefactions of Nicholas Brown Jr., totaled nearly $160,000 and included funds for building Hope College (1821\u201322) and Manning Hall (1834\u201335).\nIn 1904, the John Carter Brown Library was established as an independently funded research library on Brown's campus; the library's collection was founded on that of John Carter Brown, son of Nicholas Brown Jr.\nThe Brown family was involved in various business ventures in Rhode Island, and accrued wealth both directly and indirectly from the transatlantic slave trade. The family was divided on the issue of slavery. John Brown had defended slavery, while Moses and Nicholas Brown Jr. were fervent abolitionists.\nIn 2003, under the tenure of President Ruth Simmons, the university established a steering committee to investigate these ties of the university to slavery and recommend a strategy to address them.\nAmerican Revolution.\nWith British vessels patrolling Narragansett Bay in the fall of 1776, the college library was moved out of Providence for safekeeping. During the subsequent American Revolutionary War, Brown's University Hall was used to house French and other revolutionary troops led by General George Washington and the Comte de Rochambeau as they waited to commence the march of 1781 that led to the Siege of Yorktown and the Battle of the Chesapeake. This has been celebrated as marking the defeat of the British and the end of the war. The building functioned as barracks and hospital from December 10, 1776, to April 20, 1780, and as a hospital for French troops from June 26, 1780, to May 27, 1782.\nA number of Brown's founders and alumni played roles in the American Revolution and subsequent founding of the United States. Brown's first chancellor, Stephen Hopkins, served as a delegate to the Colonial Congress in Albany in 1754, and to the Continental Congress from 1774 to 1776. James Manning represented Rhode Island at the Congress of the Confederation, while concurrently serving as Brown's first president. Two of Brown's founders, William Ellery and Stephen Hopkins signed the Declaration of Independence.\nJames Mitchell Varnum, who graduated from Brown with honors in 1769, served as one of General George Washington's Continental Army brigadier generals and later as major general in command of the entire Rhode Island militia. Varnum is noted as the founder and commander of the 1st Rhode Island Regiment, widely regarded as the first Black battalion in U.S. military history. David Howell, who graduated with an A.M. in 1769, served as a delegate to the Continental Congress from 1782 to 1785.\nPresidents.\nNineteen individuals have served as presidents of the university since its founding in 1764. Since 2012, Christina Hull Paxson has served as president. Paxson had previously served as dean of Princeton University's School of Public and International Affairs and chair of Princeton's economics department. Paxson's immediate predecessor, Ruth Simmons, is noted as the first African American president of an Ivy League institution. Other presidents of note include academic, Vartan Gregorian; and philosopher and economist, Francis Wayland.\nNew Curriculum.\nIn 1966, the first Group Independent Study Project (GISP) at Brown was formed, involving 80 students and 15 professors. The GISP was inspired by student-initiated experimental schools, especially San Francisco State College, and sought ways to \"put students at the center of their education\" and \"teach students how to think rather than just teaching facts\".\nMembers of the GISP, Ira Magaziner and Elliot Maxwell published a paper of their findings titled, \"Draft of a Working Paper for Education at Brown University.\" The paper made proposals for a new curriculum, including interdisciplinary freshman-year courses that would introduce \"modes of thought,\" with instruction from faculty from different disciplines as well as for an end to letter grades. The following year Magaziner began organizing the student body to press for the reforms, organizing discussions and protests.\nIn 1968, university president Ray Heffner established a Special Committee on Curricular Philosophy. Composed of administrators, the committee was tasked with developing specific reforms and producing recommendations. A report, produced by the committee, was presented to the faculty, which voted the New Curriculum into existence on May 7, 1969. Its key features included:\nThe Modes of Thought course was discontinued early on, but the other elements remain in place. In 2006, the reintroduction of plus/minus grading was proposed in response to concerns regarding grade inflation. The idea was rejected by the College Curriculum Council after canvassing alumni, faculty, and students, including the original authors of the Magaziner-Maxwell Report.\n\"Slavery and Justice\" report.\nIn 2003, then-university president Ruth Simmons launched a steering committee to research Brown's eighteenth-century ties to slavery. In October 2006, the committee released a report documenting its findings.\nTitled \"Slavery and Justice\", the document detailed the ways in which the university benefited both directly and indirectly from the transatlantic slave trade and the labor of enslaved people. The report also included seven recommendations for how the university should address this legacy. Brown has since completed a number of these recommendations including the establishment of its Center for the Study of Slavery and Justice, the construction of its \"Slavery Memorial\", and the funding of a $10 million permanent endowment for Providence Public Schools.\nThe Slavery and Justice report marked the first major effort by an American university to address its ties to slavery and prompted other institutions to undertake similar processes.\nCoat of arms.\nBrown's coat of arms was created in 1834. The prior year, president Francis Wayland had commissioned a committee to update the school's original seal to match the name the university had adopted in 1804. Central in the coat of arms is a white escutcheon divided into four sectors by a red cross. Within each sector of the coat of arms lies an open book. Above the shield is a crest consisting of the upper half of a sun in splendor among the clouds atop a red and white torse.\nCampus.\nBrown is the largest institutional landowner in Providence, with properties on College Hill and in the Jewelry District. The university was built contemporaneously with the eighteenth and nineteenth-century precincts surrounding it, making Brown's campus tightly integrated into Providence's urban fabric. Among the noted architects who have shaped Brown's campus are McKim, Mead &amp; White, Philip Johnson, Rafael Vi\u00f1oly, Diller Scofidio + Renfro, and Robert A. M. Stern.\nMain campus.\nBrown's main campus, comprises 235 buildings and in the East Side neighborhood of College Hill. The university's central campus sits on a block bounded by Waterman, Prospect, George, and Thayer Streets; newer buildings extend northward, eastward, and southward. Brown's core, historic campus, constructed primary between 1770 and 1926, is defined by three greens: the Front or Quiet Green, the Middle or College Green, and the Ruth J. Simmons Quadrangle (historically known as Lincoln Field). A brick and wrought-iron fence punctuated by decorative gates and arches traces the block's perimeter. This section of campus is primarily Georgian and Richardsonian Romanesque in its architectural character.\nTo the south of the central campus are academic buildings and residential quadrangles, including Wriston, Keeney, and Gregorian quadrangles. Immediately to the east of the campus core sit Sciences Park and Brown's School of Engineering. North of the central campus are performing and visual arts facilities, life sciences labs, and the Pembroke Campus, which houses both dormitories and academic buildings. Facing the western edge of the central campus sit two of the Brown's seven libraries, the John Hay Library and the John D. Rockefeller Jr. Library.\nThe university's campus is contiguous with that of the Rhode Island School of Design, which is located immediately to Brown's west, along the slope of College Hill.\nVan Wickle Gates.\nBuilt in 1901, the Van Wickle Gates are a set of wrought iron gates that stand at the western edge of Brown's campus. The larger main gate is flanked by two smaller side gates. At Convocation the central gate opens inward to admit the procession of new students; at Commencement, the gate opens outward for the procession of graduates. A Brown superstition holds that students who walk through the central gate a second time prematurely will not graduate, although walking backward is said to cancel the hex.\nJohn Hay Library.\nThe John Hay Library is the second oldest library on campus. Opened in 1910, the library is named for John Hay (class of 1858), private secretary to Abraham Lincoln and Secretary of State under William McKinley and Theodore Roosevelt. The construction of the building was funded in large part by Hay's friend, Andrew Carnegie, who contributed half of the $300,000 cost of construction.\nThe John Hay Library serves as the repository of the university's archives, rare books and manuscripts, and special collections. Noteworthy among the latter are the Anne S. K. Brown Military Collection (described as \"the foremost American collection of material devoted to the history and iconography of soldiers and soldiering\"), the Harris Collection of American Poetry and Plays (described as \"the largest and most comprehensive collection of its kind in any research library\"), the Lownes Collection of the History of Science (described as \"one of the three most important private collections of books of science in America\"), and the papers of H. P. Lovecraft. The Hay Library is home to one of the broadest collections of incunabula in the Americas, one of Brown's two Shakespeare First Folios, the manuscript of George Orwell's \"Nineteen Eighty-Four,\" and three books bound in human skin.\nJohn Carter Brown Library.\nFounded in 1846, the John Carter Brown Library is generally regarded as the world's leading collection of primary historical sources relating to the exploration and colonization of the Americas. While administered and funded separately from the university, the library has been owned by Brown and located on its campus since 1904.\nThe library contains the best preserved of the eleven surviving copies of the Bay Psalm Book\u2014the earliest extant book printed in British North America and the most expensive printed book in the world. Other holdings include a Shakespeare First Folio and the world's largest collection of 16th-century Mexican texts.\nHaffenreffer Museum.\nThe exhibition galleries of the Haffenreffer Museum of Anthropology, Brown's teaching museum, are located in Manning Hall on the campus's main green. Its one million artifacts, available for research and educational purposes, are located at its Collections Research Center in Bristol, Rhode Island. The museum's goal is to inspire creative and critical thinking about culture by fostering an interdisciplinary understanding of the material world. It provides opportunities for faculty and students to work with collections and the public, teaching through objects and programs in classrooms and exhibitions. The museum sponsors lectures and events in all areas of anthropology and also runs an extensive program of outreach to local schools.\nAnnmary Brown Memorial.\nThe Annmary Brown Memorial was constructed from 1903 to 1907 by the politician, Civil War veteran, and book collector General Rush Hawkins, as a mausoleum for his wife, Annmary Brown, a member of the Brown family. In addition to its crypt\u2014the final repository for Brown and Hawkins\u2014the Memorial includes works of art from Hawkins's private collection, including paintings by Angelica Kauffman, Peter Paul Rubens, Gilbert Stuart, Giovanni Battista Tiepolo, Benjamin West, and Eastman Johnson, among others. His collection of over 450 incunabula was relocated to the John Hay Library in 1990. Today the Memorial is home to Brown's Medieval Studies and Renaissance Studies programs.\nThe Walk.\nThe Walk, a landscaped pedestrian corridor, connects the Pembroke Campus to the main campus. It runs parallel to Thayer Street and serves as a primary axis of campus, extending from Ruth Simmons Quadrangle at its southern terminus to the Meeting Street entrance to the Pembroke Campus at its northern end. The walk is bordered by departmental buildings as well as the Lindemann Performing Arts Center and Granoff Center for the Creative Arts\nThe corridor is home to public art including sculptures by Maya Lin and Tom Friedman.\nPembroke campus.\nThe Women's College in Brown University, known as Pembroke College, was founded in October 1891. Upon its 1971 merger with the College of Brown University, Pembroke's campus was absorbed into the larger Brown campus. The Pembroke campus is bordered by Meeting, Brown, Bowen, and Thayer Streets and sits three blocks north of Brown's central campus. The campus is dominated by brick architecture, largely of the Georgian and Victorian styles. The west side of the quadrangle comprises Pembroke Hall (1897), Smith-Buonanno Hall (1907), and Metcalf Hall (1919), while the east side comprises Alumnae Hall (1927) and Miller Hall (1910). The quadrangle culminates on the north with Andrews Hall (1947).\nEast Campus, centered on Hope and Charlesfield streets, originally served as the campus of Bryant University. In 1969, as Bryant was preparing to relocate to Smithfield, Rhode Island, Brown purchased their Providence campus for $5 million. The transaction expanded the Brown campus by and 26 buildings. In 1971, Brown renamed the area East Campus. Today, the area is largely used for dormitories.\nThayer Street runs through Brown's main campus. As a commercial corridor frequented by students, Thayer is comparable to Harvard Square or Berkeley's Telegraph Avenue. Wickenden Street, in the adjacent Fox Point neighborhood, is another commercial street similarly popular among students.\nBuilt in 1925, Brown Stadium\u2014the home of the school's football team\u2014is located approximately a mile and a half northeast of the university's central campus. Marston Boathouse, the home of Brown's crew teams, lies on the Seekonk River, to the southeast of campus. Brown's sailing teams are based out of the Ted Turner Sailing Pavilion at the Edgewood Yacht Club in adjacent Cranston.\nSince 2011, Brown's Warren Alpert Medical School has been located in Providence's historic Jewelry District, near the medical campus of Brown's teaching hospitals, Rhode Island Hospital and the Women and Infants Hospital of Rhode Island. Other university facilities, including molecular medicine labs and administrative offices, are likewise located in the area.\nBrown's School of Public Health occupies a landmark modernist building along the Providence River. Other Brown properties include the Mount Hope Grant in Bristol, Rhode Island, an important Native American site noted as a location of King Philip's War. Brown's Haffenreffer Museum of Anthropology Collection Research Center, particularly strong in Native American items, is located in the Mount Hope Grant.\nSustainability.\nBrown has committed to \"minimize its energy use, reduce negative environmental impacts, and promote environmental stewardship.\" Since 2010, the university has required all new buildings meet LEED silver standards. Between 2007 and 2018, Brown reduced its greenhouse emissions by 27 percent; the majority of this reduction is attributable to the university's Thermal Efficiency Project which converted its central heating plant from a steam-powered system to a hot water-powered system.\nIn 2020, Brown announced it had sold 90 percent of its fossil fuel investments as part of a broader divestment from direct investments and managed funds that focus on fossil fuels. In 2021, the university adopted the goal of reducing quantifiable campus emissions by 75 percent by 2025 and achieving carbon neutrality by 2040. Brown is a member of the Ivy Plus Sustainability Consortium, through which it has committed to best-practice sharing and the ongoing exchange of campus sustainability solutions along with other member institutions.\nAccording to the A. W. Kuchler U.S. potential natural vegetation types, Brown would have a dominant vegetation type of Appalachian Oak (\"104\") with a dominant vegetation form of Eastern Hardwood Forest (\"25\").\nAcademics.\nThe College.\nFounded in 1764, The College is Brown's oldest school. About 7,200 undergraduate students are enrolled in the college , and 81 concentrations are offered. For the graduating class of 2020, the most popular concentrations were Computer Science, Economics, Biology, History, Applied Mathematics, International Relations, and Political Science. A quarter of Brown undergraduates complete more than one concentration before graduating. If the existing programs do not align with their intended curricular interests, undergraduates may design and pursue independent concentrations.\nAround 35 percent of undergraduates pursue graduate or professional study immediately, 60 percent within 5 years, and 80 percent within 10 years. For the Class of 2009, 56 percent of all undergraduate alumni have since earned graduate degrees. Among undergraduate alumni who go on to receive graduate degrees, the most common degrees earned are J.D. (16%), M.D. (14%), M.A. (14%), M.Sc. (14%), and Ph.D. (11%). The most common institutions from which undergraduate alumni earn graduate degrees are Brown University, Columbia University, and Harvard University.\nThe highest fields of employment for undergraduate alumni ten years after graduation are education and higher education (15%), medicine (9%), business and finance (9%), law (8%), and computing and technology (7%).\nBrown and RISD.\nSince its 1893 relocation to College Hill, Rhode Island School of Design (RISD) has bordered Brown to its west. Since 1900, Brown and RISD students have been able to cross-register at the two institutions, with Brown students permitted to take as many as four courses at RISD to count towards their Brown degree. The two institutions partner to provide various student-life services and the two student bodies compose a synergy in the College Hill cultural scene.\nDual Degree Program.\nAfter several years of discussion between the two institutions and several students pursuing dual degrees unofficially, Brown and RISD formally established a five-year dual degree program in 2007, with the first class matriculating in the fall of 2008. The Brown|RISD Dual Degree Program, among the most selective in the country, offered admission to 20 of the 725 applicants for the class entering in autumn 2020, for an acceptance rate of 2.7%. The program combines the complementary strengths of the two institutions, integrating studio art and design at RISD with Brown's academic offerings. Students are admitted to the Dual Degree Program for a course lasting five years and culminating in both the Bachelor of Arts (A.B.) or Bachelor of Science (Sc.B.) degree from Brown and the Bachelor of Fine Arts (B.F.A.) degree from RISD. Prospective students must apply to the two schools separately and be accepted by separate admissions committees. Their application must then be approved by a third Brown|RISD joint committee.\nAdmitted students spend the first year in residence at RISD completing its first-year Experimental and Foundation Studies curriculum while taking up to three Brown classes. Students spend their second year in residence at Brown, during which students take mainly Brown courses while starting on their RISD major requirements. In the third, fourth, and fifth years, students can elect to live at either school or off-campus, and course distribution is determined by the requirements of each student's unique combination of Brown concentration and RISD major. Program participants are noted for their creative and original approach to cross-disciplinary opportunities, combining, for example, industrial design with engineering, or anatomical illustration with human biology, or philosophy with sculpture, or architecture with urban studies. An annual \"BRDD Exhibition\" is a well-publicized and heavily attended event, drawing interest and attendees from the broader world of industry, design, the media, and the fine arts.\nMADE Program.\nIn 2020, the two schools announced the establishment of a new joint Master of Arts in Design Engineering program. Abbreviated as MADE, the program intends to combine RISD's programs in industrial design with Brown's programs in engineering. The program is administered through Brown's School of Engineering and RISD's Architecture and Design Division.\nTheatre and playwriting.\nBrown's theatre and playwriting programs are among the best-regarded in the country. Six Brown graduates have received the Pulitzer Prize for Drama; Alfred Uhry '58, Lynn Nottage '86, Ayad Akhtar '93, Nilo Cruz '94, Quiara Alegr\u00eda Hudes '04, and Jackie Sibblies Drury MFA '04. In \"American Theater\" magazine's 2009 ranking of the most-produced American plays, Brown graduates occupied four of the top five places\u2014Peter Nachtrieb '97, Rachel Sheinkin '89, Sarah Ruhl '97, and Stephen Karam '02.\nThe undergraduate concentration encompasses programs in theatre history, performance theory, playwriting, dramaturgy, acting, directing, dance, speech, and technical production. Applications for doctoral and master's degree programs are made through the University Graduate School. Master's degrees in acting and directing are pursued in conjunction with the Brown/Trinity Rep MFA program, which partners with the Trinity Repertory Company, a local regional theatre.\nWriting programs.\nWriting at Brown\u2014fiction, non-fiction, poetry, playwriting, screenwriting, electronic writing, mixed media, and the undergraduate writing proficiency requirement\u2014is catered for by various centers and degree programs, and a faculty that has long included nationally and internationally known authors. The undergraduate concentration in literary arts offers courses in fiction, poetry, screenwriting, literary hypermedia, and translation. Graduate programs include the fiction and poetry MFA writing programs in the literary arts department and the MFA playwriting program in the theatre arts and performance studies department. The non-fiction writing program is offered in the English department. Screenwriting and cinema narrativity courses are offered in the departments of literary arts and modern culture and media. The undergraduate writing proficiency requirement is supported by the Writing Center.\nAuthor prizewinners.\nAlumni authors take their degrees across the spectrum of degree concentrations, but a gauge of the strength of writing at Brown is the number of major national writing prizes won. To note only winners since the year 2000: Pulitzer Prize for Fiction-winners Jeffrey Eugenides '82 (2003), Marilynne Robinson '66 (2005), and Andrew Sean Greer '92 (2018); British Orange Prize-winners Marilynne Robinson '66 (2009) and Madeline Miller '00 (2012); Pulitzer Prize for Drama-winners Nilo Cruz '94 (2003), Lynn Nottage '86 (twice, 2009, 2017), Quiara Alegr\u00eda Hudes '04 (2012), Ayad Akhtar '93 (2013), and Jackie Sibblies Drury MFA '04 (2019); Pulitzer Prize for Biography-winners David Kertzer '69 (2015) and Benjamin Moser '98 (2020); Pulitzer Prize for Journalism-winners James Risen '77 (2006), Gareth Cook '91 (2005), Tony Horwitz '80 (1995), Usha Lee McFarling '89 (2007), David Rohde '90 (1996), Kathryn Schulz '96 (2016), and Alissa J. Rubin '80 (2016); Pulitzer Prize for General Nonfiction-winner James Forman Jr. '88 (2018); Pulitzer Prize for History-winner Marcia Chatelain PhD '08 (2021); Pulitzer Prize for Criticism-winner Salamishah Tillet MAT '97 (2022); and Pulitzer Prize for Poetry-winner Peter Balakian PhD '80 (2016)\nComputer science.\nBrown began offering computer science courses through the departments of Economics and Applied Mathematics in 1956 when it acquired an IBM machine. Brown added an IBM 650 in January 1958, the only one of its type between Hartford and Boston. In 1960, Brown opened its first dedicated computer building, the Brown University Computing Laboratory. The facility, designed by Philip Johnson, received an IBM 7070 computer the following year. The first undergraduate Computer Science degrees were awarded in 1974. Brown granted computer sciences full Departmental status in 1979. In 2009, IBM and Brown announced the installation of a supercomputer (by teraflops standards), the most powerful in the southeastern New England region.\nIn the 1960s, Andries van Dam, along with Ted Nelson and Bob Wallace invented The Hypertext Editing Systems, HES and FRESS while at Brown. Nelson coined the word \"hypertext\" while Van Dam's students helped originate XML, XSLT, and related Web standards. Among the school's computer science alumni are principal architect of the Classic Mac OS, Andy Hertzfeld; principal architect of the Intel 80386 and Intel 80486 microprocessors, John Crawford; former CEO of Apple, John Sculley; and digital effects programmer Masi Oka. Other alumni include former CS department head at MIT, John Guttag; software-defined networking pioneer Scott Shenker; Workday founder, Aneel Bhusri; MongoDB founder Eliot Horowitz; Figma founders Dylan Field and Evan Wallace (the latter of whom also created esbuild); OpenSea founder Devin Finzer; and Edward D. Lazowska, professor and Bill &amp; Melinda Gates Foundation Chair emeritus at the University of Washington.\nBetween 2012 and 2018, the number of concentrators in CS tripled. In 2017, computer science overtook economics as the school's most popular undergraduate concentration.\nApplied mathematics.\nBrown's program in applied mathematics was established in 1941 making it the oldest such program in the United States. The division is highly ranked and regarded nationally. Among the 67 recipients of the Timoshenko Medal, 22 have been affiliated with Brown's applied mathematics division as faculty, researchers, or students.\nThe Joukowsky Institute for Archaeology and the Ancient World.\nEstablished in 2004, the Joukowsky Institute for Archaeology and the Ancient World is Brown's interdisciplinary research center for archeology and ancient studies. The institute pursues fieldwork, excavations, regional surveys, and academic study of the archaeology and art of the ancient Mediterranean, Egypt, and Western Asia from the Levant to the Caucasus. The institute has a very active fieldwork profile, with faculty-led excavations and regional surveys presently in Petra (Jordan), Abydos (Egypt), Turkey, Sudan, Italy, Mexico, Guatemala, Montserrat, and Providence.\nThe Joukowsky Institute's faculty includes cross-appointments from the departments of Egyptology, Assyriology, Classics, Anthropology, and History of Art and Architecture. Faculty research and publication areas include Greek and Roman art and architecture, landscape archaeology, urban and religious architecture of the Levant, Roman provincial studies, the Aegean Bronze Age, and the archaeology of the Caucasus. The institute offers visiting teaching appointments and postdoctoral fellowships which have, in recent years, included Near Eastern Archaeology and Art, Classical Archaeology and Art, Islamic Archaeology and Art, and Archaeology and Media Studies.\nEgyptology and Assyriology\nFacing the Joukowsky Institute, across the Front Green, is the Department of Egyptology and Assyriology, formed in 2006 by the merger of Brown's departments of Egyptology and History of Mathematics. It is one of only a handful of such departments in the United States. The curricular focus is on three principal areas: Egyptology, Assyriology, and the history of the ancient exact sciences (astronomy, astrology, and mathematics). Many courses in the department are open to all Brown undergraduates without prerequisites and include archaeology, languages, history, and Egyptian and Mesopotamian religions, literature, and science. Students concentrating in the department choose a track of either Egyptology or Assyriology. Graduate-level study comprises three tracks to the doctoral degree: Egyptology, Assyriology, or the History of the Exact Sciences in Antiquity.\nThe Watson Institute for International and Public Affairs.\nThe Watson Institute for International and Public Affairs, Brown's center for the study of global Issues and public affairs, is one of the leading institutes of its type in the country. The institute occupies facilities designed by Uruguayan architect Rafael Vi\u00f1oly and Japanese architect Toshiko Mori. The institute was initially endowed by Thomas Watson Jr. (Class of 1937), former Ambassador to the Soviet Union and longtime president of IBM.\nInstitute faculty and faculty emeritus include Italian prime minister and European Commission president Romano Prodi, Brazilian president Fernando Henrique Cardoso, Chilean president Ricardo Lagos Escobar, Mexican novelist and statesman Carlos Fuentes, Brazilian statesman and United Nations commission head Paulo S\u00e9rgio Pinheiro, Indian foreign minister and ambassador to the United States Nirupama Rao, American diplomat and Dayton Peace Accords author Richard Holbrooke (Class of 1962), and Sergei Khrushchev, editor of the papers of his father Nikita Khrushchev, leader of the Soviet Union.\nThe institute's curricular interest is organized into the principal themes of development, security, and governance\u2014with further focuses on globalization, economic uncertainty, security threats, environmental degradation, and poverty. Six Brown undergraduate concentrations are hosted by the Watson Institute: Development Studies, International and Public Affairs, International Relations, Latin American and Caribbean Studies, Middle East Studies, Public Policy, and South Asian Studies. Graduate programs offered at the Watson Institute include the Graduate Program in Development (Ph.D.) and the Master of Public Affairs (M.P.A) Program. The institute also offers postdoctoral, professional development, and global outreach programming. In support of these programs, the institute houses various centers, including the Brazil Initiative, Brown-India Initiative, China Initiative, Middle East Studies Center, The Center for Latin American and Caribbean Studies (CLACS), and the Taubman Center for Public Policy. In recent years, the most internationally cited product of the Watson Institute has been its Costs of War Project, first released in 2011 and continuously updated since. The project comprises a team of economists, anthropologists, political scientists, legal experts, and physicians, and seeks to calculate the economic costs, human casualties, and impact on civil liberties of the wars in Iraq, Afghanistan, and Pakistan since 2001.\nThe School of Engineering.\nEstablished in 1847, Brown's engineering program is the oldest in the Ivy League and the third oldest civilian engineering program in the country. In 1916, Brown's departments of electrical, mechanical, and civil engineering were merged into a single Division of Engineering. In 2010 the division was elevated to a School of Engineering.\nEngineering at Brown is especially interdisciplinary. The school is organized without the traditional departments or boundaries found at most schools and follows a model of connectivity between disciplines\u2014including biology, medicine, physics, chemistry, computer science, the humanities, and the social sciences. The school practices an innovative clustering of faculties in which engineers team with non-engineers to bring a convergence of ideas.\nStudent teams have launched two CubeSats with the support of the School of Engineering. Brown Space Engineering developed EQUiSat a 1U satellite, and another interdisciplinary team developed SBUDNIC a 3U satellite.\nIE Brown Executive MBA Dual Degree Program.\nSince 2009, Brown has developed an Executive MBA program in conjunction with one of the leading Business Schools in Europe, IE Business School in Madrid. This relationship has since strengthened resulting in both institutions offering a dual degree program. In this partnership, Brown provides its traditional coursework while IE provides most of the business-related subjects making a differentiated alternative program to other Ivy League's EMBAs. The cohort typically consists of 25\u201330 EMBA candidates from some 20 countries. Classes are held in Providence, Madrid, Cape Town and Online.\nThe Pembroke Center.\nThe Pembroke Center for Teaching and Research on Women was established at Brown in 1981 by Joan Wallach Scott as an interdisciplinary research center on gender. The center is named for Pembroke College, Brown's former women's college, and is affiliated with Brown's Sarah Doyle Women's Center. The Pembroke Center supports Brown's undergraduate concentration in Gender and Sexuality Studies, post-doctoral research fellowships, the annual Pembroke Seminar, and other academic programs. It also manages various collections, archives, and resources, including the Elizabeth Weed Feminist Theory Papers and the Christine Dunlap Farnham Archive.\nThe Graduate School.\nBrown introduced graduate courses in the 1870s and granted its first advanced degrees in 1888. The university established a Graduate Department in 1903 and a full Graduate School in 1927.\nWith an enrollment of approximately 2,600 students, the school currently offers 33 and 51 master's and doctoral programs, respectively. The school additionally offers a number of fifth-year master's programs. Overall, admission to the Graduate School is most competitive with an acceptance rate averaging at approximately 9 percent in recent years.\nCarney Institute for Brain Science.\nThe Robert J. &amp; Nancy D. Carney Institute for Brain Science is Brown's cross-departmental neuroscience research institute. The institute's core focus areas include brain-computer interfaces and computational neuroscience; additional areas of focus include research into mechanisms of cell death with the interest of developing therapies for neurodegenerative diseases.\nThe Carney Institute was founded by John Donoghue in 2009 as the Brown Institute for Brain Science and renamed in 2018 in recognition of a $100 million gift. The donation, one of the largest in the university's history, established the institute as one of the best-endowed university neuroscience programs in the country.\nAlpert Medical School.\nEstablished in 1811, Brown's Alpert Medical School is the fourth oldest medical school in the Ivy League.\nIn 1827, medical instruction was suspended by President Francis Wayland after the program's faculty declined to follow a new policy requiring students to live on campus. The program was reorganized in 1972; the first M.D. degrees from the new Program in Medicine were awarded to a graduating class of 58 students in 1975. In 1991, the school was officially renamed the Brown University School of Medicine, then renamed once more to Brown Medical School in October 2000. In January 2007, entrepreneur and philanthropist Warren Alpert donated $100 million to the school. In recognition of the gift, the school's name was changed to the Warren Alpert Medical School of Brown University.\nIn 2020, \"U.S. News &amp; World Report\" ranked Brown's medical school the 9th most selective in the country, with an acceptance rate of 2.8%. \"U.S. News\" ranks the school 38th for research and 35th for primary care.\nBrown's medical school is known especially for its eight-year Program in Liberal Medical Education (PLME), an eight-year combined baccalaureate-M.D. medical program. Inaugurated in 1984, the program is one of the most selective and renowned programs of its type in the country, offering admission to only 2% of applicants in 2021.\nSince 1976, the Early Identification Program (EIP) has encouraged Rhode Island residents to pursue careers in medicine by recruiting sophomores from Providence College, Rhode Island College, the University of Rhode Island, and Tougaloo College. In 2004, the school once again began to accept applications from premedical students at other colleges and universities via AMCAS like most other medical schools. The medical school also offers M.D./PhD, M.D./M.P.H. and M.D./M.P.P. dual degree programs.\nSchool of Public Health.\nBrown's School of Public Health grew out of the Alpert Medical School's Department of Community Health and was officially founded in 2013 as an independent school. The school issues undergraduate (A.B., Sc.B.), graduate (M.P.H., Sc.M., A.M.), doctoral (Ph.D.), and dual-degrees (M.P.H./M.P.A., M.D./M.P.H.).\nOnline programs.\nThe Brown University School of Professional Studies currently offers blended learning Executive master's degrees in Healthcare Leadership, Cyber Security, and Science and Technology Leadership. The master's degrees are designed to help students who have a job and life outside of academia to progress in their respective fields. The students meet in Providence every 6\u20137 weeks for a weekly seminar each trimester.\nThe university has also invested in MOOC development starting in 2013, when two courses, \"Archeology's Dirty Little Secrets\" and \"The Fiction of Relationship\", both of which received thousands of students. However, after a year of courses, the university broke its contract with Coursera and revamped its online persona and MOOC development department. By 2017, the university released new courses on edx, two of which were \"The Ethics of Memory\" and \"Artful Medicine: Art's Power to Enrich Patient Care\". In January 2018, Brown published its first \"game-ified\" course called \"Fantastic Places, Unhuman Humans: Exploring Humanity Through Literature\", which featured out-of-platform games to help learners understand materials, as well as a story-line that immerses users into a fictional world to help characters along their journey.\nAdmissions and financial aid.\nUndergraduate.\nUndergraduate admission to Brown University is considered \"most selective\" by \"U.S. News &amp; World Report.\" For the undergraduate class of 2026, Brown received 50,649 applications\u2014the largest applicant pool in the university's history and a 9% increase from the prior year. Of these applicants, 2,560 were admitted for an acceptance rate of 5.0%, the lowest in the university's history.\nIn 2021, the university reported a yield rate of 69%. For the academic year 2019\u201320 the university received 2,030 transfer applications, of which 5.8% were accepted.\nBrown's admissions policy is currently stipulated need-blind for all domestic first-year applicants, but will be extended to international first-year applicants starting with the Class of 2029. In 2017, Brown announced that loans would be eliminated from all undergraduate financial aid awards starting in 2018\u20132019, as part of a new $30 million campaign called the \"Brown Promise\". In 2016\u201317, the university awarded need-based scholarships worth $120.5 million. The average need-based award for the class of 2020 was $47,940.\nGraduate.\nIn 2017, the Graduate School accepted 11% of 9,215 applicants. In 2021, Brown received a record 948 applications for roughly 90 spots in its Master of Public Health Degree.\nIn 2020, \"U.S. News\" ranked Brown's Warren Alpert Medical School the 9th most selective in the country, with an acceptance rate of 2.8 percent.\nRankings.\nBrown University is accredited by the New England Commission of Higher Education. For their 2021 rankings, The Wall Street Journal/Times Higher Education ranked Brown 5th in the \"Best Colleges 2021\" edition.\nThe \"Forbes\" magazine annual ranking of \"America's Top Colleges 2022\"\u2014which ranked 600 research universities, liberal arts colleges and service academies\u2014ranked Brown 19th overall and 18th among universities.\n\"U.S. News &amp; World Report\" ranked Brown 9th among national universities in its 2023 edition. The 2022 edition also ranked Brown 2nd for undergraduate teaching, 25th in Most Innovative Schools, and 14th in Best Value Schools.\n\"Washington Monthly\" ranked Brown 40th in 2022 among 442 national universities in the U.S. based on its contribution to the public good, as measured by social mobility, research, and promoting public service.\nIn 2022, \"U.S. News &amp; World Report\" ranks Brown 129th globally.\nIn 2014, \"Forbes\" magazine ranked Brown 7th on its list of \"America's Most Entrepreneurial Universities.\" The \"Forbes\" analysis looked at the ratio of \"alumni and students who have identified themselves as founders and business owners on LinkedIn\" and the total number of alumni and students. LinkedIn particularized the \"Forbes\" rankings, placing Brown third (between MIT and Princeton) among \"Best Undergraduate Universities for Software Developers at Startups.\" LinkedIn's methodology involved a career-path examination of \"millions of alumni profiles\" in its membership database.\nIn 2016, 2017, 2018, and 2021 the university produced the most Fulbright recipients of any university in the nation. Brown has also produced the 7th most Rhodes Scholars of all colleges and universities in the United States.\nResearch.\nBrown is a member of the Association of American Universities since 1933 and is classified among \"R1: Doctoral Universities \u2013 Very High Research Activity\". In FY 2017, Brown spent $212.3 million on research and was ranked 103rd in the United States by total R&amp;D expenditure by National Science Foundation. In 2021 Brown's School of Public Health received the 4th most funding in NIH awards among schools of public health in the U.S.\nStudent life.\nCampus safety.\nIn 2014, Brown tied with the University of Connecticut for the highest number of reported rapes in the nation, with its \"total of reports of rape\" on their main campus standing at 43. However, such rankings have been criticized for failing to account for how different campus environments can encourage or discourage individuals from reporting sexual assault cases, thereby affecting the number of reported rapes.\nSpring weekend.\nEstablished in 1950, Spring Weekend is an annual spring music festival for students. Historical performers at the festival have included Ella Fitzgerald, Dizzy Gillespie, Ray Charles, Bob Dylan, Janis Joplin, Bruce Springsteen, and U2. More recent headliners include Kendrick Lamar, Young Thug, Daniel Caesar, Anderson .Paak, Mitski, Amin\u00e9, and Mac DeMarco. Since 1960, Spring Weekend has been organized by the student-run Brown Concert Agency.\nResidential and Greek societies.\nApproximately 12 percent of Brown students participate in Greek Life. The university recognizes thirteen active Greek organizations. Since the early 1950s, all Greek organizations on campus have been located in Wriston Quadrangle.\nSocieties and clubs.\nThe earliest societies at Brown were devoted to oration and debate. The Pronouncing Society is mentioned in the diary of Solomon Drowne, class of 1773, who was voted its president in 1771. The organization seems to have disappeared during the American Revolutionary War. Subsequent societies include the Misokosmian Society (est. 1798 and renamed the Philermenian Society), the Philandrian Society (est. 1799), the United Brothers (1806), the Philophysian Society (1818), and the Franklin Society (1824). Societies served social as well as academic purposes, with many supporting literary debate and amassing large libraries. Older societies generally aligned with Federalists while younger societies generally leaned Republican.\nSocieties remained popular into the 1860s, after which they were largely replaced by fraternities.\nThe Cammarian Club was at first a semi-secret society that \"tapped\" 15 seniors each year. In 1915, self-perpetuating membership gave way to popular election by the student body, and thenceforward the club served as the \"de facto\" undergraduate student government. The organization was dissolved in 1971 and ultimately succeeded by a formal student government.\nSocietas Domi Pacificae, known colloquially as \"Pacifica House\", is a present-day, self-described secret society. It purports a continuous line of descent from the Franklin Society of 1824, citing a supposed intermediary \"Franklin Society\" traceable in the nineteenth century.\nStudent organizations.\nThere are over 300 registered student organizations on campus with diverse interests. The Student Activities Fair, during the orientation program, provides first-year students the opportunity to become acquainted with a wide range of organizations. A sample of organizations includes:\nLGBTQ+.\nIn 2023, 38% of Brown's students identified as being LGBTQ+, in a poll by \"The Brown Daily Herald\". The 2023 LGBTQ+ self-identification level was an increase, up from 14% LGBT identification in 2010. \"Bisexual\" was the most common answer amongst LGBTQ+ respondents to the poll.\nResource centers.\nBrown has several resource centers on campus. The centers often act as sources of support as well as safe spaces for students to explore certain aspects of their identity. Additionally, the centers often provide physical spaces for students to study and have meetings. Although most centers are identity-focused, some provide academic support as well.\nThe Brown Center for Students of Color (BCSC) is a space that provides support for students of color. Established in 1972 at the demand of student protests, the BCSC encourages students to engage in critical dialogue, develop leadership skills, and promote social justice. The center houses various programs for students to share their knowledge and engage in discussion. Programs include the Third World Transition Program, the Minority Peer Counselor Program, the Heritage Series, and other student-led initiatives. Additionally, the BCSC hopes to foster community among the students it serves by providing spaces for students to meet and study.\nThe Sarah Doyle Women's Center aims to provide a space for members of the Brown community to examine and explore issues surrounding gender. The center was named after one of the first women to attend Brown, Sarah Doyle. The center emphasizes intersectionality in its conversations on gender, encouraging people to see gender as present and relevant in various aspects of life. The center hosts programs and workshops in order to facilitate dialogue and provide resources for students, faculty, and staff.\nOther centers include the LGBTQ Center, the Undocumented, First-Generation College and Low-Income Student (U-FLi) Center, and the Curricular Resource Center.\nActivism.\n1968 Black Student Walkout.\nOn December 5, 1968, several Black women from Pembroke College initiated a walkout in protest of an atmosphere at the colleges described by Black students as a \"stifling, frustrating, [and] degrading place for Black students\" after feeling the colleges were non-responsive to their concerns. In total, 65 Black students participated in the walkout. Their principal demand was to increase Black student enrollment to 11% of the student populace, in an attempt to match that of the proportion in the US. This ultimately resulted in a 300% increase in Black enrollment the following year, but some demands have yet to be met.\nDivestment from South Africa.\nIn the mid-1980s, under student pressure, the university divested from certain companies involved in South Africa. Some students were still unsatisfied with partial divestment and began a fast in Manning Chapel and the university disenrolled them. In April 1987, \"dozens\" of students interrupted a university corporation meeting, leading to 20 being put on probation.\nIsrael-Gaza protests.\nIn early November 2023, twenty students of Jewish background staged a sit in at University hall, resulting in their arrests. The students were protesting the Israel-Hamas war and calling for a ceasefire, as well as for the university to divest from companies that \"facilitate the 'Israeli military occupation' in Gaza.\" In early December 2023, forty-one more students held a sit-in with similar demands, resulting in more arrests by the university. Nineteen students participated in an eight-day hunger strike preceding a corporation meeting in early February 2024 with the demand to present their case to corporation members.\nAthletics.\nBrown is a member of the Ivy League athletic conference, which is categorized as a Division I (top-level) conference of the National Collegiate Athletic Association (NCAA).\nThe Brown Bears has one of the largest university sports programs in the United States, sponsoring 32 varsity intercollegiate teams. Brown's athletic program is one of the \"U.S. News &amp; World Report\" top 20\u2014the \"College Sports Honor Roll\"\u2014based on breadth of the program and athletes' graduation rates. \nBrown's newest varsity team is women's rugby, promoted from club-sport status in 2014. Brown women's rowing has won 7 national titles between 1999 and 2011. Brown men's rowing perennially finishes in the top 5 in the nation, most recently winning silver, bronze, and silver in the national championship races of 2012, 2013, and 2014. The men's and women's crews have also won championship trophies at the Henley Royal Regatta and the Henley Women's Regatta. Brown's men's soccer is consistently ranked in the top 20 and has won 18 Ivy League titles overall; recent soccer graduates play professionally in Major League Soccer and overseas.\nBrown football, under its most successful coach historically, Phil Estes, won Ivy League championships in 1999, 2005, and 2008. high-profile alumni of the football program include former Houston Texans head coach Bill O'Brien; former Penn State football coach Joe Paterno, Heisman Trophy namesake John W. Heisman, and Pollard Award namesake Fritz Pollard.\nBrown women's gymnastics won the Ivy League tournament in 2013 and 2014. The Brown women's sailing team has won 5 national championships, most recently in 2019 while the coed sailing team won 2 national championships in 1942 and 1948. Both teams are consistency ranked in the top 10 in the nation.\nThe first intercollegiate ice hockey game in America was played between Brown and Harvard on January 19, 1898. The first university rowing regatta larger than a dual-meet was held between Brown, Harvard, and Yale at Lake Quinsigamond in Massachusetts on July 26, 1859.\nBrown also supports competitive intercollegiate club sports, including ultimate frisbee. The men's ultimate team, Brownian Motion, has won four national championships, in 2000, 2005, 2019 and 2024.\nNotable people.\nAlumni.\nAlumni in politics and government include U.S. Secretary of State John Hay (1852), U.S. Secretary of State and U.S. Attorney General Richard Olney (1856), Chief Justice of the United States and U.S. Secretary of State Charles Evans Hughes (1881), Governor of Wyoming Territory and Nebraska Governor John Milton Thayer (1841), Rhode Island Governor Augustus Bourn (1855), Louisiana Governor Bobby Jindal '92, U.S. Senator Maggie Hassan '80 of New Hampshire, Delaware Governor Jack Markell '82, Rhode Island Representative David Cicilline '83, Minnesota Representative Dean Phillips '91, 2020 Presidential candidate and entrepreneur Andrew Yang '96, DNC Chair Tom Perez '83, diplomat Richard Holbrooke '62, and career United States diplomat W. Stuart Symington '74.\nProminent alumni in business and finance include philanthropist John D. Rockefeller Jr. (1897), managing director of McKinsey &amp; Company and \"father of modern management consulting\" Marvin Bower '25, former Chair of the Federal Reserve and current U.S. Secretary of the Treasury Janet Yellen '67, World Bank President Jim Yong Kim '82, Bank of America CEO Brian Moynihan '81, CNN founder Ted Turner '60, IBM chairman and CEO Thomas Watson Jr. '37, co-founder of Starwood Capital Group Barry Sternlicht '82, Apple Inc. CEO John Sculley '61, Blackberry Ltd. CEO John S. Chen '78, Facebook CFO David Ebersman '91, and Uber CEO Dara Khosrowshahi '91. Companies founded by Brown alumni include CNN,\"The Wall Street Journal,\" Searchlight Pictures, Netgear, W Hotels, Workday, Warby Parker, Casper, Figma, ZipRecruiter, and Cards Against Humanity.\"\"\nAlumni in the arts and media include actors Emma Watson '14, John Krasinski '01, Daveed Diggs '04, Julie Bowen '91, Tracee Ellis Ross '94, and Jessica Capshaw '98; NPR program host Ira Glass '82; singer-composer Mary Chapin Carpenter '81; humorist and Marx Brothers screenwriter S. J. Perelman '25; novelists Nathanael West '24, Jeffrey Eugenides '83, Edwidge Danticat (MFA '93), and Marilynne Robinson '66; and composer and synthesizer pioneer Wendy Carlos '62, journalist James Risen '77; political pundit Mara Liasson; MSNBC hosts Alex Wagner '99 and Chris Hayes '01; \"New York Times \"publisher A. G. Sulzberger '03, and magazine editor John F. Kennedy Jr. '83.\nImportant figures in the history of education include the father of American public school education Horace Mann (1819), civil libertarian and Amherst College president Alexander Meiklejohn, first president of the University of South Carolina Jonathan Maxcy (1787), Bates College founder Oren B. Cheney (1836), University of Michigan president (1871\u20131909) James Burrill Angell (1849), University of California president (1899\u20131919) Benjamin Ide Wheeler (1875), and Morehouse College's first African-American president John Hope (1894).\nAlumni in the computer sciences and industry include architect of Intel 386, 486, and Pentium microprocessors John H. Crawford '75, inventor of the first silicon transistor Gordon Kidd Teal '31, MongoDB founder Eliot Horowitz '03, Figma founder Dylan Field, and Macintosh developer Andy Hertzfeld '75.\nOther notable alumni include \"Lafayette of the Greek Revolution\" and its historian Samuel Gridley Howe (1821), NASA head during first seven Apollo missions Thomas O. Paine '42, sportscaster Chris Berman '77, Houston Texans head coach Bill O'Brien '92, 2018 Miss America Cara Mund '16, Penn State football coach Joe Paterno '50, Heisman Trophy namesake John W. Heisman '91, distinguished professor of law Cortney Lollar '97, Former SEC Commissioner Annette Nazareth \u201878, Olympic and world champion triathlete Joanna Zeiger, royals and nobles such as Prince Rahim Aga Khan, Prince Faisal bin Al Hussein of the Hashemite Kingdom of Jordan, Princess Leila Pahlavi of Iran '92, Prince Nikolaos of Greece and Denmark, Prince Nikita Romanov, Princess Theodora of Greece and Denmark, Prince Jaime of Bourbon-Parma, Duke of San Jaime and Count of Bardi, Prince Ra'ad bin Zeid, Lady Gabriella Windsor, Prince Alexander von F\u00fcrstenberg, Countess Cosima von B\u00fclow Pavoncelli, and her half-brother Prince Alexander-Georg von Auersperg.\nNobel Laureate alumni include humanitarian Jerry White '87 (Peace, 1997), biologist Craig Mello '82 (Physiology or Medicine, 2006), economist Guido Imbens (AM '89, PhD '91; Economic Sciences, 2021), and economist Douglas Diamond '75 (Economic Sciences, 2022).\nFaculty.\nAmong Brown's past and present faculty are seven Nobel Laureates: Lars Onsager (Chemistry, 1968), Leon Cooper (Physics, 1972), George Snell (Physiology or Medicine, 1980), George Stigler (Economic Sciences, 1982), Henry David Abraham (Peace, 1985), Vernon L. Smith (Economic Sciences, 2002), and J. Michael Kosterlitz (Physics, 2016).\nNotable past and present faculty include biologists Anne Fausto-Sterling (Ph.D. 1970) and Kenneth R. Miller (Sc.B. 1970); computer scientists Robert Sedgewick and Andries van Dam; economists Hyman Minsky, Glenn Loury, George Stigler, Mark Blyth, and Emily Oster; historians Gordon S. Wood and Joan Wallach Scott; mathematicians David Gale, David Mumford, Mary Cartwright, and Solomon Lefschetz; physicists Sylvester James Gates and Gerald Guralnik. Faculty in literature include Chinua Achebe, Ama Ata Aidoo, and Carlos Fuentes. Among Brown's faculty and fellows in political science, and public affairs are the former prime minister of Italy and former EU chief, Romano Prodi; former president of Brazil, Fernando Cardoso; former president of Chile, Ricardo Lagos; and son of Soviet Premier Nikita Khrushchev, Sergei Khrushchev. Other faculty include philosopher Martha Nussbaum, author Ibram X. Kendi, and public health doctor Ashish Jha.\nIn popular culture.\nMentions of Brown in fiction and popular culture include the following. \"Family Guy\" character Brian Griffin is a Brown alumnus. \"The O.C.\"s main character Seth Cohen is denied acceptance to Brown while his girlfriend Summer Roberts is accepted."}
{"id": "4158", "revid": "704645", "url": "https://en.wikipedia.org/wiki?curid=4158", "title": "Bill Atkinson", "text": "William \"Bill\" D. Atkinson (born March 17, 1951) is an American computer engineer, computer programmer and photographer. Atkinson worked at Apple Computer from 1978 to 1990.\nSome of Atkinson's noteworthy contributions to the field of computing include Macintosh QuickDraw and Lisa LisaGraf\n(Atkinson independently discovered the midpoint circle algorithm for fast drawing of circles by using the sum of consecutive odd numbers), Marching ants, the double-click, Menu bar, the selection lasso, MacPaint (FatBits), HyperCard, Atkinson dithering, and the app PhotoCard.\nEducation.\nHe received his undergraduate degree from the University of California, San Diego, where Apple Macintosh developer Jef Raskin was one of his professors. Atkinson continued his studies as a graduate student in neurochemistry at the University of Washington.\nApple.\nRaskin invited Atkinson to visit him at Apple Computer; Steve Jobs persuaded him to join the company immediately as employee No. 51, and Atkinson never finished his PhD. Atkinson was the principal designer and developer of the graphical user interface (GUI) of the Apple Lisa and, later, one of the first thirty members of the original Apple Macintosh development team, and was the creator of the MacPaint application. He also designed and implemented QuickDraw, the fundamental toolbox that the Lisa and Macintosh used for graphics. QuickDraw's performance was essential for the success of the Macintosh GUI. He also was one of the main designers of the Lisa and Macintosh user interfaces. Atkinson also conceived, designed and implemented HyperCard, an early and influential hypermedia system. HyperCard put the power of computer programming and database design into the hands of nonprogrammers. In 1994, Atkinson received the EFF Pioneer Award for his contributions.\nCareer after Apple.\nAround 1990, General Magic's founding, with Bill Atkinson as one of the three cofounders, met the following press in \"Byte\" magazine:\nThe obstacles to General Magic's success may appear daunting, but General Magic is not your typical start-up company. Its partners include some of the biggest players in the worlds of computing, communications, and consumer electronics, and it's loaded with top-notch engineers who have been given a clean slate to reinvent traditional approaches to ubiquitous worldwide communications.\nIn 2007, Atkinson began working as an outside developer with Numenta, a startup working on computer intelligence. On his work there Atkinson said, \"what Numenta is doing is more fundamentally important to society than the personal computer and the rise of the Internet.\"\nPhotography.\nCurrently, Atkinson works as a nature photographer, focusing on close-up photographs of stones that have been cut and polished. His 2004 book \"Within the Stone\" features a collection of his close-up photographs. The detailed images he creates are made possible by the accuracy and creative control of the digital printing process that he helped create.\nIn popular culture.\nActor Nelson Franklin portrayed him in the 2013 film \"Jobs\"."}
{"id": "4160", "revid": "46469005", "url": "https://en.wikipedia.org/wiki?curid=4160", "title": "Battle of Lostwithiel", "text": "The Battle of Lostwithiel took place over a 13-day period from 21 August to 2 September 1644, around the town of Lostwithiel and along the River Fowey valley in Cornwall during the First English Civil War. A Royalist army led by Charles I of England defeated a Parliamentarian force commanded by the Earl of Essex.\nAlthough Essex and most of the cavalry escaped, between 5,000 and 6,000 Parliamentarian infantry were forced to surrender. Since the Royalists were unable to feed so many, they were given a pass back to their own territory, arriving in Southampton a month later having lost nearly half their number to disease and desertion.\nConsidered one of the worst defeats suffered by Parliament over the course of the Wars of the Three Kingdoms, it secured South West England for the Royalists until early 1646.\nBackground.\nDuring April and May 1644, Parliamentarian commanders Sir William Waller and the Earl of Essex combined their armies and carried out a campaign against King Charles and the Royalist garrisons surrounding Oxford. Trusting Waller to deal with the King in Oxfordshire, Essex divided the Parliamentarian army on 6 June and headed southwest to relieve the Royalist siege of Lyme in Dorset. Lyme had been under siege by King Charles' nephew, Prince Maurice, and the Royalists for nearly two months.\nSouth-West England at that time was largely under the control of the Royalists. The town of Lyme, however, was a Parliamentarian stronghold and served as an important seaport for the Parliamentarian fleet of the Earl of Warwick. As Essex approached Lyme in mid-June Prince Maurice ended the siege and took his troops west to Exeter.\nEssex then proceeded further southwest toward Cornwall with the intent to relieve the siege of Plymouth. Plymouth was the only other significant Parliamentarian stronghold in the South-West and it was under siege by Richard Grenville and Cornish Royalists. Essex had been told by Lord Robartes, a wealthy politician and merchant from Cornwall, that the Parliamentarians would gain considerable military support if he moved against Grenville and freed Plymouth. Given Lord Robartes' advice, Essex advanced toward Plymouth. His action caused Grenville to end the siege. Essex then advanced further west, believing that he could take full control of the South-West from the Royalists.\nMeanwhile, in Oxfordshire, King Charles battled with the Parliamentarians and defeated Sir William Waller at the Battle of Cropredy Bridge on 29 June. On 12 July after a Royalist council of war recommended that Essex be dealt with before he could be reinforced, King Charles and his Oxford army departed Evesham. King Charles accepted the council's advice, not solely because it was good strategy, but more so because his Queen was in Exeter, where she had recently given birth to the Princess Henrietta and had been denied safe conduct to Bath by Essex.\nTrapped in Cornwall.\nOn 26 July, King Charles arrived in Exeter and joined his Oxford army with the Royalist forces commanded by Prince Maurice. On that same day, Essex and his Parliamentary force entered Cornwall. One week later, as Essex bivouacked with his army at Bodmin, he learned that King Charles had defeated Waller; brought his Oxford army to the South-West; and joined forces with Prince Maurice. Essex had also seen that he was not getting the military support from the people of Cornwall as Lord Robartes asserted. At that time, Essex understood that he and his army were trapped in Cornwall and his only salvation would be reinforcements or an escape through the port of Fowey by means of the Parliamentarian fleet.\nEssex immediately marched his troops five miles south to the small town of Lostwithiel arriving on 2 August. He immediately deployed his men in a defensive arc with detachments on the high ground to the north at Restormel Castle and the high ground to the east at Beacon Hill. Essex also sent a small contingent of foot south to secure the port of Fowey aiming to eventually evacuate his infantry by sea. At Essex's disposal was a force of 6,500 foot and 3,000 horse.\nAided through intelligence provided by the people of Cornwall , King Charles followed westward, slowly and deliberately cutting off the potential escape routes that Essex might attempt to utilize. On 6 August King Charles communicated with Essex, calling for him to surrender. Stalling for several days, Essex considered the offer but ultimately refused.\nOn 11 August, Grenville and the Cornish Royalists entered Bodmin forcing out Essex's rear-guard cavalry. Grenville then proceeded south across Respryn Bridge to meet and join forces with King Charles and Prince Maurice. It is estimated that the Royalist forces at that time were composed of 12,000 foot and 7,000 horse. Over the next two days the Royalists deployed detachments along the east side of the River Fowey to prevent a Parliamentarian escape across country. Finally the Royalists sent 200 foot with artillery south to garrison the fort at Polruan, effectively blocking the entrance to the harbour of Fowey. At about that time, Essex learned that reinforcements under the command of Sir John Middleton were turned back by the Royalists at Bridgwater in Somerset.\nFirst battle - 21\u201330 August 1644.\nAt 07:00 hours on 21 August, King Charles launched his first attack on Essex and the Parliamentarians at Lostwithiel. From the north, Grenville and the Cornish Royalists attacked Restormel Castle and easily dislodged the Parliamentarians who fell back quickly. From the east, King Charles and the Oxford army captured Beacon Hill with little resistance from the Parliamentarians. Prince Maurice and his force occupied Druid Hill. Casualties were fairly low and by nightfall the fighting ended and the Royalists held the high ground on the north and east sides of Lostwithiel.\nFor the next couple of days the two opposing forces exchanged fire only in a number of small skirmishes. On 24 August, King Charles further tightened the noose encircling the Parliamentarians when he sent Lord Goring and Sir Thomas Bassett to secure the town of St Blazey and the area to the southwest of Lostwithiel. This reduced the foraging area for the Parliamentarians and access to the coves and inlets in the vicinity of the port of Par.\nEssex and the Parliamentarians were now totally surrounded and boxed into a two-mile by five-mile area spanning from Lostwithiel in the north to the port of Fowey in the south. Knowing that he would not be able to fight his way out, Essex made his final plans for an escape. Since a sea evacuation of his cavalry would not be possible, Essex ordered his cavalry commander William Balfour to attempt a breakout to Plymouth. For the infantry, Essex planned to retreat south and meet Lord Warwick and the Parliamentarian fleet at Fowey. At 03:00 hours on 31 August, Balfour and 2,000 members of his cavalry executed the first step of Essex's plan when they successfully crossed the River Fowey and escaped intact without engaging the Royalist defenders.\nSecond battle - 31 August - 2 September 1644.\nEarly on the morning on 31 August, the Parliamentarians ransacked and looted Lostwithiel and began their withdrawal south. At 07:00 hours, the Royalists observed the actions of the Parliamentarians and immediately proceeded to attack. Grenville attacked from the north. King Charles and Prince Maurice crossed the River Fowey, joined up with Grenville, and entered Lostwithiel. Together the Royalists engaged the Parliamentarian rear-guards and quickly took possession of the town. The Royalist also sent detachments down along the east side of the River Fowey to protect against any further breakouts and to capture the town of Polruan.\nThe Royalists then began to pursue Essex and the Parliamentarian infantry down the river valley. At the outset the Royalist pushed the Parliamentarians nearly three miles south through the hedged fields, hills and valleys. At the narrow pass near St. Veep, Philip Skippon, Essex's commander of the infantry, counter-attacked the Royalists and pushed them back several fields attempting to give Essex time to set up a line of defense further south. At 11:00 hours, the Royalist cavalry mounted a charge and won back the territory lost. There was a lull in the battle at 12:00 hours as King Charles waited for his full army to come up and reform.\nThe fighting resumed and continued through the afternoon as the Parliamentarians tried to disengage and continue south. At 16:00 hours, the Parliamentarians tried again to counter-attack with their remaining cavalry only to be driven back by King Charles' Life Guard. About a mile north of Castle Dore, the Parliamentarians right flank began to give way. At 18:00 hours when the Parliamentarians were pushed back to Castle Dore they made their last attempt to rally only to be pushed back and surrounded.\nAbout that time the fighting ended with the Royalists satisfied in their accomplishments of the day. Exhausted and discouraged, the Parliamentarians hunkered down for the night. Later that evening under the darkness of night, Essex and his command staff stole away to the seashore where they used a fishing boat to flee to Plymouth, leaving Skippon in command.\nEarly on 1 September, Skippon met with his officers to inform them about Essex's escape and to discuss alternatives. It was decided that they would approach King Charles and seek terms. Concerned that Parliamentarian reinforcements might be on their way, the King quickly agreed on 2 September to generous terms. The battle was over. Six thousand Parliamentarians were taken as prisoners. Their weapons were taken away and they were marched to Southampton. They suffered the wrath of the Cornish people in route and as many as 3,000 died of exposure and disease along the way. Those that survived the journey were, however, eventually set free. Total casualties associated with the battle were extremely high especially when considering those who died on the march back to Southampton. To those numbers as many as 700 Parliamentarians are estimated to have been killed or wounded during the fighting in Cornwall along with an estimated 500 Royalists.\nAftermath.\nThe Battle of Lostwithiel was a great victory for King Charles and the greatest loss that the Parliamentarians would suffer in the First English Civil War. For King Charles the victory secured the South-West for the remainder of the war and mitigated criticism for a while against the Royalist war effort.\nFor the Parliamentarians, the defeat resulted in recriminations with Middleton ultimately being blamed for his failure to break through with reinforcements. The Parliamentarian failure at Lostwithiel along with the failure to defeat King Charles at the Second Battle of Newbury ultimately led Parliament to adopt the Self-denying Ordinance and led to the implementation of the New Model Army."}
{"id": "4162", "revid": "56299", "url": "https://en.wikipedia.org/wiki?curid=4162", "title": "Beeb", "text": "Beeb or BEEB may refer to:"}
{"id": "4163", "revid": "31793797", "url": "https://en.wikipedia.org/wiki?curid=4163", "title": "Bertrand Russell", "text": "Bertrand Arthur William Russell, 3rd Earl Russell, (18 May 1872 \u2013 2 February 1970) was a British philosopher, logician, mathematician, and public intellectual. He had influence on mathematics, logic, set theory, and various areas of analytic philosophy.\nHe was one of the early 20th century's prominent logicians and a founder of analytic philosophy, along with his predecessor Gottlob Frege, his friend and colleague G. E. Moore, and his student and prot\u00e9g\u00e9 Ludwig Wittgenstein. Russell with Moore led the British \"revolt against idealism\". Together with his former teacher A. N. Whitehead, Russell wrote \"Principia Mathematica\", a milestone in the development of classical logic and a major attempt to reduce the whole of mathematics to logic (see logicism). Russell's article \"On Denoting\" has been considered a \"paradigm of philosophy\".\nRussell was a pacifist who championed anti-imperialism and chaired the India League. He went to prison for his pacifism during World War I, and initially supported appeasement against Adolf Hitler's Nazi Germany, before changing his view in 1943, describing war as a necessary \"lesser of two evils\". In the wake of World War II, he welcomed American global hegemony in preference to either Soviet hegemony or no (or ineffective) world leadership, even if it were to come at the cost of using their nuclear weapons. He would later criticise Stalinist totalitarianism, condemn the United States' involvement in the Vietnam War, and become an outspoken proponent of nuclear disarmament.\nIn 1950, Russell was awarded the Nobel Prize in Literature \"in recognition of his varied and significant writings in which he champions humanitarian ideals and freedom of thought\". He was also the recipient of the De Morgan Medal (1932), Sylvester Medal (1934), Kalinga Prize (1957), and Jerusalem Prize (1963).\nBiography.\nEarly life and background.\nBertrand Arthur William Russell was born at Ravenscroft, a country house in Trellech, Monmouthshire, on 18 May 1872, into an influential and liberal family of the British aristocracy. His parents were Viscount and Viscountess Amberley. Lord Amberley consented to his wife's affair with their children's tutor, the biologist Douglas Spalding. Both were early advocates of birth control at a time when this was considered scandalous. Lord Amberley was a deist, and even asked the philosopher John Stuart Mill to act as Russell's secular godfather. Mill died the year after Russell's birth, but his writings later influenced Russell's life.\nRussell's paternal grandfather, Lord John Russell, later 1st Earl Russell (1792\u20131878), had twice been Prime Minister of the United Kingdom in the 1840s and 1860s. A member of Parliament since the early 1810s, he met with Napoleon Bonaparte in Elba. The Russells had been prominent in England for several centuries before this, coming to power and the peerage with the rise of the Tudor dynasty (see: Duke of Bedford). They established themselves as one of the leading Whig families and participated in political events from the dissolution of the monasteries in 1536\u20131540 to the Glorious Revolution in 1688\u20131689 and the Great Reform Act in 1832.\nLady Amberley was the daughter of Lord and Lady Stanley of Alderley. Russell often feared the ridicule of his maternal grandmother, one of the campaigners for education of women.\nChildhood and adolescence.\nRussell had two siblings: brother Frank (seven years older), and sister Rachel (four years older). In June 1874, Russell's mother died of diphtheria, followed shortly by Rachel's death. In January 1876, his father died of bronchitis after a long period of depression. Frank and Bertrand were placed in the care of Victorian paternal grandparents, who lived at Pembroke Lodge in Richmond Park. His grandfather, former Prime Minister Earl Russell, died in 1878, and was remembered by Russell as a kind old man in a wheelchair. His grandmother, the Countess Russell (n\u00e9e Lady Frances Elliot), was the central family figure for the rest of Russell's childhood and youth.\nThe Countess was from a Scottish Presbyterian family and petitioned the Court of Chancery to set aside a provision in Amberley's will requiring the children to be raised as agnostics. Despite her religious conservatism, she held progressive views in other areas (accepting Darwinism and supporting Irish Home Rule), and her influence on Bertrand Russell's outlook on social justice and standing up for principle remained with him throughout his life. Her favourite Bible verse, \"Thou shalt not follow a multitude to do evil\", became his motto. The atmosphere at Pembroke Lodge was one of frequent prayer, emotional repression and formality; Frank reacted to this with open rebellion, but the young Bertrand learned to hide his feelings.\nRussell's adolescence was lonely and he contemplated suicide. He remarked in his autobiography that his interests in \"nature and books and (later) mathematics saved me from complete despondency;\" only his wish to know more mathematics kept him from suicide. He was educated at home by a series of tutors. When Russell was eleven years old, his brother Frank introduced him to the work of Euclid, which he described in his autobiography as \"one of the great events of my life, as dazzling as first love\".\nDuring these formative years, he also discovered the works of Percy Bysshe Shelley. Russell wrote: \"I spent all my spare time reading him, and learning him by heart, knowing no one to whom I could speak of what I thought or felt, I used to reflect how wonderful it would have been to know Shelley, and to wonder whether I should meet any live human being with whom I should feel so much sympathy.\" Russell claimed that beginning at age 15, he spent considerable time thinking about the validity of Christian religious dogma, which he found unconvincing. At this age, he came to the conclusion that there is no free will and, two years later, that there is no life after death. Finally, at the age of 18, after reading Mill's \"Autobiography\", he abandoned the \"First Cause\" argument and became an atheist.\nHe travelled to the continent in 1890 with an American friend, Edward FitzGerald, and with FitzGerald's family he visited the Paris Exhibition of 1889 and climbed the Eiffel Tower soon after it was completed.\nEducation.\nRussell won a scholarship to read for the Mathematical Tripos at Trinity College, Cambridge, and began his studies there in 1890, taking as coach Robert Rumsey Webb. He became acquainted with the younger George Edward Moore and came under the influence of Alfred North Whitehead, who recommended him to the Cambridge Apostles. He distinguished himself in mathematics and philosophy, graduating as seventh Wrangler in the former in 1893 and becoming a Fellow in the latter in 1895.\nEarly career.\nRussell began his published work in 1896 with \"German Social Democracy\", a study in politics that was an early indication of his interest in political and social theory. In 1896 he taught German social democracy at the London School of Economics. He was a member of the Coefficients dining club of social reformers set up in 1902 by the Fabian campaigners Sidney and Beatrice Webb.\nHe now started a study of the foundations of mathematics at Trinity. In 1897, he wrote \"An Essay on the Foundations of Geometry\" (submitted at the Fellowship Examination of Trinity College) which discussed the Cayley\u2013Klein metrics used for non-Euclidean geometry. He attended the first International Congress of Philosophy in Paris in 1900 where he met Giuseppe Peano and Alessandro Padoa. The Italians had responded to Georg Cantor, making a science of set theory; they gave Russell their literature including the \"Formulario mathematico\". Russell was impressed by the precision of Peano's arguments at the Congress, read the literature upon returning to England, and came upon Russell's paradox. In 1903 he published \"The Principles of Mathematics\", a work on the foundations of mathematics. It advanced a thesis of logicism, that mathematics and logic are one and the same.\nAt the age of 29, in February 1901, Russell underwent what he called a \"sort of mystic illumination\", after witnessing Whitehead's wife's suffering in an angina attack. \"I found myself filled with semi-mystical feelings about beauty and with a desire almost as profound as that of the Buddha to find some philosophy which should make human life endurable\", Russell would later recall. \"At the end of those five minutes, I had become a completely different person.\"\nIn 1905, he wrote the essay \"On Denoting\", which was published in the philosophical journal \"Mind\". Russell was elected a Fellow of the Royal Society (FRS) in 1908. The three-volume \"Principia Mathematica\", written with Whitehead, was published between 1910 and 1913. This, along with the earlier \"The Principles of Mathematics\", soon made Russell world-famous in his field. Russell's first political activity was as the Independent Liberal candidate in the 1907 by-election for the Wimbledon constituency, where he was not elected.\nIn 1910, he became a lecturer at the University of Cambridge, Trinity College, where he had studied. He was considered for a fellowship, which would give him a vote in the college government and protect him from being fired for his opinions, but was passed over because he was \"anti-clerical\", because he was agnostic. He was approached by the Austrian engineering student Ludwig Wittgenstein, who started undergraduate study with him. Russell viewed Wittgenstein as a successor who would continue his work on logic. He spent hours dealing with Wittgenstein's various phobias and his bouts of despair. This was a drain on Russell's energy, but Russell continued to be fascinated by him and encouraged his academic development, including the publication of Wittgenstein's \"Tractatus Logico-Philosophicus\" in 1922. Russell delivered his lectures on logical atomism, his version of these ideas, in 1918, before the end of World War I. Wittgenstein was, at that time, serving in the Austrian Army and subsequently spent nine months in an Italian prisoner of war camp at the end of the conflict.\nFirst World War.\nDuring World War I, Russell was one of the few people to engage in active pacifist activities. In 1916, because of his lack of a fellowship, he was dismissed from Trinity College following his conviction under the Defence of the Realm Act 1914. He later described this, in \"Free Thought and Official Propaganda\", as an illegitimate means the state used to violate freedom of expression. Russell championed the case of Eric Chappelow, a poet jailed and abused as a conscientious objector. Russell played a part in the \"Leeds Convention\" in June 1917, a historic event which saw well over a thousand \"anti-war socialists\" gather; many being delegates from the Independent Labour Party and the Socialist Party, united in their pacifist beliefs and advocating a peace settlement. The international press reported that Russell appeared with a number of Labour Members of Parliament (MPs), including Ramsay MacDonald and Philip Snowden, as well as former Liberal MP and anti-conscription campaigner, Professor Arnold Lupton. After the event, Russell told Lady Ottoline Morrell that, \"to my surprise, when I got up to speak, I was given the greatest ovation that was possible to give anybody\".\nHis conviction in 1916 resulted in Russell being fined \u00a3100 (), which he refused to pay in the hope that he would be sent to prison, but his books were sold at auction to raise the money. The books were bought by friends; he later treasured his copy of the King James Bible that was stamped \"Confiscated by Cambridge Police\".\nA later conviction for publicly lecturing against inviting the United States to enter the war on the United Kingdom's side resulted in six months' imprisonment in Brixton Prison (see \"Bertrand Russell's political views\") in 1918 (he was prosecuted under the Defence of the Realm Act) He later said of his imprisonment:\nWhile he was reading Strachey's \"Eminent Victorians\" chapter about Gordon he laughed out loud in his cell prompting the warder to intervene and reminding him that \"prison was a place of punishment\".\nRussell was reinstated to Trinity in 1919, resigned in 1920, was Tarner Lecturer in 1926 and became a Fellow again in 1944 until 1949.\nIn 1924, Russell again gained press attention when attending a \"banquet\" in the House of Commons with well-known campaigners, including Arnold Lupton, who had been an MP and had also endured imprisonment for \"passive resistance to military or naval service\".\nG. H. Hardy on the Trinity controversy.\nIn 1941, G. H. Hardy wrote a 61-page pamphlet titled \"Bertrand Russell and Trinity\" \u2013 published later as a book by Cambridge University Press with a foreword by C. D. Broad\u2014in which he gave an authoritative account of Russell's 1916 dismissal from Trinity College, explaining that a reconciliation between the college and Russell had later taken place and gave details about Russell's personal life. Hardy writes that Russell's dismissal had created a scandal since the vast majority of the Fellows of the College opposed the decision. The ensuing pressure from the Fellows induced the Council to reinstate Russell. In January 1920, it was announced that Russell had accepted the reinstatement offer from Trinity and would begin lecturing in October. In July 1920, Russell applied for a one-year leave of absence; this was approved. He spent the year giving lectures in China and Japan. In January 1921, it was announced by Trinity that Russell had resigned and his resignation had been accepted. This resignation, Hardy explains, was voluntary and was not the result of another altercation.\nThe reason for the resignation, according to Hardy, was that Russell was going through a tumultuous time in his personal life with a divorce and subsequent remarriage. Russell contemplated asking Trinity for another one-year leave of absence but decided against it since this would have been an \"unusual application\" and the situation had the potential to snowball into another controversy. Although Russell did the right thing, in Hardy's opinion, the reputation of the College suffered with Russell's resignation since the 'world of learning' knew about Russell's altercation with Trinity but not that the rift had healed. In 1925, Russell was asked by the Council of Trinity College to give the \"Tarner Lectures\" on the Philosophy of the Sciences; these would later be the basis for one of Russell's best-received books according to Hardy: \"The Analysis of Matter\", published in 1927. In the preface to the Trinity pamphlet, Hardy wrote:\nBetween the wars.\nIn August 1920, Russell travelled to Soviet Russia as part of an official delegation sent by the British government to investigate the effects of the Russian Revolution. He wrote a four-part series of articles, titled \"Soviet Russia\u20141920\", for the magazine \"The Nation\". He met Vladimir Lenin and had an hour-long conversation with him. In his autobiography, he mentions that he found Lenin disappointing, sensing an \"impish cruelty\" in him and comparing him to \"an opinionated professor\". He cruised down the Volga on a steamship. His experiences destroyed his previous tentative support for the revolution. He subsequently wrote a book, \"The Practice and Theory of Bolshevism\", about his experiences on this trip, taken with a group of 24 others from the UK, all of whom came home thinking well of the Soviet regime, despite Russell's attempts to change their minds. For example, he told them that he had heard shots fired in the middle of the night and was sure that these were clandestine executions, but the others maintained that it was only cars backfiring.\nRussell's lover Dora Black, a British author, feminist and socialist campaigner, visited Soviet Russia independently at the same time; in contrast to his reaction, she was enthusiastic about the Bolshevik revolution.\nThe following year, Russell, accompanied by Dora, visited Peking (as Beijing was then known outside of China) to lecture on philosophy for a year. He went with optimism and hope, seeing China as then being on a new path. Other scholars present in China at the time included John Dewey and Rabindranath Tagore, the Indian Nobel-laureate poet. Before leaving China, Russell became gravely ill with pneumonia, and incorrect reports of his death were published in the Japanese press. When the couple visited Japan on their return journey, Dora took on the role of spurning the local press by handing out notices reading \"Mr. Bertrand Russell, having died according to the Japanese press, is unable to give interviews to Japanese journalists\". Apparently they found this harsh and reacted resentfully. Russell supported his family during this time by writing popular books explaining matters of physics, ethics, and education to the layman.\nFrom 1922 to 1927 the Russells divided their time between London and Cornwall, spending summers in Porthcurno. In the 1922 and 1923 general elections Russell stood as a Labour Party candidate in the Chelsea constituency, but only on the basis that he knew he was unlikely to be elected in such a safe Conservative seat, and he was unsuccessful on both occasions.\nAfter the birth of his two children, he became interested in education, especially early childhood education. He was not satisfied with the old traditional education and thought that progressive education also had some flaws; as a result, together with Dora, Russell founded the experimental Beacon Hill School in 1927. The school was run from a succession of different locations, including its original premises at the Russells' residence, Telegraph House, near Harting, West Sussex. During this time, he published \"On Education, Especially in Early Childhood\". On 8 July 1930, Dora gave birth to her third child Harriet Ruth. After he left the school in 1932, Dora continued it until 1943.\nIn 1927 Russell met Barry Fox (later Barry Stevens), who became a known Gestalt therapist and writer in later years. They developed an intense relationship, and in Fox's words: \"...for three years we were very close.\" Fox sent her daughter Judith to Beacon Hill School. From 1927 to 1932 Russell wrote 34 letters to Fox. Upon the death of his elder brother Frank, in 1931, Russell became the 3rd Earl Russell.\nRussell's marriage to Dora grew tenuous, and it reached a breaking point over her having two children with an American journalist, Griffin Barry. They separated in 1932 and finally divorced. On 18 January 1936, Russell married his third wife, an Oxford undergraduate named Patricia (\"Peter\") Spence, who had been his children's governess since 1930. Russell and Peter had one son, Conrad Sebastian Robert Russell, 5th Earl Russell, who became a historian and one of the leading figures in the Liberal Democrat party.\nRussell returned in 1937 to the London School of Economics to lecture on the science of power. During the 1930s, Russell became a friend and collaborator of V. K. Krishna Menon, then President of the India League, the foremost lobby in the United Kingdom for Indian independence. Russell chaired the India League from 1932 to 1939.\nSecond World War.\nRussell's political views changed over time, mostly about war. He opposed rearmament against Nazi Germany. In 1937, he wrote in a personal letter: \"If the Germans succeed in sending an invading army to England we should do best to treat them as visitors, give them quarters and invite the commander and chief to dine with the prime minister.\" In 1940, he changed his appeasement view that avoiding a full-scale world war was more important than defeating Hitler. He concluded that Adolf Hitler taking over all of Europe would be a permanent threat to democracy. In 1943, he adopted a stance toward large-scale warfare called \"relative political pacifism\": \"War was always a great evil, but in some particularly extreme circumstances, it may be the lesser of two evils.\"\nBefore World War II, Russell taught at the University of Chicago, later moving on to Los Angeles to lecture at the UCLA Department of Philosophy. He was appointed professor at the City College of New York (CCNY) in 1940, but after a public outcry the appointment was annulled by a court judgment that pronounced him \"morally unfit\" to teach at the college because of his opinions, especially those relating to sexual morality, detailed in \"Marriage and Morals\" (1929). The matter was taken to the New York Supreme Court by Jean Kay who was afraid that her daughter would be harmed by the appointment, though her daughter was not a student at CCNY. Many intellectuals, led by John Dewey, protested at his treatment. Albert Einstein's oft-quoted aphorism that \"great spirits have always encountered violent opposition from mediocre minds\" originated in his open letter, dated 19 March 1940, to Morris Raphael Cohen, a professor emeritus at CCNY, supporting Russell's appointment. Dewey and Horace M. Kallen edited a collection of articles on the CCNY affair in \"The Bertrand Russell Case\". Russell soon joined the Barnes Foundation, lecturing to a varied audience on the history of philosophy; these lectures formed the basis of \"A History of Western Philosophy\". His relationship with the eccentric Albert C. Barnes soon soured, and he returned to the UK in 1944 to rejoin the faculty of Trinity College.\nLater life.\nRussell participated in many broadcasts over the BBC, particularly \"The Brains Trust\" and for the Third Programme, on various topical and philosophical subjects. By this time Russell was known outside academic circles, frequently the subject or author of magazine and newspaper articles, and was called upon to offer opinions on a variety of subjects, even mundane ones. En route to one of his lectures in Trondheim, Russell was one of 24 survivors (out of 43 passengers) of an aeroplane crash in Hommelvik in October 1948. He said he owed his life to smoking since the people who drowned were in the non-smoking part of the plane. \"A History of Western Philosophy\" (1945) became a best-seller and provided Russell with a steady income for the remainder of his life.\nIn 1942, Russell argued in favour of a moderate socialism, capable of overcoming its metaphysical principles. In an inquiry on dialectical materialism, launched by the Austrian artist and philosopher Wolfgang Paalen in his journal \"DYN\", Russell said: \"I think the metaphysics of both Hegel and Marx plain nonsense\u2014Marx's claim to be 'science' is no more justified than Mary Baker Eddy's. This does not mean that I am opposed to socialism.\"\nIn 1943, Russell expressed support for Zionism: \"I have come gradually to see that, in a dangerous and largely hostile world, it is essential to Jews to have some country which is theirs, some region where they are not suspected aliens, some state which embodies what is distinctive in their culture\".\nIn a speech in 1948, Russell said that if the USSR's aggression continued, it would be morally worse to go to war after the USSR possessed an atomic bomb than before it possessed one, because if the USSR had no bomb the West's victory would come more swiftly and with fewer casualties than if there were atomic bombs on both sides. At that time, only the United States possessed an atomic bomb, and the USSR was pursuing an aggressive policy towards the countries in Eastern Europe which were being absorbed into the Soviet Union's sphere of influence. Many understood Russell's comments to mean that Russell approved of a first strike in a war with the USSR, including Nigel Lawson, who was present when Russell spoke of such matters. Others, including Griffin, who obtained a transcript of the speech, have argued that he was explaining the usefulness of America's atomic arsenal in deterring the USSR from continuing its domination of Eastern Europe.\nJust after the atomic bombs exploded over Hiroshima and Nagasaki, Russell wrote letters, and published articles in newspapers from 1945 to 1948, stating clearly that it was morally justified and better to go to war against the USSR using atomic bombs while the United States possessed them and before the USSR did. In September 1949, one week after the USSR tested its first A-bomb, but before this became known, Russell wrote that the USSR would be unable to develop nuclear weapons because following Stalin's purges only science based on Marxist principles would be practised in the Soviet Union. After it became known that the USSR had carried out its nuclear bomb tests, Russell declared his position advocating the total abolition of atomic weapons.\nIn 1948, Russell was invited by the BBC to deliver the inaugural Reith Lectures\u2014what was to become an annual series of lectures, still broadcast by the BBC. His series of six broadcasts, titled \"Authority and the Individual\", explored themes such as the role of individual initiative in the development of a community and the role of state control in a progressive society. Russell continued to write about philosophy. He wrote a foreword to \"Words and Things\" by Ernest Gellner, which was highly critical of the later thought of Ludwig Wittgenstein and of ordinary language philosophy. Gilbert Ryle refused to have the book reviewed in the philosophical journal \"Mind\", which caused Russell to respond via \"The Times\". The result was a month-long correspondence in \"The Times\" between the supporters and detractors of ordinary language philosophy, which was ended when the paper published an editorial critical of both sides but agreeing with the opponents of ordinary language philosophy.\nIn the King's Birthday Honours of 9 June 1949, Russell was awarded the Order of Merit, and the following year he was awarded the Nobel Prize in Literature. When he was given the Order of Merit, George VI was affable but embarrassed at decorating a former jailbird, saying, \"You have sometimes behaved in a manner that would not do if generally adopted\". Russell merely smiled, but afterwards claimed that the reply \"That's right, just like your brother\" immediately came to mind.\nIn 1950, Russell attended the inaugural conference for the Congress for Cultural Freedom, a CIA-funded anti-communist organisation committed to the deployment of culture as a weapon during the Cold War. Russell was one of the known patrons of the Congress until he resigned in 1956.\nIn 1952, Russell was divorced by Spence, with whom he had been very unhappy. Conrad, Russell's son by Spence, did not see his father between the time of the divorce and 1968 (at which time his decision to meet his father caused a permanent breach with his mother). Russell married his fourth wife, Edith Finch, soon after the divorce, on 15 December 1952. They had known each other since 1925, and Edith had taught English at Bryn Mawr College near Philadelphia, sharing a house for 20 years with Russell's old friend Lucy Donnelly. Edith remained with him until his death, and, by all accounts, their marriage was a happy, close, and loving one. Russell's eldest son John suffered from mental illness, which was the source of ongoing disputes between Russell and his former wife Dora.\nIn 1962 Russell played a public role in the Cuban Missile Crisis: in an exchange of telegrams with Soviet leader Nikita Khrushchev, Khrushchev assured him that the Soviet government would not be reckless. Russell sent this telegram to President Kennedy:\nAccording to historian Peter Knight, after JFK's assassination, Russell, \"prompted by the emerging work of the lawyer Mark Lane in the US ... rallied support from other noteworthy and left-leaning compatriots to form a Who Killed Kennedy Committee in June 1964, members of which included Michael Foot MP, Caroline Benn, the publisher Victor Gollancz, the writers John Arden and J. B. Priestley, and the Oxford history professor Hugh Trevor-Roper.\" Russell published a highly critical article in \"The Minority of One\" weeks before the Warren Commission Report was published, setting forth \"16 Questions on the Assassination.\" Russell equated the Oswald case with the Dreyfus affair of late 19th-century France, in which the state convicted an innocent man. Russell also criticised the American press for failing to heed any voices critical of the official version.\nPolitical causes.\nBertrand Russell was opposed to war from a young age; his opposition to World War I was used as grounds for his dismissal from Trinity College at Cambridge. This incident fused two of his controversial causes, as he had failed to be granted fellow status which would have protected him from firing, because he was not willing to either pretend to be a devout Christian, or at least avoid admitting he was agnostic.\nHe later described the resolution of these issues as essential to freedom of thought and expression, citing the incident in Free Thought and Official Propaganda, where he explained that the expression of any idea, even the most obviously \"bad\", must be protected not only from direct State intervention but also economic leveraging and other means of being silenced:\nRussell spent the 1950s and 1960s engaged in political causes primarily related to nuclear disarmament and opposing the Vietnam War. The 1955 Russell\u2013Einstein Manifesto was a document calling for nuclear disarmament and was signed by eleven of the most prominent nuclear physicists and intellectuals of the time. In October 1960 \"The Committee of 100\" was formed with a declaration by Russell and Michael Scott, entitled \"Act or Perish\", which called for a \"movement of nonviolent resistance to nuclear war and weapons of mass destruction\". In September 1961, at the age of 89, Russell was jailed for seven days in Brixton Prison for a \"breach of the peace\" after taking part in an anti-nuclear demonstration in London. The magistrate offered to exempt him from jail if he pledged himself to \"good behaviour\", to which Russell replied: \"No, I won't.\"\nFrom 1966 to 1967, Russell worked with Jean-Paul Sartre and many other intellectual figures to form the Russell Vietnam War Crimes Tribunal to investigate the conduct of the United States in Vietnam. He wrote many letters to world leaders during this period.\nEarly in his life, Russell supported eugenicist policies. In 1894, he proposed that the state issue certificates of health to prospective parents and withhold public benefits from those considered unfit. In 1929, he wrote that people deemed \"mentally defective\" and \"feebleminded\" should be sexually sterilised because they \"are apt to have enormous numbers of illegitimate children, all, as a rule, wholly useless to the community.\" Russell was also an advocate of population control:\nOn 20 November 1948, in a public speech at Westminster School, addressing a gathering arranged by the New Commonwealth, Russell shocked some observers by suggesting that a preemptive nuclear strike on the Soviet Union was justified. Russell argued that war between the United States and the Soviet Union seemed inevitable, so it would be a humanitarian gesture to get it over with quickly and have the United States in the dominant position. Currently, Russell argued, humanity could survive such a war, whereas a full nuclear war after both sides had manufactured large stockpiles of more destructive weapons was likely to result in the extinction of the human race. Russell later relented from this stance, instead arguing for mutual disarmament by the nuclear powers.\nIn 1956, before and during the Suez Crisis, Russell expressed his opposition to European imperialism in the Middle East. He viewed the crisis as another reminder of the pressing need for an effective mechanism for international governance, and to restrict national sovereignty in places such as the Suez Canal area \"where general interest is involved\". At the same time the Suez Crisis was taking place, the world was also captivated by the Hungarian Revolution and the subsequent crushing of the revolt by intervening Soviet forces. Russell attracted criticism for speaking out fervently against the Suez war while ignoring Soviet repression in Hungary, to which he responded that he did not criticise the Soviets \"because there was no need. Most of the so-called Western World was fulminating\". Although he later feigned a lack of concern, at the time he was disgusted by the brutal Soviet response, and on 16 November 1956, he expressed approval for a declaration of support for Hungarian scholars which Michael Polanyi had cabled to the Soviet embassy in London twelve days previously, shortly after Soviet troops had entered Budapest.\nIn November 1957 Russell wrote an article addressing US President Dwight D. Eisenhower and Soviet Premier Nikita Khrushchev, urging a summit to consider \"the conditions of co-existence\". Khrushchev responded that peace could be served by such a meeting. In January 1958 Russell elaborated his views in \"The Observer\", proposing a cessation of all nuclear weapons production, with the UK taking the first step by unilaterally suspending its own nuclear weapons program if necessary, and with Germany \"freed from all alien armed forces and pledged to neutrality in any conflict between East and West\". US Secretary of State John Foster Dulles replied for Eisenhower. The exchange of letters was published as \"The Vital Letters of Russell, Khrushchev, and Dulles\".\nRussell was asked by \"The New Republic\", a liberal American magazine, to elaborate his views on world peace. He urged that all nuclear weapons testing and flights by planes armed with nuclear weapons be halted immediately, and negotiations be opened for the destruction of all hydrogen bombs, with the number of conventional nuclear devices limited to ensure a balance of power. He proposed that Germany be reunified and accept the Oder-Neisse line as its border, and that a neutral zone be established in Central Europe, consisting at the minimum of Germany, Poland, Hungary, and Czechoslovakia, with each of these countries being free of foreign troops and influence, and prohibited from forming alliances with countries outside the zone. In the Middle East, Russell suggested that the West avoid opposing Arab nationalism, and proposed the creation of a United Nations peacekeeping force to guard Israel's frontiers to ensure that Israel was prevented from committing aggression and protected from it. He also suggested Western recognition of the People's Republic of China, and that it be admitted to the UN with a permanent seat on the UN Security Council.\nHe was in contact with Lionel Rogosin while the latter was filming his anti-war film \"Good Times, Wonderful Times\" in the 1960s. He became a hero to many of the youthful members of the New Left. In early 1963, Russell became increasingly vocal in his disapproval of the Vietnam War, and felt that the US government's policies there were near-genocidal. In 1963 he became the inaugural recipient of the Jerusalem Prize, an award for writers concerned with the freedom of the individual in society. In 1964 he was one of eleven world figures who issued an appeal to Israel and the Arab countries to accept an arms embargo and international supervision of nuclear plants and rocket weaponry. In October 1965 he tore up his Labour Party card because he suspected Harold Wilson's Labour government was going to send troops to support the United States in Vietnam.\nFinal years, death and legacy.\nIn June 1955, Russell had leased Plas Penrhyn in Penrhyndeudraeth, Merionethshire, Wales and on 5 July of the following year it became his and Edith's principal residence.\nRussell published his three-volume autobiography in 1967, 1968, and 1969. He made a cameo appearance playing himself in the anti-war Hindi film \"Aman\", by Mohan Kumar, which was released in India in 1967. This was Russell's only appearance in a feature film.\nOn 23 November 1969, he wrote to \"The Times\" newspaper saying that the preparation for show trials in Czechoslovakia was \"highly alarming\". The same month, he appealed to Secretary General U Thant of the United Nations to support an international war crimes commission to investigate alleged torture and genocide by the United States in South Vietnam during the Vietnam War. The following month, he protested to Alexei Kosygin over the expulsion of Aleksandr Solzhenitsyn from the Soviet Union of Writers.\nOn 31 January 1970, Russell issued a statement condemning \"Israel's aggression in the Middle East\", and in particular, Israeli bombing raids being carried out deep in Egyptian territory as part of the War of Attrition, which he compared to German bombing raids in the Battle of Britain and the US bombing of Vietnam. He called for an Israeli withdrawal to the pre-Six-Day War borders, stating \"The aggression committed by Israel must be condemned, not only because no state has the right to annexe foreign territory, but because every expansion is an experiment to discover how much more aggression the world will tolerate.\" This was Russell's final political statement or act. It was read out at the International Conference of Parliamentarians in Cairo on 3 February 1970, the day after his death.\nRussell died of influenza, just after 8\u00a0pm on 2 February 1970 at his home in Penrhyndeudraeth, aged 97. His body was cremated in Colwyn Bay on 5 February 1970 with five people present. In accordance with his will, there was no religious ceremony but one minute's silence; his ashes were later scattered over the Welsh mountains. Although he was born in Monmouthshire, and died in Penrhyndeudraeth in Wales, Russell identified as English. Later in 1970, on 23 October, his will was published showing he had left an estate valued at \u00a369,423 (equivalent to \u00a3\u00a0million in ). In 1980, a memorial to Russell was commissioned by a committee including the philosopher A. J. Ayer. It consists of a bust of Russell in Red Lion Square in London sculpted by Marcelle Quinton.\nLady Katharine Jane Tait, Russell's daughter, founded the Bertrand Russell Society in 1974 to preserve and understand his work. It publishes the \"Bertrand Russell Society Bulletin\", holds meetings and awards prizes for scholarship, including the Bertrand Russell Society Award. She also authored several essays about her father; as well as a book, \"My Father, Bertrand Russell\", which was published in 1975. All members receive \"Russell: The Journal of Bertrand Russell Studies\".\nFor the sesquicentennial of his birth, in May 2022, McMaster University's Bertrand Russell Archive, the university's largest and most heavily used research collection, organised both a physical and virtual exhibition on Russell's anti-nuclear stance in the post-war era, \"Scientists\" \"for Peace: the Russell-Einstein Manifesto and the Pugwash Conference\", which included the earliest version of the Russell\u2013Einstein Manifesto. The Bertrand Russell Peace Foundation held a commemoration at Conway Hall in Red Lion Square, London, on 18 May, the anniversary of his birth. For its part, on the same day, \"La Estrella de Panam\u00e1\" published a biographical sketch by Francisco D\u00edaz Montilla, who commented that \"[if he] had to characterize Russell's work in one sentence [he] would say: criticism and rejection of dogmatism.\"\nBangladesh's first leader, Mujibur Rahman, named his youngest son Sheikh Russel in honour of Bertrand Russell.\nMarriages and issue.\nIn 1889, Russell at 17 years of age, met the family of Alys Pearsall Smith, an American Quaker five years older, who was a graduate of Bryn Mawr College near Philadelphia. He became a friend of the Pearsall Smith family. They knew him as \"Lord John's grandson\" and enjoyed showing him off.\nHe fell in love with Alys, and contrary to his grandmother's wishes, married her on 13 December 1894. Their marriage began to fall apart in 1901 when it occurred to Russell, while cycling, that he no longer loved her. She asked him if he loved her and he cruelly replied that he did not. Russell also disliked Alys's mother, finding her controlling and cruel. A lengthy period of separation began in 1911 with Russell's affair with Lady Ottoline Morrell, and he and Alys finally divorced in 1921 to enable Russell to remarry.\nDuring his years of separation from Alys, Russell had affairs (often simultaneous) with a number of women, including Morrell and the actress Lady Constance Malleson. Some have suggested that at this point he had an affair with Vivienne Haigh-Wood, the English governess and writer, and first wife of T. S. Eliot.\nIn 1921, his second marriage was to Dora Winifred Black MBE (died 1986), daughter of Sir Frederick Black. Dora was six months pregnant when the couple returned to England.\nThis was dissolved in 1935, having produced two children:\nRussell's third marriage was to Patricia Helen Spence (died 2004) in 1936, with the marriage producing one child:\nRussell's third marriage ended in divorce in 1952. He married Edith Finch in the same year. Finch died in 1978.\nTitles, awards and honours.\nUpon his brother's death in 1931, Russell became the 3rd Earl Russell of Kingston Russell, and the subsidiary title of Viscount Amberley of Amberley and of Ardsalla. He held both titles, and the accompanying seat in the House of Lords, until his death in 1970.\nViews.\nPhilosophy.\nRussell is credited with being one of the founders of analytic philosophy. He was impressed by Gottfried Leibniz (1646\u20131716), and wrote on major areas of philosophy except aesthetics. He was prolific in the fields of metaphysics, logic and the philosophy of mathematics, the philosophy of language, ethics and epistemology. When Brand Blanshard asked Russell why he did not write on aesthetics, Russell replied that he did not know anything about it, though he hastened to add \"but that is not a very good excuse, for my friends tell me it has not deterred me from writing on other subjects\".\nOn ethics, Russell wrote that he was a utilitarian in his youth, yet he later distanced himself from this view.\nFor the advancement of science and protection of liberty of expression, Russell advocated The Will to Doubt, the recognition that all human knowledge is at most a best guess, that one should always remember:\nReligion.\nRussell described himself in 1947 as an agnostic or an atheist: he found it difficult to determine which term to adopt, saying: For most of his adult life, Russell maintained religion to be little more than superstition and, despite any positive effects, largely harmful to people. He believed that religion and the religious outlook serve to impede knowledge and foster fear and dependency, and to be responsible for much of our world's wars, oppression, and misery. He was a member of the advisory council of the British Humanist Association and the president of Cardiff Humanists until his death.\nSociety.\nPolitical and social activism occupied much of Russell's time for most of his life. Russell remained politically active almost to the end of his life, writing to and exhorting world leaders and lending his name to various causes. He was a prominent campaigner against Western intervention into the Vietnam War in the 1960s, writing essays and books, attending demonstrations, and even organising the Russell Tribunal in 1966 alongside other prominent philosophers such as Jean-Paul Sartre and Simone de Beauvoir, which fed into his 1967 book \"War Crimes in Vietnam.\"\nRussell argued for a \"scientific society\", where war would be abolished, population growth would be limited, and prosperity would be shared. He suggested the establishment of a \"single supreme world government\" able to enforce peace, claiming that \"the only thing that will redeem mankind is co-operation\". He was one of the signatories of the agreement to convene a convention for drafting a world constitution. As a result, for the first time in human history, a World Constituent Assembly convened to draft and adopt the Constitution for the Federation of Earth. Russell also expressed support for guild socialism, and commented positively on several socialist thinkers and activists. According to Jean Bricmont and Normand Baillargeon, \"Russell was both a liberal and a socialist, a combination that was perfectly comprehensible in his time, but which has become almost unthinkable today. He was a liberal in that he opposed concentrations of power in all its manifestations, military, governmental, or religious, as well as the superstitious or nationalist ideas that usually serve as its justification. But he was also a socialist, even as an extension of his liberalism, because he was equally opposed to the concentrations of power stemming from the private ownership of the major means of production, which therefore needed to be put under social control (which does not mean state control).\"\nRussell was an active supporter of the Homosexual Law Reform Society, being one of the signatories of A. E. Dyson's 1958 letter to \"The Times\" calling for a change in the law regarding male homosexual practices, which were partly legalised in 1967, when Russell was still alive.\nHe expressed sympathy and support for the Palestinian people and was critical of Israel's actions. He wrote in 1960 that, \"I think it was a mistake to establish a Jewish State in Palestine, but it would be a still greater mistake to try to get rid of it now that it exists.\" In his final written document, read aloud in Cairo three days after his death on 31 January 1970, he condemned Israel as an aggressive imperialist power, which \"wishes to consolidate with the least difficulty what it has already taken by violence. Every new conquest becomes the new basis of the proposed negotiation from strength, which ignores the injustice of the previous aggression.\" In regards to the Palestinian people and refugees, he wrote that, \"No people anywhere in the world would accept being expelled en masse from their own country; how can anyone require the people of Palestine to accept a punishment which nobody else would tolerate? A permanent just settlement of the refugees in their homeland is an essential ingredient of any genuine settlement in the Middle East.\"\nRussell advocated for a universal basic income. In his 1918 book \"Roads to Freedom\", Russell wrote that \"Anarchism has the advantage as regards liberty, Socialism as regards the inducement to work.\u00a0 Can we not find a method of combining these two advantages?\u00a0It seems to me that we can. [...] Stated in more familiar terms, the plan we are advocating amounts essentially to this: that a certain small income, sufficient for necessaries, should be secured to all, whether they work or not, and that a larger income \u2013 as much larger as might be warranted by the total amount of commodities produced \u2013 should be given to those who are willing to engage in some work which the community recognizes as useful...When education is finished, no one should be compelled to work, and those who choose not to work should receive a bare livelihood and be left completely free.\"\nIn \"Reflections on My Eightieth Birthday\" (\"Postscript\" in his \"Autobiography\"), Russell wrote: \"I have lived in the pursuit of a vision, both personal and social. Personal: to care for what is noble, for what is beautiful, for what is gentle; to allow moments of insight to give wisdom at more mundane times. Social: to see in imagination the society that is to be created, where individuals grow freely, and where hate and greed and envy die because there is nothing to nourish them. These things I believe, and the world, for all its horrors, has left me unshaken\".\nFreedom of opinion and expression.\nRussell supported freedom of opinion and was an opponent of both censorship and indoctrination. In 1928, he wrote: \"The fundamental argument for freedom of opinion is the doubtfulness of all our belief... when the State intervenes to ensure the indoctrination of some doctrine, it does so because there is no conclusive evidence in favour of that doctrine ... It is clear that thought is not free if the profession of certain opinions make it impossible to make a living\". In 1957, he wrote: \"'Free thought' means thinking freely ... to be worthy of the name freethinker he must be free of two things: the force of tradition and the tyranny of his own passions.\"\nEducation.\nRussell has presented ideas on the possible means of control of education in case of scientific dictatorship governments, of the kind of this excerpt taken from Chapter II \"General Effects of Scientific Technique\" of \"The Impact of Science on society\":\nHe pushed his visionary scenarios even further into details, in Chapter III \"Scientific Technique in an Oligarchy\" of the same book, stating as an example: \nSelected works.\nBelow are selected Russell's works in English, sorted by year of first publication:\nRussell was the author of more than sixty books and over two thousand articles. Additionally, he wrote many pamphlets, introductions, and letters to the editor. One pamphlet titled, \"I Appeal unto Caesar': The Case of the Conscientious Objectors\", ghostwritten for Margaret Hobhouse, the mother of imprisoned peace activist Stephen Hobhouse, allegedly helped secure the release from prison of hundreds of conscientious objectors.\nHis works can be found in anthologies and collections, including \"The Collected Papers of Bertrand Russell\", which McMaster University began publishing in 1983. By March 2017 this collection of his shorter and previously unpublished works included 18 volumes, and several more are in progress. A bibliography in three additional volumes catalogues his publications. The Russell Archives held by McMaster's William Ready Division of Archives and Research Collections possess over 40,000 of his letters."}
{"id": "4165", "revid": "628775", "url": "https://en.wikipedia.org/wiki?curid=4165", "title": "Boeing 767", "text": "The Boeing 767 is an American wide-body airliner developed and manufactured by Boeing Commercial Airplanes.\nThe aircraft was launched as the 7X7 program on July 14, 1978, the prototype first flew on September 26, 1981, and it was certified on July 30, 1982. The initial 767-200 variant entered service on September 8, 1982, with United Airlines, and the extended-range 767-200ER in 1984. It was stretched into the in October 1986, followed by the extended-range 767-300ER in 1988, the most popular variant. The 767-300F, a production freighter version, debuted in October 1995. It was stretched again into the 767-400ER from September 2000.\nDesigned to complement the larger 747, it has a seven-abreast cross-section accommodating smaller LD2 ULD cargo containers.\nThe 767 is Boeing's first wide-body twinjet, powered by General Electric CF6, Rolls-Royce RB211, or Pratt &amp; Whitney JT9D turbofans. JT9D engines were eventually replaced by PW4000 engines.\nThe aircraft has a conventional tail and a supercritical wing for reduced aerodynamic drag.\nIts two-crew glass cockpit, a first for a Boeing airliner, was developed jointly for the 757 \u2212 a narrow-body aircraft, allowing a common pilot type rating. Studies for a higher-capacity 767 in 1986 led Boeing to develop the larger 777 twinjet, introduced in June 1995.\nThe 767-200 typically seats 216 passengers over 3,900\u00a0nautical miles\u00a0[nmi] (7,200\u00a0km; ), while the 767-200ER seats 181 over a 6,590\u00a0nmi (12,200\u00a0km; ) range.\nThe 767-300 typically seats 269 passengers over 3,900\u00a0nmi (7,200\u00a0km; ), while the 767-300ER seats 218 over 5,980\u00a0nmi (11,070\u00a0km; ).\nThe 767-300F can haul over 3,225\u00a0nmi (6,025\u00a0km; ), and the 767-400ER typically seats 245 passengers over 5,625\u00a0nmi (10,415\u00a0km; ). Military derivatives include the E-767 for surveillance and the KC-767 and KC-46 aerial tankers.\nInitially marketed for transcontinental routes, a loosening of ETOPS rules starting in 1985 allowed the aircraft to operate transatlantic flights.\nA total of 742 of these aircraft were in service in July 2018, with Delta Air Lines being the largest operator with 77 aircraft in its fleet.\n, Boeing has received 1,430 orders from 74 customers, of which 1,321 airplanes have been delivered, while the remaining orders are for cargo or tanker variants. Competitors have included the Airbus A300, A310, and A330-200. Its successor, the 787 Dreamliner, entered service in 2011.\nDevelopment.\nBackground.\nIn 1970, the 747 entered service as the first wide-body jetliner with a fuselage wide enough to feature a twin-aisle cabin. Two years later, the manufacturer began a development study, code-named 7X7, for a new wide-body jetliner intended to replace the 707 and other early generation narrow-body airliners. The aircraft would also provide twin-aisle seating, but in a smaller fuselage than the existing 747, McDonnell Douglas DC-10, and Lockheed L-1011 TriStar wide-bodies. To defray the high cost of development, Boeing signed risk-sharing agreements with Italian corporation Aeritalia and the Civil Transport Development Corporation (CTDC), a consortium of Japanese aerospace companies. This marked the manufacturer's first major international joint venture, and both Aeritalia and the CTDC received supply contracts in return for their early participation. The initial 7X7 was conceived as a short take-off and landing airliner intended for short-distance flights, but customers were unenthusiastic about the concept, leading to its redefinition as a mid-size, transcontinental-range airliner. At this stage the proposed aircraft featured two or three engines, with possible configurations including over-wing engines and a T-tail.\nBy 1976, a twinjet layout, similar to the one which had debuted on the Airbus A300, became the baseline configuration. The decision to use two engines reflected increased industry confidence in the reliability and economics of new-generation jet powerplants. While airline requirements for new wide-body aircraft remained ambiguous, the 7X7 was generally focused on mid-size, high-density markets. As such, it was intended to transport large numbers of passengers between major cities. Advancements in civil aerospace technology, including high-bypass-ratio turbofan engines, new flight deck systems, aerodynamic improvements, and more efficient lightweight designs were to be applied to the 7X7. Many of these features were also included in a parallel development effort for a new mid-size narrow-body airliner, code-named 7N7, which would become the 757. Work on both proposals proceeded through the airline industry upturn in the late 1970s.\nIn January 1978, Boeing announced a major extension of its Everett factory\u2014which was then dedicated to manufacturing the 747\u2014to accommodate its new wide-body family. In February 1978, the new jetliner received the 767 model designation, and three variants were planned: a with 190 seats, a with 210 seats, and a trijet 767MR/LR version with 200 seats intended for intercontinental routes. The 767MR/LR was subsequently renamed 777 for differentiation purposes. The 767 was officially launched on July 14, 1978, when United Airlines ordered 30 of the 767-200 variant, followed by 50 more 767-200 orders from American Airlines and Delta Air Lines later that year. The 767-100 was ultimately not offered for sale, as its capacity was too close to the 757's seating, while the 777 trijet was eventually dropped in favor of standardizing the twinjet configuration.\nDesign effort.\nIn the late 1970s, operating cost replaced capacity as the primary factor in airliner purchases. As a result, the 767's design process emphasized fuel efficiency from the outset. Boeing targeted a 20 to 30\u00a0percent cost saving over earlier aircraft, mainly through new engine and wing technology. As development progressed, engineers used computer-aided design for over a third of the 767's design drawings, and performed 26,000 hours of wind tunnel tests. Design work occurred concurrently with the 757 twinjet, leading Boeing to treat both as almost one program to reduce risk and cost. Both aircraft would ultimately receive shared design features, including avionics, flight management systems, instruments, and handling characteristics. Combined development costs were estimated at $3.5 to $4\u00a0billion.\nEarly 767 customers were given the choice of Pratt &amp; Whitney JT9D or General Electric CF6 turbofans, marking the first time that Boeing had offered more than one engine option at the launch of a new airliner. Both jet engine models had a maximum output of of thrust. The engines were mounted approximately one-third the length of the wing from the fuselage, similar to previous wide-body trijets. The larger wings were designed using an aft-loaded shape which reduced aerodynamic drag and distributed lift more evenly across their surface span than any of the manufacturer's previous aircraft. The wings provided higher-altitude cruise performance, added fuel capacity, and expansion room for future stretched variants. The initial 767-200 was designed for sufficient range to fly across North America or across the northern Atlantic, and would be capable of operating routes up to .\nThe 767's fuselage width was set midway between that of the 707 and the 747 at . While it was narrower than previous wide-body designs, seven abreast seating with two aisles could be fitted, and the reduced width produced less aerodynamic drag. The fuselage was not wide enough to accommodate two standard LD3 wide-body unit load devices side-by-side, so a smaller container, the LD2, was created specifically for the 767. Using a conventional tail design also allowed the rear fuselage to be tapered over a shorter section, providing for parallel aisles along the full length of the passenger cabin, and eliminating irregular seat rows toward the rear of the aircraft.\nThe 767 was the first Boeing wide-body to be designed with a two-crew digital glass cockpit. Cathode-ray tube (CRT) color displays and new electronics replaced the role of the flight engineer by enabling the pilot and co-pilot to monitor aircraft systems directly. Despite the promise of reduced crew costs, United Airlines initially demanded a conventional three-person cockpit, citing concerns about the risks associated with introducing a new aircraft. The carrier maintained this position until July 1981, when a US presidential task force determined that a crew of two was safe for operating wide-body jets. A three-crew cockpit remained as an option and was fitted to the first production models. Ansett Australia ordered 767s with three-crew cockpits due to union demands; it was the only airline to operate 767s so configured. The 767's two-crew cockpit was also applied to the 757, allowing pilots to operate both aircraft after a short conversion course, and adding incentive for airlines to purchase both types.\nProduction and testing.\nTo produce the 767, Boeing formed a network of subcontractors which included domestic suppliers and international contributions from Italy's Aeritalia and Japan's CTDC. The wings and cabin floor were produced in-house, while Aeritalia provided control surfaces, Boeing Vertol made the leading edge for the wings, and Boeing Wichita produced the forward fuselage. The CTDC provided multiple assemblies through its constituent companies, namely Fuji Heavy Industries (wing fairings and gear doors), Kawasaki Heavy Industries (center fuselage), and Mitsubishi Heavy Industries (rear fuselage, doors, and tail). Components were integrated during final assembly at the Everett factory. For expedited production of wing spars, the main structural member of aircraft wings, the Everett factory received robotic machinery to automate the process of drilling holes and inserting fasteners. This method of wing construction expanded on techniques developed for the 747. Final assembly of the first aircraft began in July 1979.\nThe prototype aircraft, registered as N767BA and equipped with Pratt &amp; Whitney JT9D turbofans, was rolled out on August 4, 1981. By this time, the 767 program had accumulated 173 firm orders from 17 customers, including Air Canada, All Nippon Airways, Britannia Airways, Transbrasil, and Trans World Airlines (TWA). On September 26, 1981, the prototype took its maiden flight under the command of company test pilots Tommy Edmonds, Lew Wallick, and John Brit. The maiden flight was largely uneventful, save for the inability to retract the landing gear because of a hydraulic fluid leak. The prototype was used for subsequent flight tests.\nThe 10-month 767 flight test program utilized the first six aircraft built. The first four aircraft were equipped with JT9D engines, while the fifth and sixth were fitted with CF6 engines. The test fleet was largely used to evaluate avionics, flight systems, handling, and performance, while the sixth aircraft was used for route-proving flights. During testing, pilots described the 767 as generally easy to fly, with its maneuverability unencumbered by the bulkiness associated with larger wide-body jets. Following 1,600 hours of flight tests, the JT9D-powered 767-200 received certification from the US Federal Aviation Administration (FAA) and the UK Civil Aviation Authority (CAA) in July 1982. The first delivery occurred on August 19, 1982, to United Airlines. The CF6-powered 767-200 received certification in September 1982, followed by the first delivery to Delta Air Lines on October 25, 1982.\nEntry into service.\nThe 767 entered service with United Airlines on September 8, 1982. The aircraft's first commercial flight used a JT9D-powered on the Chicago-to-Denver route. The CF6-powered 767-200 commenced service three months later with Delta Air Lines. Upon delivery, early 767s were mainly deployed on domestic routes, including US transcontinental services. American Airlines and TWA began flying the 767-200 in late 1982, while Air Canada, China Airlines, El Al, and Pacific Western began operating the aircraft in 1983. The aircraft's introduction was relatively smooth, with few operational glitches and greater dispatch reliability than prior jetliners.\nExemptions from major certification rule changes.\nFollowing the 1996 in-flight explosion of TWA Flight 800, the FAA introduced new rules about flammability reduction in 2008. In 2012, Boeing requested an exemption for the 767 from new wiring separation rules that would prevent ignition sources, because design improvements it introduced fell short of meeting such rules. One of the justification by Boeing: changes to the fuel quantity indication system would require a halt of delivery by three years as production of the 767 model was expected to end shortly. FAA gave the manufacturer three years to have a compliant system while deliveries continued. In 2014, Boeing, without a new design available, asked for and received another time-limited exemption for just the 767-300 and 767-300ER until 2019 when commercial production was expected to cease. But in 2017, with continual demand for the 767-300F, Boeing asked for another exemption up to the end of 2027, well past the revised production end date. It is noted that while Boeing requested extension of the original exemption from 2016 to 2019 based upon the cost of upgrading the design and their low production rate and ending production in 2019, Boeing developed the KC-46 tanker (based on the 767) which fully compliant with the new rulings and is assembled on the same production line as the 767. Since the 2019 exemption went into effect, Boeing has increased production of the freighter to satisfy demand.\nStretched derivatives.\nFirst stretch: -300/-300ER/F.\nForecasting airline interest in larger-capacity models, Boeing announced the stretched in 1983 and the extended-range 767-300ER in 1984. Both models offered a 20\u00a0percent passenger capacity increase, while the extended-range version was capable of operating flights up to . Japan Airlines placed the first order for the -300 in September 1983. Following its first flight on January 30, 1986, the type entered service with Japan Airlines on October 20, 1986. The 767-300ER completed its first flight on December 9, 1986, but it was not until March 1987 that the first firm order, from American Airlines, was placed. The type entered service with American Airlines on March 3, 1988. The 767-300 and 767-300ER gained popularity after entering service, and came to account for approximately two-thirds of all 767s sold. Until the 777's 1995 debut, the 767-300 and 767-300ER remained Boeing's second-largest wide-bodies behind the 747.\nBuoyed by a recovering global economy and ETOPS approval, 767 sales accelerated in the mid-to-late 1980s; 1989 was the most prolific year with 132 firm orders. By the early 1990s, the wide-body twinjet had become its manufacturer's annual best-selling aircraft, despite a slight decrease due to economic recession. During this period, the 767 became the most common airliner for transatlantic flights between North America and Europe. By the end of the decade, 767s crossed the Atlantic more frequently than all other aircraft types combined. The 767 also propelled the growth of point-to-point flights which bypassed major airline hubs in favor of direct routes. Taking advantage of the aircraft's lower operating costs and smaller capacity, operators added non-stop flights to secondary population centers, thereby eliminating the need for connecting flights. The increased number of cities receiving non-stop services caused a paradigm shift in the airline industry as point-to-point travel gained prominence at the expense of the traditional hub-and-spoke model.\nIn February 1990, the first 767 equipped with Rolls-Royce RB211 turbofans, a , was delivered to British Airways. Six months later, the carrier temporarily grounded its entire 767 fleet after discovering cracks in the engine pylons of several aircraft. The cracks were related to the extra weight of the RB211 engines, which are heavier than other 767 engines. During the grounding, interim repairs were conducted to alleviate stress on engine pylon components, and a parts redesign in 1991 prevented further cracks. Boeing also performed a structural reassessment, resulting in production changes and modifications to the engine pylons of all 767s in service.\nIn January 1993, following an order from UPS Airlines, Boeing launched a freighter variant, the 767-300F, which entered service with UPS on October 16, 1995. The 767-300F featured a main deck cargo hold, upgraded landing gear, and strengthened wing structure. In November 1993, the Japanese government launched the first 767 military derivative when it placed orders for the , an Airborne Early Warning and Control (AWACS) variant based on the 767-200ER. The first two , featuring extensive modifications to accommodate surveillance radar and other monitoring equipment, were delivered in 1998 to the Japan Self-Defense Forces.\nSecond stretch:-400ER.\nIn November 1995, after abandoning development of a smaller version of the 777, Boeing announced that it was revisiting studies for a larger 767. The proposed 767-400X, a second stretch of the aircraft, offered a 12\u00a0percent capacity increase versus the , and featured an upgraded flight deck, enhanced interior, and greater wingspan. The variant was specifically aimed at Delta Air Lines' pending replacement of its aging Lockheed L-1011 TriStars, and faced competition from the A330-200, a shortened derivative of the Airbus A330. In March 1997, Delta Air Lines launched the 767-400ER when it ordered the type to replace its L-1011 fleet. In October 1997, Continental Airlines also ordered the 767-400ER to replace its McDonnell Douglas DC-10 fleet. The type completed its first flight on October 9, 1999, and entered service with Continental Airlines on September 14, 2000.\nDreamliner introduction.\nIn the early 2000s, cumulative 767 deliveries approached 900, but new sales declined during an airline industry downturn. In 2001, Boeing dropped plans for a longer-range model, the 767-400ERX, in favor of the proposed Sonic Cruiser, a new jetliner which aimed to fly 15\u00a0percent faster while having comparable fuel costs to the 767. The following year, Boeing announced the KC-767 Tanker Transport, a second military derivative of the 767-200ER. Launched with an order in October 2002 from the Italian Air Force, the KC-767 was intended for the dual role of refueling other aircraft and carrying cargo. The Japanese government became the second customer for the type in March 2003. In May 2003, the United States Air Force (USAF) announced its intent to lease KC-767s to replace its aging KC-135 tankers. The plan was suspended in March 2004 amid a conflict of interest scandal, resulting in multiple US government investigations and the departure of several Boeing officials, including Philip Condit, the company's chief executive officer, and chief financial officer Michael Sears. The first KC-767s were delivered in 2008 to the Japan Self-Defense Forces.\nIn late 2002, after airlines expressed reservations about its emphasis on speed over cost reduction, Boeing halted development of the Sonic Cruiser. The following year, the manufacturer announced the 7E7, a mid-size 767 successor made from composite materials which promised to be 20\u00a0percent more fuel efficient. The new jetliner was the first stage of a replacement aircraft initiative called the Boeing Yellowstone Project. Customers embraced the 7E7, later renamed 787 Dreamliner, and within two years it had become the fastest-selling airliner in the company's history. In 2005, Boeing opted to continue 767 production despite record Dreamliner sales, citing a need to provide customers waiting for the 787 with a more readily available option. Subsequently, the 767-300ER was offered to customers affected by 787 delays, including All Nippon Airways and Japan Airlines. Some aging 767s, exceeding 20 years in age, were also kept in service past planned retirement dates due to the delays. To extend the operational lives of older aircraft, airlines increased heavy maintenance procedures, including D-check teardowns and inspections for corrosion, a recurring issue on aging 767s. The first 787s entered service with All Nippon Airways in October 2011, 42 months behind schedule.\nContinued production.\nIn 2007, the 767 received a production boost when UPS and DHL Aviation placed a combined 33 orders for the 767-300F. Renewed freighter interest led Boeing to consider enhanced versions of the 767-200 and 767-300F with increased gross weights, 767-400ER wing extensions, and 777 avionics. Net orders for the 767 declined from 24 in 2008 to just three in 2010. During the same period, operators upgraded aircraft already in service; in 2008, the first 767-300ER retrofitted with blended winglets from Aviation Partners Incorporated debuted with American Airlines. The manufacturer-sanctioned winglets, at in height, improved fuel efficiency by an estimated 6.5\u00a0percent. Other carriers including All Nippon Airways and Delta Air Lines also ordered winglet kits.\nOn February 2, 2011, the 1,000th 767 rolled out, destined for All Nippon Airways. The aircraft was the 91st 767-300ER ordered by the Japanese carrier, and with its completion the 767 became the second wide-body airliner to reach the thousand-unit milestone after the 747. The 1,000th aircraft also marked the last model produced on the original 767 assembly line. Beginning with the 1,001st aircraft, production moved to another area in the Everett factory which occupied about half of the previous floor space. The new assembly line made room for 787 production and aimed to boost manufacturing efficiency by over twenty percent.\nAt the inauguration of its new assembly line, the 767's order backlog numbered approximately 50, only enough for production to last until 2013. Despite the reduced backlog, Boeing officials expressed optimism that additional orders would be forthcoming. On February 24, 2011, the USAF announced its selection of the KC-767 Advanced Tanker, an upgraded variant of the KC-767, for its KC-X fleet renewal program. The selection followed two rounds of tanker competition between Boeing and Airbus parent EADS, and came eight years after the USAF's original 2003 announcement of its plan to lease KC-767s. The tanker order encompassed 179 aircraft and was expected to sustain 767 production past 2013.\nIn December 2011, FedEx Express announced a 767-300F order for 27 aircraft to replace its DC-10 freighters, citing the USAF tanker order and Boeing's decision to continue production as contributing factors. FedEx Express agreed to buy 19 more of the \u2212300F variant in June 2012. In June 2015, FedEx said it was accelerating retirements of planes both to reflect demand and to modernize its fleet, recording charges of $276 million (~$ in ). On July 21, 2015, FedEx announced an order for 50 767-300F with options on another 50, the largest order for the type. With the announcement FedEx confirmed that it has firm orders for 106 of the freighters for delivery between 2018 and 2023. In February 2018, UPS announced an order for 4 more 767-300Fs to increase the total on order to 63.\nWith its successor, the Boeing New Midsize Airplane, that was planned for introduction in 2025 or later, and the 787 being much larger, Boeing could restart a passenger 767-300ER production to bridge the gap. A demand for 50 to 60 aircraft could have to be satisfied. Having to replace its 40 767s, United Airlines requested a price quote for other widebodies. In November 2017, Boeing CEO Dennis Muilenburg cited interest beyond military and freighter uses. However, in early 2018 Boeing Commercial Airplanes VP of marketing Randy Tinseth stated that the company did not intend to resume production of the passenger variant.\nIn its first quarter of 2018 earnings report, Boeing plans to increase its production from 2.5 to 3 monthly beginning in January 2020 due to increased demand in the cargo market, as FedEx had 56 on order, UPS has four, and an unidentified customer has three on order. This rate could rise to 3.5 per month in July 2020 and 4 per month in January 2021, before decreasing to 3 per month in January 2025 and then 2 per month in July 2025.\nIn 2019, unit cost was US$217.9 million for a -300ER, and US$220.3 million for a -300F.\nProduction of the 767 was expected to cease by the end of 2027 due to more stringent emissions and noise limits that will go into effect in 2028. However, , the US Congress is considering giving Boeing a waiver to continue to produce the 767 freighter for an additional five years. If granted, these aircraft would be restricted to domestic use within the US only. Boeing is widely expected to begin production of 787 Freighter during that extension period.\nContinued development.\n767-X (partial double-deck).\nAfter the debut of the first stretched 767s, Boeing sought to address airline requests for greater capacity by proposing larger models, including a partial double-deck version informally named the \"Hunchback of Mukilteo\" (from a town near Boeing's Everett factory) with a 757 body section mounted over the aft main fuselage. In 1986, Boeing proposed the 767-X, a revised model with extended wings and a wider cabin, but received little interest. The 767-X did not get enough interest from airlines to launch and the model was shelved in 1988 in favor of the Boeing 777.\n767-400ERX.\nIn March 2000, Boeing was to launch the 259-seat 767-400ERX with an initial order for three from Kenya Airways with deliveries planned for 2004, as it was proposed to Lauda Air. \nIncreased gross weight and a tailplane fuel tank would have boosted its range by , and GE could offer its CF6-80C2/G2. Rolls-Royce offered its Trent 600 for the 767-400ERX and the Boeing 747X.\nOffered in July, the longer-range -400ERX would have a strengthened wing, fuselage and landing gear for a 15,000\u00a0lb (6.8\u00a0t) higher MTOW, up to 465,000\u00a0lb (210.92 t).\nThrust would rise to for better takeoff performance, with the Trent 600 or the General Electric/Pratt &amp; Whitney Engine Alliance GP7172, also offered on the 747X.\nRange would increase by to , with an additional fuel tank of in the horizontal tail.\nThe 767-400ERX would offer the capacity of the Airbus A330-200 with 3% lower fuel burn and costs.\nBoeing cancelled the variant development in 2001. Kenya Airways then switched its order to the 777-200ER.\n767-XF (re-engine).\nIn October 2019, Boeing was reportedly studying a re-engined 767-XF for entry into service around 2025, based on the 767-400ER with an extended landing gear to accommodate larger General Electric GEnx turbofan engines.\nThe cargo market is the main target, but a passenger version could be a cheaper alternative to the proposed New Midsize Airplane.\nDesign.\nOverview.\nThe 767 is a low-wing cantilever monoplane with a conventional tail unit featuring a single fin and rudder. The wings are swept at 31.5 degrees and optimized for a cruising speed of Mach 0.8 (). Each wing features a supercritical airfoil cross-section and is equipped with six-panel leading edge slats, single- and double-slotted flaps, inboard and outboard ailerons, and six spoilers. The airframe further incorporates Carbon-fiber-reinforced polymer composite material wing surfaces, Kevlar fairings and access panels, plus improved aluminum alloys, which together reduce overall weight by versus preceding aircraft.\nTo distribute the aircraft's weight on the ground, the 767 has a retractable tricycle landing gear with four wheels on each main gear and two for the nose gear. The original wing and gear design accommodated the stretched 767-300 without major changes. The 767-400ER features a larger, more widely spaced main gear with 777 wheels, tires, and brakes. To prevent damage if the tail section contacts the runway surface during takeoff, 767-300 and 767-400ER models are fitted with a retractable tailskid.\nAll passenger 767 models have exit doors near the front and rear of the aircraft. Most 767-200 and -200ER models have one overwing exit door for emergency use; an optional second overwing exit increases maximum allowable capacity from 255 to 290. The 767-300 and -300ER typically feature two overwing exit doors or, in a configuration with no overwing exits, three exit doors on each side and a smaller exit door aft of the wing. A further configuration featuring three exit doors on each side plus one overwing exit allows an increase in maximum capacity from 290 to 351. All 767-400ERs are configured with three exit doors on each side and a smaller exit door aft of the wing. The 767-300F has one exit door at the forward left-hand side of the aircraft.\nIn addition to shared avionics and computer technology, the 767 uses the same auxiliary power unit, electric power systems, and hydraulic parts as the 757. A raised cockpit floor and the same forward cockpit windows result in similar pilot viewing angles. Related design and functionality allows 767 pilots to obtain a common type rating to operate the 757 and share the same seniority roster with pilots of either aircraft.\nFlight systems.\nThe original 767 flight deck uses six Rockwell Collins CRT screens to display electronic flight instrument system (EFIS) and engine indication and crew alerting system (EICAS) information, allowing pilots to handle monitoring tasks previously performed by the flight engineer. The CRTs replace conventional electromechanical instruments found on earlier aircraft. An enhanced flight management system, improved over versions used on early 747s, automates navigation and other functions, while an automatic landing system facilitates CAT IIIb instrument landings in low visibility situations. The 767 became the first aircraft to receive CAT IIIb certification from the FAA for landings with minimum visibility in 1984. On the 767-400ER, the cockpit layout is simplified further with six Rockwell Collins liquid crystal display (LCD) screens, and adapted for similarities with the 777 and the Next Generation 737. To retain operational commonality, the LCD screens can be programmed to display information in the same manner as earlier 767s. In 2012, Boeing and Rockwell Collins launched a further 787-based cockpit upgrade for the 767, featuring three landscape-format LCD screens that can display two windows each.\nThe 767 is equipped with three redundant hydraulic systems for operation of control surfaces, landing gear, and utility actuation systems. Each engine powers a separate hydraulic system, and the third system uses electric pumps. A ram air turbine provides power for basic controls in the event of an emergency. An early form of fly-by-wire is employed for spoiler operation, utilizing electric signaling instead of traditional control cables. The fly-by-wire system reduces weight and allows independent operation of individual spoilers.\nInterior.\nThe 767 features a twin-aisle cabin with a typical configuration of six abreast in business class and seven across in economy. The standard seven abreast, 2\u20133\u20132 economy class layout places approximately 87\u00a0percent of all seats at a window or aisle. As a result, the aircraft can be largely occupied before center seats need to be filled, and each passenger is no more than one seat from the aisle. It is possible to configure the aircraft with extra seats for up to an eight abreast configuration, but this is less common.\nThe 767 interior introduced larger overhead bins and more lavatories per passenger than previous aircraft. The bins are wider to accommodate garment bags without folding, and strengthened for heavier carry-on items. A single, large galley is installed near the aft doors, allowing for more efficient meal service and simpler ground resupply. Passenger and service doors are an overhead plug type, which retract upwards, and commonly used doors can be equipped with an electric-assist system.\nIn 2000, a 777-style interior, known as the Boeing Signature Interior, debuted on the 767-400ER. Subsequently, adopted for all new-build 767s, the Signature Interior features even larger overhead bins, indirect lighting, and sculpted, curved panels. The 767-400ER also received larger windows derived from the 777. Older 767s can be retrofitted with the Signature Interior. Some operators have adopted a simpler modification known as the Enhanced Interior, featuring curved ceiling panels and indirect lighting with minimal modification of cabin architecture, as well as aftermarket modifications such as the NuLook 767 package by Heath Tecna.\nOperational history.\nIn its first year, the 767 logged a 96.1\u00a0percent dispatch rate, which exceeded the industry average for all-new aircraft. Operators reported generally favorable ratings for the twinjet's sound levels, interior comfort, and economic performance. Resolved issues were minor and included the recalibration of a leading edge sensor to prevent false readings, the replacement of an evacuation slide latch, and the repair of a tailplane pivot to match production specifications.\nSeeking to capitalize on its new wide-body's potential for growth, Boeing offered an extended-range model, the 767-200ER, in its first year of service. Ethiopian Airlines placed the first order for the type in December 1982. Featuring increased gross weight and greater fuel capacity, the extended-range model could carry heavier payloads at distances up to , and was targeted at overseas customers. The 767-200ER entered service with El Al Airline on March 27, 1984. The type was mainly ordered by international airlines operating medium-traffic, long-distance flights. In May 1984, an Ethiopian Airlines 767-200ER set a non-stop record for a commercial twinjet of from Washington, D.C. to Addis Ababa.\nIn the mid-1980s, the 767 and its European rivals, the Airbus A300 and A310, spearheaded the growth of twinjet flights across the northern Atlantic under extended-range twin-engine operational performance standards (ETOPS) regulations, the FAA's safety rules governing transoceanic flights by aircraft with two engines. In 1976, the A300 was the first twinjet to secure permission to fly 90 minutes away from diversion airports, up from 60 minutes. In May 1985, the FAA granted its first approval for 120-minute ETOPS flights to the 767, on an individual airline basis starting with TWA, provided that the operator met flight safety criteria. This allowed the aircraft to fly overseas routes at up to two hours' distance from land. The 767 burned less fuel per hour than a Lockheed L-1011 TriStar on the route between Boston and Paris, a huge savings. The Airbus A310 secured approval for 120-minute ETOPS flights one month later in June. The larger safety margins were permitted because of the improved reliability demonstrated by twinjets and their turbofan engines. The FAA lengthened the ETOPS time to 180 minutes for CF6-powered 767s in 1989, making the type the first to be certified under the longer duration, and all available engines received approval by 1993. Regulatory approval spurred the expansion of transoceanic flights with twinjet aircraft and boosted the sales of both the 767 and its rivals.\nVariants.\nThe 767 has been produced in three fuselage lengths. These debuted in progressively larger form as the , , and 767-400ER. Longer-range variants include the 767-200ER and 767-300ER, while cargo models include the 767-300F, a production freighter, and conversions of passenger 767-200 and 767-300 models.\nWhen referring to different variants, Boeing and airlines often collapse the model number (767) and the variant designator, e.g. \u2013200 or \u2013300, into a truncated form, e.g. \"762\" or \"763\". Subsequent to the capacity number, designations may append the range identifier, though -200ER and -300ER are company marketing designations and not certificated as such. The International Civil Aviation Organization (ICAO) aircraft type designator system uses a similar numbering scheme, but adds a preceding manufacturer letter; all variants based on the 767-200 and 767-300 are classified under the codes \"B762\" and \"B763\"; the 767-400ER receives the designation of \"B764\".\n767-200.\nThe 767-200 was the original model and entered service with United Airlines in 1982. The type has been used primarily by mainline U.S. carriers for domestic routes between major hub centers such as Los Angeles to Washington. The 767-200 was the first aircraft to be used on transatlantic ETOPS flights, beginning with TWA on February 1, 1985, under 90-minute diversion rules. Deliveries for the variant totaled 128 aircraft. There were 52 examples of the model in commercial service , almost entirely as freighter conversions. The type's competitors included the Airbus A300 and A310.\nThe 767-200 was produced until 1987 when production switched to the extended-range 767-200ER. Some early 767-200s were subsequently upgraded to extended-range specification. In 1998, Boeing began offering 767-200 conversions to 767-200SF (Special Freighter) specification for cargo use, and Israel Aerospace Industries has been licensed to perform cargo conversions since 2005. The conversion process entails the installation of a side cargo door, strengthened main deck floor, and added freight monitoring and safety equipment. The 767-200SF was positioned as a replacement for Douglas DC-8 freighters.\n767-2C.\nA commercial freighter version of the Boeing with wings from the -300 series and an updated flightdeck was first flown on December 29, 2014. A military tanker variant of the Boeing 767-2C is developed for the USAF as the KC-46. Boeing is building two aircraft as commercial freighters which will be used to obtain Federal Aviation Administration certification, a further two Boeing 767-2Cs will be modified as military tankers. , Boeing does not have customers for the freighter.\n767-200ER.\nThe 767-200ER was the first extended-range model and entered service with El Al in 1984. The type's increased range is due to extra fuel capacity and higher maximum takeoff weight (MTOW) of up to . The additional fuel capacity is accomplished by using the center tank's dry dock to carry fuel. The non-ER variant's center tank is what is called \"cheek tanks\"; two interconnected halves in each wing root with a dry dock in between. The center tank is also used on the -300ER and -400ER variants.\nThis version was originally offered with the same engines as the , while more powerful Pratt &amp; Whitney PW4000 and General Electric CF6 engines later became available. The 767-200ER was the first 767 to complete a non-stop transatlantic journey, and broke the flying distance record for a twinjet airliner on April 17, 1988, with an Air Mauritius flight from Halifax, Nova Scotia to Port Louis, Mauritius, covering . The 767-200ER has been acquired by international operators seeking smaller wide-body aircraft for long-haul routes such as New York to Beijing. Deliveries of the type totaled 121 with no unfilled orders. As of July 2018, 21 examples of passenger and freighter conversion versions were in airline service. The type's main competitors of the time included the Airbus A300-600R and the A310-300.\n767-300.\nThe , the first stretched version of the aircraft, entered service with Japan Airlines in 1986. The type features a fuselage extension over the , achieved by additional sections inserted before and after the wings, for an overall length of . Reflecting the growth potential built into the original 767 design, the wings, engines, and most systems were largely unchanged on the . An optional mid-cabin exit door is positioned ahead of the wings on the left, while more powerful Pratt &amp; Whitney PW4000 and Rolls-Royce RB211 engines later became available. The 767-300's increased capacity has been used on high-density routes within Asia and Europe. The 767-300 was produced from 1986 until 2000. Deliveries for the type totaled 104 aircraft with no unfilled orders remaining. The type's main competitor was the Airbus A300.\n767-300ER.\nThe 767-300ER, the extended-range version of the , entered service with American Airlines in 1988. The type's increased range was made possible by greater fuel tankage and a higher MTOW of . Design improvements allowed the available MTOW to increase to by 1993. Power is provided by Pratt &amp; Whitney PW4000, General Electric CF6, or Rolls-Royce RB211 engines. The 767-300ER comes in three exit configurations: the baseline configuration has four main cabin doors and four over-wing window exits, the second configuration has six main cabin doors and two over-wing window exits; and the third configuration has six main cabin doors, as well as two smaller doors that are located behind the wings. Typical routes for the type include New York to Frankfurt.\nThe combination of increased capacity and range for the -300ER has been particularly attractive to both new and existing 767 operators. It is the most successful 767 version, with more orders placed than all other variants combined. , 767-300ER deliveries stand at 583 with no unfilled orders. There were 376 examples in service . The type's main competitor is the Airbus A330-200. At its 1990s peak, a new 767-300ER was valued at $85 million, dipping to around $12 million in 2018 for a 1996 build.\n767-300F.\nThe 767-300F, the production freighter version of the 767-300ER, entered service with UPS Airlines in 1995. The 767-300F can hold up to 24 standard pallets on its main deck and up to 30 LD2 unit load devices on the lower deck, with a total cargo volume of . The freighter has a main deck cargo door and crew exit, while the lower deck features two starboard-side cargo doors and one port-side cargo door. A general market version with onboard freight-handling systems, refrigeration capability, and crew facilities was delivered to Asiana Airlines on August 23, 1996. , 767-300F deliveries stand at 161 with 61 unfilled orders. Airlines operated 222 examples of the freighter variant and freighter conversions in July 2018.\nConverted freighters.\nIn June 2008, All Nippon Airways took delivery of the first 767-300BCF (Boeing Converted Freighter), a modified passenger-to-freighter model. The conversion work was performed in Singapore by ST Aerospace Services, the first supplier to offer a 767-300BCF program, and involved the addition of a main deck cargo door, strengthened main deck floor, and additional freight monitoring and safety equipment.\nIsrael Aerospace Industries offers a passenger-to-freighter conversion program called the 767-300BDSF (BEDEK Special Freighter). Wagner Aeronautical also offers a passenger-to-freighter conversion program for series aircraft.\n767-400ER.\nThe 767-400ER, the first Boeing wide-body jet resulting from two fuselage stretches, entered service with Continental Airlines in 2000. The type features a stretch over the , for a total length of . The wingspan is also increased by through the addition of raked wingtips. The exit configuration uses six main cabin doors and two smaller exit doors behind the wings, similar to certain 767-300ERs. Other differences include an updated cockpit, redesigned landing gear, and 777-style Signature Interior. Power is provided by uprated General Electric CF6 engines.\nThe FAA granted approval for the 767-400ER to operate 180-minute ETOPS flights before it entered service. Because its fuel capacity was not increased over preceding models, the 767-400ER has a range of , less than previous extended-range 767s. No 767-400 (non-extended range) version was developed.\nThe longer-range 767-400ERX was offered in July 2000 before being cancelled a year later, leaving the 767-400ER as the sole version of the largest 767. Boeing dropped the 767-400ER and the -200ER from its pricing list in 2014.\nA total of 37 767-400ERs were delivered to the variant's two airline customers, Continental Airlines (now merged with United Airlines as of 2010) and Delta Air Lines, with no unfilled orders. All 37 examples of the -400ER were in service in July 2018. One additional example was produced as a military testbed for cancelled E-10, and later sold to Bahrain as a VIP transport. The type's closest competitor is the Airbus A330-200.\nMilitary and government.\nVersions of the 767 serve in a number of military and government applications, with responsibilities ranging from airborne surveillance and refueling to cargo and VIP transport. Several military 767s have been derived from the 767-200ER, the longest-range version of the aircraft.\nOperators.\nIn July 2018, 742 aircraft were in airline service: 73 -200s, 632 -300, and 37 -400ER with 65 -300F on order; the largest operators are Delta Air Lines (77), FedEx (60; largest cargo operator), UPS Airlines (59), United Airlines (), Japan Airlines (35), All Nippon Airways (34).\nThe largest 767 customers by orders placed are FedEx Express (150), Delta Air Lines (117), All Nippon Airways (96), American Airlines (88), and United Airlines (82). Delta and United are the only customers of all -200, -300, and -400ER passenger variants. In July 2015, FedEx placed a firm order for 50 Boeing 767 freighters with deliveries from 2018 to 2023. The type's competitors included the Airbus A300 and A310.\nOrders and deliveries.\nBoeing 767 orders and deliveries (cumulative, by year): \nAccidents and incidents.\n, the Boeing 767 has been in 67 aviation occurrences, including 19 hull-loss accidents. Seven fatal crashes, including three hijackings, have resulted in a total of 854 occupant fatalities.\nAccidents.\nThe airliner's first fatal crash, Lauda Air Flight 004, occurred near Bangkok on May 26, 1991, following the in-flight deployment of the left engine thrust reverser on a 767-300ER. None of the 223 aboard survived. As a result of this accident, all 767 thrust reversers were deactivated until a redesign was implemented. Investigators determined that an electronically controlled valve, common to late-model Boeing aircraft, was to blame. A new locking device was installed on all affected jetliners, including 767s.\nOn October 31, 1999, EgyptAir Flight 990, a 767-300ER, crashed off Nantucket, Massachusetts, in international waters killing all 217 people on board. The United States National Transportation Safety Board (NTSB) concluded \"not determined\", but determined the probable cause to be a deliberate action by the first officer; the Egyptian government disputed this conclusion.\nOn April 15, 2002, Air China Flight 129, a 767-200ER, crashed into a hill amid inclement weather while trying to land at Gimhae International Airport in Busan, South Korea. The crash resulted in the death of 129 of the 166 people on board, and the cause was attributed to pilot error. This was the deadliest plane crash in South Korea at the time.\nOn February 23, 2019, Atlas Air Flight 3591, a Boeing 767-300ERF air freighter operating for Amazon Air, crashed into Trinity Bay near Houston, Texas, while on descent into George Bush Intercontinental Airport; both pilots and the single passenger were killed. The cause was attributed to pilot error and spatial disorientation.\nOn November 1, 2011, LOT Polish Airlines Flight 16, a 767-300ER, safely landed at Warsaw Chopin Airport in Warsaw, Poland, after a mechanical failure of the landing gear forced an emergency landing with the landing gear retracted. There were no injuries, but the aircraft involved was damaged and written off. At the time aviation analysts speculated that it may have been the first instance of a complete landing gear failure in the 767's service history. Subsequent investigation determined that while a damaged hose had disabled the aircraft's primary landing gear extension system, an otherwise functional backup system was inoperative due to an accidentally deactivated circuit breaker.\nOn October 29, 2015, Dynamic Airways Flight 405, a 767-200ER, caught fire while taxiing to the runway at Hollywood International Airport. There were no fatalities, but 22 people were injured, 1 of them seriously. The aircraft was written off.\nOn October 28, 2016, American Airlines Flight 383, a 767-300ER with 161 passengers and 9 crew members, aborted takeoff at Chicago O'Hare Airport following an uncontained failure of the right GE CF6-80C2 engine. The engine failure, which hurled fragments over a considerable distance, caused a fuel leak, resulting in a fire under the right wing. Fire and smoke entered the cabin. All passengers and crew evacuated the aircraft, with 20 passengers and one flight attendant sustaining minor injuries using the evacuation slides.\nThe 767 has been involved in six hijackings, three resulting in loss of life, for a combined total of 282 occupant fatalities. On November 23, 1996, Ethiopian Airlines Flight 961, a 767-200ER, was hijacked and crash-landed in the Indian Ocean near the Comoro Islands after running out of fuel, killing 125 out of the 175 persons on board; this was a rare example of occupants surviving a land-based aircraft ditching on water. Two 767s were involved in the September 11 attacks on the World Trade Center in 2001, resulting in the collapse of its two main towers. American Airlines Flight 11, a 767-200ER, crashed into the North Tower, killing all 92 people on board, and United Airlines Flight 175, a , crashed into the South Tower, with the death of all 65 on board. In addition, more than 2,600 people were killed in the towers or on the ground. A failed shoe bomb attempt in December 2001 involved an American Airlines 767-300ER.\nIncidents.\nThe 767's first incident was Air Canada Flight 143, a , on July 23, 1983. The airplane ran out of fuel at an altitude of about 41,000 feet. Eventually, the pilots had to glide with both engines out for almost to an emergency landing at Gimli, Manitoba, Canada. The pilots used the aircraft's ram air turbine to power the hydraulic systems for aerodynamic control. There were no fatalities and only minor injuries. This aircraft was nicknamed \"Gimli Glider\" after its landing site. The aircraft, registered as C-GAUN, continued flying for Air Canada until its retirement in January 2008.\nIn January 2014, the U.S. Federal Aviation Administration issued a directive that ordered inspections of the elevators on more than 400 767s beginning in March 2014; the focus was on fasteners and other parts that can fail and cause the elevators to jam. The issue was first identified in 2000 and has been the subject of several Boeing service bulletins. The inspections and repairs are required to be completed within six years. The aircraft has also had multiple occurrences of \"uncommanded escape slide inflation\" during maintenance or operations, and during flight. In late 2015, the FAA issued a preliminary directive to address the issue.\nAircraft on display.\nAs new 767 variants roll off the assembly line, older series models have been retired and converted to cargo use, stored, or scrapped. One complete aircraft, N102DA, is the first to operate for Delta Air Lines and the twelfth example built. It was retired from airline service in February 2006 after being repainted back to its original 1982 Delta widget livery and given a farewell tour. It was then put on display at the Delta Flight Museum in the Delta corporate campus at the edge of Hartsfield\u2013Jackson Atlanta International Airport. \"The Spirit of Delta\" is on public display as of 2022.\nIn 2013 a Brazilian entrepreneur purchased a 767-200 that had operated for the now-defunct carrier Transbrasil under the registration PT-TAC. The aircraft, which was sold at a bankruptcy auction, was placed on outdoor display in Taguatinga as part of a proposed commercial development. , however, the development has not come to fruition. The aircraft is devoid of engines or landing gear and has deteriorated due to weather exposure and acts of vandalism but remains publicly accessible to view.\nSpecifications.\nBelow is an organized chart composed of the variants of the 767 and their specifications."}
{"id": "4166", "revid": "33809323", "url": "https://en.wikipedia.org/wiki?curid=4166", "title": "Bill Walsh", "text": "William Ernest Walsh (November 30, 1931 \u2013 July 30, 2007) was an American professional and college football coach. He served as head coach of the San Francisco 49ers and the Stanford Cardinal, during which time he popularized the West Coast offense. After retiring from the 49ers, Walsh worked as a sports broadcaster for several years and then returned as head coach at Stanford for three seasons.\nWalsh went 102\u201363\u20131 (wins-losses-ties) with the 49ers, winning 10 of his 14 postseason games along with six division titles, three NFC Championship titles, and three Super Bowls. He was named NFL Coach of the Year in 1981 and 1984. In 1993, he was elected to the Pro Football Hall of Fame. He is widely considered amongst the greatest coaches in NFL history.\nEarly life.\nWalsh was born in Fremont, California. He attended Hayward High School in Hayward in the San Francisco Bay Area, where he played running back.\nWalsh played quarterback at the College of San Mateo for two seasons. (Both John Madden and Walsh played and coached at the College of San Mateo early in their careers.) After playing at the College of San Mateo, Walsh transferred to San Jos\u00e9 State University, where he played tight end and defensive end. He also participated in intercollegiate boxing, winning the golden glove.\nWalsh graduated from San Jose State with a bachelor's degree in physical education in 1955. After two years in the U.S. Army participating on their boxing team, Walsh built a championship team at Washington High School in Fremont before becoming an assistant coach at Cal, Stanford and then the Oakland Raiders in 1966.\nCollege coaching career.\nHe served under Bob Bronzan as a graduate assistant coach on the Spartans football coaching staff and graduated with a master's degree in physical education from San Jose State in 1959. His master's thesis was entitled \"Flank Formation Football -- Stress: Defense\". Thesis 796.W228f.\nFollowing graduation, Walsh coached the football and swim teams at Washington High School in Fremont, California. While there he interviewed for an assistant coaching position with the new head coach of the University of California, Berkeley California Golden Bears football team, Marv Levy.\n\"I was very impressed, individually, by his knowledge, by his intelligence, by his personality, and hired him,\" Levy said. Levy and Walsh, two future NFL Hall of Famers, would never produce a winning season for the Golden Bears.\nLeaving Berkeley, Walsh did a stint at Stanford University as an assistant coach of its Cardinal football team before beginning his pro coaching career.\nProfessional coaching career.\nEarly years.\nWalsh began his pro coaching career in 1966 as an assistant with the AFL's Oakland Raiders. There he was versed in the downfield-oriented \"vertical\" passing offense favored by Al Davis, an acolyte of Sid Gillman.\nWalsh left the Raiders the next year to become the head coach and general manager of the San Jose Apaches of the Continental Football League (CFL). He led the Apaches to second place in the Pacific Division, but the team ceased all football operations prior to the start of the 1968 CFL season.\nIn 1968, Walsh joined the staff of head coach Paul Brown of the AFL expansion Cincinnati Bengals, where he coached wide receivers from 1968 to 1970. It was there that Walsh developed the philosophy now known as the \"West Coast offense\". Cincinnati's new quarterback, Virgil Carter, was known for his great mobility and accuracy but lacked a strong arm necessary to throw deep passes. To suit his strengths, Walsh suggested a modification of the downfield based \"vertical passing scheme\" he had learned during his time with the Raiders with one featuring a \"horizontal\" approach that relied on quick, short throws, often spreading the ball across the entire width of the field. In 1971 Walsh was given the additional responsibility of coaching the quarterbacks, and Carter went on to lead the league in pass completion percentage.\nKen Anderson eventually replaced Carter as starting quarterback, and, together with star wide receiver Isaac Curtis, produced a consistent, effective offensive attack.\nWhen Brown retired as head coach following the 1975 season and appointed Bill \"Tiger\" Johnson as his successor, Walsh resigned and served as an assistant coach in 1976 for the San Diego Chargers under head coach Tommy Prothro. In a 2006 interview, Walsh claimed that during his tenure with the Bengals, Brown \"worked against my candidacy\" to be a head coach anywhere in the league. \"All the way through I had opportunities, and I never knew about them\", Walsh said. \"And then when I left him, he called whoever he thought was necessary to keep me out of the NFL.\" Walsh also claimed that Brown kept talking him down any time Brown was called by NFL teams considering hiring Walsh as a head coach.\nIn 1977, Walsh was hired by Stanford University as the head coach of its Cardinal football team, where he stayed for two seasons. He was quite successful, with his teams posting a 9\u20133 record in 1977 with a win in the Sun Bowl, and going 8\u20134 in 1978 with a win in the Bluebonnet Bowl. His notable players at Stanford included quarterbacks Guy Benjamin, Steve Dils, wide receivers James Lofton and Ken Margerum, linebacker Gordy Ceresino, and running back Darrin Nelson. Walsh was the Pac-8 Conference Coach of the Year in 1977.\n49ers head coach.\nOn January 9, 1979, Walsh resigned as head coach at Stanford, and San Francisco 49ers team owner Edward J. DeBartolo, Jr. fired head coach Fred O'Connor and general manager Joe Thomas following a 2\u201314 in 1978 season. Walsh was appointed head coach of the 49ers the next day.\nThe 49ers went 2-14 again in 1979. Hidden behind that record were organizational changes made by Walsh that set the team on a better course, including selecting Notre Dame quarterback Joe Montana in the third round of the 1979 NFL draft.\nIn 1980, starting quarterback Steve DeBerg got the 49ers off to a 3\u20130 start, but after a week 6 blowout loss to the Dallas Cowboys by a score of 59\u201314, Walsh gave Montana a chance to start. On December 7 vs. the New Orleans Saints, the second-year player brought the 49ers back from a 35\u20137 halftime deficit to a 38\u201335 overtime win. In spite of this switch, the team struggled to a 6\u201310 finish \u2013 a record that belied a championship team in the making.\n1981 championship.\nIn 1981, Walsh's efforts as head coach led the team to a 13\u20133 regular season. Key victories were two wins each over the Los Angeles Rams and the Dallas Cowboys. The Rams were only two seasons removed from a Super Bowl appearance, and had dominated the series with the 49ers since 1967, winning 23, losing 3 and tying 1. San Francisco's two wins over the Rams in 1981 marked the shift of dominance in favor of the 49ers that lasted until 1998 with 30 wins (including 17 consecutively) against only 6 defeats. The 49ers blew out the Cowboys in week 6 of the regular season. On \"Monday Night Football\" that week, the win was not included in the halftime highlights. Walsh felt that this was because the Cowboys were scheduled to play the Rams the next week in a Sunday night game and that showing the highlights of the 49ers' win would potentially hurt the game's ratings. However, Walsh used this as a motivating factor for his team, who felt they were disrespected.\nThe 49ers faced the Cowboys again in the . The contest was very close, and in the fourth quarter Walsh called a series of running plays as the 49ers marched down the field against the Cowboys' prevent defense, which had been expecting the 49ers to mainly pass. The 49ers came from behind to win the game on Joe Montana's pass completion to Dwight Clark for a touchdown, a play that came to be known simply as The Catch, propelling Walsh to his first appearance in a Super Bowl. Walsh would later write that the 49ers' two wins over the Rams showed a shift of power in their division, while the wins over the Cowboys showed a shift of power in the conference.\nTwo weeks later, on January 24, 1982, San Francisco faced the Cincinnati Bengals in Super Bowl XVI, winning 26\u201321 for the team's first NFL championship. Only a year removed from back-to-back two-win seasons, the 49ers had risen from the cellar to the top of the NFL in just two seasons. What came to be known as the West Coast offense developed by Walsh had proven a winner.\nIn all, Walsh served as 49ers head coach for 10 years, winning three Super Bowl championships, in the 1981, 1984, and 1988 seasons, and establishing a new NFL record.\nWalsh had a disciplined approach to game-planning, famously scripting the first 10\u201315 offensive plays before the start of each game. His innovative play calling and design earned him the nickname \"The Genius\". In the ten-year span under Walsh, San Francisco scored 3,714 points (24.4 per game), the most of any team in the league.\nIn addition to Joe Montana, Walsh drafted Ronnie Lott, Charles Haley, and Jerry Rice, each one going on to the Pro Football Hall of Fame. He also traded a 2nd and 4th round pick in the 1987 draft for Steve Young, who took over from Montana, led the team to Super Bowl success, and was enshrined in Canton after his playing career. Walsh's success at every level of football, especially with the 49ers, earned him his own ticket to Canton in 1993.\nOn January 22, 1989, Walsh coached his final game with the 49ers, the memorable Super Bowl XXIII in which San Francisco beat Cincinnati 20\u201316. Walsh resigned as the 49ers head coach after the game. Walsh admitted years later that he immediately regretted the decision saying that he left too soon.\nCoaching tree.\nUpline.\nWalsh's upline coaching tree included working as assistant for American Football League great and Hall of Fame head coach Al Davis and NFL legend and Hall of Famer Paul Brown, and, through Davis, AFL great and Hall of Fame head coach Sid Gillman of the then AFL Los Angeles/San Diego Chargers.\nDownline.\nTree updated through December 9, 2015.\nMany Walsh assistants went on to become head coaches. including George Seifert, Mike Holmgren, Ray Rhodes, and Dennis Green. Seifert succeeded Walsh as 49ers head coach, and guided San Francisco to victories in Super Bowl XXIV and Super Bowl XXIX. Holmgren won a Super Bowl with the Green Bay Packers, and made 3 Super Bowl appearances as a head coach: 2 with the Packers, and another with the Seattle Seahawks. These coaches in turn have their own disciples who have used Walsh's West Coast system, such as former Denver Broncos head coach Mike Shanahan and former Houston Texans head coach Gary Kubiak. Mike Shanahan was an offensive coordinator under George Seifert and went on to win Super Bowl XXXII and Super Bowl XXXIII during his time as head coach of the Denver Broncos. Kubiak was first a quarterback coach with the 49ers, and then offensive coordinator for Shanahan with the Broncos. In 2015, he became the Broncos' head coach and led Denver to victory in Super Bowl 50. Dennis Green trained Tony Dungy, who won a Super Bowl with the Indianapolis Colts, and Brian Billick with his brother-in law and linebackers coach Mike Smith. Billick won a Super Bowl as head coach of the Baltimore Ravens.\nMike Holmgren trained many of his assistants to become head coaches, including Jon Gruden and Andy Reid. Gruden won a Super Bowl with the Tampa Bay Buccaneers. Reid served as head coach of the Philadelphia Eagles from 1999 to 2012, and guided the Eagles to multiple winning seasons and numerous playoff appearances, including 1 Super Bowl appearance. Ever since 2013, Reid has served as head coach of the Kansas City Chiefs. He was finally able to win a Super Bowl, when his Chiefs defeated the San Francisco 49ers in Super Bowl LIV, and two consecutive when his Chiefs defeated the Eagles in Super Bowl LVII and the San Francisco 49ers in Super Bowl LVIII. In addition to this, Marc Trestman, former head coach of the Chicago Bears, served as offensive coordinator under Seifert in the 90's. Gruden himself would train Mike Tomlin, who led the Pittsburgh Steelers to their sixth Super Bowl championship, and Jim Harbaugh, whose 49ers would face his brother, John Harbaugh, whom Reid himself trained, and the Baltimore Ravens at Super Bowl XLVII, which marked the Ravens' second World Championship.\nBill Walsh was viewed as a strong advocate for African-American head coaches in the NFL and NCAA. Thus, the impact of Walsh also changed the NFL into an equal opportunity for African-American coaches. Along with Ray Rhodes and Dennis Green, Tyrone Willingham became the head coach at Stanford, then later Notre Dame and Washington. One of Mike Shanahan's assistants, Karl Dorrell, went on to be the head coach at UCLA. Walsh directly helped propel Dennis Green into the NFL head coaching ranks by offering to take on the head coaching job at Stanford.\nLater years.\nAfter leaving the coaching ranks immediately following his team's victory in Super Bowl XXIII, Walsh went to work as a broadcaster for NBC, teaming with Dick Enberg to form the lead broadcasting team, replacing Merlin Olsen.\nDuring his time with NBC, rumors began to surface that Walsh would coach again in the NFL. There were at least two known instances.\nFirst, according to a February 2015 article by Mike Florio of NBC Sports, after a 5\u201311 season in 1989, the Patriots fired Raymond Berry and unsuccessfully attempted to lure Walsh to Foxborough to become head coach and general manager. When that failed, New England promoted defensive coordinator Rod Rust; the team split its first two games and then lost 14 straight in 1990.\nSecond, late in the 1990 season, Walsh was rumored to become Tampa Bay's next head coach and general manager after the team fired Ray Perkins and promoted Richard Williamson on an interim basis. Part of the speculation was fueled by the fact that Walsh's contract with NBC, which ran for 1989 and 1990, would soon be up for renewal, to say nothing of the pressure Hugh Culverhouse faced to increase fan support and to fill the seats at Tampa Stadium. However, less than a week after Super Bowl XXV, Walsh not only declined Tampa Bay's offer, but he and NBC agreed on a contract extension. Walsh would continue in his role with NBC for 1991. Meanwhile, after unsuccessfully courting then-recently fired Eagles coach Buddy Ryan or Giants then-defensive coordinator Bill Belichick to man the sidelines for Tampa Bay in 1991, the Bucs stuck with Williamson. Under Williamson's leadership, Tampa Bay won only three games in 1991.\nOn January 15, 1992, Walsh agreed to return to Stanford to serve as their head coach with a five year contract with an annual salary of $350,000 to replace Dennis Green; he immediately named Terry Shea as offensive coordinator. That year, he led the Cardinal to a 10\u20133 record and a Pacific-10 Conference co-championship; it was the first conference championship for the program since 1971. Stanford finished the season with a victory over Penn State in the Blockbuster Bowl on January 1, 1993, and a #9 ranking in the final AP Poll. In November 1994, after consecutive losing seasons, Walsh left Stanford and retired from coaching.\nIn 1996, Walsh returned to the 49ers as an administrative aide. Walsh was the vice president and general manager for the 49ers from 1999 to 2001 and was a special consultant to the team for three years afterwards.\nIn 2004, Walsh was appointed as special assistant to the athletic director at Stanford. In 2005, after then-athletic director Ted Leland stepped down, Walsh was named interim athletic director. He also acted as a consultant for his alma mater San Jose State University in their search for an athletic director and Head Football Coach in 2005.\nWalsh was also the author of three books, a motivational speaker, and taught classes at the Stanford Graduate School of Business.\nWalsh was a board member for the Lott IMPACT Trophy, which is named after Pro Football Hall of Fame defensive back Ronnie Lott, and is awarded annually to college football's Defensive IMPACT Player of the Year. Walsh served as a keynote speaker at the award's banquet.\nPersonal life.\nBill married his college sweetheart Geri, and had 3 children; Steve, Craig and Elizabeth.\nDeath.\nBill Walsh died of leukemia on July 30, 2007, at his home in Woodside, California.\nFollowing Walsh's death, the playing field at the former Candlestick Park was renamed \"Bill Walsh Field\". Additionally, the regular San Jose State versus Stanford football game was renamed the \"Bill Walsh Legacy Game\". Super Bowl XLII was also dedicated to Walsh's memory; at the end of the player introduction ceremonies, his son, Craig, accompanied by Ronnie Lott, Jerry Rice and Steve Young, performed the ceremonial coin toss with New York Giants captain Michael Strahan, playing his final career NFL game, calling the toss on behalf of his Giants co-captains and the New England Patriots' captains.\nExternal links.\n "}
{"id": "4167", "revid": "33145", "url": "https://en.wikipedia.org/wiki?curid=4167", "title": "Box-cutter knives", "text": ""}
{"id": "4168", "revid": "10095895", "url": "https://en.wikipedia.org/wiki?curid=4168", "title": "Utility knife", "text": "A utility knife is any type of knife used for general manual work purposes. Such knives were originally fixed-blade knives with durable cutting edges suitable for rough work such as cutting cordage, cutting/scraping hides, butchering animals, cleaning fish scales, reshaping timber, and other tasks. Craft knives are small utility knives used as precision-oriented tools for finer, more delicate tasks such as carving and papercutting.\nToday, the term \"utility knife\" also includes small folding-, retractable- and/or replaceable-blade knives suited for use in the general workplace or in the construction industry. The latter type is sometimes generically called a Stanley knife, after a prominent brand designed by the American tool manufacturing company Stanley Black &amp; Decker.\nThere is also a utility knife for kitchen use, which is sized between a chef's knife and paring knife.\nHistory.\nThe fixed-blade utility knife was developed some 500,000 years ago, when human ancestors began to make stone knives. These knives were general-purpose tools, designed for cutting and shaping wooden implements, scraping hides, preparing food, and for other utilitarian purposes.\nBy the 19th century the fixed-blade utility knife had evolved into a steel-bladed outdoors field knife capable of butchering game, cutting wood, and preparing campfires and meals. With the invention of the backspring, pocket-size utility knives were introduced with folding blades and other folding tools designed to increase the utility of the overall design. The folding pocketknife and utility tool is typified by the \"Camper\" or \"Boy Scout\" pocketknife, the Swiss Army Knife, and by multi-tools fitted with knife blades. The development of stronger locking blade mechanisms for folding knives\u2014as with the Spanish navaja, the Opinel, and the Buck 110 Folding Hunter\u2014significantly increased the utility of such knives when employed for heavy-duty tasks such as preparing game or cutting through dense or tough materials.\nContemporary utility knives.\nThe fixed or folding blade utility knife is popular for both indoor and outdoor use. One of the most popular types of workplace utility knife is the retractable or folding utility knife (also known as a \"Stanley knife\", \"box cutter\", or by various other names). These types of utility knives are designed as multi-purpose cutting tools for use in a variety of trades and crafts. Designed to be lightweight and easy to carry and use, utility knives are commonly used in factories, warehouses, construction projects, and other situations where a tool is routinely needed to mark cut lines, trim plastic or wood materials, or to cut tape, cord, strapping, cardboard, or other packaging material.\nNames.\nIn British, Australian and New Zealand English, along with Dutch, Danish and Austrian German, a utility knife is often referred to as a \"Stanley knife\". This name is a generic trademark named after Stanley Works, a manufacturer of such knives. In Israel and Switzerland, these knives are known as \"Japanese knives\". In Brazil they are known as \"estiletes\" or \"cortadores Olfa\" (the latter, being another genericised trademark). In Portugal, Panama and Canada they are also known as \"X-Acto\" (yet another genericised trademark ). In India, Russia, the Philippines, France, Iraq, Italy, Egypt, and Germany, they are simply called \"cutter\". In the Flemish region of Belgium it is called \"cuttermes(je)\" (cutter knife). In general Spanish, they are known as \"cortaplumas\" (penknife, when it comes to folding blades); in Spain, Mexico, and Costa Rica, they are colloquially known as \"cutters\"; in Argentina and Uruguay the segmented fixed-blade knives are known as \"Trinchetas\". In Turkey, they are known as \"maket b\u0131\u00e7a\u011f\u0131\" (which literally translates as \"model knife\").\nOther names for the tool are \"box cutter\" or \"boxcutter\", \"blade knife\", \"carpet knife\", \"pen knife\", \"stationery knife\", \"sheetrock knife\", or \"drywall knife\".\nDesign.\nUtility knives may use fixed, folding, or retractable or replaceable blades, and come in a wide variety of lengths and styles suited to the particular set of tasks they are designed to perform. Thus, an outdoors utility knife suited for camping or hunting might use a broad fixed blade, while a utility knife designed for the construction industry might feature a replaceable utility blade for cutting packaging, cutting shingles, marking cut lines, or scraping paint.\nFixed blade utility knife.\nLarge fixed-blade utility knives are most often employed in an outdoors context, such as fishing, camping, or hunting. Outdoor utility knives typically feature sturdy blades from in length, with edge geometry designed to resist chipping and breakage.\nThe term \"utility knife\" may also refer to small fixed-blade knives used for crafts, model-making and other artisanal projects. These small knives feature light-duty blades best suited for cutting thin, lightweight materials. The small, thin blade and specialized handle permit cuts requiring a high degree of precision and control.\nWorkplace utility knives.\nThe largest construction or workplace utility knives typically feature retractable and replaceable blades, and are made of either die-cast metal or molded plastic. Some use standard blades, others specialized double-ended utility blades. The user can adjust how far the blade extends from the handle, so that, for example, the knife can be used to cut the tape sealing a package without damaging the contents of the package. When the blade becomes dull, it can be quickly reversed or switched for a new one. Spare or used blades are stored in the hollow handle of some models, and can be accessed by removing a screw and opening the handle. Other models feature a quick-change mechanism that allows replacing the blade without tools, as well as a flip-out blade storage tray. The blades for this type of utility knife come in both double- and single-ended versions, and are interchangeable with many, but not all, of the later copies. Specialized blades also exist for cutting string, linoleum, and other materials.\nAnother style is a snap-off utility knife that contains a long, segmented blade that slides out from it. As the endmost edge becomes dull, it can be broken off the remaining blade, exposing the next section, which is sharp and ready for use. The snapping is best accomplished with a blade snapper that is often built-in, or a pair of pliers, and the break occurs at the score lines, where the metal is thinnest. When all of the individual segments are used, the knife may be thrown away, or, more often, refilled with a replacement blade. This design was introduced by Japanese manufacturer OLFA in 1956 as the world's first snap-off blade and was inspired from analyzing the sharp cutting edge produced when glass is broken and how pieces of a chocolate bar break into segments. The sharp cutting edge on these knives is not on the edge where the blade is snapped off; rather one long edge of the whole blade is sharpened, and there are scored diagonal breakoff lines at intervals down the blade. Thus each snapped-off piece is roughly a parallelogram, with each long edge being a breaking edge, and one or both of the short ends being a sharpened edge.\nAnother utility knife often used for cutting open boxes consists of a simple sleeve around a rectangular handle into which single-edge utility blades can be inserted. The sleeve slides up and down on the handle, holding the blade in place during use and covering the blade when not in use. The blade holder may either retract or fold into the handle, much like a folding-blade pocketknife. The blade holder is designed to expose just enough edge to cut through one layer of corrugated fibreboard, to minimize chances of damaging contents of cardboard boxes.\nUse as weapon.\nMost utility knives are not well suited to use as offensive weapons, with the exception of some outdoor-type utility knives employing longer blades. However, even small blade type utility knives may sometimes find use as slashing weapons. The 9/11 Commission report stated passengers in cell phone calls reported knives or \"box-cutters\" were used as weapons (also Mace or a bomb) in hijacking airplanes in the September 11, 2001 terrorist attacks against the United States, though the exact design of the knives used is unknown. Two of the hijackers were known to have purchased Leatherman knives, which feature a slip-joint blade, which were not prohibited on U.S. flights at the time. Those knives were not found in the possessions the two hijackers left behind. Similar cutters, including paper cutters, have also been known to be used as a lethal weapon.\nSmall work-type utility knives have also been used to commit robbery and other crimes. In June 2004, a Japanese student was slashed to death with a segmented-type utility knife.\nIn the United Kingdom, the law was changed (effective 1 October 2007) to raise the age limit for purchasing knives, including utility knives, from 16 to 18, and to make it illegal to carry a utility knife in public without a good reason."}
{"id": "4169", "revid": "48643156", "url": "https://en.wikipedia.org/wiki?curid=4169", "title": "Bronze", "text": "Bronze is an alloy consisting primarily of copper, commonly with about 12\u201312.5% tin and often with the addition of other metals (including aluminium, manganese, nickel, or zinc) and sometimes non-metals (such as phosphorus) or metalloids (such as arsenic or silicon). These additions produce a range of alloys some of which are harder than copper alone or have other useful properties, such as strength, ductility, or machinability.\nThe archaeological period during which bronze was the hardest metal in widespread use is known as the Bronze Age. The beginning of the Bronze Age in western Eurasia and India is conventionally dated to the mid-4th millennium BCE (~3500 BCE), and to the early 2nd millennium BCE in China; elsewhere it gradually spread across regions. The Bronze Age was followed by the Iron Age, which started about 1300 BCE and reaching most of Eurasia by about 500 BCE, although bronze continued to be much more widely used than it is in modern times.\nBecause historical artworks were often made of bronzes and brasses (alloys of copper and zinc) of different metallic compositions, modern museum and scholarly descriptions of older artworks increasingly use the generalized term \"copper alloy\" instead of the names of individual alloys. This is done (at least in part) to prevent database searches from failing merely because of errors or disagreements in the naming of historic copper alloys.\nEtymology.\nThe word \"bronze\" (1730\u20131740) is borrowed from Middle French (1511), itself borrowed from Italian (13th century, transcribed in Medieval Latin as ) from either:\nHistory.\nThe discovery of bronze enabled people to create metal objects that were harder and more durable than had previously been possible. Bronze tools, weapons, armor, and building materials such as decorative tiles were harder and more durable than their stone and copper (\"Chalcolithic\") predecessors. Initially, bronze was made out of copper and arsenic or from naturally or artificially mixed ores of those metals, forming arsenic bronze.\nThe earliest known arsenic-copper-alloy artifacts come from a Yahya Culture (Period V 3800-3400 BCE) site, at Tal-i-Iblis on the Iranian plateau, and were smelted from native arsenical copper and copper-arsenides, such as algodonite and domeykite.\nThe earliest tin-copper-alloy artifact has been dated to , in a Vin\u010da culture site in Plo\u010dnik (Serbia), and believed to have been smelted from a natural tin-copper ore, stannite.\nOther early examples date to the late 4th millennium BCE in Egypt, Susa (Iran) and some ancient sites in China, Luristan (Iran), Tepe Sialk (Iran), Mundigak (Afghanistan), and Mesopotamia (Iraq).\nTin bronze was superior to arsenic bronze in that the alloying process could be more easily controlled, and the resulting alloy was stronger and easier to cast. Also, unlike those of arsenic, metallic tin and the fumes from tin refining are not toxic.\nTin became the major non-copper ingredient of bronze in the late 3rd millennium BCE. Ores of copper and the far rarer tin are not often found together (exceptions include Cornwall in the United Kingdom, one ancient site in Thailand and one in Iran), so serious bronze work has always involved trade with other regions. Tin sources and trade in ancient times had a major influence on the development of cultures. In Europe, a major source of tin was the British deposits of ore in Cornwall, which were traded as far as Phoenicia in the eastern Mediterranean. In many parts of the world, large hoards of bronze artifacts are found, suggesting that bronze also represented a store of value and an indicator of social status. In Europe, large hoards of bronze tools, typically socketed axes (illustrated above), are found, which mostly show no signs of wear. With Chinese ritual bronzes, which are documented in the inscriptions they carry and from other sources, the case is clear. These were made in enormous quantities for elite burials, and also used by the living for ritual offerings.\nTransition to iron.\nThough bronze, whose Vickers hardness is 60\u2013258, is generally harder than wrought iron, with a hardness of 30\u201380, the Bronze Age gave way to the Iron Age after a serious disruption of the tin trade: the population migrations of around 1200\u20131100 BCE reduced the shipment of tin around the Mediterranean and from Britain, limiting supplies and raising prices. As the art of working in iron improved, iron became cheaper and improved in quality. As later cultures advanced from hand-wrought iron to machine-forged iron (typically made with trip hammers powered by water), blacksmiths also learned how to make steel, which is stronger and harder than bronze and holds a sharper edge longer. Bronze was still used during the Iron Age and has continued in use for many purposes to the modern day.\nComposition.\nThere are many different bronze alloys, but typically modern bronze is about 88% copper and 12% tin. \"Alpha bronze\" consists of the alpha solid solution of tin in copper. Alpha bronze alloys of 4\u20135% tin are used to make coins, springs, turbines and blades. Historical \"bronzes\" are highly variable in composition, as most metalworkers probably used whatever scrap was on hand; the metal of the 12th-century English Gloucester Candlestick is bronze containing a mixture of copper, zinc, tin, lead, nickel, iron, antimony, arsenic and an unusually large amount of silver \u2013 between 22.5% in the base and 5.76% in the pan below the candle. The proportions of this mixture suggest that the candlestick was made from a hoard of old coins. The 13th-century Benin Bronzes are in fact brass, and the 12th-century Romanesque Baptismal font at St Bartholomew's Church, Li\u00e8ge is sometimes described as bronze and sometimes as brass.\nDuring the Bronze Age, two forms of bronze were commonly used: \"classic bronze\", about 10% tin, was used in casting; \"mild bronze\", about 6% tin, was hammered from ingots to make sheets. Bladed weapons were primarily cast from classic bronze while helmets and armor were hammered from mild bronze.\nModern commercial bronze (90% copper and 10% zinc) and architectural bronze (57% copper, 3% lead, 40% zinc) are more properly regarded as brass alloys because they contain zinc as the main alloying ingredient. They are commonly used in architectural applications. Plastic bronze contains a significant quantity of lead, which makes for improved plasticity, and may have been used by the ancient Greeks in ship construction. has a composition of Si: 2.80\u20133.80%, Mn: 0.50\u20131.30%, Fe: 0.80% max., Zn: 1.50% max., Pb: 0.05% max., Cu: balance. Other bronze alloys include aluminium bronze, phosphor bronze, manganese bronze, bell metal, arsenical bronze, speculum metal, bismuth bronze, and cymbal alloys.\nProperties.\nCopper-based alloys have lower melting points than steel or iron and are more readily produced from their constituent metals. They are generally about 10 percent denser than steel, although alloys using aluminum or silicon may be slightly less dense. Bronze conducts heat and electricity better than most steels. Copper-base alloys are generally more costly than steels but less so than nickel-base alloys.\nBronzes are typically ductile alloys and are considerably less brittle than cast iron. Copper and its alloys have a huge variety of uses that reflect their versatile physical, mechanical, and chemical properties. Some common examples are the high electrical conductivity of pure copper, the low-friction properties of bearing bronze (bronze that has a high lead content\u2014 6\u20138%), the resonant qualities of bell bronze (20% tin, 80% copper), and the resistance to corrosion by seawater of several bronze alloys.\nThe melting point of bronze is about but varies depending on the ratio of the alloy components. Bronze is usually nonmagnetic, but certain alloys containing iron or nickel may have magnetic properties. Bronze typically oxidizes only superficially; once a copper oxide (eventually becoming copper carbonate) layer is formed, the underlying metal is protected from further corrosion. This can be seen on statues from the Hellenistic period. If copper chlorides are formed, a corrosion-mode called \"bronze disease\" will eventually destroy it completely.\nUses.\nBronze, or bronze-like alloys and mixtures, were used for coins over a longer period. Bronze was especially suitable for use in boat and ship fittings prior to the wide employment of stainless steel owing to its combination of toughness and resistance to salt water corrosion. Bronze is still commonly used in ship propellers and submerged bearings. In the 20th century, silicon was introduced as the primary alloying element, creating an alloy with wide application in industry and the major form used in contemporary statuary. Sculptors may prefer silicon bronze because of the ready availability of silicon bronze brazing rod, which allows color-matched repair of defects in castings. Aluminum is also used for the structural metal aluminum bronze. Bronze parts are tough and typically used for bearings, clips, electrical connectors and springs.\nBronze also has low friction against dissimilar metals, making it important for cannons prior to modern tolerancing, where iron cannonballs would otherwise stick in the barrel. It is still widely used today for springs, bearings, bushings, automobile transmission pilot bearings, and similar fittings, and is particularly common in the bearings of small electric motors. Phosphor bronze is particularly suited to precision-grade bearings and springs. It is also used in guitar and piano strings. Unlike steel, bronze struck against a hard surface will not generate sparks, so it (along with beryllium copper) is used to make hammers, mallets, wrenches and other durable tools to be used in explosive atmospheres or in the presence of flammable vapors. Bronze is used to make bronze wool for woodworking applications where steel wool would discolor oak. Phosphor bronze is used for ships' propellers, musical instruments, and electrical contacts. Bearings are often made of bronze for its friction properties. It can be impregnated with oil to make the proprietary Oilite and similar material for bearings. Aluminum bronze is hard and wear-resistant, and is used for bearings and machine tool ways. The Doehler Die Casting Co. of Toledo, Ohio were known for the production of Brastil, a high tensile corrosion resistant bronze alloy.\nArchitectural bronze.\nThe Seagram Building on New York City's Park Avenue is the \"iconic glass box sheathed in bronze, designed by Mies van der Rohe.\" The Seagram Building was the first time that an entire building was sheathed in bronze. The General Bronze Corporation fabricated 3,200,000 pounds (1,600 tons) of bronze at its plant in Garden City, New York. The Seagram Building is a 38-story, 516-foot bronze-and-topaz-tinted glass building. The building looks like a \"squarish 38-story tower clad in a restrained curtain wall of metal and glass.\" \"Bronze was selected because of its color, both before and after aging, its corrosion resistance, and its extrusion properties. In 1958, it was not only the most expensive building of its time \u2014 $36 million \u2014 but it was the first building in the world with floor-to-ceiling glass walls. Mies van der Rohe achieved the crisp edges that were custom-made with specific detailing by General Bronze and \"even the screws that hold in the fixed glass-plate windows were made of brass.\"\nSculptures.\nBronze is widely used for casting bronze sculptures. Common bronze alloys have the unusual and desirable property of expanding slightly just before they set, thus filling the finest details of a mould. Then, as the bronze cools, it shrinks a little, making it easier to separate from the mould. The Assyrian king Sennacherib (704\u2013681 BCE) claims to have been the first to cast monumental bronze statues (of up to 30 tonnes) using two-part moulds instead of the lost-wax method.\nBronze statues were regarded as the highest form of sculpture in Ancient Greek art, though survivals are few, as bronze was a valuable material in short supply in the Late Antique and medieval periods. Many of the most famous Greek bronze sculptures are known through Roman copies in marble, which were more likely to survive. In India, bronze sculptures from the Kushana (Chausa hoard) and Gupta periods (Brahma from Mirpur-Khas, Akota Hoard, Sultanganj Buddha) and later periods (Hansi Hoard) have been found. Indian Hindu artisans from the period of the Chola empire in Tamil Nadu used bronze to create intricate statues via the lost-wax casting method with ornate detailing depicting the deities of Hinduism. The art form survives to this day, with many silpis, craftsmen, working in the areas of Swamimalai and Chennai.\nIn antiquity other cultures also produced works of high art using bronze. For example: in Africa, the bronze heads of the Kingdom of Benin; in Europe, Grecian bronzes typically of figures from Greek mythology; in east Asia, Chinese ritual bronzes of the Shang and Zhou dynasty\u2014more often ceremonial vessels but including some figurine examples. Bronze continues into modern times as one of the materials of choice for monumental statuary.\nLamps.\nTiffany Glass Studios, made famous by Louis C. Tiffany commonly referred to his product as favrile glass or \"\"Tiffany glass\",\" and used bronze in their artisan work for his Tiffany lamps.\nFountains and doors.\nThe largest and most ornate bronze fountain known to be cast in the world was by the Roman Bronze Works and General Bronze Corporation in 1952. The material used for the fountain, known as statuary bronze, is a quaternary alloy made of copper, zinc, tin, and lead, and traditionally golden brown in color. This was made for the Andrew W. Mellon Memorial Fountain in Federal Triangle in Washington, DC. Another example of the massive, ornate design projects of bronze, and attributed to General Bronze/Roman Bronze Works were the massive bronze doors to the United States Supreme Court Building in Washington, DC.\nMirrors.\nBefore it became possible to produce glass with acceptably flat surfaces, bronze was a standard material for mirrors. Bronze was used for this purpose in many parts of the world, probably based on independent discoveries. Bronze mirrors survive from the Egyptian Middle Kingdom (2040\u20131750 BCE), and China from at least . In Europe, the Etruscans were making bronze mirrors in the sixth century BCE, and Greek and Roman mirrors followed the same pattern. Although other materials such as speculum metal had come into use, and Western glass mirrors had largely taken over, bronze mirrors were still being made in Japan and elsewhere in the eighteenth century, and are still made on a small scale in Kerala, India.\nMusical instruments.\nBronze is the preferred metal for bells in the form of a high tin bronze alloy known as bell metal, which is typically about 23% tin.\nNearly all professional cymbals are made from bronze, which gives a desirable balance of durability and timbre. Several types of bronze are used, commonly B20 bronze, which is roughly 20% tin, 80% copper, with traces of silver, or the tougher B8 bronze made from 8% tin and 92% copper. As the tin content in a bell or cymbal rises, the timbre drops.\nBronze is also used for the windings of steel and nylon strings of various stringed instruments such as the double bass, piano, harpsichord, and guitar. Bronze strings are commonly reserved on pianoforte for the lower pitch tones, as they possess a superior sustain quality to that of high-tensile steel.\nBronzes of various metallurgical properties are widely used in struck idiophones around the world, notably bells, singing bowls, gongs, cymbals, and other idiophones from Asia. Examples include Tibetan singing bowls, temple bells of many sizes and shapes, Javanese gamelan, and other bronze musical instruments. The earliest bronze archeological finds in Indonesia date from 1\u20132 BCE, including flat plates probably suspended and struck by a wooden or bone mallet. Ancient bronze drums from Thailand and Vietnam date back 2,000 years. Bronze bells from Thailand and Cambodia date back to 3600 BCE.\nSome companies are now making saxophones from phosphor bronze (3.5 to 10% tin and up to 1% phosphorus content). Bell bronze/B20 is used to make the tone rings of many professional model banjos. The tone ring is a heavy (usually ) folded or arched metal ring attached to a thick wood rim, over which a skin, or most often, a plastic membrane (or head) is stretched \u2013 it is the bell bronze that gives the banjo a crisp powerful lower register and clear bell-like treble register.\nCoins and medals.\nBronze has also been used in coins; most \"copper\" coins are actually bronze, with about 4 percent tin and 1 percent zinc.\nAs with coins, bronze has been used in the manufacture of various types of medals for centuries, and \"bronze medals\" are known in contemporary times for being awarded for third place in sporting competitions and other events. The term is now often used for third place even when no actual bronze medal is awarded. The usage in part arose from the trio of gold, silver and bronze to represent the first three Ages of Man in Greek mythology: the Golden Age, when men lived among the gods; the Silver age, where youth lasted a hundred years; and the Bronze Age, the era of heroes. It was first adopted for a sports event at the 1904 Summer Olympics. At the 1896 event, silver was awarded to winners and bronze to runners-up, while at 1900 other prizes were given rather than medals.\nBronze is the normal material for the related form of the plaquette, normally a rectangular work of art with a scene in relief, for a collectors' market.\nBronze is also associated with eighth wedding anniversaries.\nBiblical references.\nThere are over 125 references to bronze ('nehoshet'), which appears to be the Hebrew word used for copper and any of its alloys. However, the Old Testament era Hebrews are not thought to have had the capability to manufacture zinc (needed to make brass) and so it is likely that 'nehoshet' refers to copper and its alloys with tin, now called bronze. In the King James Version, there is no use of the word 'bronze' and 'nehoshet' was translated as 'brass'. Modern translations use 'bronze'. Bronze (nehoshet) was used widely in the Tabernacle for items such as the bronze altar (Exodus Ch.27), bronze laver (Exodus Ch.30), utensils, and mirror (Exodus Ch.38). It was mentioned in the account of Moses holding up a bronze snake on a pole in Numbers Ch.21. In First Kings, it is mentioned that Hiram was very skilled in working with bronze, and he made many furnishings for Solomon's Temple including pillars, capitals, stands, wheels, bowls, and plates, some of which were highly decorative (see I Kings 7:13-47). Bronze was also widely used as battle armor and helmet, as in the battle of David and Goliath in I Samuel 17:5-6;38 (also see II Chron. 12:10)."}
{"id": "4170", "revid": "41030369", "url": "https://en.wikipedia.org/wiki?curid=4170", "title": "Benelux", "text": "The Benelux Union (; ; ; ) or Benelux is a politico-economic union, alliance and formal international intergovernmental cooperation of three neighbouring states in Western Europe: Belgium, the Netherlands, and Luxembourg. The name is a portmanteau formed from joining the first few letters of each country's name and was first used to name the customs agreement that initiated the union (signed in 1944). It is now used more generally to refer to the geographic, economic, and cultural grouping of the three countries.\nThe Benelux is an economically dynamic and densely populated region, with 5.6% of the European population (29.55 million residents) and 7.9% of the joint EU GDP (\u20ac36,000/resident) on 1.7% of the whole surface of the EU. In 2015, 37% of the total number of EU cross-border workers worked in the Benelux; 35,000 Belgian citizens work in Luxembourg, while 37,000 Belgian citizens cross the border to work in the Netherlands each day. In addition, 12,000 Dutch and close to a thousand Luxembourg residents work in Belgium.\nThe main institutions of the Union are the Committee of Ministers, the Council of the Union, the General Secretariat, the Interparliamentary Consultative Council and the Benelux Court of Justice while the Benelux Office for Intellectual Property covers the same land but is not part of the Benelux Union.\nThe Benelux General Secretariat is located in Brussels. It is the central platform of the Benelux Union cooperation. It handles the secretariat of the Committee of Ministers, the Council of Benelux Union and the sundry committees and working parties. The General Secretariat provides day-to-day support for the Benelux cooperation on the substantive, procedural, diplomatic and logistical levels. The Secretary-General is Frans Weekers from the Netherlands and there are two deputies: Deputy Secretary-General Michel-Etienne Tilemans from Belgium and Deputy Secretary-General Jean-Claude Meyer from Luxembourg.\nThe presidency of the Benelux is held in turn by the three countries for a period of one year. Belgium holds the presidency for 2024.\nAbout 80 percent of the Benelux population speaks Dutch, about 20 percent speaks French and one percent Luxembourgish as their native language. A small minority under one percent are native German speakers.\nHistory.\nIn 1944, exiled representatives of the three countries signed the London Customs Convention, the treaty that established the Benelux Customs Union. Ratified in 1947, the treaty was in force from 1948 until it was superseded by the Benelux Economic Union. The initial form of economic cooperation expanded steadily over time, leading to the signing of the treaty establishing the Benelux Economic Union (\"Benelux Economische Unie\", \"Union \u00c9conomique Benelux\") on 3 February 1958 in The Hague, which came into force on 1 November 1960. Initially, the purpose of cooperation among the three partners was to put an end to customs barriers at their borders and ensure free movement of persons, capital, services, and goods between the three countries. This treaty was the first example of international economic integration in Europe since the Second World War.\nThe three countries therefore foreshadowed and provided the model for future European integration, such as the European Coal and Steel Community, the European Economic Community (EEC), and the European Community\u2013European Union (EC\u2013EU). The three partners also launched the Schengen process, which came into operation in 1985. Benelux cooperation has been constantly adapted and now goes much further than mere economic cooperation, extending to new and topical policy areas connected with security, sustainable development, and the economy. \nIn 1965, the treaty establishing a Benelux Court of Justice was signed. It entered into force in 1974. The court, composed of judges from the highest courts of the three states, has to guarantee the uniform interpretation of common legal rules. This international judicial institution is located in Luxembourg.\nRenewal of the agreement.\nThe 1958 Treaty between the Benelux countries establishing the Benelux Economic Union was limited to a period of 50 years. During the following years, and even more so after the creation of the European Union, the Benelux cooperation focused on developing other fields of activity within a constantly changing international context.\nAt the end of the 50 years, the governments of the three Benelux countries decided to renew the agreement, taking into account the new aspects of the Benelux-cooperation \u2013 such as security \u2013 and the new federal government structure of Belgium. The original establishing treaty, set to expire in 2010, was replaced by a new legal framework (called the Treaty revising the Treaty establishing the Benelux Economic Union), which was signed on 17 June 2008.\nThe new treaty has no set time limit and the name of the \"Benelux Economic Union\" changed to \"Benelux Union\" to reflect the broad scope on the union. The main objectives of the treaty are the continuation and enlargement of the cooperation between the three member states within a larger European context. The renewed treaty explicitly foresees the possibility that the Benelux countries will cooperate with other European member states or with regional cooperation structures. The new Benelux cooperation focuses on three main topics: internal market and economic union, sustainability, justice and internal affairs. The number of structures in the renewed Treaty has been reduced and thus simplified.\nActivities since 2008.\nBenelux seeks region-to-region cooperation, be it with France and Germany (North Rhine-Westphalia) or beyond with the Baltic States, the Nordic Council, the Visegrad countries, or even further. In 2018, a renewed political declaration was adopted between Benelux and North Rhine-Westphalia to give cooperation a further impetus.\nThe Benelux is particularly active in the field of intellectual property. The three countries established a Benelux Trademarks Office and a Benelux Designs Office, both situated in The Hague. In 2005, they concluded a treaty establishing the Benelux Office for Intellectual Property, which replaced both offices upon its entry into force on 1 September 2006. This organisation is the official body for the registration of trademarks and designs in the Benelux. In addition, it offers the possibility to formally record the existence of ideas, concepts, designs, prototypes and the like.\nSome examples of recent Benelux initiatives include: automatic level recognition of diplomas and degrees within the Benelux for bachelor's and master's programs in 2015, and for all other degrees in 2018; common road inspections in 2014; and a Benelux pilot with digital consignment notes (e-CMR) in 2017; a new Benelux Treaty on Police Cooperation in 2018, providing for direct access to each other's police databases and population registers within the limits of national legislation, and allowing some police forces to cross borders in some situations. The Benelux is also committed to working together on adaptation to climate change. A joint political declaration in July 2020 called on the European Commission to prioritise cycling in European climate policy and Sustainable Transport strategies, to co-finance the construction of cycling infrastructure, and to provide funds to stimulate cycling policy.\nOn 5 June 2018, the Benelux Treaty celebrated its 60 years of existence. In 2018, a Benelux Youth Parliament was created.\nIn addition to cooperation based on a Treaty, there is also political cooperation in the Benelux context, including summits of the Benelux government leaders. In 2019 a Benelux summit was held in Luxembourg. In 2020, a Benelux summit was held \u2013 online, due to the COVID-19 pandemic \u2013 under Dutch Presidency on 7 October between the prime ministers.\nAs of 1 January 2017, a new arrangement for NATO Air Policing started for the airspace of Belgium, the Netherlands and Luxemburg (Benelux). The Belgian Air Component and the Royal Netherlands Air Force will take four-month turns to ensure that Quick Reaction Alert (QRA) fighter jets are available at all times to be launched under NATO control.\nCooperation with other geopolitical regions.\nThe Benelux countries also work together in the so-called Pentalateral Energy Forum, a regional cooperation group formed of five members\u2014the Benelux states, France, Germany, Austria, and Switzerland. Formed on 6 June 2007, the ministers for energy from the various countries represent a total of 200 million residents and 40% of the European electricity network.\nIn 2017 the members of the Benelux, the Baltic Assembly, three members of the Nordic Council (Sweden, Denmark and Finland), and all the other countries EU member states, sought to increase cooperation in the Digital Single Market, as well as discussing social matters, the Economic and Monetary Union of the European Union, immigration and defence cooperation. Foreign relations in the wake of Russia's annexation of Crimea and the 2017 Turkish constitutional referendum were also on the agenda.\nSince 2008 the Benelux Union works together with the German Land (state) North Rhine-Westphalia.\nIn 2018 Benelux Union signed a declaration with France to strengthen cross-border cooperation.\nPolitics.\nBenelux institutions.\nUnder the 2008 treaty there are five Benelux institutions: the Benelux Committee of Ministers, the Benelux Council, the Benelux Parliament, the Benelux Court of Justice, the Benelux Secretariat General. Beside these five institutions, the Benelux Organisation for Intellectual Property is also an independent organisation.\nBenelux Committee of Ministers:\nThe Committee of Ministers is the supreme decision-making body of the Benelux. It includes at least one representative at ministerial level from the three countries. Its composition varies according to its agenda. The ministers determine the orientations and priorities of Benelux cooperation. The presidency of the Committee rotates between the three countries on an annual basis.\nBenelux Council:\nThe council is composed of senior officials from the relevant ministries. Its composition varies according to its agenda. The council's main task is to prepare the dossiers for the ministers.\nBenelux InterParliamentary Consultative Council:\nThe Benelux Parliament (officially referred to as an \"Interparliamentary Consultative Council\") was created in 1955. This parliamentary assembly is composed of 49 members from the respective national parliaments (21 members of the Dutch parliament, 21 members of the Belgian national and regional parliaments, and 7 members of the Luxembourg parliament). Its members inform and advise their respective governments on all Benelux matters. On 20 January 2015, the governments of the three countries, including, as far as Belgium is concerned, the community and regional governments, signed in Brussels the Treaty of the Benelux Interparliamentary Assembly. This treaty entered into force on 1 August 2019. This superseded the 1955 Convention on the Consultative Interparliamentary Council for the Benelux. The official name has been largely obsolete in daily practice for a number of years: both internally in the Benelux and in external references, the name Benelux Parliament has been used \"de facto\" for a number of years now.\nBenelux Court of Justice:\nThe Benelux Court of Justice is an international court. Its mission is to promote uniformity in the application of Benelux legislation. When faced with difficulty interpreting a common Benelux legal rule, national courts must seek an interpretive ruling from the Benelux Court, which subsequently renders a binding decision. The members of the Court are appointed from among the judges of the 'Cour de cassation' of Belgium, the 'Hoge Raad of the Netherlands' and the 'Cour de cassation' of Luxembourg.\nBenelux General Secretariat:\nThe General Secretariat, which is based in Brussels, forms the cooperation platform of the Benelux Union. It acts as the secretariat of the Committee of Ministers, the council and various commissions and working groups. The General Secretariat has years of expertise in the area of Benelux cooperation and is familiar with the policy agreements and differences between the three countries. Building on what already been achieved, the General Secretariat puts its knowledge, network and experience at the service of partners and stakeholders who endorse its mission. It initiates, supports and monitors cooperation results in the areas of economy, sustainability and security.\nBenelux works together on the basis of an annual plan embedded in a four-year joint work programme.\nBenelux legal instruments.\nThe Benelux Union involves intergovernmental cooperation.\nThe Treaty establishing the Benelux Union explicitly provides that the Benelux Committee of Ministers can resort to four legal instruments (art. 6, paragraph 2, under a), f), g) and h)):\n1. Decisions\nDecisions are legally binding regulations for implementing the Treaty establishing the Benelux Union or other Benelux treaties.\nTheir legally binding force concerns the Benelux states (and their sub-state entities), which have to implement them. However, they have no direct effect towards individual citizens or companies (notwithstanding any indirect protection of their rights based on such decisions as a source of international law). Only national provisions implementing a decision can directly create rights and obligations for citizens or companies.\n2. Agreements\nThe Committee of Ministers can draw up agreements, which are then submitted to the Benelux states (and/or their sub-state entities) for signature and subsequent parliamentary ratification. These agreements can deal with any subject matter, also in policy areas that are not yet covered by cooperation in the framework of the Benelux Union.\nThese are in fact traditional treaties, with the same direct legally binding force towards both authorities and citizens or companies. The negotiations do however take place in the established context of the Benelux working groups and institutions, rather than on an ad hoc basis.\n3. Recommendations\nRecommendations are non-binding orientations, adopted at ministerial level, which underpin the functioning of the Benelux Union. These (policy) orientations may not be legally binding, but given their adoption at the highest political level and their legal basis vested directly in the Treaty, they do entail a strong moral obligation for any authority concerned in the Benelux countries.\n4. Directives\nDirectives of the Committee of Ministers are mere inter-institutional instructions towards the Benelux Council and/or the Secretariat-General, for which they are binding. This instrument has so far only been used occasionally, basically in order to organize certain activities within a Benelux working group or to give them impetus.\nAll four instruments require the unanimous approval of the members of the Committee of Ministers (and, in the case of agreements, subsequent signature and ratification at national level)."}
{"id": "4171", "revid": "34986788", "url": "https://en.wikipedia.org/wiki?curid=4171", "title": "Boston Herald", "text": "The Boston Herald is an American daily newspaper whose primary market is Boston, Massachusetts, and its surrounding area. It was founded in 1846 and is one of the oldest daily newspapers in the United States. It has been awarded eight Pulitzer Prizes in its history, including four for editorial writing and three for photography before it was converted to tabloid format in 1981. The \"Herald\" was named one of the \"10 Newspapers That 'Do It Right' in 2012 by \"Editor &amp; Publisher\".\nIn December 2017, the \"Herald\" filed for bankruptcy. On February 14, 2018, Digital First Media successfully bid $11.9 million to purchase the company in a bankruptcy auction; the acquisition was completed on March 19, 2018. As of August 2018, the paper had approximately 110 total employees, compared to about 225 before the sale.\nHistory.\nThe \"Herald\" history traces back through two lineages, the \"Daily Advertiser\" and the old \"Boston Herald\", and two media moguls, William Randolph Hearst and Rupert Murdoch.\nFounding.\nThe original \"Boston Herald\" was founded in 1846 by a group of Boston printers jointly under the name of John A. French &amp; Company. The paper was published as a single two-sided sheet, selling for one cent. Its first editor, William O. Eaton, just 22 years old, said \"The \"Herald\" will be independent in politics and religion; liberal, industrious, enterprising, critically concerned with literacy and dramatic matters, and diligent in its mission to report and analyze the news, local and global.\"\nIn 1847, the \"Boston Herald\" absorbed the Boston \"American Eagle\".\n\"The Boston Herald and Boston Journal\".\nIn October 1917, John H. Higgins, the publisher and treasurer of the Boston Herald bought out its next door neighbor \"The Boston Journal\" and created \"The Boston Herald and Boston Journal\"\n\"The American Traveler\".\nEven earlier than the \"Herald\", the weekly \"American Traveler\" was founded in 1825 as a bulletin for stagecoach listings.\nThe \"Boston Evening Traveller\".\nThe \"Boston Evening Traveler\" was founded in 1845. The \" Boston Evening Traveler\" was the successor to the weekly \"American Traveler\" and the semi-weekly \"Boston Traveler\". In 1912, the \"Herald\" acquired the \"Traveler\", continuing to publish both under their own names. For many years, the newspaper was controlled by many of the investors in United Shoe Machinery Corporation. After a newspaper strike in 1967, Herald-Traveler Corp. suspended the afternoon \"Traveler\" and absorbed the evening edition into the Herald to create the \"Boston Herald Traveler.\"\n\"The Boston Daily Advertiser\".\nThe \"Boston Daily Advertiser\" was established in 1813 in Boston by Nathan Hale. The paper grew to prominence throughout the 19th century, taking over other Boston area papers. In 1832 The Advertiser took over control of \"The Boston Patriot\", and then in 1840 it took over and absorbed \"The Boston Gazette\". The paper was purchased by William Randolph Hearst in 1917. In 1920 the \"Advertiser\" was merged with \"The Boston Record\", initially the combined newspaper was called the \"Boston Advertiser\" however when the combined newspaper became an illustrated tabloid in 1921 it was renamed \"The Boston American\". Hearst Corp. continued using the name \"Advertiser\" for its Sunday paper until the early 1970s.\n\"The Boston Record\".\nOn September 3, 1884, \"The Boston Evening Record\" was started by the \"Boston Advertiser\" as a campaign newspaper. The \"Record\" was so popular that it was made a permanent publication.\n\"The Boston American\".\nIn 1904, William Randolph Hearst began publishing his own newspaper in Boston called \"The American\". Hearst ultimately ended up purchasing the \"Daily Advertiser\" in 1917. By 1938, the \"Daily Advertiser\" had changed to the \"Daily Record\", and \"The American\" had become the \"Sunday Advertiser\". A third paper owned by Hearst, called the \"Afternoon Record\", which had been renamed the \"Evening American\", merged in 1961 with the \"Daily Record\" to form the \"Record American\". The \"Sunday Advertiser\" and \"Record American\" would ultimately be merged in 1972 into \"The Boston Herald Traveler\" a line of newspapers that stretched back to the old \"Boston Herald\".\n\"The Boston Herald Traveler\".\nIn 1946, Herald-Traveler Corporation acquired Boston radio station WHDH. Two years later, WHDH-FM was licensed, and on November 26, 1957, WHDH-TV made its debut as an ABC affiliate on channel 5. In 1961, WHDH-TV's affiliation switched to CBS. The television station operated for years beginning some time after under temporary authority from the Federal Communications Commission. Controversy arose over luncheon meetings the newspaper's chief executive purportedly had with John C. Doerfer, chairman of the FCC between 1957 and 1960, who served as a commissioner during the original licensing process. (Some Boston broadcast historians accuse \"The Boston Globe\" of being covertly behind the proceeding as a sort of vendetta for not getting a license\u2014The \"Herald Traveler\" was Republican in sympathies, and the \"Globe\" then had a firm policy of not endorsing political candidates, although Doerfer's history at the FCC also lent suspicions.) The FCC ordered comparative hearings, and in 1969 a competing applicant, Boston Broadcasters, Inc., was granted a construction permit to replace WHDH-TV on channel 5. Herald-Traveler Corporation fought the decision in court\u2014by this time, revenues from channel 5 were all but keeping the newspaper afloat\u2014but lost its final appeal. On March 19, 1972, WHDH-TV was forced to surrender channel 5 to the new WCVB-TV.\n\"The Boston Herald Traveler and Record American\".\nWithout a television station to subsidize the newspaper, the \"Herald Traveler\" was no longer able to remain in business, and the newspaper was sold to Hearst Corporation, which published the rival all-day newspaper, the \"Record American\". The two papers were merged to become an all-day paper called the \"Boston Herald Traveler and Record American\" in the morning and \"Record American and Boston Herald Traveler\" in the afternoon. The first editions published under the new combined name were those of June 19, 1972. The afternoon edition was soon dropped and the unwieldy name shortened to \"Boston Herald American\", with the Sunday edition called the \"Sunday Herald Advertiser\". The \"Herald American\" was printed in broadsheet format, and failed to target a particular readership; where the \"Record American\" had been a typical city tabloid, the \"Herald Traveler\" was a Republican paper.\nMurdoch purchases \"The Herald American\".\nThe \"Herald American\" converted to tabloid format in September 1981, but Hearst faced steep declines in circulation and advertising. The company announced it would close the \"Herald American\"\u2014making Boston a one-newspaper town\u2014on December 3, 1982. When the deadline came, Australian-born media baron Rupert Murdoch was negotiating to buy the paper and save it. He closed on the deal after 31 hours of talks with Hearst and newspaper unions\u2014and five hours after Hearst had sent out notices to newsroom employees telling them they were terminated. The newspaper announced its own survival the next day with a full-page headline: \"You Bet We're Alive!\"\nThe \"Boston Herald\".\nMurdoch changed the paper's name back to the \"Boston Herald\". The \"Herald\" continued to grow, expanding its coverage and increasing its circulation until 2001, when nearly all newspapers fell victim to declining circulations and revenue.\nIndependent ownership.\nIn February 1994, Murdoch's News Corporation was forced to sell the paper, in order that its subsidiary Fox Television Stations could legally consummate its purchase of Fox affiliate WFXT (Channel 25) because Massachusetts Senator Ted Kennedy included language in an appropriations bill barring one company from owning a newspaper and television station in the same market. Patrick J. Purcell, who was the publisher of the \"Boston Herald\" and a former News Corporation executive, purchased the \"Herald\" and established it as an independent newspaper. Several years later, Purcell would give the \"Herald\" a suburban presence it never had by purchasing the money-losing Community Newspaper Company from Fidelity Investments. Although the companies merged under the banner of Herald Media, Inc., the suburban papers maintained their distinct editorial and marketing identity.\nAfter years of operating profits at Community Newspaper and losses at the \"Herald\", Purcell in 2006 sold the suburban chain to newspaper conglomerate Liberty Group Publishing of Illinois, which soon after changed its name to GateHouse Media. The deal, which also saw GateHouse acquiring \"The Patriot Ledger\" and \"The Enterprise\" respectively in south suburban Quincy and Brockton, netted $225 million for Purcell, who vowed to use the funds to clear the \"Herald\"'s debt and reinvest in the Paper.\nBoston Herald Radio.\nOn August 5, 2013, the \"Herald\" launched an internet radio station named Boston Herald Radio, which includes shows hosted by much of the \"Herald\" staff. The station's morning lineup is simulcast on 830 AM WCRN from 10 am Eastern time to 12 noon Eastern time.\nBankruptcy.\nIn December 2017, the \"Herald\" announced plans to sell itself to GateHouse Media after filing for chapter 11 bankruptcy protection. The deal was scheduled to be completed by February 2018, with the new company streamlining and having layoffs in coming months. However, in early January 2018, another potential buyer, Revolution Capital Group of Los Angeles, filed a bid with the federal bankruptcy court; the \"Herald\" reported in a press release that \"the court requires BHI [Boston Herald, Inc.] to hold an auction to allow all potential buyers an opportunity to submit competing offers.\"\nDigital First Media acquisition.\nIn February 2018, acquisition of the \"Herald\" by Digital First Media for almost $12 million was approved by the bankruptcy court judge in Delaware. The new owner, DFM, said they would be keeping 175 of the approximately 240 employees the \"Herald\" had when it sought bankruptcy protection in December 2017. The acquisition was completed on March 19, 2018.\nThe Herald and parent DFM were criticized for ending the ten-year printing contract with competitor \"The Boston Globe\", moving printing from Taunton, Massachusetts, to Rhode Island and its \"dehumanizing cost-cutting efforts\" in personnel. In June, some design and advertising layoffs were expected, with work moving to a sister paper, \"The Denver Post\". The \"consolidation\" took effect in August, with nine jobs eliminated.\nIn late August 2018, it was announced that the \"Herald\" would move its offices from Boston's Seaport District to Braintree, Massachusetts, in late November or early December.\nOn October 27, 2020, the \"Boston Herald\" endorsed Donald Trump for the 2020 U.S. Presidential Election.\nIn July 2024, the newspaper laid off three employees. It is not publicly known how many people still work at the \"Boston Herald\", but the newsroom in 2020 consisted of 24 employees. A few years prior, the paper employed 240 people.\nReferences.\n Boston Herald July 29, 1998"}
{"id": "4173", "revid": "372290", "url": "https://en.wikipedia.org/wiki?curid=4173", "title": "Babe Ruth", "text": "George Herman \"Babe\" Ruth (February 6, 1895 \u2013 August 16, 1948) was an American professional baseball player whose career in Major League Baseball (MLB) spanned 22\u00a0seasons, from 1914 through 1935. Nicknamed \"the Bambino\" and \"the Sultan of Swat\", he began his MLB career as a star left-handed pitcher for the Boston Red Sox, but achieved his greatest fame as a slugging outfielder for the New York Yankees. Ruth is regarded as one of the greatest sports heroes in American culture and is considered by many to be the greatest baseball player of all time. In 1936, Ruth was elected to the Baseball Hall of Fame as one of its \"first five\" inaugural members.\nAt age seven, Ruth was sent to St. Mary's Industrial School for Boys, a reformatory where he was mentored by Brother Matthias Boutlier of the Xaverian Brothers, the school's disciplinarian and a capable baseball player. In 1914, Ruth was signed to play Minor League baseball for the Baltimore Orioles but was soon sold to the Red Sox. By 1916, he had built a reputation as an outstanding pitcher who sometimes hit long home runs, a feat unusual for any player in the dead-ball era. Although Ruth twice won 23 games in a season as a pitcher and was a member of three World Series championship teams with the Red Sox, he wanted to play every day and was allowed to convert to an outfielder. With regular playing time, he broke the MLB single-season home run record in 1919 with 29.\nAfter that season, Red Sox owner Harry Frazee sold Ruth to the Yankees amid controversy. The trade fueled Boston's subsequent 86-year championship drought and popularized the \"Curse of the Bambino\" superstition. In his 15 years with the Yankees, Ruth helped the team win seven American League (AL) pennants and four World Series championships. His big swing led to escalating home run totals that not only drew fans to the ballpark and boosted the sport's popularity but also helped usher in baseball's live-ball era, which evolved from a low-scoring game of strategy to a sport where the home run was a major factor. As part of the Yankees' vaunted \"Murderers' Row\" lineup of 1927, Ruth hit 60 home runs, which extended his own MLB single-season record by a single home run. Ruth's last season with the Yankees was 1934, and he retired after a short stint with the Boston Braves the following year. In his career, he led the AL in home runs twelve times.\nDuring Ruth's career, he was the target of intense press and public attention for his baseball exploits and off-field penchants for drinking and womanizing. After his retirement as a player, he was denied the opportunity to manage a major league club, most likely because of poor behavior during parts of his playing career. In his final years, Ruth made many public appearances, especially in support of American efforts in World War II. In 1946, he became ill with nasopharyngeal cancer and died from the disease two years later. Ruth remains a major figure in American culture.\nEarly life.\nGeorge Herman Ruth Jr. was born on February 6, 1895, at 216 Emory Street in the Pigtown section of Baltimore, in a house which belonged to his maternal grandfather Pius Schamberger, a German immigrant and trade unionist. Ruth's parents, Katherine (n\u00e9e Schamberger) and George Herman Ruth Sr., were both of German ancestry. According to the 1880 census, his parents were both born in Maryland. His paternal grandparents were from Prussia and Hanover, Germany. Ruth Sr. worked a series of jobs that included lightning rod salesman and streetcar operator. The elder Ruth then became a counterman in a family-owned combination grocery and saloon business on Frederick Street. Only one of young Ruth's seven siblings, his younger sister Mamie, survived infancy.\nMany details of Ruth's childhood are unknown, including the date of his parents' marriage. As a child, Ruth spoke German. When Ruth was a toddler, the family moved to 339 South Woodyear Street, not far from the rail yards; by the time he was six years old, his father had a saloon with an upstairs apartment at 426 West Camden Street. Details are equally scanty about why Ruth was sent at the age of seven to St. Mary's Industrial School for Boys, a reformatory and orphanage. However, according to Julia Ruth Stevens' recount in 1999, because George Sr. was a saloon owner in Baltimore and had given Ruth little supervision growing up, he became a delinquent. Ruth was sent to St. Mary's because George Sr. ran out of ideas to discipline and mentor his son. As an adult, Ruth admitted that as a youth he ran the streets, rarely attended school, and drank beer when his father was not looking. Some accounts say that following a violent incident at his father's saloon, the city authorities decided that this environment was unsuitable for a small child. Ruth entered St. Mary's on June 13, 1902. He was recorded as \"incorrigible\" and spent much of the next 12 years there.\nAlthough St. Mary's boys received an education, students were also expected to learn work skills and help operate the school, particularly once the boys turned 12. Ruth became a shirtmaker and was also proficient as a carpenter. He would adjust his own shirt collars, rather than having a tailor do so, even during his well-paid baseball career. The boys, aged 5 to 21, did most of the work around the facility, from cooking to shoemaking, and renovated St. Mary's in 1912. The food was simple, and the Xaverian Brothers who ran the school insisted on strict discipline; corporal punishment was common. Ruth's nickname there was \"Niggerlips\", as he had large facial features and was darker than most boys at the all-white reformatory.\nRuth was sometimes allowed to rejoin his family or was placed at St. James's Home, a supervised residence with work in the community, but he was always returned to St. Mary's. He was rarely visited by his family; his mother died when he was 12 and, by some accounts, he was permitted to leave St. Mary's only to attend the funeral. How Ruth came to play baseball there is uncertain: according to one account, his placement at St. Mary's was due in part to repeatedly breaking Baltimore's windows with long hits while playing street ball; by another, he was told to join a team on his first day at St. Mary's by the school's athletic director, Brother Herman, becoming a catcher even though left-handers rarely play that position. During his time there he also played third base and shortstop, again unusual for a left-hander, and was forced to wear mitts and gloves made for right-handers. He was encouraged in his pursuits by the school's Prefect of Discipline, Brother Matthias Boutlier, a native of Nova Scotia. A large man, Brother Matthias was greatly respected by the boys both for his strength and for his fairness. For the rest of his life, Ruth would praise Brother Matthias, and his running and hitting styles closely resembled his teacher's. Ruth stated, \"I think I was born as a hitter the first day I ever saw him hit a baseball.\" The older man became a mentor and role model to Ruth; biographer Robert W. Creamer commented on the closeness between the two:\nThe school's influence remained with Ruth in other ways. He was a lifelong Catholic who would sometimes attend Mass after carousing all night, and he became a well-known member of the Knights of Columbus. He would visit orphanages, schools, and hospitals throughout his life, often avoiding publicity. He was generous to St. Mary's as he became famous and rich, donating money and his presence at fundraisers, and spending $5,000 to buy Brother Matthias a Cadillac in 1926\u2014subsequently replacing it when it was destroyed in an accident. Nevertheless, his biographer Leigh Montville suggests that many of the off-the-field excesses of Ruth's career were driven by the deprivations of his time at St. Mary's.\nMost of the boys at St. Mary's played baseball in organized leagues at different levels of proficiency. Ruth later estimated that he played 200 games a year as he steadily climbed the ladder of success. Although he played all positions at one time or another, he gained stardom as a pitcher. According to Brother Matthias, Ruth was standing to one side laughing at the bumbling pitching efforts of fellow students, and Matthias told him to go in and see if he could do better. Ruth had become the best pitcher at St. Mary's, and when he was 18 in 1913, he was allowed to leave the premises to play weekend games on teams that were drawn from the community. He was mentioned in several newspaper articles, for both his pitching prowess and ability to hit long home runs.\nProfessional baseball.\nMinor leagues: Baltimore Orioles.\nIn early 1914, Ruth signed a professional baseball contract with Jack Dunn, who owned and managed the minor-league Baltimore Orioles, an International League team. The circumstances of Ruth's signing are not known with certainty. By some accounts, Dunn was urged to attend a game between an all-star team from St. Mary's and one from another Xaverian facility, Mount St. Mary's College. Some versions have Ruth running away before the eagerly awaited game, to return in time to be punished, and then pitching St. Mary's to victory as Dunn watched. Others have Washington Senators pitcher Joe Engel, a Mount St. Mary's graduate, pitching in an alumni game after watching a preliminary contest between the college's freshmen and a team from St. Mary's, including Ruth. Engel watched Ruth play, then told Dunn about him at a chance meeting in Washington. Ruth, in his autobiography, stated only that he worked out for Dunn for a half hour, and was signed. According to biographer Kal Wagenheim, there were legal difficulties to be straightened out as Ruth was supposed to remain at the school until he turned 21, though SportsCentury stated in a documentary that Ruth had already been discharged from St. Mary's when he turned 19, and earned a monthly salary of $100.\nThe train journey to spring training in Fayetteville, North Carolina, in early March was likely Ruth's first outside the Baltimore area. The rookie ballplayer was the subject of various pranks by veteran players, who were probably also the source of his famous nickname. There are various accounts of how Ruth came to be called \"Babe\", but most center on his being referred to as \"Dunnie's babe\" (or some variant). SportsCentury reported that his nickname was gained because he was the new \"darling\" or \"project\" of Dunn, not only because of Ruth's raw talent, but also because of his lack of knowledge of the proper etiquette of eating out in a restaurant, being in a hotel, or being on a train. \"Babe\" was, at that time, a common nickname in baseball, with perhaps the most famous to that point being Pittsburgh Pirates pitcher and 1909 World Series hero Babe Adams, who appeared younger than his actual age.\nRuth made his first appearance as a professional ballplayer in an inter-squad game on March 7, 1914. He played shortstop and pitched the last two innings of a 15\u20139 victory. In his second at-bat, Ruth hit a long home run to right field; the blast was locally reported to be longer than a legendary shot hit by Jim Thorpe in Fayetteville. Ruth made his first appearance against a team in organized baseball in an exhibition game versus the major-league Philadelphia Phillies. Ruth pitched the middle three innings and gave up two runs in the fourth, but then settled down and pitched a scoreless fifth and sixth innings. In a game against the Phillies the following afternoon, Ruth entered during the sixth inning and did not allow a run the rest of the way. The Orioles scored seven runs in the bottom of the eighth inning to overcome a 6\u20130 deficit, and Ruth was the winning pitcher.\nOnce the regular season began, Ruth was a star pitcher who was also dangerous at the plate. The team performed well, yet received almost no attention from the Baltimore press. A third major league, the Federal League, had begun play, and the local franchise, the Baltimore Terrapins, restored that city to the major leagues for the first time since 1902. Few fans visited Oriole Park, where Ruth and his teammates labored in relative obscurity. Ruth may have been offered a bonus and a larger salary to jump to the Terrapins; when rumors to that effect swept Baltimore, giving Ruth the most publicity he had experienced to date, a Terrapins official denied it, stating it was their policy not to sign players under contract to Dunn.\nThe competition from the Terrapins caused Dunn to sustain large losses. Although by late June the Orioles were in first place, having won over two-thirds of their games, the paid attendance dropped as low as 150. Dunn explored a possible move by the Orioles to Richmond, Virginia, as well as the sale of a minority interest in the club. These possibilities fell through, leaving Dunn with little choice other than to sell his best players to major league teams to raise money. He offered Ruth to the reigning World Series champions, Connie Mack's Philadelphia Athletics, but Mack had his own financial problems. The Cincinnati Reds and New York Giants expressed interest in Ruth, but Dunn sold his contract, along with those of pitchers Ernie Shore and Ben Egan, to the Boston Red Sox of the American League (AL) on July 4. The sale price was announced as $25,000 but other reports lower the amount to half that, or possibly $8,500 plus the cancellation of a $3,000 loan. Ruth remained with the Orioles for several days while the Red Sox completed a road trip, and reported to the team in Boston on July 11.\nBoston Red Sox (1914\u20131919).\nDeveloping star.\nOn July 11, 1914, Ruth arrived in Boston with Egan and Shore. Ruth later told the story of how that morning he had met Helen Woodford, who would become his first wife. She was a 16-year-old waitress at Landers Coffee Shop, and Ruth related that she served him when he had breakfast there. Other stories, though, suggested that the meeting occurred on another day, and perhaps under other circumstances. Regardless of when he began to court his first wife, he won his first game as a pitcher for the Red Sox that afternoon, 4\u20133, over the Cleveland Naps. His catcher was Bill Carrigan, who was also the Red Sox manager. Shore was given a start by Carrigan the next day; he won that and his second start and thereafter was pitched regularly. Ruth lost his second start, and was thereafter little used. In his major league debut as a batter, Ruth went 0-for-2 against left-hander Willie Mitchell, striking out in his first at bat before being removed for a pinch hitter in the seventh inning. Ruth was not much noticed by the fans, as Bostonians watched the Red Sox's crosstown rivals, the Braves, begin a legendary comeback that would take them from last place on the Fourth of July to the 1914 World Series championship.\nEgan was traded to Cleveland after two weeks on the Boston roster. During his time with the Red Sox, he kept an eye on the inexperienced Ruth, much as Dunn had in Baltimore. When he was traded, no one took his place as supervisor. Ruth's new teammates considered him brash and would have preferred him as a rookie to remain quiet and inconspicuous. When Ruth insisted on taking batting practice despite being both a rookie who did not play regularly and a pitcher, he arrived to find his bats sawed in half. His teammates nicknamed him \"the Big Baboon\", a name the swarthy Ruth, who had disliked the nickname \"Niggerlips\" at St. Mary's, detested. Ruth had received a raise on promotion to the major leagues and quickly acquired tastes for fine food, liquor, and women, among other temptations.\nManager Carrigan allowed Ruth to pitch two exhibition games in mid-August. Although Ruth won both against minor-league competition, he was not restored to the pitching rotation. It is uncertain why Carrigan did not give Ruth additional opportunities to pitch. There are legends\u2014filmed for the screen in \"The Babe Ruth Story\" (1948)\u2014that the young pitcher had a habit of signaling his intent to throw a curveball by sticking out his tongue slightly, and that he was easy to hit until this changed. Creamer pointed out that it is common for inexperienced pitchers to display such habits, and the need to break Ruth of his would not constitute a reason to not use him at all. The biographer suggested that Carrigan was unwilling to use Ruth because of the rookie's poor behavior.\nOn July 30, 1914, Boston owner Joseph Lannin had purchased the minor-league Providence Grays, members of the International League. The Providence team had been owned by several people associated with the Detroit Tigers, including star hitter Ty Cobb, and as part of the transaction, a Providence pitcher was sent to the Tigers. To soothe Providence fans upset at losing a star, Lannin announced that the Red Sox would soon send a replacement to the Grays. This was intended to be Ruth, but his departure for Providence was delayed when Cincinnati Reds owner Garry Herrmann claimed him by waiver. After Lannin wrote to Herrmann explaining that the Red Sox wanted Ruth in Providence so he could develop as a player, and would not release him to a major league club, Herrmann allowed Ruth to be sent to the minors. Carrigan later stated that Ruth was not sent down to Providence to make him a better player, but to help the Grays win the International League pennant (league championship).\nRuth joined the Grays on August 18, 1914. After Dunn's deals, the Baltimore Orioles managed to hold on to first place until August 15, after which they continued to fade, leaving the pennant race between Providence and Rochester. Ruth was deeply impressed by Providence manager \"Wild Bill\" Donovan, previously a star pitcher with a 25\u20134 win\u2013loss record for Detroit in 1907; in later years, he credited Donovan with teaching him much about pitching. Ruth was often called upon to pitch, in one stretch starting (and winning) four games in eight days. On September 5 at Maple Leaf Park in Toronto, Ruth pitched a one-hit 9\u20130 victory, and hit his first professional home run, his only one as a minor leaguer, off Ellis Johnson. Recalled to Boston after Providence finished the season in first place, he pitched and won a game for the Red Sox against the New York Yankees on October 2, getting his first major league hit, a double. Ruth finished the season with a record of 2\u20131 as a major leaguer and 23\u20138 in the International League (for Baltimore and Providence). Once the season concluded, Ruth married Helen in Ellicott City, Maryland. Creamer speculated that they did not marry in Baltimore, where the newlyweds boarded with George Ruth Sr., to avoid possible interference from those at St. Mary's\u2014both bride and groom were not yet of age and Ruth remained on parole from that institution until his 21st birthday.\nIn March 1915, Ruth reported to Hot Springs, Arkansas, for his first major league spring training. Despite a relatively successful first season, he was not slated to start regularly for the Red Sox, who already had two \"superb\" left-handed pitchers, according to Creamer: the established stars Dutch Leonard, who had broken the record for the lowest earned run average (ERA) in a single season; and Ray Collins, a 20-game winner in both 1913 and 1914. Ruth was ineffective in his first start, taking the loss in the third game of the season. Injuries and ineffective pitching by other Boston pitchers gave Ruth another chance, and after some good relief appearances, Carrigan allowed Ruth another start, and he won a rain-shortened seven inning game. Ten days later, the manager had him start against the New York Yankees at the Polo Grounds. Ruth took a 3\u20132 lead into the ninth, but lost the game 4\u20133 in 13 innings. Ruth, hitting ninth as was customary for pitchers, hit a massive home run into the upper deck in right field off of Jack Warhop. At the time, home runs were rare in baseball, and Ruth's majestic shot awed the crowd. The winning pitcher, Warhop, would in August 1915 conclude a major league career of eight seasons, undistinguished but for being the first major league pitcher to give up a home run to Babe Ruth.\nCarrigan was sufficiently impressed by Ruth's pitching to give him a spot in the starting rotation. Ruth finished the 1915 season 18\u20138 as a pitcher; as a hitter, he batted .315 and had four home runs. The Red Sox won the AL pennant, but with the pitching staff healthy, Ruth was not called upon to pitch in the 1915 World Series against the Philadelphia Phillies. Boston won in five games. Ruth was used as a pinch hitter in Game Five, but grounded out against Phillies ace Grover Cleveland Alexander. Despite his success as a pitcher, Ruth was acquiring a reputation for long home runs; at Sportsman's Park against the St. Louis Browns, a Ruth hit soared over Grand Avenue, breaking the window of a Chevrolet dealership.\nIn 1916, attention focused on Ruth's pitching as he engaged in repeated pitching duels with Washington Senators' ace Walter Johnson. The two met five times during the season with Ruth winning four and Johnson one (Ruth had a no decision in Johnson's victory). Two of Ruth's victories were by the score of 1\u20130, one in a 13-inning game. Of the 1\u20130 shutout decided without extra innings, AL president Ban Johnson stated, \"That was one of the best ball games I have ever seen.\" For the season, Ruth went 23\u201312, with a 1.75 ERA and nine shutouts, both of which led the league. Ruth's nine shutouts in 1916 set a league record for left-handers that would remain unmatched until Ron Guidry tied it in 1978. The Red Sox won the pennant and World Series again, this time defeating the Brooklyn Robins (as the Dodgers were then known) in five games. Ruth started and won Game 2, 2\u20131, in 14 innings. Until another game of that length was played in 2005, this was the longest World Series game, and Ruth's pitching performance is still the longest postseason complete game victory.\nCarrigan retired as player and manager after 1916, returning to his native Maine to be a businessman. Ruth, who played under four managers who are in the National Baseball Hall of Fame, always maintained that Carrigan, who is not enshrined there, was the best skipper he ever played for. There were other changes in the Red Sox organization that offseason, as Lannin sold the team to a three-man group headed by New York theatrical promoter Harry Frazee. Jack Barry was hired by Frazee as manager.\nEmergence as a hitter.\nRuth went 24\u201313 with a 2.01 ERA and six shutouts in 1917, but the Sox finished in second place in the league, nine games behind the Chicago White Sox in the standings. On June 23 at Washington, when home plate umpire 'Brick' Owens called the first four pitches as balls, Ruth was ejected from the game and threw a punch at him, and was later suspended for ten days and fined $100. Ernie Shore was called in to relieve Ruth, and was allowed eight warm-up pitches. The runner who had reached base on the walk was caught stealing, and Shore retired all 26 batters he faced to win the game. Shore's feat was listed as a perfect game for many years. In 1991, Major League Baseball's (MLB) Committee on Statistical Accuracy amended it to be listed as a combined no-hitter. In 1917, Ruth was used little as a batter, other than for his plate appearances while pitching, and hit .325 with two home runs.\nThe United States' entry into World War I occurred at the start of the season and overshadowed baseball. Conscription was introduced in September 1917, and most baseball players in the big leagues were of draft age. This included Barry, who was a player-manager, and who joined the Naval Reserve in an attempt to avoid the draft, only to be called up after the 1917 season. Frazee hired International League President Ed Barrow as Red Sox manager. Barrow had spent the previous 30 years in a variety of baseball jobs, though he never played the game professionally. With the major leagues shorthanded because of the war, Barrow had many holes in the Red Sox lineup to fill.\nRuth also noticed these vacancies in the lineup. He was dissatisfied in the role of a pitcher who appeared every four or five days and wanted to play every day at another position. Barrow used Ruth at first base and in the outfield during the exhibition season, but he restricted him to pitching as the team moved toward Boston and the season opener. At the time, Ruth was possibly the best left-handed pitcher in baseball, and allowing him to play another position was an experiment that could have backfired.\nInexperienced as a manager, Barrow had player Harry Hooper advise him on baseball game strategy. Hooper urged his manager to allow Ruth to play another position when he was not pitching, arguing to Barrow, who had invested in the club, that the crowds were larger on days when Ruth played, as they were attracted by his hitting. In early May, Barrow gave in; Ruth promptly hit home runs in four consecutive games (one an exhibition), the last off of Walter Johnson. For the first time in his career (disregarding pinch-hitting appearances), Ruth was assigned a place in the batting order higher than ninth.\nAlthough Barrow predicted that Ruth would beg to return to pitching the first time he experienced a batting slump, that did not occur. Barrow used Ruth primarily as an outfielder in the war-shortened 1918 season. Ruth hit .300, with 11 home runs, enough to secure him a share of the major league home run title with Tilly Walker of the Philadelphia Athletics. He was still occasionally used as a pitcher, and had a 13\u20137 record with a 2.22 ERA. On July 8th, in a scoreless game, with a runner on first base Ruth hit a ball out of the ballpark to drive in the game-winning run; this was recorded as a triple, since the rules at that time considered the game over once the winning run scored. In 1968 the Special Baseball Records Committee unanimously ruled this, along with 36 other hits, a home run, but in part due to the perceived importance of preserving Ruth's home run total at 714, in 1969 the committee reversed this decision.\nIn 1918, the Red Sox won their third pennant in four years and faced the Chicago Cubs in the World Series, which began on September 5, the earliest date in history. The season had been shortened because the government had ruled that baseball players who were eligible for the military would have to be inducted or work in critical war industries, such as armaments plants. Ruth pitched and won Game One for the Red Sox, a 1\u20130 shutout. Before Game Four, Ruth injured his left hand in a fight but pitched anyway. He gave up seven hits and six walks, but was helped by outstanding fielding behind him and by his own batting efforts, as a fourth-inning triple by Ruth gave his team a 2\u20130 lead. The Cubs tied the game in the eighth inning, but the Red Sox scored to take a 3\u20132 lead again in the bottom of that inning. After Ruth gave up a hit and a walk to start the ninth inning, he was relieved on the mound by Joe Bush. To keep Ruth and his bat in the game, he was sent to play left field. Bush retired the side to give Ruth his second win of the Series, and the third and last World Series pitching victory of his career, against no defeats, in three pitching appearances. Ruth's effort gave his team a three-games-to-one lead, and two days later the Red Sox won their third Series in four years, four-games-to-two. Before allowing the Cubs to score in Game Four, Ruth pitched consecutive scoreless innings, a record for the World Series that stood for more than 40 years until 1961, broken by Whitey Ford. Ruth was prouder of that record than he was of any of his batting feats.\nWith the World Series over, Ruth gained exemption from the war draft by accepting a nominal position with a Pennsylvania steel mill. Many industrial establishments took pride in their baseball teams and sought to hire major leaguers. The end of the war in November set Ruth free to play baseball without such contrivances.\nDuring the 1919 season, Ruth was used as a pitcher in only 17 of his 130 games and compiled a 9\u20135 record. Barrow used him as a pitcher mostly in the early part of the season, when the Red Sox manager still had hopes of a second consecutive pennant. By late June, the Red Sox were clearly out of the race, and Barrow had no objection to Ruth concentrating on his hitting, if only because it drew people to the ballpark. Ruth had hit a home run against the Yankees on Opening Day, and another during a month-long batting slump that soon followed. Relieved of his pitching duties, Ruth began an unprecedented spell of slugging home runs, which gave him widespread public and press attention. Even his failures were seen as majestic\u2014one sportswriter said, \"When Ruth misses a swipe at the ball, the stands quiver.\"\nTwo home runs by Ruth on July 5, and one in each of two consecutive games a week later, raised his season total to 11, tying his career best from 1918. The first record to fall was the AL single-season mark of 16, set by Ralph \"Socks\" Seybold in 1902. Ruth matched that on July 29, then pulled ahead toward the major league record of 25, set by Buck Freeman in 1899. By the time Ruth reached this in early September, writers had discovered that Ned Williamson of the 1884 Chicago White Stockings had hit 27\u2014though in a ballpark where the distance to right field was only . On September 20, \"Babe Ruth Day\" at Fenway Park, Ruth won the game with a home run in the bottom of the ninth inning, tying Williamson. He broke the record four days later against the Yankees at the Polo Grounds, and hit one more against the Senators to finish with 29. The home run at Washington made Ruth the first major league player to hit a home run at all eight ballparks in his league. In spite of Ruth's hitting heroics, the Red Sox finished sixth, games behind the league champion White Sox. In his six seasons with Boston, he won 89 games and recorded a 2.19 ERA. He had a four-year stretch where he was second in the AL in wins and ERA behind Walter Johnson, and Ruth had a winning record against Johnson in head-to-head matchups.\nSale to New York.\nAs an out-of-towner from New York City, Frazee had been regarded with suspicion by Boston's sportswriters and baseball fans when he bought the team. He won them over with success on the field and a willingness to build the Red Sox by purchasing or trading for players. He offered the Senators $60,000 for Walter Johnson, but Washington owner Clark Griffith was unwilling. Even so, Frazee was successful in bringing other players to Boston, especially as replacements for players in the military. This willingness to spend for players helped the Red Sox secure the 1918 title. The 1919 season saw record-breaking attendance, and Ruth's home runs for Boston made him a national sensation. In March 1919 Ruth was reported as having accepted a three-year contract for a total of $27,000, after protracted negotiations. Nevertheless, on December 26, 1919, Frazee sold Ruth's contract to the New York Yankees.\nNot all the circumstances concerning the sale are known, but brewer and former congressman Jacob Ruppert, the New York team's principal owner, reportedly asked Yankee manager Miller Huggins what the team needed to be successful. \"Get Ruth from Boston\", Huggins supposedly replied, noting that Frazee was perennially in need of money to finance his theatrical productions. An often-told story is that Frazee needed money, and sold Ruth to finance the musical \"No, No, Nanette\"; that play did not open until 1925, by which time Frazee had sold the Red Sox, but was based on a Frazee-produced play, \"My Lady Friends\", which opened in 1919. There were also other financial pressures on Frazee, despite his team's success. Ruth, fully aware of baseball's popularity and his role in it, wanted to renegotiate his contract, signed before the 1919 season for $10,000 per year through 1921. He demanded that his salary be doubled, or he would sit out the season and cash in on his popularity through other ventures. Ruth's salary demands were causing other players to ask for more money. Additionally, Frazee still owed Lannin as much as $125,000 from the purchase of the club.\nAlthough Ruppert and his co-owner, Colonel Tillinghast Huston, were both wealthy, and had aggressively purchased and traded for players in 1918 and 1919 to build a winning team, Ruppert faced losses in his brewing interests as Prohibition was implemented, and if their team left the Polo Grounds, where the Yankees were the tenants of the New York Giants, building a stadium in New York would be expensive. Nevertheless, when Frazee, who moved in the same social circles as Huston, hinted to the colonel that Ruth was available for the right price, the Yankees owners quickly pursued the purchase.\nFrazee sold the rights to Babe Ruth for $100,000, the largest sum ever paid for a baseball player. The deal also involved a $350,000 loan from Ruppert to Frazee, secured by a mortgage on Fenway Park. Once it was agreed, Frazee informed Barrow, who, stunned, told the owner that he was getting the worse end of the bargain. Cynics have suggested that Barrow may have played a larger role in the Ruth sale, as less than a year after, he became the Yankee general manager, and in the following years made a number of purchases of Red Sox players from Frazee. The $100,000 price included $25,000 in cash, and notes for the same amount due November 1 in 1920, 1921, and 1922; Ruppert and Huston assisted Frazee in selling the notes to banks for immediate cash.\nThe transaction was contingent on Ruth signing a new contract, which was quickly accomplished\u2014Ruth agreed to fulfill the remaining two years on his contract, but was given a $20,000 bonus, payable over two seasons. The deal was announced on January 6, 1920. Reaction in Boston was mixed: some fans were embittered at the loss of Ruth; others conceded that Ruth had become difficult to deal with. \"The New York Times\" suggested that \"The short right field wall at the Polo Grounds should prove an easy target for Ruth next season and, playing seventy-seven games at home, it would not be surprising if Ruth surpassed his home run record of twenty-nine circuit clouts next Summer.\" According to Reisler, \"The Yankees had pulled off the sports steal of the century.\"\nAccording to Marty Appel in his history of the Yankees, the transaction, \"changed the fortunes of two high-profile franchises for decades\". The Red Sox, winners of five of the first 16 World Series, those played between 1903 and 1919, would not win another pennant until 1946, or another World Series until 2004, a drought attributed in baseball superstition to Frazee's sale of Ruth and sometimes dubbed the \"Curse of the Bambino\". Conversely, the Yankees had not won the AL championship prior to their acquisition of Ruth. They won seven AL pennants and four World Series with him, and lead baseball with 40 pennants and 27 World Series titles in their history.\nNew York Yankees (1920\u20131934).\nInitial success (1920\u20131923).\nWhen Ruth signed with the Yankees, his transition from a pitcher to a power-hitting outfielder was complete. His fifteen-season Yankee career consisted of over 2,000 games, and Ruth broke many batting records while making only five widely scattered appearances on the mound, winning all of them.\nAt the end of April 1920, the Yankees were 4\u20137, with the Red Sox leading the league with a 10\u20132 mark. Ruth had done little, having injured himself swinging the bat. Both situations began to change on May 1, when Ruth hit a tape measure home run that sent the ball completely out of the Polo Grounds, a feat believed to have been previously accomplished only by Shoeless Joe Jackson. The Yankees won, 6\u20130, taking three out of four from the Red Sox. Ruth hit his second home run on May 2, and by the end of the month had set a major league record for home runs in a month with 11, and promptly broke it with 13 in June. Fans responded with record attendance figures. On May 16, Ruth and the Yankees drew 38,600 to the Polo Grounds, a record for the ballpark, and 15,000 fans were turned away. Large crowds jammed stadiums to see Ruth play when the Yankees were on the road.\nThe home runs kept on coming. Ruth tied his own record of 29 on July 15 and broke it with home runs in both games of a doubleheader four days later. By the end of July, he had 37, but his pace slackened somewhat after that. Nevertheless, on September 4, he both tied and broke the organized baseball record for home runs in a season, snapping Perry Werden's 1895 mark of 44 in the minor Western League. The Yankees played well as a team, battling for the league lead early in the summer, but slumped in August in the AL pennant battle with Chicago and Cleveland. The pennant and the World Series were won by Cleveland, who surged ahead after the Black Sox Scandal broke on September 28 and led to the suspension of many of Chicago's top players, including Shoeless Joe Jackson. The Yankees finished third, but drew 1.2\u00a0million fans to the Polo Grounds, the first time a team had drawn a seven-figure attendance. The rest of the league sold 600,000 more tickets, many fans there to see Ruth, who led the league with 54 home runs, 158 runs, and 137 runs batted in (RBIs).\nIn 1920 and afterwards, Ruth was aided in his power hitting by the fact that A.J. Reach Company\u2014the maker of baseballs used in the major leagues\u2014was using a more efficient machine to wind the yarn found within the baseball. The new baseballs went into play in 1920 and ushered the start of the live-ball era; the number of home runs across the major leagues increased by 184 over the previous year. Baseball statistician Bill James pointed out that while Ruth was likely aided by the change in the baseball, there were other factors at work, including the gradual abolition of the spitball (accelerated after the death of Ray Chapman, struck by a pitched ball thrown by Mays in August 1920) and the more frequent use of new baseballs (also a response to Chapman's death). Nevertheless, James theorized that Ruth's 1920 explosion might have happened in 1919, had a full season of 154 games been played rather than 140, had Ruth refrained from pitching 133 innings that season, and if he were playing at any other home field but Fenway Park, where he hit only 9 of 29 home runs.\nYankees business manager Harry Sparrow had died early in the 1920 season. Ruppert and Huston hired Barrow to replace him. The two men quickly made a deal with Frazee for New York to acquire some of the players who would be mainstays of the early Yankee pennant-winning teams, including catcher Wally Schang and pitcher Waite Hoyt. The 21-year-old Hoyt became close to Ruth:\nIn the offseason, Ruth spent some time in Havana, Cuba, where he was said to have lost $35,000 () betting on horse races.\nRuth hit home runs early and often in the 1921 season, during which he broke Roger Connor's mark for home runs in a career, 138. Each of the almost 600 home runs Ruth hit in his career after that extended his own record. After a slow start, the Yankees were soon locked in a tight pennant race with Cleveland, winners of the 1920 World Series. On September 15, Ruth hit his 55th home run, breaking his year-old single-season record. In late September, the Yankees visited Cleveland and won three out of four games, giving them the upper hand in the race, and clinched their first pennant a few days later. Ruth finished the regular season with 59 home runs, batting .378 and with a slugging percentage of .846. Ruth's 177 runs scored, 119 extra-base hits, and 457 total bases set modern-era records that still stand .\nThe Yankees had high expectations when they met the New York Giants in the 1921 World Series, every game of which was played in the Polo Grounds. The Yankees won the first two games with Ruth in the lineup. However, Ruth badly scraped his elbow during Game 2 when he slid into third base (he had walked and stolen both second and third bases). After the game, he was told by the team physician not to play the rest of the series. Despite this advice, he did play in the next three games, and pinch-hit in Game Eight of the best-of-nine series, but the Yankees lost, five games to three. Ruth hit .316, drove in five runs and hit his first World Series home run.\nAfter the Series, Ruth and teammates Bob Meusel and Bill Piercy participated in a barnstorming tour in the Northeast. A rule then in force prohibited World Series participants from playing in exhibition games during the offseason, the purpose being to prevent Series participants from replicating the Series and undermining its value. Baseball Commissioner Kenesaw Mountain Landis suspended the trio until May 20, 1922, and fined them their 1921 World Series checks. In August 1922, the rule was changed to allow limited barnstorming for World Series participants, with Landis's permission required.\nOn March 4, 1922, Ruth signed a new contract for three years at $52,000 a year (). This was more than two times the largest sum ever paid to a ballplayer up to that point and it represented 40% of the team's player payroll.\nDespite his suspension, Ruth was named the Yankees' new on-field captain prior to the 1922 season. During the suspension, he worked out with the team in the morning and played exhibition games with the Yankees on their off days. He and Meusel returned on May 20 to a sellout crowd at the Polo Grounds, but Ruth batted 0-for-4 and was booed. On May 25, he was thrown out of the game for throwing dust in umpire George Hildebrand's face, then climbed into the stands to confront a heckler. Ban Johnson ordered him fined, suspended, and stripped of position as team captain. In his shortened season, Ruth appeared in 110 games, batted .315, with 35 home runs, and drove in 99 runs, but the 1922 season was a disappointment in comparison to his two previous dominating years. Despite Ruth's off-year, the Yankees managed to win the pennant and faced the New York Giants in the World Series for the second consecutive year. In the Series, Giants manager John McGraw instructed his pitchers to throw him nothing but curveballs, and Ruth never adjusted. Ruth had just two hits in 17 at bats, and the Yankees lost to the Giants for the second straight year, by 4\u20130 (with one tie game). Sportswriter Joe Vila called him, \"an exploded phenomenon\".\nAfter the season, Ruth was a guest at an Elks Club banquet, set up by Ruth's agent with Yankee team support. There, each speaker, concluding with future New York mayor Jimmy Walker, censured him for his poor behavior. An emotional Ruth promised reform, and, to the surprise of many, followed through. When he reported to spring training, he was in his best shape as a Yankee, weighing only .\nThe Yankees' status as tenants of the Giants at the Polo Grounds had become increasingly uneasy, and in 1922, Giants owner Charles Stoneham said the Yankees' lease, expiring after that season, would not be renewed. Ruppert and Huston had long contemplated a new stadium, and had taken an option on property at 161st Street and River Avenue in the Bronx. Yankee Stadium was completed in time for the home opener on April 18, 1923, at which Ruth hit the first home run in what was quickly dubbed \"the House that Ruth Built\". The ballpark was designed with Ruth in mind: although the venue's left-field fence was further from home plate than at the Polo Grounds, Yankee Stadium's right-field fence was closer, making home runs easier to hit for left-handed batters. To spare Ruth's eyes, right field\u2014his defensive position\u2014was not pointed into the afternoon sun, as was traditional; left fielder Meusel soon developed headaches from squinting toward home plate.\nDuring the 1923 season, the Yankees were never seriously challenged and won the AL pennant by 17 games. Ruth finished the season with a career-high .393 batting average and 41 home runs, which tied Cy Williams for the most in the major-leagues that year. Ruth hit a career-high 45 doubles in 1923, and he reached base 379 times, then a major league record. For the third straight year, the Yankees faced the Giants in the World Series, which Ruth dominated. He batted .368, walked eight times, scored eight runs, hit three home runs and slugged 1.000 during the series, as the Yankees christened their new stadium with their first World Series championship, four games to two.\nBatting title and \"bellyache\" (1924\u20131925).\nIn 1924, the Yankees were favored to become the first team to win four consecutive pennants. Plagued by injuries, they found themselves in a battle with the Senators. Although the Yankees won 18 of 22 at one point in September, the Senators beat out the Yankees by two games. Ruth hit .378, winning his only AL batting title, with a league-leading 46 home runs.\nRuth did not look like an athlete; he was described as \"toothpicks attached to a piano\", with a big upper body but thin wrists and legs. Ruth had kept up his efforts to stay in shape in 1923 and 1924, but by early 1925 weighed nearly . His annual visit to Hot Springs, Arkansas, where he exercised and took saunas early in the year, did him no good as he spent much of the time carousing in the resort town. He became ill while there, and relapsed during spring training. Ruth collapsed in Asheville, North Carolina, as the team journeyed north. He was put on a train for New York, where he was briefly hospitalized. A rumor circulated that he had died, prompting British newspapers to print a premature obituary. In New York, Ruth collapsed again and was found unconscious in his hotel bathroom. He was taken to a hospital where he had multiple convulsions. After sportswriter W. O. McGeehan wrote that Ruth's illness was due to binging on hot dogs and soda pop before a game, it became known as \"the bellyache heard 'round the world\". However, the exact cause of his ailment has never been confirmed and remains a mystery. Glenn Stout, in his history of the Yankees, writes that the Ruth legend is \"still one of the most sheltered in sports\"; he suggests that alcohol was at the root of Ruth's illness, pointing to the fact that Ruth remained six weeks at St. Vincent's Hospital but was allowed to leave, under supervision, for workouts with the team for part of that time. He concludes that the hospitalization was behavior-related. Playing just 98 games, Ruth had his worst season as a Yankee; he finished with a .290 average and 25 home runs. The Yankees finished next to last in the AL with a 69\u201385 record, their last season with a losing record until 1965.\nMurderers' Row (1926\u20131928).\nRuth spent part of the offseason of 1925\u201326 working out at Artie McGovern's gym, where he got back into shape. Barrow and Huggins had rebuilt the team and surrounded the veteran core with good young players like Tony Lazzeri and Lou Gehrig, but the Yankees were not expected to win the pennant.\nRuth returned to his normal production during 1926, when he batted .372 with 47 home runs and 146 RBIs. The Yankees built a 10-game lead by mid-June and coasted to win the pennant by three games. The St. Louis Cardinals had won the National League with the lowest winning percentage for a pennant winner to that point (.578) and the Yankees were expected to win the World Series easily. Although the Yankees won the opener in New York, St. Louis took Games Two and Three. In Game Four, Ruth hit three home runs\u2014the first time this had been done in a World Series game\u2014to lead the Yankees to victory. In the fifth game, Ruth caught a ball as he crashed into the fence. The play was described by baseball writers as a defensive gem. New York took that game, but Grover Cleveland Alexander won Game Six for St. Louis to tie the Series at three games each, then got very drunk. He was nevertheless inserted into Game Seven in the seventh inning and shut down the Yankees to win the game, 3\u20132, and win the Series. Ruth had hit his fourth home run of the Series earlier in the game and was the only Yankee to reach base off Alexander; he walked in the ninth inning before being thrown out to end the game when he attempted to steal second base. Although Ruth's attempt to steal second is often deemed a baserunning blunder, Creamer pointed out that the Yankees' chances of tying the game would have been greatly improved with a runner in scoring position.\nThe 1926 World Series was also known for Ruth's promise to Johnny Sylvester, a hospitalized 11-year-old boy. Ruth promised the child that he would hit a home run on his behalf. Sylvester had been injured in a fall from a horse, and a friend of Sylvester's father gave the boy two autographed baseballs signed by Yankees and Cardinals. The friend relayed a promise from Ruth (who did not know the boy) that he would hit a home run for him. After the Series, Ruth visited the boy in the hospital. When the matter became public, the press greatly inflated it, and by some accounts, Ruth allegedly saved the boy's life by visiting him, emotionally promising to hit a home run, and doing so. Ruth's 1926 salary of $52,000 was far more than any other baseball player, but he made at least twice as much in other income, including $100,000 from 12 weeks of vaudeville.\nThe 1927 New York Yankees team is considered one of the greatest squads to ever take the field. Known as Murderers' Row because of the power of its lineup, the team clinched first place on Labor Day, won a then-AL-record 110 games and took the AL pennant by 19 games. There was no suspense in the pennant race, and the nation turned its attention to Ruth's pursuit of his own single-season home run record of 59 round trippers. Ruth was not alone in this chase. Teammate Lou Gehrig proved to be a slugger who was capable of challenging Ruth for his home run crown; he tied Ruth with 24 home runs late in June. Through July and August, the dynamic duo was never separated by more than two home runs. Gehrig took the lead, 45\u201344, in the first game of a doubleheader at Fenway Park early in September; Ruth responded with two blasts of his own to take the lead, as it proved permanently\u2014Gehrig finished with 47. Even so, as of September 6, Ruth was still several games off his 1921 pace, and going into the final series against the Senators, had only 57. He hit two in the first game of the series, including one off of Paul Hopkins, facing his first major league batter, to tie the record. The following day, September 30, he broke it with his 60th homer, in the eighth inning off Tom Zachary to break a 2\u20132 tie. \"Sixty! Let's see some son of a bitch try to top that one\", Ruth exulted after the game. In addition to his career-high 60 home runs, Ruth batted .356, drove in 164 runs and slugged .772. In the 1927 World Series, the Yankees swept the Pittsburgh Pirates in four games; the National Leaguers were disheartened after watching the Yankees take batting practice before Game One, with ball after ball leaving Forbes Field. According to Appel, \"The 1927 New York Yankees. Even today, the words inspire awe... all baseball success is measured against the '27 team.\"\nThe following season started off well for the Yankees, who led the league in the early going. But the Yankees were plagued by injuries, erratic pitching and inconsistent play. The Philadelphia Athletics, rebuilding after some lean years, erased the Yankees' big lead and even took over first place briefly in early September. The Yankees, however, regained first place when they beat the Athletics three out of four games in a pivotal series at Yankee Stadium later that month, and clinched the pennant in the final weekend of the season. Ruth's play in 1928 mirrored his team's performance. He got off to a hot start and on August 1, he had 42 home runs. This put him ahead of his 60 home run pace from the previous season. He then slumped for the latter part of the season, and he hit just twelve home runs in the last two months. Ruth's batting average also fell to .323, well below his career average. Nevertheless, he ended the season with 54 home runs. The Yankees swept the favored Cardinals in four games in the World Series, with Ruth batting .625 and hitting three home runs in Game Four, including one off Alexander.\n\"Called shot\" and final Yankee years (1929\u20131934).\nBefore the 1929 season, Ruppert (who had bought out Huston in 1923) announced that the Yankees would wear uniform numbers to allow fans at cavernous Yankee Stadium to easily identify the players. The Cardinals and Indians had each experimented with uniform numbers; the Yankees were the first to use them on both home and away uniforms. Ruth batted third and was given number 3. According to a long-standing baseball legend, the Yankees adopted their now-iconic pinstriped uniforms in hopes of making Ruth look slimmer. In truth, though, they had been wearing pinstripes since 1915.\nAlthough the Yankees started well, the Athletics soon proved they were the better team in 1929, splitting two series with the Yankees in the first month of the season, then taking advantage of a Yankee losing streak in mid-May to gain first place. Although Ruth performed well, the Yankees were not able to catch the Athletics\u2014Connie Mack had built another great team. Tragedy struck the Yankees late in the year as manager Huggins died at 51 of erysipelas, a bacterial skin infection, on September 25, only ten days after he had last directed the team. Despite their past differences, Ruth praised Huggins and described him as a \"great guy\". The Yankees finished second, 18 games behind the Athletics. Ruth hit .345 during the season, with 46 home runs and 154 RBIs.\nOn October 17, the Yankees hired Bob Shawkey as manager; he was their fourth choice. Ruth had politicked for the job of player-manager, but Ruppert and Barrow never seriously considered him for the position. Stout deemed this the first hint Ruth would have no future with the Yankees once he retired as a player. Shawkey, a former Yankees player and teammate of Ruth, would prove unable to command Ruth's respect.\nOn January 7, 1930, salary negotiations between the Yankees and Ruth quickly broke down. Having just concluded a three-year contract at an annual salary of $70,000, Ruth promptly rejected both the Yankees' initial proposal of $70,000 for one year and their 'final' offer of two years at seventy-five\u2014the latter figure equaling the annual salary of then US President Herbert Hoover; instead, Ruth demanded at least $85,000 and three years. When asked why he thought he was \"worth more than the President of the United States,\" Ruth responded: \"Say, if I hadn't been sick last summer, I'd have broken hell out of that home run record! Besides, the President gets a four-year contract. I'm only asking for three.\" Exactly two months later, a compromise was reached, with Ruth settling for two years at an unprecedented $80,000 per year. Ruth's salary was more than 2.4 times greater than the next-highest salary that season, a record margin .\nIn 1930, Ruth hit .359 with 49 home runs (his best in his years after 1928) and 153 RBIs, and pitched his first game in nine years, a complete game victory. Nevertheless, the Athletics won their second consecutive pennant and World Series, as the Yankees finished in third place, sixteen games back. At the end of the season, Shawkey was fired and replaced with Cubs manager Joe McCarthy, though Ruth again unsuccessfully sought the job.\nMcCarthy was a disciplinarian, but chose not to interfere with Ruth, who did not seek conflict with the manager. The team improved in 1931, but was no match for the Athletics, who won 107 games, games in front of the Yankees. Ruth, for his part, hit .373, with 46 home runs and 163 RBIs. He had 31 doubles, his most since 1924. In the 1932 season, the Yankees went 107\u201347 and won the pennant. Ruth's effectiveness had decreased somewhat, but he still hit .341 with 41 home runs and 137 RBIs. Nevertheless, he was sidelined twice because of injuries during the season.\nThe Yankees faced the Cubs, McCarthy's former team, in the 1932 World Series. There was bad blood between the two teams as the Yankees resented the Cubs only awarding half a World Series share to Mark Koenig, a former Yankee. The games at Yankee Stadium had not been sellouts; both were won by the home team, with Ruth collecting two singles, but scoring four runs as he was walked four times by the Cubs pitchers. In Chicago, Ruth was resentful at the hostile crowds that met the Yankees' train and jeered them at the hotel. The crowd for Game Three included New York Governor Franklin D. Roosevelt, the Democratic candidate for president, who sat with Chicago Mayor Anton Cermak. Many in the crowd threw lemons at Ruth, a sign of derision, and others (as well as the Cubs themselves) shouted abuse at Ruth and other Yankees. They were briefly silenced when Ruth hit a three-run home run off Charlie Root in the first inning, but soon revived, and the Cubs tied the score at 4\u20134 in the fourth inning, partly due to Ruth's fielding error in the outfield. When Ruth came to the plate in the top of the fifth, the Chicago crowd and players, led by pitcher Guy Bush, were screaming insults at Ruth. With the count at two balls and one strike, Ruth gestured, possibly in the direction of center field, and after the next pitch (a strike), may have pointed there with one hand. Ruth hit the fifth pitch over the center field fence; estimates were that it traveled nearly . Whether or not Ruth intended to indicate where he planned to (and did) hit the ball (Charlie Devens, who, in 1999, was interviewed as Ruth's surviving teammate in that game, did not think so), the incident has gone down in legend as Babe Ruth's called shot. The Yankees won Game Three, and the following day clinched the Series with another victory. During that game, Bush hit Ruth on the arm with a pitch, causing words to be exchanged and provoking a game-winning Yankee rally.\nRuth remained productive in 1933. He batted .301, with 34 home runs, 103 RBIs, and a league-leading 114 walks, as the Yankees finished in second place, seven games behind the Senators. Athletics manager Connie Mack selected him to play right field in the first Major League Baseball All-Star Game, held on July 6, 1933, at Comiskey Park in Chicago. He hit the first home run in the All-Star Game's history, a two-run blast against Bill Hallahan during the third inning, which helped the AL win the game 4\u20132. During the final game of the 1933 season, as a publicity stunt organized by his team, Ruth was called upon and pitched a complete game victory against the Red Sox, his final appearance as a pitcher. Despite unremarkable pitching numbers, Ruth had a 5\u20130 record in five games for the Yankees, raising his career totals to 94\u201346.\nIn 1934, Ruth played in his last full season with the Yankees. By this time, years of high living were starting to catch up with him. His conditioning had deteriorated to the point that he could no longer field or run. He accepted a pay cut to $35,000 from Ruppert, but he was still the highest-paid player in the major leagues. He could still handle a bat, recording a .288 batting average with 22 home runs, and on July 13, 1934, he hit his 700th career home run. However, Reisler described these statistics as \"merely mortal\" by Ruth's previous standards. Ruth was selected to the AL All-Star team for the second consecutive year, even though he was in the twilight of his career. During the game, New York Giants pitcher Carl Hubbell struck out Ruth and four other future Hall-of-Famers consecutively. The Yankees finished second again, seven games behind the Tigers.\nBoston Braves (1935).\nBy this time, Ruth knew he was nearly finished as a player. He desired to remain in baseball as a manager. He was often spoken of as a possible candidate as managerial jobs opened up, but in 1932, when he was mentioned as a contender for the Red Sox position, Ruth stated that he was not yet ready to leave the field. There were rumors that Ruth was a likely candidate each time when the Cleveland Indians, Cincinnati Reds, and Detroit Tigers were looking for a manager, but nothing came of them.\nJust before the 1934 season, Ruppert offered to make Ruth the manager of the Yankees' top minor-league team, the Newark Bears, but he was talked out of it by his wife, Claire, and his business manager, Christy Walsh. Tigers owner Frank Navin seriously considered acquiring Ruth and making him player-manager. However, Ruth insisted on delaying the meeting until he came back from a trip to Hawaii. Navin was unwilling to wait. Ruth opted to go on his trip, despite Barrow advising him that he was making a mistake; in any event, Ruth's asking price was too high for the notoriously tight-fisted Navin. The Tigers' job ultimately went to Mickey Cochrane.\nEarly in the 1934 season, Ruth openly campaigned to become the Yankees manager. However, the Yankee job was never a serious possibility. Ruppert always supported McCarthy, who would remain in his position for another 12 seasons. The relationship between Ruth and McCarthy had been lukewarm at best, and Ruth's managerial ambitions further chilled their interpersonal relations. By the end of the season, Ruth hinted that he would retire unless Ruppert named him manager of the Yankees. When the time came, Ruppert wanted Ruth to leave the team without drama or hard feelings.\nDuring the 1934\u201335 offseason, Ruth circled the world with his wife; the trip included a barnstorming tour of the Far East. At his final stop in the United Kingdom before returning home, Ruth was introduced to cricket by Australian player Alan Fairfax, and after having little luck in a cricketer's stance, he stood as a baseball batter and launched some massive shots around the field, destroying the bat in the process. Although Fairfax regretted that he could not have the time to make Ruth a cricket player, Ruth had lost any interest in such a career upon learning that the best batsmen made only about $40 per week.\nAlso during the offseason, Ruppert had been sounding out the other clubs in hopes of finding one that would be willing to take Ruth as a manager and/or a player. However, the only serious offer came from Athletics owner-manager Connie Mack, who gave some thought to stepping down as manager in favor of Ruth. However, Mack later dropped the idea, saying that Ruth's wife would be running the team in a month if Ruth ever took over.\nWhile the barnstorming tour was underway, Ruppert began negotiating with Boston Braves owner Judge Emil Fuchs, who wanted Ruth as a gate attraction. The Braves had enjoyed modest recent success, finishing fourth in the National League in both 1933 and 1934, but the team drew poorly at the box office. Unable to afford the rent at Braves Field, Fuchs had considered holding dog races there when the Braves were not at home, only to be turned down by Landis. After a series of phone calls, letters, and meetings, the Yankees traded Ruth to the Braves on February 26, 1935. Ruppert had stated that he would not release Ruth to go to another team as a full-time player. For this reason, it was announced that Ruth would become a team vice president and would be consulted on all club transactions, in addition to playing. He was also made assistant manager to Braves skipper Bill McKechnie. In a long letter to Ruth a few days before the press conference, Fuchs promised Ruth a share in the Braves' profits, with the possibility of becoming co-owner of the team. Fuchs also raised the possibility of Ruth succeeding McKechnie as manager, perhaps as early as 1936. Ruppert called the deal \"the greatest opportunity Ruth ever had\".\nThere was considerable attention as Ruth reported for spring training. He did not hit his first home run of the spring until after the team had left Florida, and was beginning the road north in Savannah. He hit two in an exhibition game against the Bears. Amid much press attention, Ruth played his first home game in Boston in over 16 years. Before an opening-day crowd of over 25,000, including five of New England's six state governors, Ruth accounted for all the Braves' runs in a 4\u20132 win over the New York Giants, hitting a two-run home run, singling to drive in a third run and later in the inning scoring the fourth. Although age and weight had slowed him, he made a running catch in left field that sportswriters deemed the defensive highlight of the game.\nRuth had two hits in the second game of the season, but it quickly went downhill both for him and the Braves from there. The season soon settled down to a routine of Ruth performing poorly on the few occasions he even played at all. As April passed into May, Ruth's physical deterioration became even more pronounced. While he remained productive at the plate early on, he could do little else. His conditioning had become so poor that he could barely trot around the bases. He made so many errors that three Braves pitchers told McKechnie they would not take the mound if he was in the lineup. Before long, Ruth stopped hitting as well. He grew increasingly annoyed that McKechnie ignored most of his advice. McKechnie later said that Ruth's presence made enforcing discipline nearly impossible.\nRuth soon realized that Fuchs had deceived him, and had no intention of making him manager or giving him any significant off-field duties. He later said his only duties as vice president consisted of making public appearances and autographing tickets. Ruth also found out that far from giving him a share of the profits, Fuchs wanted him to invest some of \"his\" money in the team in a last-ditch effort to improve its balance sheet. As it turned out, Fuchs and Ruppert had both known all along that Ruth's non-playing positions were meaningless.\nBy the end of the first month of the season, Ruth concluded he was finished even as a part-time player. As early as May 12, he asked Fuchs to let him retire. Ultimately, Fuchs persuaded Ruth to remain at least until after the Memorial Day doubleheader in Philadelphia. In the interim was a western road trip, at which the rival teams had scheduled days to honor him. In Chicago and St. Louis, Ruth performed poorly, and his batting average sank to .155, with only two additional home runs for a total of three on the season so far. In the first two games in Pittsburgh, Ruth had only one hit, though a long fly caught by Paul Waner probably would have been a home run in any other ballpark besides Forbes Field.\nRuth played in the third game of the Pittsburgh series on May 25, 1935, and added one more tale to his playing legend. Ruth went 4-for-4, including three home runs, though the Braves lost the game 11\u20137. The last two were off Ruth's old Cubs nemesis, Guy Bush. The final home run, both of the game and of Ruth's career, sailed out of the park over the right field upper deck\u2013the first time anyone had hit a fair ball completely out of Forbes Field. Ruth was urged to make this his last game, but he had given his word to Fuchs and played in Cincinnati and Philadelphia. The first game of the doubleheader in Philadelphia\u2014the Braves lost both\u2014was his final major league appearance. Ruth retired on June 2 after an argument with Fuchs. He finished 1935 with a .181 average\u2014easily his worst as a full-time position player\u2014and the final six of his 714 home runs. The Braves, 10\u201327 when Ruth left, finished 38\u2013115, at .248 the worst winning percentage in modern National League history. Insolvent like his team, Fuchs gave up control of the Braves before the end of the season; the National League took over the franchise at the end of the year.\nRetirement.\nAlthough Fuchs had given Ruth his unconditional release, no major league team expressed an interest in hiring him in any capacity. Ruth still hoped to be hired as a manager if he could not play anymore, but only one managerial position, Cleveland, became available between Ruth's retirement and the end of the 1937 season. Asked if he had considered Ruth for the job, Indians owner Alva Bradley replied negatively. Of the five members in the inaugural class of Baseball Hall of Fame in 1936 (Ty Cobb, Honus Wagner, Christy Mathewson, Walter Johnson and Ruth), only Ruth was not given an offer to manage a baseball team. Team owners and general managers assessed Ruth's flamboyant personal habits as a reason to exclude him from a managerial job; Barrow said of him, \"How can he manage other men when he can't even manage himself?\" Creamer believed Ruth was unfairly treated in never being given an opportunity to manage a major league club. The author believed there was not necessarily a relationship between personal conduct and managerial success, noting that John McGraw, Billy Martin, and Bobby Valentine were winners despite character flaws.\nRuth played much golf and in a few exhibition baseball games, where he demonstrated a continuing ability to draw large crowds. This appeal contributed to the Dodgers hiring him as first base coach in 1938. When Ruth was hired, Brooklyn general manager Larry MacPhail made it clear that Ruth would not be considered for the manager's job if, as expected, Burleigh Grimes retired at the end of the season. Although much was said about what Ruth could teach the younger players, in practice, his duties were to appear on the field in uniform and encourage base runners\u2014he was not called upon to relay signs. In August, shortly before the baseball rosters expanded, Ruth sought an opportunity to return as an active player in a pinch hitting role. Ruth often took batting practice before games and felt that he could take on the limited role. Grimes denied his request, citing Ruth's poor vision in his right eye, his inability to run the bases, and the risk of an injury to Ruth.\nRuth got along well with everyone except team captain Leo Durocher, who was hired as Grimes' replacement at season's end. Ruth then left his job as a first base coach and would never again work in any capacity in the game of baseball.\nOn July 4, 1939, Ruth spoke on Lou Gehrig Appreciation Day at Yankee Stadium as members of the 1927 Yankees and a sellout crowd turned out to honor the first baseman, who was forced into premature retirement by ALS, which would kill him two years later. The next week, Ruth went to Cooperstown, New York, for the formal opening of the Baseball Hall of Fame. Three years earlier, he was one of the first five players elected to the hall. As radio broadcasts of baseball games became popular, Ruth sought a job in that field, arguing that his celebrity and knowledge of baseball would assure large audiences, but he received no offers. During World War II, he made many personal appearances to advance the war effort, including his last appearance as a player at Yankee Stadium, in a 1943 exhibition for the Army-Navy Relief Fund. He hit a long fly ball off Walter Johnson; the blast left the field, curving foul, but Ruth circled the bases anyway. In 1946, he made a final effort to gain a job in baseball when he contacted new Yankees boss MacPhail, but he was sent a rejection letter. In 1999, Ruth's granddaughter, Linda Tosetti, and his daughter, Julia Ruth Stevens, said that Babe's inability to land a managerial role with the Yankees caused him to feel hurt and slump into a severe depression.\nRuth started playing golf when he was 20 and continued playing the game throughout his life. His appearance at many New York courses drew spectators and headlines. Rye Golf Club was among the courses he played with teammate Lyn Lary in June 1933. With birdies on 3 holes, Ruth posted the best score. In retirement, he became one of the first celebrity golfers participating in charity tournaments, including one where he was pitted against Ty Cobb.\nPersonal life.\nRuth met Helen Woodford, by some accounts, in a coffee shop in Boston, where she was a waitress. They married as teenagers on October 17, 1914. Although Ruth later claimed to have been married in Elkton, Maryland, records show that they were married at St. Paul's Catholic Church in Ellicott City. They adopted a daughter, Dorothy, in 1921. Ruth and Helen separated around 1925 reportedly because of Ruth's repeated infidelities and neglect. They appeared in public as a couple for the last time during the 1926 World Series. Helen died in January 1929 at age 31 in a fire in a house in Watertown, Massachusetts owned by Edward Kinder, a dentist with whom she had been living as \"Mrs. Kinder\". In her book, \"My Dad, the Babe\", Dorothy claimed that she was Ruth's biological child by a mistress named Juanita Jennings. In 1980, Juanita, who was at the time very ill, admitted this to Dorothy and Dorothy's sister, Julia.\nOn April 17, 1929, three months after the death of his first wife, Ruth married actress and model Claire Merritt Hodgson and adopted her daughter Julia. It was the second and final marriage for both parties. Claire, unlike Helen, was well-travelled and educated, and put structure into Ruth's life, like Miller Huggins did for him on the field.\nBy one account, Julia and Dorothy were, through no fault of their own, the reason for the seven-year rift in Ruth's relationship with teammate Lou Gehrig. Sometime in 1932, during a conversation that she assumed was private, Gehrig's mother remarked, \"It's a shame [Claire] doesn't dress Dorothy as nicely as she dresses her own daughter.\" When the comment got back to Ruth, he angrily told Gehrig to tell his mother to mind her own business. Gehrig, in turn, took offense at what he perceived as Ruth's comment about his mother. The two men reportedly never spoke off the field until they reconciled at Yankee Stadium on Lou Gehrig Appreciation Day, July 4, 1939, shortly after Gehrig's retirement from baseball.\nAlthough Ruth was married throughout most of his baseball career, when team co-owner Tillinghast 'Cap' Huston asked him to tone down his lifestyle, Ruth replied, \"I'll promise to go easier on drinking and to get to bed earlier, but not for you, fifty thousand dollars, or two-hundred and fifty thousand dollars will I give up women. They're too much fun.\" A detective that the Yankees hired to follow him one night in Chicago reported that Ruth had been with six women. Ping Bodie said that he was not Ruth's roommate while traveling; \"I room with his suitcase\". Before the start of the 1922 season, Ruth had signed a three-year contract at $52,000 per year with an option to renew for two additional years. His performance during the 1922 season had been disappointing, attributed in part to his drinking and late-night hours. After the end of the 1922 season, he was asked to sign a contract addendum with a morals clause. Ruth and Ruppert signed it on November 11, 1922. It called for Ruth to abstain entirely from the use of intoxicating liquors, and to not stay up later than 1:00\u00a0a.m. during the training and playing season without permission of the manager. Ruth was also enjoined from any action or misbehavior that would compromise his ability to play baseball.\nRuth was a self described Democrat. In 1928, Ruth campaigned for Democratic U.S. Presidential nominee Al Smith.\nCancer and death (1946\u20131948).\nAs early as the war years, doctors had cautioned Ruth to take better care of his health, and he grudgingly followed their advice, limiting his drinking and not going on a proposed trip to support the troops in the South Pacific. In 1946, Ruth began experiencing severe pain over his left eye and had difficulty swallowing. In November 1946, Ruth entered French Hospital in New York for tests, which revealed that he had an inoperable malignant tumor at the base of his skull and in his neck. The malady was a lesion known as nasopharyngeal carcinoma, or \"lymphoepithelioma\". A physician who reviewed Ruth's autopsy in 1998 concluded that Ruth's lifelong use of tobacco \"probably played a part\" in his cancer. His name and fame gave him access to experimental treatments, and he was one of the first cancer patients to receive both drugs and radiation treatment simultaneously. Having lost , he was discharged from the hospital in February and went to Florida to recuperate. He returned to New York and Yankee Stadium after the season started. The new commissioner, Happy Chandler (Judge Landis had died in 1944), proclaimed April 27, 1947, Babe Ruth Day around the major leagues, with the most significant observance to be at Yankee Stadium. A number of teammates and others spoke in honor of Ruth, who briefly addressed the crowd of almost 60,000. By then, his voice was a soft whisper with a very low, raspy tone.\nAround this time, developments in chemotherapy offered some hope for Ruth. The doctors had not told Ruth he had cancer because of his family's fear that he might do himself harm. They treated him with pterolyl triglutamate (Teropterin), a folic acid derivative; he may have been the first human subject. Ruth showed dramatic improvement during the summer of 1947, so much so that his case was presented by his doctors at a scientific meeting, without using his name. He was able to travel around the country, doing promotional work for the Ford Motor Company on American Legion Baseball. He appeared again at another day in his honor at Yankee Stadium in September, but was not well enough to pitch in an old-timers game as he had hoped.\nThe improvement was only a temporary remission, and by late 1947, Ruth was unable to help with the writing of his autobiography, \"The Babe Ruth Story\", which was almost entirely ghostwritten. In and out of the hospital in Manhattan, he left for Florida in February 1948, doing what activities he could. After six weeks he returned to New York to appear at a book-signing party. He also traveled to California to witness the filming of the movie based on the book.\nOn June 5, 1948, a \"gaunt and hollowed-out\" Ruth visited Yale University to donate a manuscript of \"The Babe Ruth Story\" to its library. At Yale, he met with future president George H. W. Bush, who was the captain of the Yale baseball team. On June 13, Ruth visited Yankee Stadium for the final time in his life, appearing at the 25th-anniversary celebrations of \"The House that Ruth Built\". By this time he had lost much weight and had difficulty walking. Introduced along with his surviving teammates from 1923, Ruth used a bat as a cane. Nat Fein's photo of Ruth taken from behind, standing near home plate and facing \"Ruthville\" (right field) became one of baseball's most famous and widely circulated photographs, and won the Pulitzer Prize.\nRuth made one final trip on behalf of American Legion Baseball. He then entered Memorial Hospital, where he would die. He was never told he had cancer; however, before his death, he surmised it. He was able to leave the hospital for a few short trips, including a final visit to Baltimore. On July 26, 1948, Ruth left the hospital to attend the premiere of the film \"The Babe Ruth Story\". Shortly thereafter, he returned to the hospital for the final time. He was barely able to speak. Ruth's condition gradually grew worse, and only a few visitors were permitted to see him, one of whom was National League president and future Commissioner of Baseball Ford C. Frick. \"Ruth was so thin it was unbelievable. He had been such a big man and his arms were just skinny little bones, and his face was so haggard\", Frick said years later.\nThousands of New Yorkers, including many children, stood vigil outside the hospital during Ruth's final days. On August 16, 1948, at 8:01\u00a0p.m., Ruth died in his sleep at the age of 53. His funeral service took place over three days. His open casket was placed on display in the rotunda of Yankee Stadium, where it remained for two days; 77,000 people filed past to pay him tribute. His Requiem Mass was celebrated by Francis Cardinal Spellman at St. Patrick's Cathedral; a crowd estimated at 75,000 waited outside. Ruth is buried with his second wife, Claire, on a hillside in Section 25 at the Gate of Heaven Cemetery in Hawthorne, New York.\nMemorial and museum.\nOn April 19, 1949, the Yankees unveiled a granite monument in Ruth's honor in center field of Yankee Stadium. The monument was located in the field of play next to a flagpole and similar tributes to Huggins and Gehrig until the stadium was remodeled from 1974 to 1975, which resulted in the outfield fences moving inward and enclosing the monuments from the playing field. This area was known thereafter as Monument Park. Yankee Stadium, \"the House that Ruth Built\", was replaced after the 2008 season with a new Yankee Stadium across the street from the old one; Monument Park was subsequently moved to the new venue behind the center field fence. Ruth's uniform number 3 has been retired by the Yankees, and he is one of five Yankees players or managers to have a granite monument within the stadium.\nIn 1974, Ruth's birthplace in Baltimore was renovated and opened to the public as the Babe Ruth Birthplace and Museum. The museum houses a collection of artifacts from Ruth's life, including some rare baseball cards and the earliest known signature of Ruth, from when he was still pitching in the schoolyard. Ruth's widow, Claire, his two daughters, Dorothy and Julia, and his sister, Mamie, helped select and install exhibits for the museum.\nImpact.\nRuth was the first baseball star to be the subject of overwhelming public adulation. Baseball had been known for star players such as Ty Cobb and \"Shoeless Joe\" Jackson, but both men had uneasy relations with fans. In Cobb's case, the incidents were sometimes marked by violence. Ruth's biographers agreed that he benefited from the timing of his ascension to \"Home Run King\". The country had been hit hard by both the war and the 1918 flu pandemic and longed for something to help put these traumas behind it. Ruth also resonated in a country which felt, in the aftermath of the war, that it took second place to no one. Montville argued that Ruth was a larger-than-life figure who was capable of unprecedented athletic feats in the nation's largest city. Ruth became an icon of the social changes that marked the early 1920s. In his history of the Yankees, Glenn Stout writes that \"Ruth was New York incarnate\u2014uncouth and raw, flamboyant and flashy, oversized, out of scale, and absolutely unstoppable\".\nDuring his lifetime, Ruth became a symbol of the United States. During World War II, Japanese soldiers yelled in English, \"To hell with Babe Ruth\", to anger American soldiers. Ruth replied that he hoped \"every Jap that mention[ed] my name gets shot\". Creamer recorded that \"Babe Ruth transcended sport and moved far beyond the artificial limits of baselines and outfield fences and sports pages\". Wagenheim stated, \"He appealed to a deeply rooted American yearning for the definitive climax: clean, quick, unarguable.\" According to Glenn Stout, \"Ruth's home runs were [an] exalted, uplifting experience that meant more to fans than any runs they were responsible for. A Babe Ruth home run was an event unto itself, one that meant anything was possible.\"\nAlthough Ruth was not just a power hitter\u2014he was the Yankees' best bunter, and an excellent outfielder\u2014Ruth's penchant for hitting home runs altered how baseball is played. Prior to 1920, home runs were unusual, and managers tried to win games by getting a runner on base and bringing him around to score through such means as the stolen base, the bunt, and the hit and run. Advocates of what was dubbed \"inside baseball\", such as Giants manager McGraw, disliked the home run, considering it a blot on the purity of the game. According to sportswriter W. A. Phelon, after the 1920 season, Ruth's breakout performance that season and the response in excitement and attendance, \"settled, for all time to come, that the American public is nuttier over the Home Run than the Clever Fielding or the Hitless Pitching. Viva el Home Run and two times viva Babe Ruth, exponent of the home run, and overshadowing star.\" Bill James states, \"When the owners discovered that the fans \"liked\" to see home runs, and when the foundations of the games were simultaneously imperiled by disgrace [in the Black Sox Scandal], then there was no turning back.\" While a few, such as McGraw and Cobb, decried the passing of the old-style play, teams quickly began to seek and develop sluggers.\nAccording to sportswriter Grantland Rice, only two sports figures of the 1920s approached Ruth in popularity\u2014boxer Jack Dempsey and racehorse Man o' War. One of the factors that contributed to Ruth's broad appeal was the uncertainty about his family and early life. Ruth appeared to exemplify the American success story, that even an uneducated, unsophisticated youth, without any family wealth or connections, can do something better than anyone else in the world. Montville writes that \"the fog [surrounding his childhood] will make him forever accessible, universal. He will be the patron saint of American possibility.\" Similarly, the fact that Ruth played in the pre-television era, when a relatively small portion of his fans had the opportunity to see him play, allowed his legend to grow through word of mouth and the hyperbole of sports reporters. Reisler states that recent sluggers who surpassed Ruth's 60-home run mark, such as Mark McGwire and Barry Bonds, generated much less excitement than when Ruth repeatedly broke the single-season home run record in the 1920s. Ruth dominated a relatively small sports world, while Americans of the present era have many sports available to watch.\nLegacy.\nCreamer describes Ruth as \"a unique figure in the social history of the United States\". Thomas Barthel describes him as one of the first celebrity athletes; numerous biographies have portrayed him as \"larger than life\". A dominant figure in a field, whether within or outside sports, is often referred to as \"the Babe Ruth\" of that field. Similarly, \"Ruthian\" has come to mean in sports, \"colossal, dramatic, prodigious, magnificent; with great power\". He was the first athlete to make more money from endorsements and other off-the-field activities than from his sport.\nIn 2006, Montville stated that more books have been written about Ruth than any other member of the Baseball Hall of Fame. At least five of these books (including Creamer's and Wagenheim's) were written in 1973 and 1974 to capitalize on the increase in public interest in Ruth as Hank Aaron approached his career home run mark, which he broke on April 8, 1974. Montville suggested that Ruth is probably even more popular today than he was then. The long ball era that Ruth started continues in baseball: owners build ballparks to encourage home runs.\nIn various surveys and rankings, Ruth has been named the greatest baseball player of all time. In 1998, \"The Sporting News\" ranked him number one on the list of \"Baseball's 100 Greatest Players\". In 1999, baseball fans named Ruth to the Major League Baseball All-Century Team. He was named baseball's Greatest Player Ever in a ballot commemorating the 100th anniversary of professional baseball in 1969. The Associated Press reported in 1993 that Muhammad Ali was tied with Babe Ruth as the most recognized athlete in America. In a 1999 ESPN poll, he was ranked as the second-greatest U.S. athlete of the century, behind Michael Jordan. In 1983, the United States Postal Service honored Ruth with a twenty-cent stamp. In 2022, \"The Sporting News\" named Ruth on their \"New York Mount Rushmore of Sports\".\nSeveral of the most expensive items of sports memorabilia and baseball memorabilia ever sold at auction are associated with Ruth. , Ruth's 1920 Yankees jersey, which sold for $4,415,658 in 2012 (equivalent to $ million in ), is the third most expensive piece of sports memorabilia ever sold. The bat with which he hit the first home run at Yankee Stadium is in \"The Guinness Book of World Records\" as the most expensive baseball bat sold at auction, having fetched $1.265\u00a0million on December 2, 2004 (equivalent to $ million in ). A hat of Ruth's from the 1934 season set a record for a baseball cap when David Wells sold it at auction for $537,278 in 2012. In 2017, Charlie Sheen sold Ruth's 1927 World Series ring for $2,093,927 at auction, a record for a championship ring. The jersey Ruth wore when hitting his \"called shot\" home run in the 1932 World Series sold in 2024 for $24\u00a0million. It set a new record for a sports collectible.\nOne long-term survivor of the craze over Ruth may be the Baby Ruth candy bar. The original company to market the confectionery, the Curtis Candy Company, maintained that the bar was named after Ruth Cleveland, daughter of former president Grover Cleveland. She died in 1904 and the bar was first marketed in 1921, at the height of the craze over Ruth. He later sought to market candy bearing his name; he was refused a trademark because of the Baby Ruth bar. The Ruth estate licensed his likeness for use in an advertising campaign for Baby Ruth in 1995. In 2005, the Baby Ruth bar became the official candy bar of Major League Baseball.\nIn 2018, Ruth was posthumously awarded the Presidential Medal of Freedom by President Donald Trump; his grandson Tom Stevens accepted the award on his behalf. Montville describes the continuing relevance of Babe Ruth in American culture:\nExternal links.\n \n \n \n "}
{"id": "4174", "revid": "20836525", "url": "https://en.wikipedia.org/wiki?curid=4174", "title": "Bacon number", "text": ""}
{"id": "4177", "revid": "27330517", "url": "https://en.wikipedia.org/wiki?curid=4177", "title": "Barge", "text": "A barge is typically a flat-bottomed vessel which does not have its own means of mechanical propulsion. Original use was on inland waterways, while modern use is on both inland and marine water environments. The first modern barges were pulled by tugs, but on inland waterways, most are pushed by pusher boats, or other vessels. The term \"barge\" has a rich history, and therefore there are many types of barges.\nHistory of the barge.\nEtymology.\n\"Barge\" is attested from 1300, from Old French \"barge\", from Vulgar Latin \"barga\". The word originally could refer to any small boat; the modern meaning arose around 1480. \"Bark\" \"small ship\" is attested from 1420, from Old French \"barque\", from Vulgar Latin \"barca\" (400 AD). A more precise meaning (see Barque)) arose in the 17th century and often takes the French spelling for disambiguation. Both are probably derived from the Latin \"barica\", from Greek \"baris\" \"Egyptian boat\", from Coptic \"bari\" \"small boat\", hieroglyphic Egyptian and similar \"ba-y-r\" for \"basket-shaped boat\". By extension, the term \"embark\" literally means to board the kind of boat called a \"barque\".\nBritish river barges.\n18th century.\nIn Great Britain, a merchant barge was originally a flat bottomed merchant vessel for use on navigable rivers. Most of these barges had sails. For traffic on the River Severn, the barge was described thus: \"The lesser sort are called barges and frigates, being from forty to sixty feet in length, having a single mast and square sail, and carrying from twenty to forty tons burthen.\" The larger vessels were called trows. On the River Irwell, there was reference to barges passing below Barton Aqueduct with their mast and sails standing. Early barges on the Thames were called west country barges.\n19th century.\nIn the United Kingdom, the word barge had many meanings by the 1890s, and these varied locally. On the Mersey, a barge was called a 'Flat', on the Thames a Lighter or barge, and on the Humber a 'Keel'. A Lighter had neither mast nor rigging. A keel did have a single mast with sails. Barge and lighter were used indiscriminately. A local distinction was that any flat that was not propelled by steam was a barge, although it might be a sailing flat.\nThe term Dumb barge was probably taken into use to end the confusion. The term Dumb barge surfaced in the early nineteenth century. It first denoted the use of a barge as a mooring platform in a fixed place. As it went up and down with the tides, it made a very convenient mooring place for steam vessels. Within a few decades, the term dumb barge evolved and came to mean: 'a vessel propelled by oars only'. By the 1890s, Dumb barge was still used only on the Thames.\nBy 1880, barges on British rivers and canals were often towed by steam tugboats. On the Thames, many dumb barges still relied on their poles, oars and the tide. Others dumb barges made use of about 50 tugboats to tow them to their destinations. While many coal barges were towed, many dumb barges that handled single parcels were not.\nThe Thames barge and Dutch barge today.\nOn the British river system and larger waterways, the Thames sailing barge, and Dutch barge and unspecified other styles of barge, are still known as barges. The term Dutch barge is nowadays often used to refer to an accommodation ship, but originally refers to the slightly larger Dutch version of the Thames sailing barge.\nBritish canals: narrowboats and widebeams.\nDuring the Industrial Revolution, a substantial network of canals was developed in Great Britain from 1750 onward. Whilst the largest of these could accommodate ocean-going vessels, e.g the later Manchester Ship Canal, a complex network of smaller canals was also developed. These smaller canals had locks, bridges and tunnels that were at minimum only wide at the waterline. On wider sections, standard barges and other vessels could trade, but full access to the network necessitated the parallel development of the narrowboat, which usually had a beam a couple of inches less to allow for clearance, e.g. . It was soon realized that the narrow locks were too limiting, and later locks were therefore doubled in width to . This led to the development of the widebeam canal boat. The narrowboat (one word) definition in the \"Oxford English Dictionary\" is:\nThe narrowboats were initially also known as barges, and the new canals were constructed with an adjacent towpath along which draft horses walked, towing the barges. These types of canal craft are so specific that on the British canal system the term 'barge' is no longer used to describe narrowboats and widebeams. Narrowboats and widebeams are still seen on canals, mostly for leisure cruising, and now engine-powered.\nCrew and pole.\nThe people who moved barges were known as lightermen. Poles are used on barges to fend off other nearby vessels or a wharf. These are often called 'pike poles'. The long pole used to maneuver or propel a barge has given rise to the saying \"I wouldn't touch that [subject/thing] with a barge pole.\"\nThe 19th century American barge.\nIn the United States a barge was not a sailing vessel by the end of the 19th century. Indeed, barges were often created by cutting down (razeeing) sailing vessels. In New York this was an accepted meaning of the term barge. The somewhat smaller scow was built as such, but the scow also had its sailing counterpart the sailing scow.\nThe modern barge.\nThe iron barge.\nThe innovation that led to the modern barge was the use of iron barges towed by a steam tugboat. These were first used to transport grain and other bulk products. From about 1840 to 1870 the towed iron barge was quickly introduced on the Rhine, Danube, Don, Dniester, and rivers in Egypt, India and Australia. Many of these barges were built in Great Britain.\nNowadays 'barge' generally refers to a dumb barge. In Europe, a Dumb barge is: \"An inland waterway transport freight vessel designed to be towed which does not have its own means of mechanical propulsion\". In America, a barge is generally pushed.\nModern use.\nBarges are used today for transporting low-value bulk items, as the cost of hauling goods that way is very low and for larger project cargo, such as offshore wind turbine blades. Barges are also used for very heavy or bulky items; a typical American barge measures , and can carry up to about of cargo. The most common European barges measure and can carry up to about .\nAs an example, on June 26, 2006, in the US a catalytic cracking unit reactor was shipped by barge from the Tulsa Port of Catoosa in Oklahoma to a refinery in Pascagoula, Mississippi. Extremely large objects are normally shipped in sections and assembled after delivery, but shipping an assembled unit reduces costs and avoids reliance on construction labor at the delivery site, which in the case of the reactor was still recovering from Hurricane Katrina. Of the reactor's journey, only about were traveled overland, from the final port to the refinery.\nThe Transportation Institute at Texas A&amp;M found that inland barge transportation in the US produces far fewer emissions of carbon dioxide for each ton of cargo moved compared to transport by truck or rail. According to the study, transporting cargo by barge produces 43% less greenhouse gas emissions than rail and more than 800% less than trucks. Environmentalists claim that in areas where barges, tugboats and towboats idle may produce more emissions like in the locks and dams of the Mississippi River.\nSelf-propelled barges may be used for traveling downstream or upstream in placid waters; they are operated as an unpowered barge, with the assistance of a tugboat, when traveling upstream in faster waters. Canal barges are usually made for the particular canal in which they will operate.\nUnpowered vessels\u2014barges\u2014may be used for other purposes, such as large accommodation vessels, towed to where they are needed and stationed there as long as necessary. An example is the Bibby Stockholm."}
{"id": "4178", "revid": "2842084", "url": "https://en.wikipedia.org/wiki?curid=4178", "title": "Bill Schelter", "text": "William Frederick Schelter (1947 \u2013 July 30, 2001) was a professor of mathematics at The University of Texas at Austin and a Lisp developer and programmer. Schelter is credited with the development of the GNU Common Lisp (GCL) implementation of Common Lisp and the GPL'd version of the computer algebra system Macsyma called Maxima. Schelter authored Austin Kyoto Common Lisp (AKCL) under contract with IBM. AKCL formed the foundation for Axiom, another computer algebra system. AKCL eventually became GNU Common Lisp. He is also credited with the first port of the GNU C compiler to the Intel 386 architecture, used in the original implementation of the Linux kernel.\nSchelter obtained his Ph.D. at McGill University in 1972. His mathematical specialties were noncommutative ring theory and computational algebra and its applications, including automated theorem proving in geometry.\nIn the summer of 2001, age 54, he died suddenly of a heart attack while traveling in Russia."}
{"id": "4179", "revid": "20542576", "url": "https://en.wikipedia.org/wiki?curid=4179", "title": "British English", "text": "British English (abbreviations: BrE, en-GB, and BE) is the set of varieties of the English language native to the United Kingdom. More narrowly, it can refer specifically to the English language in England, or, more broadly, to the collective dialects of English throughout the British Isles taken as a single umbrella variety, for instance additionally incorporating Scottish English, Welsh English, and Northern Irish English. Tom McArthur in the Oxford Guide to World English acknowledges that British English shares \"all the ambiguities and tensions [with] the word 'British' and as a result can be used and interpreted in two ways, more broadly or more narrowly, within a range of blurring and ambiguity\".\nVariations exist in formal (both written and spoken) English in the United Kingdom. For example, the adjective \"wee\" is almost exclusively used in parts of Scotland, north-east England, Northern Ireland, Ireland, and occasionally Yorkshire, whereas the adjective \"little\" is predominant elsewhere. Nevertheless, there is a meaningful degree of uniformity in written English within the United Kingdom, and this could be described by the term \"British English\". The forms of spoken English, however, vary considerably more than in most other areas of the world where English is spoken and so a uniform concept of British English is more difficult to apply to the spoken language. \nGlobally, countries that are former British colonies or members of the Commonwealth tend to follow British English, as is the case for English used by European Union institutions. In China, both British English and American English are taught. The UK government actively teaches and promotes English around the world and operates in over 100 countries.\nHistory.\nOrigins.\nEnglish is a West Germanic language that originated from the Anglo-Frisian dialects brought to Britain by Germanic settlers from various parts of what is now northwest Germany and the northern Netherlands. The resident population at this time was generally speaking Common Brittonic\u2014the insular variety of Continental Celtic, which was influenced by the Roman occupation. This group of languages (Welsh, Cornish, Cumbric) cohabited alongside English into the modern period, but due to their remoteness from the Germanic languages, influence on English was notably limited. However, the degree of influence remains debated, and it has recently been argued that its grammatical influence accounts for the substantial innovations noted between English and the other West Germanic languages.\nInitially, Old English was a diverse group of dialects, reflecting the varied origins of the Anglo-Saxon kingdoms of England. One of these dialects, Late West Saxon, eventually came to dominate. The original Old English was then influenced by two waves of invasion: the first was by speakers of the Scandinavian branch of the Germanic family, who settled in parts of Britain in the eighth and ninth centuries; the second was the Normans in the 11th century, who spoke Old Norman and ultimately developed an English variety of this called Anglo-Norman. These two invasions caused English to become \"mixed\" to some degree (though it was never a truly mixed language in the strictest sense of the word; mixed languages arise from the cohabitation of speakers of different languages, who develop a hybrid tongue for basic communication).\nThe more idiomatic, concrete and descriptive English is, the more it is from Anglo-Saxon origins. The more intellectual and abstract English is, the more it contains Latin and French influences, e.g. swine (like the Germanic ) is the animal in the field bred by the occupied Anglo-Saxons and pork (like the French ) is the animal at the table eaten by the occupying Normans. Another example is the Anglo-Saxon meaning cow, and the French meaning beef.\nCohabitation with the Scandinavians resulted in a significant grammatical simplification and lexical enrichment of the Anglo-Frisian core of English; the later Norman occupation led to the grafting onto that Germanic core of a more elaborate layer of words from the Romance branch of the European languages. This Norman influence entered English largely through the courts and government. Thus, English developed into a \"borrowing\" language of great flexibility and with a huge vocabulary.\nDialects.\nDialects and accents vary amongst the four countries of the United Kingdom, as well as within the countries themselves.\nThe major divisions are normally classified as English English (or English as spoken in England (which is itself broadly grouped into Southern English, West Country, East and West Midlands English and Northern English), Northern Irish English (in Northern Ireland), Welsh English (not to be confused with the Welsh language), and Scottish English (not to be confused with the Scots language or Scottish Gaelic). Each group includes a range of dialects, some markedly different from others. The various British dialects also differ in the words that they have borrowed from other languages.\nAround the middle of the 15th century, there were points where within the 5 major dialects there were almost 500 ways to spell the word \"though\".\nResearch.\nFollowing its last major survey of English Dialects (1949\u20131950), the University of Leeds has started work on a new project. In May 2007 the Arts and Humanities Research Council awarded a grant to Leeds to study British regional dialects.\nThe team are sifting through a large collection of examples of regional slang words and phrases turned up by the \"Voices project\" run by the BBC, in which they invited the public to send in examples of English still spoken throughout the country. The BBC Voices project also collected hundreds of news articles about how the British speak English from swearing through to items on language schools. This information will also be collated and analysed by Johnson's team both for content and for where it was reported. \"Perhaps the most remarkable finding in the Voices study is that the English language is as diverse as ever, despite our increased mobility and constant exposure to other accents and dialects through TV and radio\". When discussing the award of the grant in 2007, Leeds University stated:\nEnglish regional.\nMost people in Britain speak with a regional accent or dialect. However, about 2% of Britons speak with an accent called Received Pronunciation (also called \"the King's English\", \"Oxford English\" and \"BBC English\"), that is essentially region-less. It derives from a mixture of the Midlands and Southern dialects spoken in London in the early modern period. It is frequently used as a model for teaching English to foreign learners.\nIn the South East, there are significantly different accents; the Cockney accent spoken by some East Londoners is strikingly different from Received Pronunciation (RP). Cockney rhyming slang can be (and was initially intended to be) difficult for outsiders to understand, although the extent of its use is often somewhat exaggerated.\nLondoners speak with a mixture of accents, depending on ethnicity, neighbourhood, class, age, upbringing, and sundry other factors. Estuary English has been gaining prominence in recent decades: it has some features of RP and some of Cockney. Immigrants to the UK in recent decades have brought many more languages to the country and particularly to London. Surveys started in 1979 by the Inner London Education Authority discovered over 125 languages being spoken domestically by the families of the inner city's schoolchildren. Notably Multicultural London English, a sociolect that emerged in the late 20th century spoken mainly by young, working-class people in multicultural parts of London.\nSince the mass internal migration to Northamptonshire in the 1940s and given its position between several major accent regions, it has become a source of various accent developments. In Northampton the older accent has been influenced by overspill Londoners. There is an accent known locally as the Kettering accent, which is a transitional accent between the East Midlands and East Anglian. It is the last southern Midlands accent to use the broad \"a\" in words like \"bath\" or \"grass\" (i.e. or ). Conversely \"crass\" or \"plastic\" use a slender \"a\". A few miles northwest in Leicestershire the slender \"a\" becomes more widespread generally. In the town of Corby, north, one can find Corbyite which, unlike the Kettering accent, is largely influenced by the West Scottish accent.\nFeatures.\nPhonological features characteristic of British English revolve around the pronunciation of the letter R, as well as the dental plosive T and some diphthongs specific to this dialect.\nT-stopping.\nOnce regarded as a Cockney feature, in a number of forms of spoken British English, has become commonly realised as a glottal stop when it is in the intervocalic position, in a process called T-glottalisation. National media, being based in London, have seen the glottal stop spreading more widely than it once was in word endings, \"not\" being heard as \"no\" and \"bottle of water\" being heard as \"bole of waer\". It is still stigmatised when used at the beginning and central positions, such as \"later\", while \"often\" has all but regained . Other consonants subject to this usage in Cockney English are \"p\", as in paer and \"k\" as in baer.\nR-dropping.\nIn most areas of England and Wales, outside the West Country and other near-by counties of the UK, the consonant R is not pronounced if not followed by a vowel, lengthening the preceding vowel instead. This phenomenon is known as non-rhoticity.\nIn these same areas, a tendency exists to insert an R between a word ending in a vowel and a next word beginning with a vowel. This is called the intrusive R. It could be understood as a merger, in that words that once ended in an R and words that did not are no longer treated differently. This is also due to London-centric influences. Examples of R-dropping are \"car\" and \"sugar\", where the R is not pronounced.\nDiphthongisation.\nBritish dialects differ on the extent of diphthongisation of long vowels, with southern varieties extensively turning them into diphthongs, and with northern dialects normally preserving many of them. As a comparison, North American varieties could be said to be in-between.\nNorth.\nLong vowels /i\u02d0/ and /u\u02d0/ are usually preserved, and in several areas also /o\u02d0/ and /e\u02d0/, as in go and say (unlike other varieties of English, that change them to [o\u028a] and [e\u026a] respectively). Some areas go as far as not diphthongising medieval /i\u02d0/ and /u\u02d0/, that give rise to modern /a\u026a/ and /a\u028a/; that is, for example, in the traditional accent of Newcastle upon Tyne, 'out' will sound as 'oot', and in parts of Scotland and North-West England, 'my' will be pronounced as 'me'.\nSouth.\nLong vowels /i\u02d0/ and /u\u02d0/ are diphthongised to [\u026ai] and [\u028au] respectively (or, more technically, [\u028f\u0289], with a raised tongue), so that ee and oo in feed and food are pronounced with a movement. The diphthong [o\u028a] is also pronounced with a greater movement, normally [\u0259\u028a], [\u0259\u0289] or [\u0259\u0268].\nPeople in groups.\nDropping a morphological grammatical number, in collective nouns, is stronger in British English than North American English. This is to treat them as plural when once grammatically singular, a perceived natural number prevails, especially when applying to institutional nouns and groups of people.\nThe noun 'police', for example, undergoes this treatment:\nA football team can be treated likewise:\nThis tendency can be observed in texts produced already in the 19th century. For example, Jane Austen, a British author, writes in Chapter 4 of \"Pride and Prejudice\", published in 1813: However, in Chapter 16, the grammatical number is used. \nNegatives.\nSome dialects of British English use negative concords, also known as double negatives. Rather than changing a word or using a positive, words like nobody, not, nothing, and never would be used in the same sentence. While this does not occur in Standard English, it does occur in non-standard dialects. The double negation follows the idea of two different morphemes, one that causes the double negation, and one that is used for the point or the verb.\nStandard British English.\nStandard English in the United Kingdom, as in other English-speaking nations, is widely enforced in schools and by social norms for formal contexts but not by any singular authority; for instance, there is no institution equivalent to the with French or the Royal Spanish Academy with Spanish. Standard British English differs notably in certain vocabulary, grammar, and pronunciation features from standard American English and certain other standard English varieties around the world. British and American spelling also differ in minor ways.\nThe accent, or pronunciation system, of standard British English, based in southeastern England, has been known for over a century as Received Pronunciation (RP). However, due to language evolution and changing social trends, some linguists argue that RP is losing prestige or has been replaced by another accent, one that the linguist Geoff Lindsey for instance calls Standard Southern British English. Other scholars suggest that more regionally-oriented standard accents are emerging in England. Outside of England, namely in Scotland and Northern Ireland, RP exerts very little influence, particularly in the 21st century. RP, while long established as the standard English accent around the globe due to the spread of the British Empire, is distinct from the standard English pronunciation in some parts of the world; most prominently, RP notably contrasts with standard North American accents.\nAs of the 21st century, dictionaries such as the \"Oxford English Dictionary\", the \"Longman Dictionary of Contemporary English\", the \"Chambers Dictionary\", and the \"Collins Dictionary\" record actual usage rather than attempting to prescribe it. In addition, vocabulary and usage change with time; words are freely borrowed from other languages and other varieties of English, and neologisms are frequent.\nHistory of standardisation.\nFor historical reasons dating back to the rise of London in the ninth century, the form of language spoken in London and the East Midlands became standard English within the Court, and ultimately became the basis for generally accepted use in the law, government, literature and education in Britain. The standardisation of British English is thought to be from both dialect levelling and a thought of social superiority. Speaking in the Standard dialect created class distinctions; those who did not speak the standard English would be considered of a lesser class or social status and often discounted or considered of a low intelligence. Another contribution to the standardisation of British English was the introduction of the printing press to England in the mid-15th century. In doing so, William Caxton enabled a common language and spelling to be dispersed among the entirety of England at a much faster rate.\n\"Samuel Johnson's A Dictionary of the English Language\" (1755) was a large step in the English-language spelling reform, where the purification of language focused on standardising both speech and spelling. By the early 20th century, British authors had produced numerous books intended as guides to English grammar and usage, a few of which achieved sufficient acclaim to have remained in print for long periods and to have been reissued in new editions after some decades. These include, most notably of all, Fowler's \"Modern English Usage\" and \"The Complete Plain Words\" by Sir Ernest Gowers.\nDetailed guidance on many aspects of writing British English for publication is included in style guides issued by various publishers including \"The Times\" newspaper, the \"Oxford University Press\" and the \"Cambridge University Press\". \"The Oxford University Press\" guidelines were originally drafted as a single broadsheet page by Horace Henry Hart, and were at the time (1893) the first guide of their type in English; they were gradually expanded and eventually published, first as \"Hart's Rules\", and in 2002 as part of \"The Oxford Manual of Style\". Comparable in authority and stature to \"The Chicago Manual of Style\" for published American English, the Oxford Manual is a fairly exhaustive standard for published British English that writers can turn to in the absence of specific guidance from their publishing house.\nRelationship with Commonwealth English.\nBritish English is the basis of, and very similar to, Commonwealth English. Commonwealth English is English as spoken and written in the Commonwealth countries, though often with some local variation. This includes English spoken in Australia, Malta, New Zealand, Nigeria, and South Africa. It also includes South Asian English used in South Asia, in English varieties in Southeast Asia, and in parts of Africa. Canadian English is based on British English, but has more influence from American English, often grouped together due to their close proximity. British English, for example, is the closest English to Indian English, but Indian English has extra vocabulary and some English words are assigned different meanings."}
{"id": "4181", "revid": "13286072", "url": "https://en.wikipedia.org/wiki?curid=4181", "title": "Battle", "text": "A battle is an occurrence of combat in warfare between opposing military units of any number or size. A war usually consists of multiple battles. In general, a battle is a military engagement that is well defined in duration, area, and force commitment. An engagement with only limited commitment between the forces and without decisive results is sometimes called a skirmish.\nThe word \"battle\" can also be used infrequently to refer to an entire operational campaign, although this usage greatly diverges from its conventional or customary meaning. Generally, the word \"battle\" is used for such campaigns if referring to a protracted combat encounter in which either one or both of the combatants had the same methods, resources, and strategic objectives throughout the encounter. Some prominent examples of this would be the Battle of the Atlantic, Battle of Britain, and the Battle of France, all in World War II.\nWars and military campaigns are guided by military strategy, whereas battles take place on a level of planning and execution known as operational mobility. German strategist Carl von Clausewitz stated that \"the employment of battles ... to achieve the object of war\" was the essence of strategy.\nEtymology.\nBattle is a loanword from the Old French , first attested in 1297, from Late Latin , meaning \"exercise of soldiers and gladiators in fighting and fencing\", from Late Latin (taken from Germanic) \"beat\", from which the English word battery is also derived via Middle English .\nCharacteristics.\nThe defining characteristic of the fight as a concept in military science has changed with the variations in the organisation, employment and technology of military forces. The English military historian John Keegan suggested an ideal definition of battle as \"something which happens between two armies leading to the moral then physical disintegration of one or the other of them\" but the origins and outcomes of battles can rarely be summarized so neatly. Battle in the 20th and 21st centuries is defined as the combat between large components of the forces in a military campaign, used to achieve military objectives. Where the duration of the battle is longer than a week, it is often for reasons of planning called an operation. Battles can be planned, encountered or forced by one side when the other is unable to withdraw from combat.\nA battle always has as its purpose the reaching of a mission goal by use of military force. A victory in the battle is achieved when one of the opposing sides forces the other to abandon its mission and surrender its forces, routs the other (i.e., forces it to retreat or renders it militarily ineffective for further combat operations) or annihilates the latter, resulting in their deaths or capture. A battle may end in a Pyrrhic victory, which ultimately favors the defeated party. If no resolution is reached in a battle, it can result in a stalemate. A conflict in which one side is unwilling to reach a decision by a direct battle using conventional warfare often becomes an insurgency.\nUntil the 19th century the majority of battles were of short duration, many lasting a part of a day. (The Battle of Preston (1648), the Battle of Nations (1813) and the Battle of Gettysburg (1863) were exceptional in lasting three days.) This was mainly due to the difficulty of supplying armies in the field or conducting night operations. The means of prolonging a battle was typically with siege warfare. Improvements in transport and the sudden evolving of trench warfare, with its siege-like nature during the First World War in the 20th century, lengthened the duration of battles to days and weeks. This created the requirement for unit rotation to prevent combat fatigue, with troops preferably not remaining in a combat area of operations for more than a month.\nThe use of the term \"battle\" in military history has led to its misuse when referring to almost any scale of combat, notably by strategic forces involving hundreds of thousands of troops that may be engaged in either one battle at a time (Battle of Leipzig) or operations (Battle of Wuhan). The space a battle occupies depends on the range of the weapons of the combatants. A \"battle\" in this broader sense may be of long duration and take place over a large area, as in the case of the Battle of Britain or the Battle of the Atlantic. Until the advent of artillery and aircraft, battles were fought with the two sides within sight, if not reach, of each other. The depth of the battlefield has also increased in modern warfare with inclusion of the supporting units in the rear areas; supply, artillery, medical personnel etc. often outnumber the front-line combat troops.\nBattles are made up of a multitude of individual combats, skirmishes and small engagements and the combatants will usually only experience a small part of the battle. To the infantryman, there may be little to distinguish between combat as part of a minor raid or a big offensive, nor is it likely that he anticipates the future course of the battle; few of the British infantry who went over the top on the first day on the Somme, 1 July 1916, would have anticipated that the battle would last five months. Some of the Allied infantry who had just dealt a crushing defeat to the French at the Battle of Waterloo fully expected to have to fight again the next day (at the Battle of Wavre).\nBattlespace.\nBattlespace is a unified strategic concept to integrate and combine armed forces for the military theatre of operations, including air, information, land, sea and space. It includes the environment, factors and conditions that must be understood to apply combat power, protect the force or complete the mission, comprising enemy and friendly armed forces; facilities; weather; terrain; and the electromagnetic spectrum.\nFactors.\nBattles are decided by various factors, the number and quality of combatants and equipment, the skill of commanders and terrain are among the most prominent. Weapons and armour can be decisive; on many occasions armies have achieved victory through more advanced weapons than those of their opponents. An extreme example was in the Battle of Omdurman, in which a large army of Sudanese Mahdists armed in a traditional manner were destroyed by an Anglo-Egyptian force equipped with Maxim machine guns and artillery.\nOn some occasions, simple weapons employed in an unorthodox fashion have proven advantageous; Swiss pikemen gained many victories through their ability to transform a traditionally defensive weapon into an offensive one. Zulus in the early 19th century were victorious in battles against their rivals in part because they adopted a new kind of spear, the iklwa. Forces with inferior weapons have still emerged victorious at times, for example in the Wars of Scottish Independence. Disciplined troops are often of greater importance; at the Battle of Alesia, the Romans were greatly outnumbered but won because of superior training.\nBattles can also be determined by terrain. Capturing high ground has been the main tactic in innumerable battles. An army that holds the high ground forces the enemy to climb and thus wear themselves down. Areas of jungle and forest, with dense vegetation act as force-multipliers, of benefit to inferior armies. Terrain may have lost importance in modern warfare, due to the advent of aircraft, though the terrain is still vital for camouflage, especially for guerrilla warfare.\nGenerals and commanders also play an important role, Hannibal, Julius Caesar, Khalid ibn Walid, Subutai and Napoleon Bonaparte were all skilled generals and their armies were extremely successful at times. An army that can trust the commands of their leaders with conviction in its success invariably has a higher morale than an army that doubts its every move. The British in the naval Battle of Trafalgar owed its success to the reputation of Admiral Lord Nelson.\nTypes.\nBattles can be fought on land, at sea, and in the air. Naval battles have occurred since before the 5th century BC. Air battles have been far less common, due to their late conception, the most prominent being the Battle of Britain in 1940. Since the Second World War, land or sea battles have come to rely on air support. During the Battle of Midway, five aircraft carriers were sunk without either fleet coming into direct contact.\nBattles are usually hybrids of different types listed above.\nA \"decisive battle\" is one with political effects, determining the course of the war such as the Battle of Smolensk or bringing hostilities to an end, such as the Battle of Hastings or the Battle of Hattin. A decisive battle can change the balance of power or boundaries between countries. The concept of the \"decisive battle\" became popular with the publication in 1851 of Edward Creasy's \"The Fifteen Decisive Battles of the World\". British military historians J.F.C. Fuller (\"The Decisive Battles of the Western World\") and B.H. Liddell Hart (\"Decisive Wars of History\"), among many others, have written books in the style of Creasy's work.\nLand.\nThere is an obvious difference in the way battles have been fought. Early battles were probably fought between rival hunting bands as unorganized crowds. During the Battle of Megiddo, the first reliably documented battle in the fifteenth century BC, both armies were organised and disciplined; during the many wars of the Roman Empire, barbarians continued to use mob tactics.\nAs the Age of Enlightenment dawned, armies began to fight in highly disciplined lines. Each would follow the orders from their officers and fight as a unit instead of individuals. Armies were divided into regiments, battalions, companies and platoons. These armies would march, line up and fire in divisions.\nNative Americans, on the other hand, did not fight in lines, using guerrilla tactics. American colonists and European forces continued using disciplined lines into the American Civil War.\nA new style arose from the 1850s to the First World War, known as trench warfare, which also led to tactical radio. Chemical warfare also began in 1915.\nBy the Second World War, the use of the smaller divisions, platoons and companies became much more important as precise operations became vital. Instead of the trench stalemate of 1915\u20131917, in the Second World War, battles developed where small groups encountered other platoons. As a result, elite squads became much more recognized and distinguishable. Maneuver warfare also returned with an astonishing pace with the advent of the tank, replacing the cannon of the Enlightenment Age. Artillery has since gradually replaced the use of frontal troops. Modern battles resemble those of the Second World War, along with indirect combat through the use of aircraft and missiles which has come to constitute a large portion of wars in place of battles, where battles are now mostly reserved for capturing cities.\nNaval.\nOne significant difference of modern naval battles, as opposed to earlier forms of combat is the use of marines, which introduced amphibious warfare. Today, a marine is actually an infantry regiment that sometimes fights solely on land and is no longer tied to the navy. A good example of an ancient naval battle is the Battle of Salamis. Most ancient naval battles were fought by fast ships using the battering ram to sink opposing fleets or steer close enough for boarding in hand-to-hand combat. Troops were often used to storm enemy ships as used by Romans and pirates. This tactic was usually used by civilizations that could not beat the enemy with ranged weaponry. Another invention in the late Middle Ages was the use of Greek fire by the Byzantines, which was used to set enemy fleets on fire. Empty demolition ships utilized the tactic to crash into opposing ships and set it afire with an explosion. After the invention of cannons, naval warfare became useful as support units for land warfare. During the 19th century, the development of mines led to a new type of naval warfare. The ironclad, first used in the American Civil War, resistant to cannons, soon made the wooden ship obsolete. The invention of military submarines, during World War I, brought naval warfare to both above and below the surface. With the development of military aircraft during World War II, battles were fought in the sky as well as below the ocean. Aircraft carriers have since become the central unit in naval warfare, acting as a mobile base for lethal aircraft.\nAerial.\nAlthough the use of aircraft has for the most part always been used as a supplement to land or naval engagements, since their first major military use in World War I aircraft have increasingly taken on larger roles in warfare. During World War I, the primary use was for reconnaissance, and small-scale bombardment. Aircraft began becoming much more prominent in the Spanish Civil War and especially World War II. Aircraft design began specializing, primarily into two types: bombers, which carried explosive payloads to bomb land targets or ships; and fighter-interceptors, which were used to either intercept incoming aircraft or to escort and protect bombers (engagements between fighter aircraft were known as dog fights). Some of the more notable aerial battles in this period include the Battle of Britain and the Battle of Midway. Another important use of aircraft came with the development of the helicopter, which first became heavily used during the Vietnam War, and still continues to be widely used today to transport and augment ground forces. Today, direct engagements between aircraft are rare \u2013 the most modern fighter-interceptors carry much more extensive bombing payloads, and are used to bomb precision land targets, rather than to fight other aircraft. Anti-aircraft batteries are used much more extensively to defend against incoming aircraft than interceptors. Despite this, aircraft today are much more extensively used as the primary tools for both army and navy, as evidenced by the prominent use of helicopters to transport and support troops, the use of aerial bombardment as the \"first strike\" in many engagements, and the replacement of the battleship with the aircraft carrier as the center of most modern navies.\nNaming.\nBattles are usually named after some feature of the battlefield geography, such as a town, forest or river, commonly prefixed \"Battle of...\". Occasionally battles are named after the date on which they took place, such as The Glorious First of June. In the Middle Ages it was considered important to settle on a suitable name for a battle which could be used by the chroniclers. After Henry V of England defeated a French army on October 25, 1415, he met with the senior French herald and they agreed to name the battle after the nearby castle and so it was called the Battle of Agincourt. In other cases, the sides adopted different names for the same battle, such as the Battle of Gallipoli which is known in Turkey as the Battle of \u00c7anakkale. During the American Civil War, the Union tended to name the battles after the nearest watercourse, such as the Battle of Wilsons Creek and the Battle of Stones River, whereas the Confederates favoured the nearby towns, as in the Battles of Chancellorsville and Murfreesboro. Occasionally both names for the same battle entered the popular culture, such as the First Battle of Bull Run and the Second Battle of Bull Run, which are also referred to as the First and Second Battles of Manassas.\nSometimes in desert warfare, there is no nearby town name to use; map coordinates gave the name to the Battle of 73 Easting in the First Gulf War. Some place names have become synonymous with battles, such as the Passchendaele, Pearl Harbor, the Alamo, Thermopylae and Waterloo. Military operations, many of which result in battle, are given codenames, which are not necessarily meaningful or indicative of the type or the location of the battle. Operation Market Garden and Operation Rolling Thunder are examples of battles known by their military codenames. When a battleground is the site of more than one battle in the same conflict, the instances are distinguished by ordinal number, such as the First and Second Battles of Bull Run. An extreme case are the twelve Battles of the Isonzo\u2014First to Twelfth\u2014between Italy and Austria-Hungary during the First World War.\nSome battles are named for the convenience of military historians so that periods of combat can be neatly distinguished from one another. Following the First World War, the British Battles Nomenclature Committee was formed to decide on standard names for all battles and subsidiary actions. To the soldiers who did the fighting, the distinction was usually academic; a soldier fighting at Beaumont Hamel on November 13, 1916, was probably unaware he was taking part in what the committee named the Battle of the Ancre. Many combats are too small to be battles; terms such as \"action\", \"affair\", \"skirmish\", \"firefight\", \"raid\", or \"offensive patrol\" are used to describe small military encounters. These combats often take place within the time and space of a battle and while they may have an objective, they are not necessarily \"decisive\". Sometimes the soldiers are unable to immediately gauge the significance of the combat; in the aftermath of the Battle of Waterloo, some British officers were in doubt as to whether the day's events merited the title of \"battle\" or would be called an \"action\".\nEffects.\nBattles affect the individuals who take part, as well as the political actors. Personal effects of battle range from mild psychological issues to permanent and crippling injuries. Some battle-survivors have nightmares about the conditions they encountered or abnormal reactions to certain sights or sounds and some experience flashbacks. Physical effects of battle can include scars, amputations, lesions, loss of bodily functions, blindness, paralysis and death. Battles affect politics; a decisive battle can cause the losing side to surrender, while a Pyrrhic victory such as the Battle of Asculum can cause the winning side to reconsider its goals. Battles in civil wars have often decided the fate of monarchs or political factions. Famous examples include the Wars of the Roses, as well as the Jacobite risings. Battles affect the commitment of one side or the other to the continuance of a war, for example the Battle of Inchon and the Battle of Hu\u1ebf during the Tet Offensive."}
{"id": "4182", "revid": "24473539", "url": "https://en.wikipedia.org/wiki?curid=4182", "title": "Berry Berenson", "text": "Berinthia \"Berry\" Berenson-Perkins ( Berenson; April 14, 1948 \u2013 September 11, 2001) was an American actress, model and photographer. She was the widow of actor Anthony Perkins. She died in the September 11 attacks, being a passenger on American Airlines Flight 11.\nEarly life.\nBerry Berenson was born in Murray Hill, Manhattan, New York City. Her mother was born Maria-Luisa Yvonne Radha de Wendt de Kerlor, better known as Gogo Schiaparelli, a socialite of Italian, Swiss, &amp; French ancestry. Her father, Robert Lawrence Berenson, was an American career diplomat turned shipping executive. He was of Russian-Jewish and Polish-Jewish descent, and his family's original surname was \"Valvrojenski\".\nBerenson's maternal grandmother was the Italian-born fashion designer Elsa Schiaparelli, and her maternal grandfather was Wilhelm de Wendt de Kerlor, a Theosophist and psychic medium. Her elder sister, Marisa Berenson, became a well-known model and actress. She also was a great-grandniece of Giovanni Schiaparelli, an Italian astronomer who believed he had discovered canals on Mars, and a second cousin, once removed, of art expert Bernard Berenson (1865\u20131959), and his sister Senda Berenson (1868\u20131954), an athlete and educator who was one of the first two women elected to the Basketball Hall of Fame.\nCareer.\nFollowing a brief modeling career in the late 1960s, Berenson became a freelance photographer. In 1972, Berenson's fianc\u00e9 Richard Bernstein was hired as the cover artist for Andy Warhol's \"Interview\" magazine. Berenson would recruit models for the cover and photograph them, and Bernstein illustrated the images. By 1973, her photographs had been published in \"Life\", \"Glamour\", \"Vogue\" and \"Newsweek\".\nBerenson studied acting at New York's The American Place Theatre with Wynn Handman along with Richard Gere, Philip Anglim, Penelope Milford, Robert Ozn, Ingrid Boulting and her sister Marisa.\nAs an actress, Berenson starred opposite her husband Anthony Perkins in the 1978 Alan Rudolph film \"Remember My Name\". She also appeared with Jeff Bridges in the 1979 film \"Winter Kills\", and with Malcolm McDowell in \"Cat People\" (1982).\nPersonal life.\nBerenson was engaged to artist Richard Bernstein. In 1972, Berenson had an affair with actor Anthony Perkins and they married on August 9, 1973, in Wellfleet, Massachusetts while she was three months pregnant. The couple raised two sons: actor-director Oz Perkins and folk/rock singer-songwriter Elvis Perkins. Although Perkins was gay, they remained married until Perkins died from AIDS-related complications on September 12, 1992.\nDeath.\nBerenson died on September 11, 2001, a day before the ninth anniversary of Perkins\u2019 death, as she was returning home to Los Angeles from a vacation on Cape Cod. She and the other passengers and crew aboard American Airlines Flight 11 died when the plane was hijacked and deliberately crashed into the North Tower of the World Trade Center during the September 11 attacks on the US.\nAt the National September 11 Memorial &amp; Museum, Berenson's name is inscribed on Panel N-76 at the North Pool."}
{"id": "4183", "revid": "2927383", "url": "https://en.wikipedia.org/wiki?curid=4183", "title": "Botany", "text": "Botany, also called plant science or phytology, is the branch of natural science and biology studying plants, especially their anatomy, taxonomy, and ecology. A botanist, plant scientist or phytologist is a scientist who specialises in this field. Nowadays, botanists (in the strict sense) study approximately 410,000 species of land plants, including some 391,000 species of vascular plants (of which approximately 369,000 are flowering plants) and approximately 20,000 bryophytes.\nBotany originated in prehistory as herbalism with the efforts of early humans to identify \u2013 and later cultivate \u2013 plants that were edible, poisonous, and possibly medicinal, making it one of the first endeavours of human investigation. Medieval physic gardens, often attached to monasteries, contained plants possibly having medicinal benefit. They were forerunners of the first botanical gardens attached to universities, founded from the 1540s onwards. One of the earliest was the Padua botanical garden. These gardens facilitated the academic study of plants. Efforts to catalogue and describe their collections were the beginnings of plant taxonomy and led in 1753 to the binomial system of nomenclature of Carl Linnaeus that remains in use to this day for the naming of all biological species.\nIn the 19th and 20th centuries, new techniques were developed for the study of plants, including methods of optical microscopy and live cell imaging, electron microscopy, analysis of chromosome number, plant chemistry and the structure and function of enzymes and other proteins. In the last two decades of the 20th century, botanists exploited the techniques of molecular genetic analysis, including genomics and proteomics and DNA sequences to classify plants more accurately.\nModern botany is a broad subject with contributions and insights from most other areas of science and technology. Research topics include the study of plant structure, growth and differentiation, reproduction, biochemistry and primary metabolism, chemical products, development, diseases, evolutionary relationships, systematics, and plant taxonomy. Dominant themes in 21st-century plant science are molecular genetics and epigenetics, which study the mechanisms and control of gene expression during differentiation of plant cells and tissues. Botanical research has diverse applications in providing staple foods, materials such as timber, oil, rubber, fibre and drugs, in modern horticulture, agriculture and forestry, plant propagation, breeding and genetic modification, in the synthesis of chemicals and raw materials for construction and energy production, in environmental management, and the maintenance of biodiversity.\nEtymology.\nThe term \"botany\" comes from the Ancient Greek word ' () meaning \"pasture\", \"herbs\" \"grass\", or \"fodder\"; ' is in turn derived from \"\" (Greek: ), \"to feed\" or \"to graze\". Traditionally, botany has also included the study of fungi and algae by mycologists and phycologists respectively, with the study of these three groups of organisms remaining within the sphere of interest of the International Botanical Congress.\nHistory.\nEarly botany.\nBotany originated as herbalism, the study and use of plants for their possible medicinal properties. The early recorded history of botany includes many ancient writings and plant classifications. Examples of early botanical works have been found in ancient texts from India dating back to before 1100 BCE, Ancient Egypt, in archaic Avestan writings, and in works from China purportedly from before 221 BCE.\nModern botany traces its roots back to Ancient Greece specifically to Theophrastus (\u2013287 BCE), a student of Aristotle who invented and described many of its principles and is widely regarded in the scientific community as the \"Father of Botany\". His major works, \"Enquiry into Plants\" and \"On the Causes of Plants\", constitute the most important contributions to botanical science until the Middle Ages, almost seventeen centuries later.\nAnother work from Ancient Greece that made an early impact on botany is , a five-volume encyclopedia about preliminary herbal medicine written in the middle of the first century by Greek physician and pharmacologist Pedanius Dioscorides. was widely read for more than 1,500 years. Important contributions from the medieval Muslim world include Ibn Wahshiyya's \"Nabatean Agriculture\", Ab\u016b \u1e24an\u012bfa D\u012bnawar\u012b's (828\u2013896) the \"Book of Plants\", and Ibn Bassal's \"The Classification of Soils\". In the early 13th century, Abu al-Abbas al-Nabati, and Ibn al-Baitar (d. 1248) wrote on botany in a systematic and scientific manner.\nIn the mid-16th century, botanical gardens were founded in a number of Italian universities. The Padua botanical garden in 1545 is usually considered to be the first which is still in its original location. These gardens continued the practical value of earlier \"physic gardens\", often associated with monasteries, in which plants were cultivated for suspected medicinal uses. They supported the growth of botany as an academic subject. Lectures were given about the plants grown in the gardens. Botanical gardens came much later to northern Europe; the first in England was the University of Oxford Botanic Garden in 1621.\nGerman physician Leonhart Fuchs (1501\u20131566) was one of \"the three German fathers of botany\", along with theologian Otto Brunfels (1489\u20131534) and physician Hieronymus Bock (1498\u20131554) (also called Hieronymus Tragus). Fuchs and Brunfels broke away from the tradition of copying earlier works to make original observations of their own. Bock created his own system of plant classification.\nPhysician Valerius Cordus (1515\u20131544) authored a botanically and pharmacologically important herbal \"Historia Plantarum\" in 1544 and a pharmacopoeia of lasting importance, the \"Dispensatorium\" in 1546. Naturalist Conrad von Gesner (1516\u20131565) and herbalist John Gerard (1545\u2013) published herbals covering the supposed medicinal uses of plants. Naturalist Ulisse Aldrovandi (1522\u20131605) was considered the \"father of natural history\", which included the study of plants. In 1665, using an early microscope, Polymath Robert Hooke discovered cells (a term he coined) in cork, and a short time later in living plant tissue.\nEarly modern botany.\nDuring the 18th century, systems of plant identification were developed comparable to dichotomous keys, where unidentified plants are placed into taxonomic groups (e.g. family, genus and species) by making a series of choices between pairs of characters. The choice and sequence of the characters may be artificial in keys designed purely for identification (diagnostic keys) or more closely related to the natural or phyletic order of the taxa in synoptic keys. By the 18th century, new plants for study were arriving in Europe in increasing numbers from newly discovered countries and the European colonies worldwide. In 1753, Carl Linnaeus published his Species Plantarum, a hierarchical classification of plant species that remains the reference point for modern botanical nomenclature. This established a standardised binomial or two-part naming scheme where the first name represented the genus and the second identified the species within the genus. For the purposes of identification, Linnaeus's \"Systema Sexuale\" classified plants into 24 groups according to the number of their male sexual organs. The 24th group, \"Cryptogamia\", included all plants with concealed reproductive parts, mosses, liverworts, ferns, algae and fungi.\nIncreasing knowledge of plant anatomy, morphology and life cycles led to the realisation that there were more natural affinities between plants than the artificial sexual system of Linnaeus. Adanson (1763), de Jussieu (1789), and Candolle (1819) all proposed various alternative natural systems of classification that grouped plants using a wider range of shared characters and were widely followed. The Candollean system reflected his ideas of the progression of morphological complexity and the later Bentham &amp; Hooker system, which was influential until the mid-19th century, was influenced by Candolle's approach. Darwin's publication of the \"Origin of Species\" in 1859 and his concept of common descent required modifications to the Candollean system to reflect evolutionary relationships as distinct from mere morphological similarity.\nIn the 19th century botany was a socially acceptable hobby for upper-class women. These women would collect and paint flowers and plants from around the world with scientific accuracy. The paintings were used to record many species that could not be transported or maintained in other environments. Marianne North illustrated over 900 species in extreme detail with watercolor and oil paintings. Her work and many other women's botany work was the beginning of popularizing botany to a wider audience.\nBotany was greatly stimulated by the appearance of the first \"modern\" textbook, Matthias Schleiden's \"\", published in English in 1849 as \"Principles of Scientific Botany\". Schleiden was a microscopist and an early plant anatomist who co-founded the cell theory with Theodor Schwann and Rudolf Virchow and was among the first to grasp the significance of the cell nucleus that had been described by Robert Brown in 1831. In 1855, Adolf Fick formulated Fick's laws that enabled the calculation of the rates of molecular diffusion in biological systems.\nLate modern botany.\nBuilding upon the gene-chromosome theory of heredity that originated with Gregor Mendel (1822\u20131884), August Weismann (1834\u20131914) proved that inheritance only takes place through gametes. No other cells can pass on inherited characters. The work of Katherine Esau (1898\u20131997) on plant anatomy is still a major foundation of modern botany. Her books \"Plant Anatomy\" and \"Anatomy of Seed Plants\" have been key plant structural biology texts for more than half a century.\nThe discipline of plant ecology was pioneered in the late 19th century by botanists such as Eugenius Warming, who produced the hypothesis that plants form communities, and his mentor and successor Christen C. Raunki\u00e6r whose system for describing plant life forms is still in use today. The concept that the composition of plant communities such as temperate broadleaf forest changes by a process of ecological succession was developed by Henry Chandler Cowles, Arthur Tansley and Frederic Clements. Clements is credited with the idea of climax vegetation as the most complex vegetation that an environment can support and Tansley introduced the concept of ecosystems to biology. Building on the extensive earlier work of Alphonse de Candolle, Nikolai Vavilov (1887\u20131943) produced accounts of the biogeography, centres of origin, and evolutionary history of economic plants.\nParticularly since the mid-1960s there have been advances in understanding of the physics of plant physiological processes such as transpiration (the transport of water within plant tissues), the temperature dependence of rates of water evaporation from the leaf surface and the molecular diffusion of water vapour and carbon dioxide through stomatal apertures. These developments, coupled with new methods for measuring the size of stomatal apertures, and the rate of photosynthesis have enabled precise description of the rates of gas exchange between plants and the atmosphere. Innovations in statistical analysis by Ronald Fisher, Frank Yates and others at Rothamsted Experimental Station facilitated rational experimental design and data analysis in botanical research. The discovery and identification of the auxin plant hormones by Kenneth V. Thimann in 1948 enabled regulation of plant growth by externally applied chemicals. Frederick Campion Steward pioneered techniques of micropropagation and plant tissue culture controlled by plant hormones. The synthetic auxin 2,4-dichlorophenoxyacetic acid or 2,4-D was one of the first commercial synthetic herbicides.\n20th century developments in plant biochemistry have been driven by modern techniques of organic chemical analysis, such as spectroscopy, chromatography and electrophoresis. With the rise of the related molecular-scale biological approaches of molecular biology, genomics, proteomics and metabolomics, the relationship between the plant genome and most aspects of the biochemistry, physiology, morphology and behaviour of plants can be subjected to detailed experimental analysis. The concept originally stated by Gottlieb Haberlandt in 1902 that all plant cells are totipotent and can be grown \"in vitro\" ultimately enabled the use of genetic engineering experimentally to knock out a gene or genes responsible for a specific trait, or to add genes such as GFP that report when a gene of interest is being expressed. These technologies enable the biotechnological use of whole plants or plant cell cultures grown in bioreactors to synthesise pesticides, antibiotics or other pharmaceuticals, as well as the practical application of genetically modified crops designed for traits such as improved yield.\nModern morphology recognises a continuum between the major morphological categories of root, stem (caulome), leaf (phyllome) and trichome. Furthermore, it emphasises structural dynamics. Modern systematics aims to reflect and discover phylogenetic relationships between plants. Modern Molecular phylogenetics largely ignores morphological characters, relying on DNA sequences as data. Molecular analysis of DNA sequences from most families of flowering plants enabled the Angiosperm Phylogeny Group to publish in 1998 a phylogeny of flowering plants, answering many of the questions about relationships among angiosperm families and species. The theoretical possibility of a practical method for identification of plant species and commercial varieties by DNA barcoding is the subject of active current research.\nBranches of botany.\nBotany is divided along several axes.\nSome subfields of botany relate to particular groups of organisms. Divisions related to the broader historical sense of botany include bacteriology, mycology (or fungology) and phycology - the study of bacteria, fungi and algae respectively - with lichenology as a subfield of mycology. The narrower sense of botany in the sense of the study of embryophytes (land plants) is disambiguated as phytology. Bryology is the study of mosses (and in the broader sense also liverworts and hornworts). Pteridology (or filicology) is the study of ferns and allied plants. A number of other taxa of ranks varying from family to subgenus have terms for their study, including agrostology (or graminology) for the study of grasses, synantherology for the study of composites, and batology for the study of brambles.\nStudy can also be divided by guild rather than clade or grade. Dendrology is the study of woody plants.\nMany divisions of biology have botanical subfields. These are commonly denoted by prefixing the word plant (e.g. plant taxonomy, plant ecology, plant anatomy, plant morphology, plant systematics, plant ecology), or prefixing or substituting the prefix phyto- (e.g. phytochemistry, phytogeography). The study of fossil plants is palaeobotany. Other fields are denoted by adding or substituting the word botany (e.g. systematic botany).\nPhytosociology is a subfield of plant ecology that classifies and studies communities of plants.\nThe intersection of fields from the above pair of categories gives rise to fields such as bryogeography (the study of the distribution of mosses).\nDifferent parts of plants also give rise to their own subfields, including xylology, carpology (or fructology) and palynology, these being the study of wood, fruit and pollen/spores respectively.\nBotany also overlaps on the one hand with agriculture, horticulture and silviculture, and on the other hand with medicine and pharmacology, giving rise to fields such as agronomy, horticultural botany, phytopathology and phytopharmacology.\nScope and importance.\nThe study of plants is vital because they underpin almost all animal life on Earth by generating a large proportion of the oxygen and food that provide humans and other organisms with aerobic respiration with the chemical energy they need to exist. Plants, algae and cyanobacteria are the major groups of organisms that carry out photosynthesis, a process that uses the energy of sunlight to convert water and carbon dioxide into sugars that can be used both as a source of chemical energy and of organic molecules that are used in the structural components of cells. As a by-product of photosynthesis, plants release oxygen into the atmosphere, a gas that is required by nearly all living things to carry out cellular respiration. In addition, they are influential in the global carbon and water cycles and plant roots bind and stabilise soils, preventing soil erosion. Plants are crucial to the future of human society as they provide food, oxygen, biochemicals, and products for people, as well as creating and preserving soil.\nHistorically, all living things were classified as either animals or plants and botany covered the study of all organisms not considered animals. Botanists examine both the internal functions and processes within plant organelles, cells, tissues, whole plants, plant populations and plant communities. At each of these levels, a botanist may be concerned with the classification (taxonomy), phylogeny and evolution, structure (anatomy and morphology), or function (physiology) of plant life.\nThe strictest definition of \"plant\" includes only the \"land plants\" or embryophytes, which include seed plants (gymnosperms, including the pines, and flowering plants) and the free-sporing cryptogams including ferns, clubmosses, liverworts, hornworts and mosses. Embryophytes are multicellular eukaryotes descended from an ancestor that obtained its energy from sunlight by photosynthesis. They have life cycles with alternating haploid and diploid phases. The sexual haploid phase of embryophytes, known as the gametophyte, nurtures the developing diploid embryo sporophyte within its tissues for at least part of its life, even in the seed plants, where the gametophyte itself is nurtured by its parent sporophyte. Other groups of organisms that were previously studied by botanists include bacteria (now studied in bacteriology), fungi (mycology) \u2013 including lichen-forming fungi (lichenology), non-chlorophyte algae (phycology), and viruses (virology). However, attention is still given to these groups by botanists, and fungi (including lichens) and photosynthetic protists are usually covered in introductory botany courses.\nPalaeobotanists study ancient plants in the fossil record to provide information about the evolutionary history of plants. Cyanobacteria, the first oxygen-releasing photosynthetic organisms on Earth, are thought to have given rise to the ancestor of plants by entering into an endosymbiotic relationship with an early eukaryote, ultimately becoming the chloroplasts in plant cells. The new photosynthetic plants (along with their algal relatives) accelerated the rise in atmospheric oxygen started by the cyanobacteria, changing the ancient oxygen-free, reducing, atmosphere to one in which free oxygen has been abundant for more than 2 billion years.\nAmong the important botanical questions of the 21st century are the role of plants as primary producers in the global cycling of life's basic ingredients: energy, carbon, oxygen, nitrogen and water, and ways that our plant stewardship can help address the global environmental issues of resource management, conservation, human food security, biologically invasive organisms, carbon sequestration, climate change, and sustainability.\nHuman nutrition.\nVirtually all staple foods come either directly from primary production by plants, or indirectly from animals that eat them. Plants and other photosynthetic organisms are at the base of most food chains because they use the energy from the sun and nutrients from the soil and atmosphere, converting them into a form that can be used by animals. This is what ecologists call the first trophic level. The modern forms of the major staple foods, such as hemp, teff, maize, rice, wheat and other cereal grasses, pulses, bananas and plantains, as well as hemp, flax and cotton grown for their fibres, are the outcome of prehistoric selection over thousands of years from among wild ancestral plants with the most desirable characteristics.\nBotanists study how plants produce food and how to increase yields, for example through plant breeding, making their work important to humanity's ability to feed the world and provide food security for future generations. Botanists also study weeds, which are a considerable problem in agriculture, and the biology and control of plant pathogens in agriculture and natural ecosystems. Ethnobotany is the study of the relationships between plants and people. When applied to the investigation of historical plant\u2013people relationships ethnobotany may be referred to as archaeobotany or palaeoethnobotany. Some of the earliest plant-people relationships arose between the indigenous people of Canada in identifying edible plants from inedible plants. This relationship the indigenous people had with plants was recorded by ethnobotanists.\nPlant biochemistry.\nPlant biochemistry is the study of the chemical processes used by plants. Some of these processes are used in their primary metabolism like the photosynthetic Calvin cycle and crassulacean acid metabolism. Others make specialised materials like the cellulose and lignin used to build their bodies, and secondary products like resins and aroma compounds.\nPlants and various other groups of photosynthetic eukaryotes collectively known as \"algae\" have unique organelles known as chloroplasts. Chloroplasts are thought to be descended from cyanobacteria that formed endosymbiotic relationships with ancient plant and algal ancestors. Chloroplasts and cyanobacteria contain the blue-green pigment chlorophyll \"a\". Chlorophyll \"a\" (as well as its plant and green algal-specific cousin chlorophyll \"b\") absorbs light in the blue-violet and orange/red parts of the spectrum while reflecting and transmitting the green light that we see as the characteristic colour of these organisms. The energy in the red and blue light that these pigments absorb is used by chloroplasts to make energy-rich carbon compounds from carbon dioxide and water by oxygenic photosynthesis, a process that generates molecular oxygen (O2) as a by-product.\nThe light energy captured by chlorophyll \"a\" is initially in the form of electrons (and later a proton gradient) that's used to make molecules of ATP and NADPH which temporarily store and transport energy. Their energy is used in the light-independent reactions of the Calvin cycle by the enzyme rubisco to produce molecules of the 3-carbon sugar glyceraldehyde 3-phosphate (G3P). Glyceraldehyde 3-phosphate is the first product of photosynthesis and the raw material from which glucose and almost all other organic molecules of biological origin are synthesised. Some of the glucose is converted to starch which is stored in the chloroplast. Starch is the characteristic energy store of most land plants and algae, while inulin, a polymer of fructose is used for the same purpose in the sunflower family Asteraceae. Some of the glucose is converted to sucrose (common table sugar) for export to the rest of the plant.\nUnlike in animals (which lack chloroplasts), plants and their eukaryote relatives have delegated many biochemical roles to their chloroplasts, including synthesising all their fatty acids, and most amino acids. The fatty acids that chloroplasts make are used for many things, such as providing material to build cell membranes out of and making the polymer cutin which is found in the plant cuticle that protects land plants from drying out. \nPlants synthesise a number of unique polymers like the polysaccharide molecules cellulose, pectin and xyloglucan from which the land plant cell wall is constructed.\nVascular land plants make lignin, a polymer used to strengthen the secondary cell walls of xylem tracheids and vessels to keep them from collapsing when a plant sucks water through them under water stress. Lignin is also used in other cell types like sclerenchyma fibres that provide structural support for a plant and is a major constituent of wood. Sporopollenin is a chemically resistant polymer found in the outer cell walls of spores and pollen of land plants responsible for the survival of early land plant spores and the pollen of seed plants in the fossil record. It is widely regarded as a marker for the start of land plant evolution during the Ordovician period.\nThe concentration of carbon dioxide in the atmosphere today is much lower than it was when plants emerged onto land during the Ordovician and Silurian periods. Many monocots like maize and the pineapple and some dicots like the Asteraceae have since independently evolved pathways like Crassulacean acid metabolism and the carbon fixation pathway for photosynthesis which avoid the losses resulting from photorespiration in the more common carbon fixation pathway. These biochemical strategies are unique to land plants.\nMedicine and materials.\nPhytochemistry is a branch of plant biochemistry primarily concerned with the chemical substances produced by plants during secondary metabolism. Some of these compounds are toxins such as the alkaloid coniine from hemlock. Others, such as the essential oils peppermint oil and lemon oil are useful for their aroma, as flavourings and spices (e.g., capsaicin), and in medicine as pharmaceuticals as in opium from opium poppies. Many medicinal and recreational drugs, such as tetrahydrocannabinol (active ingredient in cannabis), caffeine, morphine and nicotine come directly from plants. Others are simple derivatives of botanical natural products. For example, the pain killer aspirin is the acetyl ester of salicylic acid, originally isolated from the bark of willow trees, and a wide range of opiate painkillers like heroin are obtained by chemical modification of morphine obtained from the opium poppy. Popular stimulants come from plants, such as caffeine from coffee, tea and chocolate, and nicotine from tobacco. Most alcoholic beverages come from fermentation of carbohydrate-rich plant products such as barley (beer), rice (sake) and grapes (wine). Native Americans have used various plants as ways of treating illness or disease for thousands of years. This knowledge Native Americans have on plants has been recorded by enthnobotanists and then in turn has been used by pharmaceutical companies as a way of drug discovery.\nPlants can synthesise coloured dyes and pigments such as the anthocyanins responsible for the red colour of red wine, yellow weld and blue woad used together to produce Lincoln green, indoxyl, source of the blue dye indigo traditionally used to dye denim and the artist's pigments gamboge and rose madder.\nSugar, starch, cotton, linen, hemp, some types of rope, wood and particle boards, papyrus and paper, vegetable oils, wax, and natural rubber are examples of commercially important materials made from plant tissues or their secondary products. Charcoal, a pure form of carbon made by pyrolysis of wood, has a long history as a metal-smelting fuel, as a filter material and adsorbent and as an artist's material and is one of the three ingredients of gunpowder. Cellulose, the world's most abundant organic polymer, can be converted into energy, fuels, materials and chemical feedstock. Products made from cellulose include rayon and cellophane, wallpaper paste, biobutanol and gun cotton. Sugarcane, rapeseed and soy are some of the plants with a highly fermentable sugar or oil content that are used as sources of biofuels, important alternatives to fossil fuels, such as biodiesel. Sweetgrass was used by Native Americans to ward off bugs like mosquitoes. These bug repelling properties of sweetgrass were later found by the American Chemical Society in the molecules phytol and coumarin.\nPlant ecology.\nPlant ecology is the science of the functional relationships between plants and their habitats\u00a0\u2013 the environments where they complete their life cycles. Plant ecologists study the composition of local and regional floras, their biodiversity, genetic diversity and fitness, the adaptation of plants to their environment, and their competitive or mutualistic interactions with other species. Some ecologists even rely on empirical data from indigenous people that is gathered by ethnobotanists. This information can relay a great deal of information on how the land once was thousands of years ago and how it has changed over that time. The goals of plant ecology are to understand the causes of their distribution patterns, productivity, environmental impact, evolution, and responses to environmental change.\nPlants depend on certain edaphic (soil) and climatic factors in their environment but can modify these factors too. For example, they can change their environment's albedo, increase runoff interception, stabilise mineral soils and develop their organic content, and affect local temperature. Plants compete with other organisms in their ecosystem for resources. They interact with their neighbours at a variety of spatial scales in groups, populations and communities that collectively constitute vegetation. Regions with characteristic vegetation types and dominant plants as well as similar abiotic and biotic factors, climate, and geography make up biomes like tundra or tropical rainforest.\nHerbivores eat plants, but plants can defend themselves and some species are parasitic or even carnivorous. Other organisms form mutually beneficial relationships with plants. For example, mycorrhizal fungi and rhizobia provide plants with nutrients in exchange for food, ants are recruited by ant plants to provide protection, honey bees, bats and other animals pollinate flowers and humans and other animals act as dispersal vectors to spread spores and seeds.\nPlants, climate and environmental change.\nPlant responses to climate and other environmental changes can inform our understanding of how these changes affect ecosystem function and productivity. For example, plant phenology can be a useful proxy for temperature in historical climatology, and the biological impact of climate change and global warming. Palynology, the analysis of fossil pollen deposits in sediments from thousands or millions of years ago allows the reconstruction of past climates. Estimates of atmospheric concentrations since the Palaeozoic have been obtained from stomatal densities and the leaf shapes and sizes of ancient land plants. Ozone depletion can expose plants to higher levels of ultraviolet radiation-B (UV-B), resulting in lower growth rates. Moreover, information from studies of community ecology, plant systematics, and taxonomy is essential to understanding vegetation change, habitat destruction and species extinction.\nGenetics.\nInheritance in plants follows the same fundamental principles of genetics as in other multicellular organisms. Gregor Mendel discovered the genetic laws of inheritance by studying inherited traits such as shape in \"Pisum sativum\" (peas). What Mendel learned from studying plants has had far-reaching benefits outside of botany. Similarly, \"jumping genes\" were discovered by Barbara McClintock while she was studying maize. Nevertheless, there are some distinctive genetic differences between plants and other organisms.\nSpecies boundaries in plants may be weaker than in animals, and cross species hybrids are often possible. A familiar example is peppermint, \"Mentha\" \u00d7 \"piperita\", a sterile hybrid between \"Mentha aquatica\" and spearmint, \"Mentha spicata\". The many cultivated varieties of wheat are the result of multiple inter- and intra-specific crosses between wild species and their hybrids. Angiosperms with monoecious flowers often have self-incompatibility mechanisms that operate between the pollen and stigma so that the pollen either fails to reach the stigma or fails to germinate and produce male gametes. This is one of several methods used by plants to promote outcrossing. In many land plants the male and female gametes are produced by separate individuals. These species are said to be dioecious when referring to vascular plant sporophytes and dioicous when referring to bryophyte gametophytes.\nCharles Darwin in his 1878 book The Effects of Cross and Self-Fertilization in the Vegetable Kingdom at the start of chapter XII noted \"The first and most important of the conclusions which may be drawn from the observations given in this volume, is that generally cross-fertilisation is beneficial and self-fertilisation often injurious, at least with the plants on which I experimented.\" An important adaptive benefit of outcrossing is that it allows the masking of deleterious mutations in the genome of progeny. This beneficial effect is also known as hybrid vigor or heterosis. Once outcrossing is established, subsequent switching to inbreeding becomes disadvantageous since it allows expression of the previously masked deleterious recessive mutations, commonly referred to as inbreeding depression.\nUnlike in higher animals, where parthenogenesis is rare, asexual reproduction may occur in plants by several different mechanisms. The formation of stem tubers in potato is one example. Particularly in arctic or alpine habitats, where opportunities for fertilisation of flowers by animals are rare, plantlets or bulbs, may develop instead of flowers, replacing sexual reproduction with asexual reproduction and giving rise to clonal populations genetically identical to the parent. This is one of several types of apomixis that occur in plants. Apomixis can also happen in a seed, producing a seed that contains an embryo genetically identical to the parent.\nMost sexually reproducing organisms are diploid, with paired chromosomes, but doubling of their chromosome number may occur due to errors in cytokinesis. This can occur early in development to produce an autopolyploid or partly autopolyploid organism, or during normal processes of cellular differentiation to produce some cell types that are polyploid (endopolyploidy), or during gamete formation. An allopolyploid plant may result from a hybridisation event between two different species. Both autopolyploid and allopolyploid plants can often reproduce normally, but may be unable to cross-breed successfully with the parent population because there is a mismatch in chromosome numbers. These plants that are reproductively isolated from the parent species but live within the same geographical area, may be sufficiently successful to form a new species. Some otherwise sterile plant polyploids can still reproduce vegetatively or by seed apomixis, forming clonal populations of identical individuals. Durum wheat is a fertile tetraploid allopolyploid, while bread wheat is a fertile hexaploid. The commercial banana is an example of a sterile, seedless triploid hybrid. Common dandelion is a triploid that produces viable seeds by apomictic seed.\nAs in other eukaryotes, the inheritance of endosymbiotic organelles like mitochondria and chloroplasts in plants is non-Mendelian. Chloroplasts are inherited through the male parent in gymnosperms but often through the female parent in flowering plants.\nMolecular genetics.\nA considerable amount of new knowledge about plant function comes from studies of the molecular genetics of model plants such as the Thale cress, \"Arabidopsis thaliana\", a weedy species in the mustard family (Brassicaceae). The genome or hereditary information contained in the genes of this species is encoded by about 135 million base pairs of DNA, forming one of the smallest genomes among flowering plants. \"Arabidopsis\" was the first plant to have its genome sequenced, in 2000. The sequencing of some other relatively small genomes, of rice (\"Oryza sativa\") and \"Brachypodium distachyon\", has made them important model species for understanding the genetics, cellular and molecular biology of cereals, grasses and monocots generally.\nModel plants such as \"Arabidopsis thaliana\" are used for studying the molecular biology of plant cells and the chloroplast. Ideally, these organisms have small genomes that are well known or completely sequenced, small stature and short generation times. Corn has been used to study mechanisms of photosynthesis and phloem loading of sugar in plants. The single celled green alga \"Chlamydomonas reinhardtii\", while not an embryophyte itself, contains a green-pigmented chloroplast related to that of land plants, making it useful for study. A red alga \"Cyanidioschyzon merolae\" has also been used to study some basic chloroplast functions. Spinach, peas, soybeans and a moss \"Physcomitrella patens\" are commonly used to study plant cell biology.\n\"Agrobacterium tumefaciens\", a soil rhizosphere bacterium, can attach to plant cells and infect them with a callus-inducing Ti plasmid by horizontal gene transfer, causing a callus infection called crown gall disease. Schell and Van Montagu (1977) hypothesised that the Ti plasmid could be a natural vector for introducing the Nif gene responsible for nitrogen fixation in the root nodules of legumes and other plant species. Today, genetic modification of the Ti plasmid is one of the main techniques for introduction of transgenes to plants and the creation of genetically modified crops.\nEpigenetics.\nEpigenetics is the study of heritable changes in gene function that cannot be explained by changes in the underlying DNA sequence but cause the organism's genes to behave (or \"express themselves\") differently. One example of epigenetic change is the marking of the genes by DNA methylation which determines whether they will be expressed or not. Gene expression can also be controlled by repressor proteins that attach to silencer regions of the DNA and prevent that region of the DNA code from being expressed. Epigenetic marks may be added or removed from the DNA during programmed stages of development of the plant, and are responsible, for example, for the differences between anthers, petals and normal leaves, despite the fact that they all have the same underlying genetic code. Epigenetic changes may be temporary or may remain through successive cell divisions for the remainder of the cell's life. Some epigenetic changes have been shown to be heritable, while others are reset in the germ cells.\nEpigenetic changes in eukaryotic biology serve to regulate the process of cellular differentiation. During morphogenesis, totipotent stem cells become the various pluripotent cell lines of the embryo, which in turn become fully differentiated cells. A single fertilised egg cell, the zygote, gives rise to the many different plant cell types including parenchyma, xylem vessel elements, phloem sieve tubes, guard cells of the epidermis, etc. as it continues to divide. The process results from the epigenetic activation of some genes and inhibition of others.\nUnlike animals, many plant cells, particularly those of the parenchyma, do not terminally differentiate, remaining totipotent with the ability to give rise to a new individual plant. Exceptions include highly lignified cells, the sclerenchyma and xylem which are dead at maturity, and the phloem sieve tubes which lack nuclei. While plants use many of the same epigenetic mechanisms as animals, such as chromatin remodelling, an alternative hypothesis is that plants set their gene expression patterns using positional information from the environment and surrounding cells to determine their developmental fate.\nEpigenetic changes can lead to paramutations, which do not follow the Mendelian heritage rules. These epigenetic marks are carried from one generation to the next, with one allele inducing a change on the other.\nPlant evolution.\nThe chloroplasts of plants have a number of biochemical, structural and genetic similarities to cyanobacteria, (commonly but incorrectly known as \"blue-green algae\") and are thought to be derived from an ancient endosymbiotic relationship between an ancestral eukaryotic cell and a .\nThe algae are a polyphyletic group and are placed in various divisions, some more closely related to plants than others. There are many differences between them in features such as cell wall composition, biochemistry, pigmentation, chloroplast structure and nutrient reserves. The algal division Charophyta, sister to the green algal division Chlorophyta, is considered to contain the ancestor of true plants. The Charophyte class Charophyceae and the land plant sub-kingdom Embryophyta together form the monophyletic group or clade Streptophytina.\nNonvascular land plants are embryophytes that lack the vascular tissues xylem and phloem. They include mosses, liverworts and hornworts. Pteridophytic vascular plants with true xylem and phloem that reproduced by spores germinating into free-living gametophytes evolved during the Silurian period and diversified into several lineages during the late Silurian and early Devonian. Representatives of the lycopods have survived to the present day. By the end of the Devonian period, several groups, including the lycopods, sphenophylls and progymnosperms, had independently evolved \"megaspory\" \u2013 their spores were of two distinct sizes, larger megaspores and smaller microspores. Their reduced gametophytes developed from megaspores retained within the spore-producing organs (megasporangia) of the sporophyte, a condition known as endospory. Seeds consist of an endosporic megasporangium surrounded by one or two sheathing layers (integuments). The young sporophyte develops within the seed, which on germination splits to release it. The earliest known seed plants date from the latest Devonian Famennian stage. Following the evolution of the seed habit, seed plants diversified, giving rise to a number of now-extinct groups, including seed ferns, as well as the modern gymnosperms and angiosperms. Gymnosperms produce \"naked seeds\" not fully enclosed in an ovary; modern representatives include conifers, cycads, \"Ginkgo\", and Gnetales. Angiosperms produce seeds enclosed in a structure such as a carpel or an ovary. Ongoing research on the molecular phylogenetics of living plants appears to show that the angiosperms are a sister clade to the gymnosperms.\nPlant physiology.\nPlant physiology encompasses all the internal chemical and physical activities of plants associated with life. Chemicals obtained from the air, soil and water form the basis of all plant metabolism. The energy of sunlight, captured by oxygenic photosynthesis and released by cellular respiration, is the basis of almost all life. Photoautotrophs, including all green plants, algae and cyanobacteria gather energy directly from sunlight by photosynthesis. Heterotrophs including all animals, all fungi, all completely parasitic plants, and non-photosynthetic bacteria take in organic molecules produced by photoautotrophs and respire them or use them in the construction of cells and tissues. Respiration is the oxidation of carbon compounds by breaking them down into simpler structures to release the energy they contain, essentially the opposite of photosynthesis.\nMolecules are moved within plants by transport processes that operate at a variety of spatial scales. Subcellular transport of ions, electrons and molecules such as water and enzymes occurs across cell membranes. Minerals and water are transported from roots to other parts of the plant in the transpiration stream. Diffusion, osmosis, and active transport and mass flow are all different ways transport can occur. Examples of elements that plants need to transport are nitrogen, phosphorus, potassium, calcium, magnesium, and sulfur. In vascular plants, these elements are extracted from the soil as soluble ions by the roots and transported throughout the plant in the xylem. Most of the elements required for plant nutrition come from the chemical breakdown of soil minerals. Sucrose produced by photosynthesis is transported from the leaves to other parts of the plant in the phloem and plant hormones are transported by a variety of processes.\nPlant hormones.\nPlants are not passive, but respond to external signals such as light, touch, and injury by moving or growing towards or away from the stimulus, as appropriate. Tangible evidence of touch sensitivity is the almost instantaneous collapse of leaflets of \"Mimosa pudica\", the insect traps of Venus flytrap and bladderworts, and the pollinia of orchids.\nThe hypothesis that plant growth and development is coordinated by plant hormones or plant growth regulators first emerged in the late 19th century. Darwin experimented on the movements of plant shoots and roots towards light and gravity, and concluded \"It is hardly an exaggeration to say that the tip of the radicle . . acts like the brain of one of the lower animals . . directing the several movements\". About the same time, the role of auxins (from the Greek , to grow) in control of plant growth was first outlined by the Dutch scientist Frits Went. The first known auxin, indole-3-acetic acid (IAA), which promotes cell growth, was only isolated from plants about 50 years later. This compound mediates the tropic responses of shoots and roots towards light and gravity. The finding in 1939 that plant callus could be maintained in culture containing IAA, followed by the observation in 1947 that it could be induced to form roots and shoots by controlling the concentration of growth hormones were key steps in the development of plant biotechnology and genetic modification.\nCytokinins are a class of plant hormones named for their control of cell division (especially cytokinesis). The natural cytokinin zeatin was discovered in corn, \"Zea mays\", and is a derivative of the purine adenine. Zeatin is produced in roots and transported to shoots in the xylem where it promotes cell division, bud development, and the greening of chloroplasts. The gibberelins, such as gibberelic acid are diterpenes synthesised from acetyl CoA via the mevalonate pathway. They are involved in the promotion of germination and dormancy-breaking in seeds, in regulation of plant height by controlling stem elongation and the control of flowering. Abscisic acid (ABA) occurs in all land plants except liverworts, and is synthesised from carotenoids in the chloroplasts and other plastids. It inhibits cell division, promotes seed maturation, and dormancy, and promotes stomatal closure. It was so named because it was originally thought to control abscission. Ethylene is a gaseous hormone that is produced in all higher plant tissues from methionine. It is now known to be the hormone that stimulates or regulates fruit ripening and abscission, and it, or the synthetic growth regulator ethephon which is rapidly metabolised to produce ethylene, are used on industrial scale to promote ripening of cotton, pineapples and other climacteric crops.\nAnother class of phytohormones is the jasmonates, first isolated from the oil of \"Jasminum grandiflorum\" which regulates wound responses in plants by unblocking the expression of genes required in the systemic acquired resistance response to pathogen attack.\nIn addition to being the primary energy source for plants, light functions as a signalling device, providing information to the plant, such as how much sunlight the plant receives each day. This can result in adaptive changes in a process known as photomorphogenesis. Phytochromes are the photoreceptors in a plant that are sensitive to light.\nPlant anatomy and morphology.\nPlant anatomy is the study of the structure of plant cells and tissues, whereas plant morphology is the study of their external form.\nAll plants are multicellular eukaryotes, their DNA stored in nuclei. The characteristic features of plant cells that distinguish them from those of animals and fungi include a primary cell wall composed of the polysaccharides cellulose, hemicellulose and pectin, larger vacuoles than in animal cells and the presence of plastids with unique photosynthetic and biosynthetic functions as in the chloroplasts. Other plastids contain storage products such as starch (amyloplasts) or lipids (elaioplasts). Uniquely, streptophyte cells and those of the green algal order Trentepohliales divide by construction of a phragmoplast as a template for building a cell plate late in cell division.\nThe bodies of vascular plants including clubmosses, ferns and seed plants (gymnosperms and angiosperms) generally have aerial and subterranean subsystems. The shoots consist of stems bearing green photosynthesising leaves and reproductive structures. The underground vascularised roots bear root hairs at their tips and generally lack chlorophyll. Non-vascular plants, the liverworts, hornworts and mosses do not produce ground-penetrating vascular roots and most of the plant participates in photosynthesis. The sporophyte generation is nonphotosynthetic in liverworts but may be able to contribute part of its energy needs by photosynthesis in mosses and hornworts.\nThe root system and the shoot system are interdependent \u2013 the usually nonphotosynthetic root system depends on the shoot system for food, and the usually photosynthetic shoot system depends on water and minerals from the root system. Cells in each system are capable of creating cells of the other and producing adventitious shoots or roots. Stolons and tubers are examples of shoots that can grow roots. Roots that spread out close to the surface, such as those of willows, can produce shoots and ultimately new plants. In the event that one of the systems is lost, the other can often regrow it. In fact it is possible to grow an entire plant from a single leaf, as is the case with plants in \"Streptocarpus\" sect. \"Saintpaulia\", or even a single cell \u2013 which can dedifferentiate into a callus (a mass of unspecialised cells) that can grow into a new plant.\nIn vascular plants, the xylem and phloem are the conductive tissues that transport resources between shoots and roots. Roots are often adapted to store food such as sugars or starch, as in sugar beets and carrots.\nStems mainly provide support to the leaves and reproductive structures, but can store water in succulent plants such as cacti, food as in potato tubers, or reproduce vegetatively as in the stolons of strawberry plants or in the process of layering. Leaves gather sunlight and carry out photosynthesis. Large, flat, flexible, green leaves are called foliage leaves. Gymnosperms, such as conifers, cycads, \"Ginkgo\", and gnetophytes are seed-producing plants with open seeds. Angiosperms are seed-producing plants that produce flowers and have enclosed seeds. Woody plants, such as azaleas and oaks, undergo a secondary growth phase resulting in two additional types of tissues: wood (secondary xylem) and bark (secondary phloem and cork). All gymnosperms and many angiosperms are woody plants. Some plants reproduce sexually, some asexually, and some via both means.\nAlthough reference to major morphological categories such as root, stem, leaf, and trichome are useful, one has to keep in mind that these categories are linked through intermediate forms so that a continuum between the categories results. Furthermore, structures can be seen as processes, that is, process combinations.\nSystematic botany.\nSystematic botany is part of systematic biology, which is concerned with the range and diversity of organisms and their relationships, particularly as determined by their evolutionary history. It involves, or is related to, biological classification, scientific taxonomy and phylogenetics. Biological classification is the method by which botanists group organisms into categories such as genera or species. Biological classification is a form of scientific taxonomy. Modern taxonomy is rooted in the work of Carl Linnaeus, who grouped species according to shared physical characteristics. These groupings have since been revised to align better with the Darwinian principle of common descent \u2013 grouping organisms by ancestry rather than superficial characteristics. While scientists do not always agree on how to classify organisms, molecular phylogenetics, which uses DNA sequences as data, has driven many recent revisions along evolutionary lines and is likely to continue to do so. The dominant classification system is called Linnaean taxonomy. It includes ranks and binomial nomenclature. The nomenclature of botanical organisms is codified in the International Code of Nomenclature for algae, fungi, and plants (ICN) and administered by the International Botanical Congress.\nKingdom Plantae belongs to Domain Eukaryota and is broken down recursively until each species is separately classified. The order is: Kingdom; Phylum (or Division); Class; Order; Family; Genus (plural \"genera\"); Species. The scientific name of a plant represents its genus and its species within the genus, resulting in a single worldwide name for each organism. For example, the tiger lily is \"Lilium columbianum\". \"Lilium\" is the genus, and \"columbianum\" the specific epithet. The combination is the name of the species. When writing the scientific name of an organism, it is proper to capitalise the first letter in the genus and put all of the specific epithet in lowercase. Additionally, the entire term is ordinarily italicised (or underlined when italics are not available).\nThe evolutionary relationships and heredity of a group of organisms is called its phylogeny. Phylogenetic studies attempt to discover phylogenies. The basic approach is to use similarities based on shared inheritance to determine relationships. As an example, species of \"Pereskia\" are trees or bushes with prominent leaves. They do not obviously resemble a typical leafless cactus such as an \"Echinocactus\". However, both \"Pereskia\" and \"Echinocactus\" have spines produced from areoles (highly specialised pad-like structures) suggesting that the two genera are indeed related.\nJudging relationships based on shared characters requires care, since plants may resemble one another through convergent evolution in which characters have arisen independently. Some euphorbias have leafless, rounded bodies adapted to water conservation similar to those of globular cacti, but characters such as the structure of their flowers make it clear that the two groups are not closely related. The cladistic method takes a systematic approach to characters, distinguishing between those that carry no information about shared evolutionary history \u2013 such as those evolved separately in different groups (homoplasies) or those left over from ancestors (plesiomorphies) \u2013 and derived characters, which have been passed down from innovations in a shared ancestor (apomorphies). Only derived characters, such as the spine-producing areoles of cacti, provide evidence for descent from a common ancestor. The results of cladistic analyses are expressed as cladograms: tree-like diagrams showing the pattern of evolutionary branching and descent.\nFrom the 1990s onwards, the predominant approach to constructing phylogenies for living plants has been molecular phylogenetics, which uses molecular characters, particularly DNA sequences, rather than morphological characters like the presence or absence of spines and areoles. The difference is that the genetic code itself is used to decide evolutionary relationships, instead of being used indirectly via the characters it gives rise to. Clive Stace describes this as having \"direct access to the genetic basis of evolution.\" As a simple example, prior to the use of genetic evidence, fungi were thought either to be plants or to be more closely related to plants than animals. Genetic evidence suggests that the true evolutionary relationship of multicelled organisms is as shown in the cladogram below \u2013 fungi are more closely related to animals than to plants.\nIn 1998, the Angiosperm Phylogeny Group published a phylogeny for flowering plants based on an analysis of DNA sequences from most families of flowering plants. As a result of this work, many questions, such as which families represent the earliest branches of angiosperms, have now been answered. Investigating how plant species are related to each other allows botanists to better understand the process of evolution in plants. Despite the study of model plants and increasing use of DNA evidence, there is ongoing work and discussion among taxonomists about how best to classify plants into various taxa. Technological developments such as computers and electron microscopes have greatly increased the level of detail studied and speed at which data can be analysed.\nSymbols.\nA few symbols are in current use in botany. A number of others are obsolete; for example, Linnaeus used planetary symbols (Mars) for biennial plants, (Jupiter) for herbaceous perennials and (Saturn) for woody perennials, based on the planets' orbital periods of 2, 12 and 30 years; and Willd used (Saturn) for neuter in addition to (Mercury) for hermaphroditic. The following symbols are still used:"}
{"id": "4184", "revid": "43408364", "url": "https://en.wikipedia.org/wiki?curid=4184", "title": "Bacillus thuringiensis", "text": "Bacillus thuringiensis (or Bt) is a gram-positive, soil-dwelling bacterium, the most commonly used biological pesticide worldwide. \"B. thuringiensis\" also occurs naturally in the gut of caterpillars of various types of moths and butterflies, as well on leaf surfaces, aquatic environments, animal feces, insect-rich environments, flour mills and grain-storage facilities. It has also been observed to parasitize moths such as \"Cadra calidella\"\u2014in laboratory experiments working with \"C. calidella\", many of the moths were diseased due to this parasite.\nDuring sporulation, many Bt strains produce crystal proteins (proteinaceous inclusions), called delta endotoxins, that have insecticidal action. This has led to their use as insecticides, and more recently to genetically modified crops using Bt genes, such as Bt corn. Many crystal-producing Bt strains, though, do not have insecticidal properties. The subspecies \"israelensis\" is commonly used for control of mosquitoes and of fungus gnats.\nAs a toxic mechanism, \"cry\" proteins bind to specific receptors on the membranes of mid-gut (epithelial) cells of the targeted pests, resulting in their rupture. Other organisms (including humans, other animals and non-targeted insects) that lack the appropriate receptors in their gut cannot be affected by the \"cry\" protein, and therefore are not affected by Bt.\nTaxonomy and discovery.\nIn 1902, \"B. thuringiensis\" was first discovered in silkworms by Japanese sericultural engineer . He named it \"B. sotto\", using the Japanese word , here referring to bacillary paralysis. In 1911, German microbiologist Ernst Berliner rediscovered it when he isolated it as the cause of a disease called \"\" in flour moth caterpillars in Thuringia (hence the specific name \"thuringiensis\", \"Thuringian\"). \"B. sotto\" would later be reassigned as \"B. thuringiensis\" var. \"sotto\".\nIn 1976, Robert A. Zakharyan reported the presence of a plasmid in a strain of \"B. thuringiensis\" and suggested the plasmid's involvement in endospore and crystal formation. \"B. thuringiensis\" is closely related to \"B. cereus\", a soil bacterium, and \"B. anthracis\", the cause of anthrax; the three organisms differ mainly in their plasmids. Like other members of the genus, all three are capable of producing endospores.\nSpecies group placement.\n\"B. thuringiensis\" is placed in the \"Bacillus cereus\" group which is variously defined as: seven closely related species: \"B.\u00a0cereus\" \"sensu stricto\" (\"B.\u00a0cereus\"), \"B.\u00a0anthracis\", \"B.\u00a0thuringiensis\", \"B. mycoides\", \"B. pseudomycoides\", and \"B.\u00a0cytotoxicus\"; or as six species in a \"Bacillus cereus\" sensu lato: \"B. weihenstephanensis\", \"B. mycoides\", \"B. pseudomycoides\", \"B. cereus\", \"B. thuringiensis\", and \"B. anthracis\". Within this grouping \"B.t.\" is more closely related to \"B.ce.\" It is more distantly related to \"B.w.\", \"B.m.\", \"B.p.\", and \"B.cy.\"\nSubspecies.\nThere are several dozen recognized subspecies of \"B. thuringiensis\". Subspecies commonly used as insecticides include \"B. thuringiensis\" subspecies \"kurstaki\" (Btk), subspecies \"israelensis\" (Bti) and (Bta). Some Bti lineages are clonal.\nGenetics.\nSome strains are known to carry the same genes that produce enterotoxins in \"B. cereus\", and so it is possible that the entire \"B. cereus\" sensu lato group may have the potential to be enteropathogens.\nThe proteins that \"B. thuringiensis\" is most known for are encoded by \"cry\" genes. In most strains of \"B. thuringiensis\", these genes are located on a plasmid (in other words \"cry\" is not a chromosomal gene in most strains). If these plasmids are lost it becomes indistinguishable from \"B. cereus\" as \"B. thuringiensis\" has no other species characteristics. Plasmid exchange has been observed both naturally and experimentally both within \"B.t.\" and between \"B.t.\" and two congeners, \"B. cereus\" and \"B. mycoides\".\nplcR is an indispensable transcription regulator of most virulence factors, its absence greatly reducing virulence and toxicity. Some strains do naturally complete their life cycle with an inactivated plcR. It is half of a two-gene operon along with the heptapeptide . papR is part of quorum sensing in \"B. thuringiensis\".\nVarious strains including \"Btk\" ATCC 33679 carry plasmids belonging to the wider pXO1-like family. (The pXO1 family being a \"B. cereus\"-common family with members of \u2248330kb length. They differ from pXO1 by replacement of the pXO1 pathogenicity island.) The insect parasite \"Btk\" HD73 carries a pXO2-like plasmid (pBT9727) lacking the 35kb pathogenicity island of pXO2 itself, and in fact having no identifiable virulence factors. (The pXO2 family does not have replacement of the pathogenicity island, instead simply lacking that part of pXO2.)\nThe genomes of the \"B. cereus\" group may contain two types of introns, dubbed group I and group II. \"B.t\" strains have variously 0\u20135 group Is and 0\u201313 group IIs.\nThere is still insufficient information to determine whether chromosome-plasmid coevolution to enable adaptation to particular environmental niches has occurred or is even possible.\nCommon with \"B. cereus\" but so far not found elsewhere \u2013 including in other members of the species group \u2013 are the efflux pump BC3663, the \"N\"-acyl--amino-acid amidohydrolase BC3664, and the methyl-accepting chemotaxis protein BC5034.\nProteome.\nIt has a similar proteome diversity to its close relative \"B. cereus\".\nInto the BT Cotton protein is 'Crystal protein'.\nMechanism of insecticidal action.\nUpon sporulation, \"B. thuringiensis\" forms crystals of two types of proteinaceous insecticidal delta endotoxins (\u03b4-endotoxins) called crystal proteins or Cry proteins, which are encoded by \"cry\" genes, and Cyt proteins.\nCry toxins have specific activities against insect species of the orders Lepidoptera (moths and butterflies), Diptera (flies and mosquitoes), Coleoptera (beetles) and Hymenoptera (wasps, bees, ants and sawflies), as well as against nematodes. A specific example of \"B. thuringiensis\" use against beetles is the fight against Colorado Potato Beetles in potato crops. Thus, \"B. thuringiensis\" serves as an important reservoir of Cry toxins for production of biological insecticides and insect-resistant genetically modified crops. When insects ingest toxin crystals, their alkaline digestive tracts denature the insoluble crystals, making them soluble and thus amenable to being cut with proteases found in the insect gut, which liberate the toxin from the crystal. The Cry toxin is then inserted into the insect gut cell membrane, paralyzing the digestive tract and forming a pore. The insect stops eating and starves to death; live Bt bacteria may also colonize the insect, which can contribute to death. Death occurs within a few hours or weeks. The midgut bacteria of susceptible larvae may be required for \"B. thuringiensis\" insecticidal activity.\nA \"B. thuringiensis\" small RNA called BtsR1 can silence the Cry5Ba toxin expression when outside the host by binding to the RBS site of the Cry5Ba toxin transcript to avoid nematode behavioral defenses. The silencing results in an increase of the bacteria ingestion by \"C. elegans\". The expression of BtsR1 is then reduced after ingestion, resulting in Cry5Ba toxin production and host death.\nIn 1996 another class of insecticidal proteins in Bt was discovered: the vegetative insecticidal proteins (Vip; ). Vip proteins do not share sequence homology with Cry proteins, in general do not compete for the same receptors, and some kill different insects than do Cry proteins.\nIn 2000, a novel subgroup of Cry protein, designated parasporin, was discovered from non-insecticidal \"B. thuringiensis\" isolates. The proteins of parasporin group are defined as \"B. thuringiensis\" and related bacterial parasporal proteins that are not hemolytic, but capable of preferentially killing cancer cells. As of January 2013, parasporins comprise six subfamilies: PS1 to PS6.\nUse of spores and proteins in pest control.\nSpores and crystalline insecticidal proteins produced by \"B. thuringiensis\" have been used to control insect pests since the 1920s and are often applied as liquid sprays. They are now used as specific insecticides under trade names such as DiPel and Thuricide. Because of their specificity, these pesticides are regarded as environmentally friendly, with little or no effect on humans, wildlife, pollinators, and most other beneficial insects, and are used in organic farming; however, the manuals for these products do contain many environmental and human health warnings, and a 2012 European regulatory peer review of five approved strains found, while data exist to support some claims of low toxicity to humans and the environment, the data are insufficient to justify many of these claims.\nNew strains of Bt are developed and introduced over time as insects develop resistance to Bt, or the desire occurs to force mutations to modify organism characteristics, or to use homologous recombinant genetic engineering to improve crystal size and increase pesticidal activity, or broaden the host range of Bt and obtain more effective formulations. Each new strain is given a unique number and registered with the U.S. EPA and allowances may be given for genetic modification depending on \"its parental strains, the proposed pesticide use pattern, and the manner and extent to which the organism has been genetically modified\". Formulations of Bt that are approved for organic farming in the US are listed at the website of the Organic Materials Review Institute (OMRI) and several university extension websites offer advice on how to use Bt spore or protein preparations in organic farming.\nUse of Bt genes in genetic engineering of plants for pest control.\nThe Belgian company Plant Genetic Systems (now part of Bayer CropScience) was the first company (in 1985) to develop genetically modified crops (tobacco) with insect tolerance by expressing \"cry\" genes from \"B. thuringiensis\"; the resulting crops contain delta endotoxin. The Bt tobacco was never commercialized; tobacco plants are used to test genetic modifications since they are easy to manipulate genetically and are not part of the food supply.\nUsage.\nIn 1995, were approved safe by the Environmental Protection Agency, making it the first human-modified pesticide-producing crop to be approved in the US, though many plants produce pesticides naturally, including tobacco, coffee plants, cocoa, cotton and black walnut. This was the 'New Leaf' potato, and it was removed from the market in 2001 due to lack of interest.\nIn 1996, was approved, which killed the European corn borer and related species; subsequent Bt genes were introduced that killed corn rootworm larvae.\nThe Bt genes engineered into crops and approved for release include, singly and stacked: Cry1A.105, CryIAb, CryIF, Cry2Ab, Cry3Bb1, Cry34Ab1, Cry35Ab1, mCry3A, and VIP, and the engineered crops include corn and cotton.\nCorn genetically modified to produce VIP was first approved in the US in 2010.\nIn India, by 2014, more than seven million cotton farmers, occupying twenty-six million acres, had adopted .\nMonsanto developed a and the glyphosate-resistance gene for the Brazilian market, which completed the Brazilian regulatory process in 2010.\n - specifically \"Populus\" hybrids - have been developed. They do suffer lesser leaf damage from insect herbivory. The results have not been entirely positive however: The intended result - better timber yield - was not achieved, with no growth advantage despite that reduction in herbivore damage; one of their major pests still preys upon the transgenic trees; and besides that, their leaf litter decomposes differently due to the transgenic toxins, resulting in alterations to the aquatic insect populations nearby.\nSafety studies.\nThe use of Bt toxins as plant-incorporated protectants prompted the need for extensive evaluation of their safety for use in foods and potential unintended impacts on the environment.\nDietary risk assessment.\nConcerns over the safety of consumption of genetically modified plant materials that contain Cry proteins have been addressed in extensive dietary risk assessment studies. As a toxic mechanism, \"cry\" proteins bind to specific receptors on the membranes of mid-gut (epithelial) cells of the targeted pests, resulting in their rupture. While the target pests are exposed to the toxins primarily through leaf and stalk material, Cry proteins are also expressed in other parts of the plant, including trace amounts in maize kernels which are ultimately consumed by both humans and animals. However, other organisms (including humans, other animals and non-targeted insects) that lack the appropriate receptors in their gut cannot be affected by the \"cry\" protein, and therefore are not affected by Bt.\nToxicology studies.\nAnimal models have been used to assess human health risk from consumption of products containing Cry proteins. The United States Environmental Protection Agency recognizes mouse acute oral feeding studies where doses as high as 5,000\u00a0mg/kg body weight resulted in no observed adverse effects. Research on other known toxic proteins suggests that , further suggesting that Bt toxins are not toxic to mammals. The results of toxicology studies are further strengthened by the lack of observed toxicity from decades of use of \"B. thuringiensis\" and its crystalline proteins as an insecticidal spray.\nAllergenicity studies.\nIntroduction of a new protein raised concerns regarding the potential for allergic responses in sensitive individuals. Bioinformatic analysis of known allergens has indicated there is no concern of allergic reactions as a result of consumption of Bt toxins. Additionally, skin prick testing using purified Bt protein resulted in no detectable production of toxin-specific IgE antibodies, even in atopic patients.\nDigestibility studies.\nStudies have been conducted to evaluate the fate of Bt toxins that are ingested in foods. Bt toxin proteins have been shown to digest within minutes of exposure to simulated gastric fluids. The instability of the proteins in digestive fluids is an additional indication that Cry proteins are unlikely to be allergenic, since most known food allergens resist degradation and are ultimately absorbed in the small intestine.\nPersistence in environment.\nConcerns over possible environmental impact from accumulation of Bt toxins from plant tissues, pollen dispersal, and direct secretion from roots have been investigated. Bt toxins may persist in soil for over 200 days, with half-lives between 1.6 and 22 days. Much of the toxin is initially degraded rapidly by microorganisms in the environment, while some is adsorbed by organic matter and persists longer. Some studies, in contrast, claim that the toxins do not persist in the soil. Bt toxins are less likely to accumulate in bodies of water, but pollen shed or soil runoff may deposit them in an aquatic ecosystem. Fish species are not susceptible to Bt toxins if exposed.\nImpact on non-target organisms.\nThe toxic nature of Bt proteins has an adverse impact on many major crop pests, but some ecological risk assessments has been conducted to ensure safety of beneficial non-target organisms that may come into contact with the toxins. Toxicity for the monarch butterfly, has been shown to not reach dangerous levels. Most soil-dwelling organisms, potentially exposed to Bt toxins through root exudates, are probably not impacted by the growth of Bt crops.\nInsect resistance.\nMultiple insects have developed a resistance to \"B. thuringiensis\". In November 2009, Monsanto scientists found the pink bollworm had become resistant to the first-generation Bt cotton in parts of Gujarat, India - that generation expresses one Bt gene, \"Cry1Ac\". This was the first instance of Bt resistance confirmed by Monsanto anywhere in the world. Monsanto responded by introducing a second-generation cotton with multiple Bt proteins, which was rapidly adopted. Bollworm resistance to first-generation Bt cotton was also identified in Australia, China, Spain, and the United States. Additionally, resistance to Bt was documented in field population of diamondback moth in Hawaii, the continental US, and Asia. Studies in the cabbage looper have suggested that a mutation in the membrane transporter ABCC2 can confer resistance to Bt \"Cry1Ac\".\nSecondary pests.\nSeveral studies have documented surges in \"sucking pests\" (which are not affected by Bt toxins) within a few years of adoption of Bt cotton. In China, the main problem has been with mirids, which have in some cases \"completely eroded all benefits from Bt cotton cultivation\". The increase in sucking pests depended on local temperature and rainfall conditions and increased in half the villages studied. The increase in insecticide use for the control of these secondary insects was far smaller than the reduction in total insecticide use due to Bt cotton adoption. Another study in five provinces in China found the reduction in pesticide use in Bt cotton cultivars is significantly lower than that reported in research elsewhere, consistent with the hypothesis suggested by recent studies that more pesticide sprayings are needed over time to control emerging secondary pests, such as aphids, spider mites, and lygus bugs.\nSimilar problems have been reported in India, with both mealy bugs and aphids although a survey of small Indian farms between 2002 and 2008 concluded Bt cotton adoption has led to higher yields and lower pesticide use, decreasing over time.\nControversies.\nThe controversies surrounding Bt use are among the many genetically modified food controversies more widely.\nLepidopteran toxicity.\nThe most publicised problem associated with Bt crops is the claim that pollen from Bt maize could kill the monarch butterfly. The paper produced a public uproar and demonstrations against Bt maize; however by 2001 several follow-up studies coordinated by the USDA had asserted that \"the most common types of Bt maize pollen are not toxic to monarch larvae in concentrations the insects would encounter in the fields.\" Similarly, \"B. thuringiensis\" has been widely used for controlling \"Spodoptera littoralis\" larvae growth due to their detrimental pest activities in Africa and Southern Europe. However, \"S. littoralis\" showed resistance to many strains of \"B. thuriginesis\" and were only effectively controlled by a few strains.\nWild maize genetic mixing.\nA study published in \"Nature\" in 2001 reported Bt-containing maize genes were found in maize in its center of origin, Oaxaca, Mexico. Another \"Nature\" paper published in 2002 claimed that the previous paper's conclusion was the result of an artifact caused by an inverse polymerase chain reaction and that \"the evidence available is not sufficient to justify the publication of the original paper.\" A significant controversy happened over the paper and \"Nature\"s unprecedented notice.\nA subsequent large-scale study in 2005 failed to find any evidence of genetic mixing in Oaxaca. A 2007 study found the \"transgenic proteins expressed in maize were found in two (0.96%) of 208 samples from farmers' fields, located in two (8%) of 25 sampled communities.\" Mexico imports a substantial amount of maize from the U.S., and due to formal and informal seed networks among rural farmers, many potential routes are available for transgenic maize to enter into food and feed webs. One study found small-scale (about 1%) introduction of transgenic sequences in sampled fields in Mexico; it did not find evidence for or against this introduced genetic material being inherited by the next generation of plants. That study was immediately criticized, with the reviewer writing, \"Genetically, any given plant should be either non-transgenic or transgenic, therefore for leaf tissue of a single transgenic plant, a GMO level close to 100% is expected. In their study, the authors chose to classify leaf samples as transgenic despite GMO levels of about 0.1%. We contend that results such as these are incorrectly interpreted as positive and are more likely to be indicative of contamination in the laboratory.\"\nColony collapse disorder.\nAs of 2007, a new phenomenon called colony collapse disorder (CCD) began affecting bee hives all over North America. Initial speculation on possible causes included new parasites, pesticide use, and the use of Bt transgenic crops. The Mid-Atlantic Apiculture Research and Extension Consortium found no evidence that pollen from Bt crops is adversely affecting bees. According to the USDA, \"Genetically modified (GM) crops, most commonly Bt corn, have been offered up as the cause of CCD. But there is no correlation between where GM crops are planted and the pattern of CCD incidents. Also, GM crops have been widely planted since the late 1990s, but CCD did not appear until 2006. In addition, CCD has been reported in countries that do not allow GM crops to be planted, such as Switzerland. German researchers have noted in one study a possible correlation between exposure to Bt pollen and compromised immunity to \"Nosema\".\" The actual cause of CCD was unknown in 2007, and scientists believe it may have multiple exacerbating causes.\nBeta-exotoxins.\nSome isolates of \"B. thuringiensis\" produce a class of insecticidal small molecules called beta-exotoxin, the common name for which is thuringiensin. A consensus document produced by the OECD says: \"Beta-exotoxins are known to be toxic to humans and almost all other forms of life and its presence is prohibited in \"B. thuringiensis\" microbial products\". Thuringiensins are nucleoside analogues. They inhibit RNA polymerase activity, a process common to all forms of life, in rats and bacteria alike.\nOther hosts.\nThis bacterium is an opportunistic pathogen of animals other than insects, causing necrosis, pulmonary infection, and/or food poisoning. It is unknown how common this is, because these infections are always taken to be \"B. cereus\" infections and are rarely tested for the \"Cry\" and \"Cyt\" proteins that are the only factor distinguishing \"B. thuringiensis\" from \"B. cereus\".\nNew nomenclature for pesticidal proteins (Bt toxins).\n\"Bacillus thuringiensis\" is no longer the sole source of pesticidal proteins. The Bacterial Pesticidal Protein Resource Center (BPPRC) provides information on the rapidly expanding field of pesticidal proteins for academics, regulators, and research and development personnel."}
{"id": "4185", "revid": "48546149", "url": "https://en.wikipedia.org/wiki?curid=4185", "title": "Bacteriophage", "text": "A bacteriophage (), also known informally as a phage (), is a virus that infects and replicates within bacteria and archaea. The term is derived . Bacteriophages are composed of proteins that encapsulate a DNA or RNA genome, and may have structures that are either simple or elaborate. Their genomes may encode as few as four genes (e.g. MS2) and as many as hundreds of genes. Phages replicate within the bacterium following the injection of their genome into its cytoplasm.\nBacteriophages are among the most common and diverse entities in the biosphere. Bacteriophages are ubiquitous viruses, found wherever bacteria exist. It is estimated there are more than 1031 bacteriophages on the planet, more than every other organism on Earth, including bacteria, combined. Viruses are the most abundant biological entity in the water column of the world's oceans, and the second largest component of biomass after prokaryotes, where up to 9x108 virions per millilitre have been found in microbial mats at the surface, and up to 70% of marine bacteria may be infected by bacteriophages.\nBacteriophages were used from the 1920s as an alternative to antibiotics in the former Soviet Union and Central Europe, as well as in France. They are seen as a possible therapy against multi-drug-resistant strains of many bacteria (see phage therapy).\nBacteriophages are known to interact with the immune system both indirectly via bacterial expression of phage-encoded proteins and directly by influencing innate immunity and bacterial clearance. Phage\u2013host interactions are becoming increasingly important areas of research.\nClassification.\nBacteriophages occur abundantly in the biosphere, with different genomes and lifestyles. Phages are classified by the International Committee on Taxonomy of Viruses (ICTV) according to morphology and nucleic acid.\nIt has been suggested that members of \"Picobirnaviridae\" infect bacteria, but not mammals.\nThere are also many unassigned genera of the class \"Leviviricetes\": \"Chimpavirus\", \"Hohglivirus\", \"Mahrahvirus\", \"Meihzavirus\", \"Nicedsevirus\", \"Sculuvirus\", \"Skrubnovirus\", \"Tetipavirus\" and \"Winunavirus\" containing linear ssRNA genomes and the unassigned genus \"Lilyvirus\" of the order \"Caudovirales\" containing a linear dsDNA genome.\nHistory.\nIn 1896, Ernest Hanbury Hankin reported that something in the waters of the Ganges and Yamuna rivers in India had a marked antibacterial action against cholera and it could pass through a very fine porcelain filter. In 1915, British bacteriologist Frederick Twort, superintendent of the Brown Institution of London, discovered a small agent that infected and killed bacteria. He believed the agent must be one of the following:\nTwort's research was interrupted by the onset of World War I, as well as a shortage of funding and the discoveries of antibiotics.\nIndependently, French-Canadian microbiologist F\u00e9lix d'H\u00e9relle, working at the Pasteur Institute in Paris, announced on 3 September 1917 that he had discovered \"an invisible, antagonistic microbe of the dysentery bacillus\". For d'H\u00e9relle, there was no question as to the nature of his discovery: \"In a flash I had understood: what caused my clear spots was in fact an invisible microbe... a virus parasitic on bacteria.\" D'H\u00e9relle called the virus a bacteriophage, a bacterium-eater (from the Greek \"\", meaning \"to devour\"). He also recorded a dramatic account of a man suffering from dysentery who was restored to good health by the bacteriophages. It was d'H\u00e9relle who conducted much research into bacteriophages and introduced the concept of phage therapy. In 1919, in Paris, France, d'H\u00e9relle conducted the first clinical application of a bacteriophage, with the first reported use in the United States being in 1922.\nNobel prizes awarded for phage research.\nIn 1969, Max Delbr\u00fcck, Alfred Hershey, and Salvador Luria were awarded the Nobel Prize in Physiology or Medicine for their discoveries of the replication of viruses and their genetic structure. Specifically the work of Hershey, as contributor to the Hershey\u2013Chase experiment in 1952, provided convincing evidence that DNA, not protein, was the genetic material of life. Delbr\u00fcck and Luria carried out the Luria\u2013Delbr\u00fcck experiment which demonstrated statistically that mutations in bacteria occur randomly and thus follow Darwinian rather than Lamarckian principles.\nUses.\nPhage therapy.\nPhages were discovered to be antibacterial agents and were used in the former Soviet Republic of Georgia (pioneered there by Giorgi Eliava with help from the co-discoverer of bacteriophages, F\u00e9lix d'H\u00e9relle) during the 1920s and 1930s for treating bacterial infections. \nD'Herelle \"quickly learned that bacteriophages are found wherever bacteria thrive: in sewers, in rivers that catch waste runoff from pipes, and in the stools of convalescent patients.\" \nThey had widespread use, including treatment of soldiers in the Red Army. However, they were abandoned for general use in the West for several reasons:\nThe use of phages has continued since the end of the Cold War in Russia, Georgia, and elsewhere in Central and Eastern Europe. The first regulated, randomized, double-blind clinical trial was reported in the \"Journal of Wound Care\" in June 2009, which evaluated the safety and efficacy of a bacteriophage cocktail to treat infected venous ulcers of the leg in human patients. The FDA approved the study as a Phase I clinical trial. The study's results demonstrated the safety of therapeutic application of bacteriophages, but did not show efficacy. The authors explained that the use of certain chemicals that are part of standard wound care (e.g. lactoferrin or silver) may have interfered with bacteriophage viability. Shortly after that, another controlled clinical trial in Western Europe (treatment of ear infections caused by \"Pseudomonas aeruginosa\") was reported in the journal \"Clinical Otolaryngology\" in August 2009. The study concludes that bacteriophage preparations were safe and effective for treatment of chronic ear infections in humans. Additionally, there have been numerous animal and other experimental clinical trials evaluating the efficacy of bacteriophages for various diseases, such as infected burns and wounds, and cystic fibrosis-associated lung infections, among others. On the other hand, phages of \"Inoviridae\" have been shown to complicate biofilms involved in pneumonia and cystic fibrosis and to shelter the bacteria from drugs meant to eradicate disease, thus promoting persistent infection.\nMeanwhile, bacteriophage researchers have been developing engineered viruses to overcome antibiotic resistance, and engineering the phage genes responsible for coding enzymes that degrade the biofilm matrix, phage structural proteins, and the enzymes responsible for lysis of the bacterial cell wall. There have been results showing that T4 phages that are small in size and short-tailed can be helpful in detecting \"E. coli\" in the human body.\nTherapeutic efficacy of a phage cocktail was evaluated in a mouse model with nasal infection of multi-drug-resistant (MDR) \"A. baumannii\". Mice treated with the phage cocktail showed a 2.3-fold higher survival rate compared to those untreated at seven days post-infection. \nIn 2017, a 68-year-old diabetic patient with necrotizing pancreatitis complicated by a pseudocyst infected with MDR \"A. baumannii\" strains was being treated with a cocktail of Azithromycin, Rifampicin, and Colistin for 4 months without results and overall rapidly declining health. \nBecause discussion had begun of the clinical futility of further treatment, an Emergency Investigational New Drug (eIND) was filed as a last effort to at the very least gain valuable medical data from the situation, and approved, so he was subjected to phage therapy using a percutaneously (PC) injected cocktail containing nine different phages that had been identified as effective against the primary infection strain by rapid isolation and testing techniques (a process which took under a day). This proved effective for a very brief period, although the patient remained unresponsive and his health continued to worsen; soon isolates of a strain of \"A. baumannii\" were being collected from drainage of the cyst that showed resistance to this cocktail, and a second cocktail which was tested to be effective against this new strain was added, this time by intravenous (IV) injection as it had become clear that the infection was more pervasive than originally thought. \nOnce on the combination of the IV and PC therapy the patient's downward clinical trajectory reversed, and within two days he had awoken from his coma and become responsive. As his immune system began to function he had to be temporarily removed from the cocktail because his fever was spiking to over , but after two days the phage cocktails were re-introduced at levels he was able to tolerate. The original three-antibiotic cocktail was replaced by minocycline after the bacterial strain was found not to be resistant to this and he rapidly regained full lucidity, although he was not discharged from the hospital until roughly 145 days after phage therapy began. Towards the end of the therapy it was discovered that the bacteria had become resistant to both of the original phage cocktails, but they were continued because they seemed to be preventing minocycline resistance from developing in the bacterial samples collected so were having a useful synergistic effect.\nOther.\nFood industry.\nPhages have increasingly been used to safen food products and to forestall spoilage bacteria. Since 2006, the United States Food and Drug Administration (FDA) and United States Department of Agriculture (USDA) have approved several bacteriophage products. LMP-102 (Intralytix) was approved for treating ready-to-eat (RTE) poultry and meat products. In that same year, the FDA approved LISTEX (developed and produced by Micreos) using bacteriophages on cheese to kill \"Listeria monocytogenes\" bacteria, in order to give them generally recognized as safe (GRAS) status. In July 2007, the same bacteriophage were approved for use on all food products. In 2011 USDA confirmed that LISTEX is a clean label processing aid and is included in USDA. Research in the field of food safety is continuing to see if lytic phages are a viable option to control other food-borne pathogens in various food products.\nWater indicators.\nBacteriophages, including those specific to \"Escherichia coli\", have been employed as indicators of fecal contamination in water sources. Due to their shared structural and biological characteristics, coliphages can serve as proxies for viral fecal contamination and the presence of pathogenic viruses such as rotavirus, norovirus, and HAV. Research conducted on wastewater treatment systems has revealed significant disparities in the behavior of coliphages compared to fecal coliforms, demonstrating a distinct correlation with the recovery of pathogenic viruses at the treatment's conclusion. Establishing a secure discharge threshold, studies have determined that discharges below 3000 PFU/100 mL are considered safe in terms of limiting the release of pathogenic viruses.\nDiagnostics.\nIn 2011, the FDA cleared the first bacteriophage-based product for in vitro diagnostic use. The KeyPath MRSA/MSSA Blood Culture Test uses a cocktail of bacteriophage to detect \"Staphylococcus aureus\" in positive blood cultures and determine methicillin resistance or susceptibility. The test returns results in about five hours, compared to two to three days for standard microbial identification and susceptibility test methods. It was the first accelerated antibiotic-susceptibility test approved by the FDA.\nCounteracting bioweapons and toxins.\nGovernment agencies in the West have for several years been looking to Georgia and the former Soviet Union for help with exploiting phages for counteracting bioweapons and toxins, such as anthrax and botulism. Developments are continuing among research groups in the U.S. Other uses include spray application in horticulture for protecting plants and vegetable produce from decay and the spread of bacterial disease. Other applications for bacteriophages are as biocides for environmental surfaces, e.g., in hospitals, and as preventative treatments for catheters and medical devices before use in clinical settings. The technology for phages to be applied to dry surfaces, e.g., uniforms, curtains, or even sutures for surgery now exists. Clinical trials reported in \"Clinical Otolaryngology\" show success in veterinary treatment of pet dogs with otitis.\nBacterium sensing and identification.\nThe sensing of phage-triggered ion cascades (SEPTIC) bacterium sensing and identification method uses the ion emission and its dynamics during phage infection and offers high specificity and speed for detection.\nPhage display.\nPhage display is a different use of phages involving a library of phages with a variable peptide linked to a surface protein. Each phage genome encodes the variant of the protein displayed on its surface (hence the name), providing a link between the peptide variant and its encoding gene. Variant phages from the library may be selected through their binding affinity to an immobilized molecule (e.g., botulism toxin) to neutralize it. The bound, selected phages can be multiplied by reinfecting a susceptible bacterial strain, thus allowing them to retrieve the peptides encoded in them for further study.\nAntimicrobial drug discovery.\nPhage proteins often have antimicrobial activity and may serve as leads for peptidomimetics, i.e. drugs that mimic peptides. Phage-ligand technology makes use of phage proteins for various applications, such as binding of bacteria and bacterial components (e.g. endotoxin) and lysis of bacteria.\nBasic research.\nBacteriophages are important model organisms for studying principles of evolution and ecology.\nDetriments.\nDairy industry.\nBacteriophages present in the environment can cause cheese to not ferment. In order to avoid this, mixed-strain starter cultures and culture rotation regimes can be used. Genetic engineering of culture microbes \u2013 especially \"Lactococcus lactis\" and \"Streptococcus thermophilus\" \u2013 have been studied for genetic analysis and modification to improve phage resistance. This has especially focused on plasmid and recombinant chromosomal modifications.\nSome research has focused on the potential of bacteriophages as antimicrobial against foodborne pathogens and biofilm formation within the dairy industry. As the spread of antibiotic resistance is a main concern within the dairy industry, phages can serve as a promising alternative.\nReplication.\nThe life cycle of bacteriophages tends to be either a lytic cycle or a lysogenic cycle. In addition, some phages display pseudolysogenic behaviors.\nWith \"lytic phages\" such as the T4 phage, bacterial cells are broken open (lysed) and destroyed after immediate replication of the virion. As soon as the cell is destroyed, the phage progeny can find new hosts to infect. Lytic phages are more suitable for phage therapy. Some lytic phages undergo a phenomenon known as lysis inhibition, where completed phage progeny will not immediately lyse out of the cell if extracellular phage concentrations are high. This mechanism is not identical to that of the temperate phage going dormant and usually is temporary.\nIn contrast, the \"lysogenic cycle\" does not result in immediate lysing of the host cell. Those phages able to undergo lysogeny are known as temperate phages. Their viral genome will integrate with host DNA and replicate along with it, relatively harmlessly, or may even become established as a plasmid. The virus remains dormant until host conditions deteriorate, perhaps due to depletion of nutrients, then, the endogenous phages (known as prophages) become active. At this point they initiate the reproductive cycle, resulting in lysis of the host cell. As the lysogenic cycle allows the host cell to continue to survive and reproduce, the virus is replicated in all offspring of the cell. An example of a bacteriophage known to follow the lysogenic cycle and the lytic cycle is the phage lambda of \"E. coli.\"\nSometimes prophages may provide benefits to the host bacterium while they are dormant by adding new functions to the bacterial genome, in a phenomenon called lysogenic conversion. Examples are the conversion of harmless strains of \"Corynebacterium diphtheriae\" or \"Vibrio cholerae\" by bacteriophages to highly virulent ones that cause diphtheria or cholera, respectively. Strategies to combat certain bacterial infections by targeting these toxin-encoding prophages have been proposed.\nAttachment and penetration.\nBacterial cells are protected by a cell wall of polysaccharides, which are important virulence factors protecting bacterial cells against both immune host defenses and antibiotics. \nHost growth conditions also influence the ability of the phage to attach and invade them. As phage virions do not move independently, they must rely on random encounters with the correct receptors when in solution, such as blood, lymphatic circulation, irrigation, soil water, etc.\nMyovirus bacteriophages use a hypodermic syringe-like motion to inject their genetic material into the cell. After contacting the appropriate receptor, the tail fibers flex to bring the base plate closer to the surface of the cell. This is known as reversible binding. Once attached completely, irreversible binding is initiated and the tail contracts, possibly with the help of ATP present in the tail, injecting genetic material through the bacterial membrane. The injection is accomplished through a sort of bending motion in the shaft by going to the side, contracting closer to the cell and pushing back up. Podoviruses lack an elongated tail sheath like that of a myovirus, so instead, they use their small, tooth-like tail fibers enzymatically to degrade a portion of the cell membrane before inserting their genetic material.\nSynthesis of proteins and nucleic acid.\nWithin minutes, bacterial ribosomes start translating viral mRNA into protein. For RNA-based phages, RNA replicase is synthesized early in the process. Proteins modify the bacterial RNA polymerase so it preferentially transcribes viral mRNA. The host's normal synthesis of proteins and nucleic acids is disrupted, and it is forced to manufacture viral products instead. These products go on to become part of new virions within the cell, helper proteins that contribute to the assemblage of new virions, or proteins involved in cell lysis. In 1972, Walter Fiers (University of Ghent, Belgium) was the first to establish the complete nucleotide sequence of a gene and in 1976, of the viral genome of bacteriophage MS2. Some dsDNA bacteriophages encode ribosomal proteins, which are thought to modulate protein translation during phage infection.\nVirion assembly.\nIn the case of the T4 phage, the construction of new virus particles involves the assistance of helper proteins that act catalytically during phage morphogenesis. The base plates are assembled first, with the tails being built upon them afterward. The head capsids, constructed separately, will spontaneously assemble with the tails. During assembly of the phage T4 virion, the morphogenetic proteins encoded by the phage genes interact with each other in a characteristic sequence. Maintaining an appropriate balance in the amounts of each of these proteins produced during viral infection appears to be critical for normal phage T4 morphogenesis. The DNA is packed efficiently within the heads. The whole process takes about 15 minutes.\nEarly studies of bactioriophage T4 (1962-1964) provided an opportunity to gain understanding of virtually all of the genes that are essential for growth of the bacteriophage under laboratory conditions. These studies were made possible by the availability of two classes of conditional lethal mutants. One class of such mutants was referred to as amber mutants. The other class of conditional lethal mutants was referred to as temperature-sensitive mutants Studies of these two classes of mutants led to considerable insight into the functions and interactions of the proteins employed in the machinery of DNA replication, repair and recombination, and on how viruses are assembled from protein and nucleic acid components (molecular morphogenesis).\nRelease of virions.\nPhages may be released via cell lysis, by extrusion, or, in a few cases, by budding. Lysis, by tailed phages, is achieved by an enzyme called endolysin, which attacks and breaks down the cell wall peptidoglycan. An altogether different phage type, the filamentous phage, makes the host cell continually secrete new virus particles. Released virions are described as free, and, unless defective, are capable of infecting a new bacterium. Budding is associated with certain \"Mycoplasma\" phages. In contrast to virion release, phages displaying a lysogenic cycle do not kill the host and instead become long-term residents as prophages.\nCommunication.\nResearch in 2017 revealed that the bacteriophage \u03a63T makes a short viral protein that signals other bacteriophages to lie dormant instead of killing the host bacterium. Arbitrium is the name given to this protein by the researchers who discovered it.\nGenome structure.\nGiven the millions of different phages in the environment, phage genomes come in a variety of forms and sizes. RNA phages such as MS2 have the smallest genomes, with only a few kilobases. However, some DNA phages such as T4 may have large genomes with hundreds of genes; the size and shape of the capsid varies along with the size of the genome. The largest bacteriophage genomes reach a size of 735 kb.Bacteriophage genomes can be highly mosaic, i.e. the genome of many phage species appear to be composed of numerous individual modules. These modules may be found in other phage species in different arrangements. Mycobacteriophages, bacteriophages with mycobacterial hosts, have provided excellent examples of this mosaicism. In these mycobacteriophages, genetic assortment may be the result of repeated instances of site-specific recombination and illegitimate recombination (the result of phage genome acquisition of bacterial host genetic sequences). Evolutionary mechanisms shaping the genomes of bacterial viruses vary between different families and depend upon the type of the nucleic acid, characteristics of the virion structure, as well as the mode of the viral life cycle.\nSome marine roseobacter phages contain deoxyuridine (dU) instead of deoxythymidine (dT) in their genomic DNA. There is some evidence that this unusual component is a mechanism to evade bacterial defense mechanisms such as restriction endonucleases and CRISPR/Cas systems which evolved to recognize and cleave sequences within invading phages, thereby inactivating them. Other phages have long been known to use unusual nucleotides. In 1963, Takahashi and Marmur identified a \"Bacillus\" phage that has dU substituting dT in its genome, and in 1977, Kirnos et al. identified a cyanophage containing 2-aminoadenine (Z) instead of adenine (A).\nSystems biology.\nThe field of systems biology investigates the complex networks of interactions within an organism, usually using computational tools and modeling. For example, a phage genome that enters into a bacterial host cell may express hundreds of phage proteins which will affect the expression of numerous host genes or the host's metabolism. All of these complex interactions can be described and simulated in computer models.\nFor instance, infection of \"Pseudomonas aeruginosa\" by the temperate phage PaP3 changed the expression of 38% (2160/5633) of its host's genes. Many of these effects are probably indirect, hence the challenge becomes to identify the direct interactions among bacteria and phage.\nSeveral attempts have been made to map protein\u2013protein interactions among phage and their host. For instance, bacteriophage lambda was found to interact with its host, \"E. coli\", by dozens of interactions. Again, the significance of many of these interactions remains unclear, but these studies suggest that there most likely are several key interactions and many indirect interactions whose role remains uncharacterized.\nHost resistance.\nBacteriophages are a major threat to bacteria and prokaryotes have evolved numerous mechanisms to block infection or to block the replication of bacteriophages within host cells. The CRISPR system is one such mechanism as are retrons and the anti-toxin system encoded by them. The Thoeris defense system is known to deploy a unique strategy for bacterial antiphage resistance via NAD+ degradation.\nBacteriophage\u2013host symbiosis.\nTemperate phages are bacteriophages that integrate their genetic material into the host as extrachromosomal episomes or as a prophage during a lysogenic cycle. Some temperate phages can confer fitness advantages to their host in numerous ways, including giving antibiotic resistance through the transfer or introduction of antibiotic resistance genes (ARGs), protecting hosts from phagocytosis, protecting hosts from secondary infection through superinfection exclusion, enhancing host pathogenicity, or enhancing bacterial metabolism or growth. Bacteriophage\u2013host symbiosis may benefit bacteria by providing selective advantages while passively replicating the phage genome.\nIn the environment.\nMetagenomics has allowed the in-water detection of bacteriophages that was not possible previously.\nAlso, bacteriophages have been used in hydrological tracing and modelling in river systems, especially where surface water and groundwater interactions occur. The use of phages is preferred to the more conventional dye marker because they are significantly less absorbed when passing through ground waters and they are readily detected at very low concentrations. Non-polluted water may contain approximately 2\u00d7108 bacteriophages per ml.\nBacteriophages are thought to contribute extensively to horizontal gene transfer in natural environments, principally via transduction, but also via transformation. Metagenomics-based studies also have revealed that viromes from a variety of environments harbor antibiotic-resistance genes, including those that could confer multidrug resistance.\nRecent findings have mapped the complex and intertwined arsenal of anti-phage defense tools in environmental bacteria.\nIn humans.\nAlthough phages do not infect humans, there are countless phage particles in the human body, given the extensive human microbiome. One's phage population has been called the human phageome, including the \"healthy gut phageome\" (HGP) and the \"diseased human phageome\" (DHP). The active phageome of a healthy human (i.e., actively replicating as opposed to nonreplicating, integrated prophage) has been estimated to comprise dozens to thousands of different viruses.\nThere is evidence that bacteriophages and bacteria interact in the human gut microbiome both antagonistically and beneficially.\nPreliminary studies have indicated that common bacteriophages are found in 62% of healthy individuals on average, while their prevalence was reduced by 42% and 54% on average in patients with ulcerative colitis (UC) and Crohn's disease (CD). Abundance of phages may also decline in the elderly.\nThe most common phages in the human intestine, found worldwide, are crAssphages. CrAssphages are transmitted from mother to child soon after birth, and there is some evidence suggesting that they may be transmitted locally. Each person develops their own unique crAssphage clusters. CrAss-like phages also may be present in primates besides humans.\nCommonly studied bacteriophages.\nAmong the countless phages, only a few have been studied in detail, including some historically important phage that were discovered in the early days of microbial genetics. These, especially the T-phage, helped to discover important principles of gene structure and function."}
{"id": "4186", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=4186", "title": "Bacteriostat", "text": ""}
{"id": "4187", "revid": "1217113604", "url": "https://en.wikipedia.org/wiki?curid=4187", "title": "Bactericide", "text": "A bactericide or bacteriocide, sometimes abbreviated Bcidal, is a substance which kills bacteria. Bactericides are disinfectants, antiseptics, or antibiotics.\nHowever, material surfaces can also have bactericidal properties based solely on their physical surface structure, as for example biomaterials like insect wings.\nDisinfectants.\nThe most used disinfectants are those applying\nAntiseptics.\nAs antiseptics (i.e., germicide agents that can be used on human or animal body, skin, mucosae, wounds and the like), few of the above-mentioned disinfectants can be used, under proper conditions (mainly concentration, pH, temperature and toxicity toward humans and animals). Among them, some important are\nOthers are generally not applicable as safe antiseptics, either because of their corrosive or toxic nature.\nAntibiotics.\nBactericidal antibiotics kill bacteria; bacteriostatic antibiotics slow their growth or reproduction.\nBactericidal antibiotics that inhibit cell wall synthesis: the beta-lactam antibiotics (penicillin derivatives (penams), cephalosporins (cephems), monobactams, and carbapenems) and vancomycin.\nAlso bactericidal are daptomycin, fluoroquinolones, metronidazole, nitrofurantoin, co-trimoxazole, telithromycin.\nAminoglycosidic antibiotics are usually considered bactericidal, although they may be bacteriostatic with some organisms.\nAs of 2004, the distinction between bactericidal and bacteriostatic agents appeared to be clear according to the basic/clinical definition, but this only applies under strict laboratory conditions and it is important to distinguish microbiological and clinical definitions. The distinction is more arbitrary when agents are categorized in clinical situations. The supposed superiority of bactericidal agents over bacteriostatic agents is of little relevance when treating the vast majority of infections with gram-positive bacteria, particularly in patients with uncomplicated infections and noncompromised immune systems. Bacteriostatic agents have been effectively used for treatment that are considered to require bactericidal activity. Furthermore, some broad classes of antibacterial agents considered bacteriostatic can exhibit bactericidal activity against some bacteria on the basis of in vitro determination of MBC/MIC values. At high concentrations, bacteriostatic agents are often bactericidal against some susceptible organisms. The ultimate guide to treatment of any infection must be clinical outcome.\nSurfaces.\nMaterial surfaces can exhibit bactericidal properties because of their crystallographic surface structure.\nSomewhere in the mid-2000s it was shown that metallic nanoparticles can kill bacteria. The effect of a silver nanoparticle for example depends on its size with a preferential diameter of about 1\u201310\u00a0nm to interact with bacteria.\nIn 2013, cicada wings were found to have a selective anti-gram-negative bactericidal effect based on their physical surface structure. Mechanical deformation of the more or less rigid nanopillars found on the wing releases energy, striking and killing bacteria within minutes, hence called a mechano-bactericidal effect.\nIn 2020 researchers combined cationic polymer adsorption and femtosecond laser surface structuring to generate a bactericidal effect against both gram-positive \"Staphylococcus aureus\" and gram-negative \"Escherichia coli\" bacteria on borosilicate glass surfaces, providing a practical platform for the study of the bacteria-surface interaction."}
{"id": "4188", "revid": "1020372", "url": "https://en.wikipedia.org/wiki?curid=4188", "title": "Brion Gysin", "text": "Brion Gysin (19 January 1916 \u2013 13 July 1986) was a British-Canadian painter, writer, sound poet, performance artist and inventor of experimental devices.\nHe is best known for his use of the cut-up technique, alongside his close friend, the novelist William S. Burroughs. With the engineer Ian Sommerville he also invented the Dreamachine, a flicker device designed as an art object to be viewed with the eyes closed. It was in painting and drawing, however, that Gysin devoted his greatest efforts, creating calligraphic works inspired by cursive Japanese \"grass\" script and Arabic script. Burroughs later stated that \"Brion Gysin was the only man I ever respected.\"\nBiography.\nEarly years.\nJohn Clifford Brian Gysin was born at the Canadian military hospital in Taplow, Buckinghamshire, England. His mother, Stella Margaret Martin, was a Canadian from Deseronto, Ontario. His father, Leonard Gysin, a captain with the Canadian Expeditionary Force, was killed in action eight months after his son's birth. Stella returned to Canada and settled in Edmonton, Alberta where her son became \"the only Catholic day-boy at an Anglican boarding school\". Leaving that school at the age of fifteen, Gysin was sent next to Downside School in Stratton-on-the-Fosse, near Bath in England, a prestigious school for boys run by Benedictine monks. Despite attending both Anglican and Roman Catholic schools, Gysin was already an atheist when he left St Joseph's.\nSurrealism.\nIn 1934, he moved to Paris to study \"La Civilisation Fran\u00e7aise\", an open course given at the Sorbonne where he made literary and artistic contacts through Marie Berthe Aurenche, Max Ernst's second wife. He joined the Surrealist Group and began associating with Valentine Hugo, Leonor Fini, Salvador Dal\u00ed, Picasso and Dora Maar. A year later, he had his first exhibition at the \"Gal\u00e9rie Quatre Chemins\" in Paris with Ernst, Picasso, Hans Arp, Hans Bellmer, Victor Brauner, Giorgio de Chirico, Dal\u00ed, Marcel Duchamp, Ren\u00e9 Magritte, Man Ray and Yves Tanguy. On the day of the preview, however, he was expelled from the Surrealist Group by Andr\u00e9 Breton, who ordered the poet Paul \u00c9luard to take down his pictures. Gysin was 19 years old. His biographer, John Geiger, suggests the arbitrary expulsion \"had the effect of a curse. Years later, he blamed other failures on the Breton incident. It gave rise to conspiracy theories about the powerful interests who seek control of the art world. He gave various explanations for the expulsion, the more elaborate involving 'insubordination' or \"l\u00e8se majest\u00e9\" towards Breton\".\nAfter World War II.\nAfter serving in the U.S. army during World War II, Gysin published a biography of Josiah \"Uncle Tom\" Henson titled, \"To Master, a Long Goodnight: The History of Slavery in Canada\" (1946). A gifted draughtsman, he took an 18-month course learning the Japanese language (including calligraphy) that would greatly influence his artwork. In 1949, he was among the first Fulbright Fellows. His goal was to research, at the University of Bordeaux and in the Archivo de Indias in Seville, Spain, the history of slavery, a project that he later abandoned. He moved to Tangier, Morocco, after visiting the city with novelist and composer Paul Bowles in 1950. In 1952/3 he met the travel writer and sexual adventurer Anne Cumming and they remained friends until his death.\nMorocco and the Beat Hotel.\nIn 1954 in Tangier, Gysin opened a restaurant called The 1001 Nights, with his friend Mohamed Hamri, who was the cook. Gysin hired the Master Musicians of Jajouka from the village of Jajouka to perform alongside entertainment that included acrobats, a dancing boy and fire eaters. The musicians performed there for an international clientele that included William S. Burroughs. Gysin lost the business in 1958, and the restaurant closed permanently. That same year, Gysin returned to Paris, taking lodgings in a flophouse located at 9 rue G\u00eet-le-C\u0153ur that would become famous as the Beat Hotel. Working on a drawing, he discovered a Dada technique by accident:\nWilliam Burroughs and I first went into techniques of writing, together, back in room No. 15 of the Beat Hotel during the cold Paris spring of 1958... Burroughs was more intent on Scotch-taping his photos together into one great continuum on the wall, where scenes faded and slipped into one another, than occupied with editing the monster manuscript... \"Naked Lunch\" appeared and Burroughs disappeared. He kicked his habit with Apomorphine and flew off to London to see Dr Dent, who had first turned him on to the cure. While cutting a mount for a drawing in room No. 15, I sliced through a pile of newspapers with my Stanley blade and thought of what I had said to Burroughs some six months earlier about the necessity for turning painters' techniques directly into writing. I picked up the raw words and began to piece together texts that later appeared as \"First Cut-Ups\" in \"Minutes to Go\" (Two Cities, Paris 1960).\nWhen Burroughs returned from London in September 1959, Gysin not only shared his discovery with his friend but the new techniques he had developed for it. Burroughs then put the techniques to use while completing \"Naked Lunch\" and the experiment dramatically changed the landscape of American literature. Gysin helped Burroughs with the editing of several of his novels including \"Interzone\", and wrote a script for a film version of \"Naked Lunch\", which was never produced. The pair collaborated on a large manuscript for Grove Press titled \"The Third Mind\", but it was determined that it would be impractical to publish it as originally envisioned. The book later published under that title incorporates little of this material. Interviewed for \"The Guardian\" in 1997, Burroughs explained that Gysin was \"the only man that I've ever respected in my life. I've admired people, I've liked them, but he's the only man I've ever respected.\" In 1969, Gysin completed his finest novel, \"The Process\", a work judged by critic Robert Palmer as \"a classic of 20th century modernism\".\nA consummate innovator, Gysin altered the cut-up technique to produce what he called permutation poems in which a single phrase was repeated several times with the words rearranged in a different order with each reiteration. An example of this is \"I don't dig work, man / Man, work I don't dig.\" Many of these permutations were derived using a random sequence generator in an early computer program written by Ian Sommerville. Commissioned by the BBC in 1960 to produce material for broadcast, Gysin's results included \"Pistol Poem\", which was created by recording a gun firing at different distances and then splicing the sounds. That year, the piece was subsequently used as a theme for the Paris performance of Le Domaine Poetique, a showcase for experimental works by people like Gysin, Fran\u00e7ois Dufr\u00eane, Bernard Heidsieck, and Henri Chopin.\nWith Sommerville, he built the Dreamachine in 1961. Described as \"the first art object to be seen with the eyes closed\", the flicker device uses alpha waves in the 8\u201316 Hz range to produce a change of consciousness in receptive viewers.\nLater years.\nIn April 1974, while sitting at a social engagement, Gysin had a very noticeable rectal bleeding. In May he wrote to Burroughs complaining he was not feeling well. A short time later he was diagnosed with colon cancer and began to receive cobalt treatment. Between December 1974 and April 1975, Gysin had to undergo several surgeries, among them a very traumatic colostomy, that drove him to extreme depression and to a suicide attempt. Later, in \"Fire: Words by Day \u2013 Images by Night\" (1975), a crudely lucid text, he would describe the horrendous ordeal he went through.\nIn 1985 Gysin was made an American Commander of the French Ordre des Arts et des Lettres. He'd begun to work extensively with noted jazz soprano saxophonist Steve Lacy. They recorded an album in 1986 with French musician Ramuntcho Matta, featuring Gysin singing/rapping his own texts, with performances by Lacy, Don Cherry, Elli Medeiros, Lizzy Mercier Descloux and more. The album was reissued on CD in 1993 by Crammed Discs, under the title \"Self-Portrait Jumping\".\nDeath.\nOn 13 July 1986 Brion Gysin died of lung cancer. Anne Cumming arranged his funeral and for his ashes to be scattered at the Caves of Hercules in Morocco. An obituary by Robert Palmer published in \"The New York Times\" described him as a man who \"threw off the sort of ideas that ordinary artists would parlay into a lifetime career, great clumps of ideas, as casually as a locomotive throws off sparks\". Later that year a heavily edited version of his novel, \"The Last Museum\", was published posthumously by Faber &amp; Faber (London) and by Grove Press (New York).\nAs a joke, Gysin had contributed a recipe for marijuana fudge to a cookbook by Alice B. Toklas; it was included for publication, becoming famous under the name Alice B. Toklas brownies.\nBurroughs on the Gysin cut-up.\nIn a 1966 interview by Conrad Knickerbocker for \"The Paris Review\", William S. Burroughs explained that Brion Gysin was, to his knowledge, \"the first to create cut-ups\":\nA friend, Brion Gysin, an American poet and painter, who has lived in Europe for thirty years, was, as far as I know, the first to create cut-ups. His cut-up poem, \"Minutes to Go\", was broadcast by the BBC and later published in a pamphlet. I was in Paris in the summer of 1960; this was after the publication there of \"Naked Lunch\". I became interested in the possibilities of this technique, and I began experimenting myself. Of course, when you think of it, \"The Waste Land\" was the first great cut-up collage, and Tristan Tzara had done a bit along the same lines. Dos Passos used the same idea in 'The Camera Eye' sequences in \"USA\". I felt I had been working toward the same goal; thus it was a major revelation to me when I actually saw it being done.\nInfluence.\nAccording to Jos\u00e9 F\u00e9rez Kuri, author of \"Brion Gysin: Tuning in to the Multimedia Age\" (2003) and co-curator of a major retrospective of the artist's work at The Edmonton Art Gallery in 1998, Gysin's wide range of \"radical ideas would become a source of inspiration for artists of the Beat Generation, as well as for their successors (among them David Bowie, Mick Jagger, Keith Haring, and Laurie Anderson)\". Other artists include Genesis P-Orridge, John Zorn (as displayed on the 2013's Dreamachines album) and Brian Jones.\nSelected bibliography.\nGysin is the subject of John Geiger's biography, \"Nothing Is True Everything Is Permitted: The Life of Brion Gysin\", and features in \"Chapel of Extreme Experience: A Short History of Stroboscopic Light and the Dream Machine\", also by Geiger. \"Man From Nowhere: Storming the Citadels of Enlightenment with William Burroughs and Brion Gysin\", a biographical study of Burroughs and Gysin with a collection of homages to Gysin, was authored by Joe Ambrose, Frank Rynne, and Terry Wilson with contributions by Marianne Faithfull, John Cale, William S. Burroughs, John Giorno, Stanley Booth, Bill Laswell, Mohamed Hamri, Keith Haring and Paul Bowles. A monograph on Gysin was published in 2003 by Thames and Hudson.\nWorks.\nProse\nRadio\nCinema\nMusic\nPainting"}
{"id": "4190", "revid": "4141940", "url": "https://en.wikipedia.org/wiki?curid=4190", "title": "Bulgarian", "text": "Bulgarian may refer to:"}
{"id": "4191", "revid": "2428506", "url": "https://en.wikipedia.org/wiki?curid=4191", "title": "BCG vaccine", "text": "The Bacillus Calmette\u2013Gu\u00e9rin (BCG) vaccine is a vaccine primarily used against tuberculosis (TB). It is named after its inventors Albert Calmette and Camille Gu\u00e9rin. In countries where tuberculosis or leprosy is common, one dose is recommended in healthy babies as soon after birth as possible. In areas where tuberculosis is not common, only children at high risk are typically immunized, while suspected cases of tuberculosis are individually tested for and treated. Adults who do not have tuberculosis and have not been previously immunized, but are frequently exposed, may be immunized, as well. BCG also has some effectiveness against Buruli ulcer infection and other nontuberculous mycobacterial infections. Additionally, it is sometimes used as part of the treatment of bladder cancer.\nRates of protection against tuberculosis infection vary widely and protection lasts up to 20 years. Among children, it prevents about 20% from getting infected and among those who do get infected, it protects half from developing disease. The vaccine is injected into the skin. No evidence shows that additional doses are beneficial.\nSerious side effects are rare. Redness, swelling, and mild pain often occur at the injection site. A small ulcer may also form with some scarring after healing. Side effects are more common and potentially more severe in those with immunosuppression. Although no harmful effects on the fetus have been observed, there is insufficient evidence about the safety of BCG vaccination during pregnancy. Therefore, the vaccine is not recommended for use during pregnancy. The vaccine was originally developed from \"Mycobacterium bovis\", which is commonly found in cattle. While it has been weakened, it is still live.\nThe BCG vaccine was first used medically in 1921. It is on the World Health Organization's List of Essential Medicines. , the vaccine is given to about 100 million children per year globally. However, it is not commonly administered in the United States.\nMedical uses.\nTuberculosis.\nThe main use of BCG is for vaccination against tuberculosis. BCG vaccine can be administered after birth intradermally. BCG vaccination can cause a false positive Mantoux test.\nThe most controversial aspect of BCG is the variable efficacy found in different clinical trials, which appears to depend on geography. Trials in the UK consistently show a 60 to 80% protective effect. Still, those trials conducted elsewhere have shown no protective effect, and efficacy appears to fall the closer one gets to the equator.\nA 1994 systematic review found that BCG reduces the risk of getting tuberculosis by about 50%. Differences in effectiveness depend on region, due to factors such as genetic differences in the populations, changes in environment, exposure to other bacterial infections, and conditions in the laboratory where the vaccine is grown, including genetic differences between the strains being cultured and the choice of growth medium.\nA systematic review and meta-analysis conducted in 2014 demonstrated that the BCG vaccine reduced infections by 19\u201327% and reduced progression to active tuberculosis by 71%. The studies included in this review were limited to those that used interferon gamma release assay.\nThe duration of protection of BCG is not clearly known. In those studies showing a protective effect, the data are inconsistent. The MRC study showed protection waned to 59% after 15 years and to zero after 20 years; however, a study looking at Native Americans immunized in the 1930s found evidence of protection even 60 years after immunization, with only slightly waning in efficacy.\nBCG seems to have its greatest effect in preventing miliary tuberculosis or tuberculosis meningitis, so it is still extensively used even in countries where efficacy against pulmonary tuberculosis is negligible.\nThe 100th anniversary of the BCG vaccine was in 2021. It remains the only vaccine licensed against tuberculosis, which is an ongoing pandemic. Tuberculosis elimination is a goal of the World Health Organization (WHO). The development of new vaccines with greater efficacy against adult pulmonary tuberculosis may be needed to make substantial progress.\nEfficacy.\nSeveral possible reasons for the variable efficacy of BCG in different countries have been proposed. None has been proven, some have been disproved, and none can explain the lack of efficacy in low tuberculosis-burden countries (US) and high tuberculosis-burden countries (India). The reasons for variable efficacy have been discussed at length in a WHO document on BCG.\nMycobacteria.\nBCG has protective effects against some nontuberculosis mycobacteria.\nCancer.\nBCG has been one of the most successful immunotherapies. BCG vaccine has been the \"standard of care for patients with bladder cancer (NMIBC)\" since 1977. By 2014, more than eight different considered biosimilar agents or strains used to treat nonmuscle-invasive bladder cancer.\nMethod of administration.\nA pre-injection tuberculin skin test is usually carried out before administering the BCG vaccine. A reactive tuberculin skin test is a contraindication to BCG due to the risk of severe local inflammation and scarring; it does not indicate immunity. BCG is also contraindicated in certain people who have IL-12 receptor pathway defects.\nBCG is given as a single intradermal injection at the insertion of the deltoid. If BCG is accidentally given subcutaneously, then a local abscess may form (a \"BCG-oma\") that can sometimes ulcerate, and may require treatment with antibiotics immediately, otherwise without treatment it could spread the infection, causing severe damage to vital organs. An abscess is not always associated with incorrect administration, and it is one of the more common complications that can occur with the vaccination. Numerous medical studies on the treatment of these abscesses with antibiotics have been done with varying results, but the consensus is once pus is aspirated and analysed, provided no unusual bacilli are present, the abscess will generally heal on its own in a matter of weeks.\nThe characteristic raised scar that BCG immunization leaves is often used as proof of prior immunization. This scar must be distinguished from that of smallpox vaccination, which it may resemble.\nWhen given for bladder cancer, the vaccine is not injected through the skin but is instilled into the bladder through the urethra using a soft catheter.\nAdverse effects.\nBCG immunization generally causes some pain and scarring at the site of injection. The main adverse effects are keloids\u2014large, raised scars. The insertion to the deltoid muscle is most frequently used because the local complication rate is smallest when that site is used. Nonetheless, the buttock is an alternative site of administration because it provides better cosmetic outcomes.\nBCG vaccine should be given intradermally. If given subcutaneously, it may induce local infection and spread to the regional lymph nodes, causing either suppurative (production of pus) or nonsuppurative lymphadenitis. Conservative management is usually adequate for nonsuppurative lymphadenitis. If suppuration occurs, it may need needle aspiration. For unresolved suppuration, surgical excision may be required. Evidence for the treatment of these complications is scarce.\nUncommonly, breast and gluteal abscesses can occur due to haematogenous (carried by the blood) and lymphangiomatous spread. Regional bone infection (BCG osteomyelitis or osteitis) and disseminated BCG infection are rare complications of BCG vaccination, but potentially life-threatening. Systemic antituberculous therapy may be helpful in severe complications.\nWhen BCG is used for bladder cancer, around 2.9% of treated patients discontinue immunotherapy due to a genitourinary or systemic BCG-related infection, however while symptomatic bladder BCG infection is frequent, the involvement of other organs is very uncommon. When systemic involvement occurs, liver and lungs are the first organs to be affected (1 week [median] after the last BCG instillation).\nIf BCG is accidentally given to an immunocompromised patient (e.g., an infant with severe combined immune deficiency), it can cause disseminated or life-threatening infection. The documented incidence of this happening is less than one per million immunizations given. In 2007, the WHO stopped recommending BCG for infants with HIV, even if the risk of exposure to tuberculosis is high, because of the risk of disseminated BCG infection (which is roughly 400 per 100,000 in that higher risk context).\nUsage.\nThe person's age and the frequency with which BCG is given have always varied from country to country. The WHO recommends childhood BCG for all countries with a high incidence of tuberculosis and/or high leprosy burden. This is a partial list of historic and active BCG practices around the globe. A complete atlas of past and present practice has been generated. As of 2022, 155 countries offer the BCG vaccine in their schedule.\nManufacture.\nBCG is prepared from a strain of the attenuated (virulence-reduced) live bovine tuberculosis bacillus, \"Mycobacterium bovis\", that has lost its ability to cause disease in humans. It is specially subcultured in a culture medium, usually Middlebrook 7H9. Because the living bacilli evolve to make the best use of available nutrients, they become less well-adapted to human blood and can no longer induce disease when introduced into a human host. Still, they are similar enough to their wild ancestors to provide some immunity against human tuberculosis. The BCG vaccine can be anywhere from 0 to 80% effective in preventing tuberculosis for 15 years; however, its protective effect appears to vary according to geography and the lab in which the vaccine strain was grown.\nSeveral companies make BCG, sometimes using different genetic strains of the bacterium. This may result in different product characteristics. OncoTICE, used for bladder instillation for bladder cancer, was developed by Organon Laboratories (since acquired by Schering-Plough, and in turn acquired by Merck &amp; Co.). A similar application is the product of Onko BCG of the Polish company Biomed-Lublin, which owns the Brazilian substrain M. bovis BCG Moreau which is less reactogenic than vaccines including other BCG strains. Pacis BCG, made from the Montr\u00e9al (Institut Armand-Frappier) strain, was first marketed by Urocor in about 2002. Urocor was since acquired by Dianon Systems. Evans Vaccines (a subsidiary of PowderJect Pharmaceuticals). Statens Serum Institut in Denmark has marketed a BCG vaccine prepared using Danish strain 1331. The production of BCG Danish strain 1331 and its distribution was later undertaken by AJVaccines company since the ownership transfer of SSI's vaccine production business to AJ Vaccines Holding A/S which took place on 16 January 2017. Japan BCG Laboratory markets its vaccine, based on the Tokyo 172 substrain of Pasteur BCG, in 50 countries worldwide.\nAccording to a UNICEF report published in December 2015, on BCG vaccine supply security, global demand increased in 2015 from 123 to 152.2\u00a0million doses. To improve security and to [diversify] sources of affordable and flexible supply,\" UNICEF awarded seven new manufacturers contracts to produce BCG. Along with supply availability from existing manufacturers, and a \"new WHO prequalified vaccine\" the total supply will be \"sufficient to meet both suppressed 2015 demand carried over to 2016, as well as total forecast demand through 2016\u20132018.\"\nSupply shortage.\nIn 2011, the Sanofi Pasteur plant flooded, causing problems with mold. The facility, located in Toronto, Ontario, Canada, produced BCG vaccine products made with substrain Connaught such as a tuberculosis vaccine and ImmuCYST, a BCG immunotherapeutic and bladder cancer drug. By April 2012 the FDA had found dozens of documented problems with sterility at the plant including mold, nesting birds and rusted electrical conduits. The resulting closure of the plant for over two years caused shortages of bladder cancer and tuberculosis vaccines. On 29 October 2014 Health Canada gave the permission for Sanofi to resume production of BCG. A 2018 analysis of the global supply concluded that the supplies are adequate to meet forecast BCG vaccine demand, but that risks of shortages remain, mainly due to dependence of 75 percent of WHO pre-qualified supply on just two suppliers.\nDried.\nSome BCG vaccines are freeze dried and become fine powder. Sometimes the powder is sealed with vacuum in a glass ampoule. Such a glass ampoule has to be opened slowly to prevent the airflow from blowing out the powder. Then the powder has to be diluted with saline water before injecting.\nHistory.\nThe history of BCG is tied to that of smallpox. By 1865 Jean Antoine Villemin had demonstrated that rabbits could be infected with tuberculosis from humans; by 1868 he had found that rabbits could be infected with tuberculosis from cows and that rabbits could be infected with tuberculosis from other rabbits. Thus, he concluded that tuberculosis was transmitted via some unidentified microorganism (or \"virus\", as he called it). In 1882 Robert Koch regarded human and bovine tuberculosis as identical. But in 1895, Theobald Smith presented differences between human and bovine tuberculosis, which he reported to Koch. By 1901 Koch distinguished \"Mycobacterium bovis\" from \"Mycobacterium tuberculosis\". Following the success of vaccination in preventing smallpox, established during the 18th century, scientists thought to find a corollary in tuberculosis by drawing a parallel between bovine tuberculosis and cowpox: it was hypothesized that infection with bovine tuberculosis might protect against infection with human tuberculosis. In the late 19th century, clinical trials using \"M. bovis\" were conducted in Italy with disastrous results, because \"M. bovis\" was found to be just as virulent as \"M. tuberculosis\".\nAlbert Calmette, a French physician and bacteriologist, and his assistant and later colleague, Camille Gu\u00e9rin, a veterinarian, were working at the Institut Pasteur de Lille (Lille, France) in 1908. Their work included subculturing virulent strains of the tuberculosis bacillus and testing different culture media. They noted a glycerin-bile-potato mixture grew bacilli that seemed less virulent and changed the course of their research to see if repeated subculturing would produce a strain that was attenuated enough to be considered for use as a vaccine. The BCG strain was isolated after subculturing 239 times during 13 years from a virulent strain on glycerine potato medium. The research continued throughout World War I until 1919 when the now avirulent bacilli were unable to cause tuberculosis disease in research animals. Calmette and Guerin transferred to the Paris Pasteur Institute in 1919. The BCG vaccine was first used in humans in 1921.\nPublic acceptance was slow, and the L\u00fcbeck disaster, in particular, did much to harm it. Between 1929 and 1933 in L\u00fcbeck, 251 infants were vaccinated in the first 10 days of life; 173 developed tuberculosis and 72 died. It was subsequently discovered that the BCG administered there had been contaminated with a virulent strain that was being stored in the same incubator, which led to legal action against the vaccine's manufacturers.\nDr. R. G. Ferguson, working at the Fort Qu'Appelle Sanatorium in Saskatchewan, was among the pioneers in developing the practice of vaccination against tuberculosis. In Canada, more than 600 children from residential schools were used as involuntary participants in BCG vaccine trials between 1933 and 1945. In 1928, the BCG vaccine was adopted by the Health Committee of the League of Nations (predecessor to the World Health Organization (WHO)). Because of opposition, however, it only became widely used after World War II. From 1945 to 1948, relief organizations (International Tuberculosis Campaign or Joint Enterprises) vaccinated over eight million babies in Eastern Europe and prevented the predicted typical increase of tuberculosis after a major war.\nThe BCG vaccine is very efficacious against tuberculous meningitis in the pediatric age group, but its efficacy against pulmonary tuberculosis appears variable. Some countries have removed the BCG vaccine from routine vaccination. Two countries that have never used it routinely are the United States and the Netherlands (in both countries, it is felt that having a reliable Mantoux test and therefore being able to accurately detect active disease is more beneficial to society than vaccinating against a relatively rare condition).\nOther names include \"Vaccin Bili\u00e9 de Calmette et Gu\u00e9rin vaccine\" and \"Bacille de Calmette et Gu\u00e9rin vaccine\".\nResearch.\nTentative evidence exists for a beneficial non-specific effect of BCG vaccination on overall mortality in low-income countries, or for its reducing other health problems including sepsis and respiratory infections when given early, with greater benefit the earlier it is used.\nIn rhesus macaques, BCG shows improved rates of protection when given intravenously. Some risks must be evaluated before it can be translated to humans.\nThe University of Oxford Jenner Institute is conducting a study comparing the efficacy of injected versus inhaled BCG vaccine in already-vaccinated adults.\nType 1 diabetes.\n, BCG vaccine is in the early stages of being studied in type 1 diabetes (T1D).\nCOVID-19.\nUse of the BCG vaccine may provide protection against COVID-19. However, epidemiologic observations in this respect are ambiguous. The WHO does not recommend its use for prevention .\n, 20 BCG trials are in various clinical stages. , the results are extremely mixed. A 15-month trial involving people thrice-vaccinated over the two years before the pandemic shows positive results in preventing infection in BCG-naive people with type 1 diabetes. On the other hand, a 5-month trial shows that re-vaccinating with BCG does not help prevent infection in healthcare workers. Both of these trials were double-blind randomized controlled trials."}
{"id": "4192", "revid": "1224058286", "url": "https://en.wikipedia.org/wiki?curid=4192", "title": "Bunsen", "text": "Bunsen may refer to:"}
{"id": "4193", "revid": "7611264", "url": "https://en.wikipedia.org/wiki?curid=4193", "title": "Common buzzard", "text": "The common buzzard (Buteo buteo) is a medium-to-large bird of prey which has a large range. It is a member of the genus \"Buteo\" in the family Accipitridae. The species lives in most of Europe and extends its breeding range across much of the Palearctic as far as northwestern China (Tian Shan), far western Siberia and northwestern Mongolia. Over much of its range, it is a year-round resident. However, buzzards from the colder parts of the Northern Hemisphere as well as those that breed in the eastern part of their range typically migrate south for the northern winter, many journeying as far as South Africa.\nThe common buzzard is an opportunistic predator that can take a wide variety of prey, but it feeds mostly on small mammals, especially rodents such as voles. It typically hunts from a perch. Like most accipitrid birds of prey, it builds a nest, typically in trees in this species, and is a devoted parent to a relatively small brood of young. The common buzzard appears to be the most common diurnal raptor in Europe, as estimates of its total global population run well into the millions.\nTaxonomy.\nThe first formal description of the common buzzard was by the Swedish naturalist Carl Linnaeus in 1758 in the tenth edition of his \"Systema Naturae\" under the binomial name \"Falco buteo\". The genus \"Buteo\" was introduced by the French naturalist Bernard Germain de Lac\u00e9p\u00e8de in 1799 by tautonymy with the specific name of this species. The word \"buteo\" is Latin for a buzzard. It should not be confused with the Turkey vulture, which is sometimes called a buzzard in American English.\nThe Buteoninae subfamily originated from and is most diversified in the Americas, with occasional broader radiations that led to common buzzards and other Eurasian and African buzzards. The common buzzard is a member of the genus \"Buteo\", a group of medium-sized raptors with robust bodies and broad wings. The \"Buteo\" species of Eurasia and Africa are usually commonly referred to as \"buzzards\" while those in the Americas are called hawks. Under current classification, the genus includes approximately 28 species, the second most diverse of all extant accipitrid genera behind only \"Accipiter\". DNA testing shows that the common buzzard is fairly closely related to the red-tailed hawk (\"Buteo jamaicensis\") of North America, which occupies a similar ecological niche to the buzzard in that continent. The two species may belong to the same species complex. Three buzzards in Africa are likely closely related to the common buzzard based on genetic materials, the Mountain buzzard (\"Buteo oreophilus\"), Forest buzzards (\"Buteo trizonatus\") and the Madagascar buzzard (\"Buteo brachypterus\"), to the point where it has been questioned whether they are sufficiently distinct to qualify as full species. However, the distinctiveness of these African buzzards has generally been supported. Genetic studies have further indicated that the modern buzzards of Eurasia and Africa are a relatively young group, showing that they diverged at about 300,000 years ago. Nonetheless, fossils dating earlier than 5 million year old (the late Miocene period) showed \"Buteo\" species were present in Europe much earlier than that would imply, although it cannot be stated to a certainty that these would have been related to the extant buzzards.\nSubspecies and species splits.\nSome 16 subspecies have been described in the past and up to 11 are often considered valid, although some authorities accept as few as seven. Common buzzard subspecies fall into two groups.\nThe western \"buteo\" group is mainly resident or short-distance migrants and includes:\nThe eastern \"vulpinus\" group includes:\nAt one time, races of the common buzzard were thought to range as far in Asia as a breeding bird well into the Himalayas and as far east as northeastern China, Russia to the Sea of Okhotsk, and all the islands of the Kurile Islands and of Japan, despite both the Himalayan and eastern birds showing a natural gap in distribution from the next nearest breeding common buzzard. However, DNA testing has revealed that the buzzards of these populations probably belong to different species. Most authorities now accept these buzzards as full species: the eastern buzzard (\"Buteo japonicus\"; with three subspecies of its own) and the Himalayan buzzard (\"Buteo refectus\"). Buzzards found on the islands of Cape Verde off of the coast of western Africa, once referred to as the subspecies \"B. b. bannermani\", and Socotra Island off of the northern peninsula of Arabia, once referred to as the rarely recognized subspecies \"B. b. socotrae\", are now generally thought not to belong to the common buzzard. DNA testing has indicated that these insular buzzards are actually more closely related to the long-legged buzzard (\"Buteo rufinus\") than to the common buzzard. Subsequently, some researchers have advocated full species status for the Cape Verde population, but the placement of these buzzards is generally deemed unclear.\nDescription.\nThe common buzzard is a medium to large sized raptor that is highly variable in plumage. Most buzzards are distinctly round headed with a somewhat slender bill, relatively long wings that either reach or fall slightly short of the tail tip when perched, a fairly short tail, and somewhat short and mainly bare tarsi. They can appear fairly compact in overall appearance but may also appear large relative to other more common raptorial birds such as kestrels and sparrowhawks. The common buzzard measures between in length with a wingspan. Females average about 2\u20137% larger than males linearly and weigh about 15% more. Body mass can show considerable variation. Buzzards from Great Britain alone can vary from in males, while females there can range from .\nIn Europe, most typical buzzards are dark brown above and on the upperside of the head and mantle, but can become paler and warmer brown with worn plumage. The flight feathers on perched European buzzards are always brown in the nominate subspecies (\"B. b. buteo\"). Usually the tail will usually be narrowly barred grey-brown and dark brown with a pale tip and a broad dark subterminal band but the tail in palest birds can show a varying amount a white and reduced subterminal band or even appear almost all white. In European buzzards, the underside coloring can be variable but most typically show a brown-streaked white throat with a somewhat darker chest. A pale U across breast is often present; followed by a pale line running down the belly which separates the dark areas on breast-side and flanks. These pale areas tend to have highly variable markings that tend to form irregular bars. Juvenile buzzards are quite similar to adult in the nominate race, being best told apart by having a paler eye, a narrower subterminal band on the tail and underside markings that appear as streaks rather than bars. Furthermore, juveniles may show variable creamy to rufous fringes to upperwing coverts but these also may not be present. Seen from below in flight, buzzards in Europe typically have a dark trailing edge to the wings. If seen from above, one of the best marks is their broad dark subterminal tail band. Flight feathers of typical European buzzards are largely greyish, the aforementioned dark wing linings at front with contrasting paler band along the median coverts. In flight, paler individuals tend to show dark carpal patches that can appears as blackish arches or commas but these may be indistinct in darker individuals or can appear light brownish or faded in paler individuals. Juvenile nominate buzzards are best told apart from adults in flight by the lack of a distinct subterminal band (instead showing fairly even barring throughout) and below by having less sharp and brownish rather than blackish trailing wing edge. Juvenile buzzards show streaking paler parts of under wing and body showing rather than barring as do adults. Beyond the typical mid-range brownish buzzard, birds in Europe can range from almost uniform black-brown above to mainly white. Extreme dark individuals may range from chocolate brown to blackish with almost no pale showing but a variable, faded U on the breast and with or without faint lighter brown throat streaks. Extreme pale birds are largely whitish with variable widely spaced streaks or arrowheads of light brown about the mid-chest and flanks and may or may not show dark feather-centres on the head, wing-coverts and sometimes all but part of mantle. Individuals can show nearly endless variation of colours and hues in between these extremes and the common buzzard is counted among the most variably plumage diurnal raptors for this reason. One study showed that this variation may actually be the result of diminished single-locus genetic diversity.\nBeyond the nominate form (\"B. b. buteo\") that occupies most of the common buzzard's European range, a second main, widely distributed subspecies is known as the steppe buzzard (\"B. b. vulpinus\"). The steppe buzzard race shows three main colour morphs, each of which can be predominant in a region of breeding range. It is more distinctly polymorphic rather than just individually very variable like the nominate race. This may be because, unlike the nominate buzzard, the steppe buzzard is highly migratory. Polymorphism has been linked with migratory behaviour. The most common type of steppe buzzard is the rufous morph which gives this subspecies its scientific name (\"vulpes\" is Latin for \"fox\"). This morph comprises a majority of birds seen in passage east of the Mediterranean. Rufous morph buzzards are a paler grey-brown above than most nominate \"B. b. buteo\". Compared to the nominate race, rufous \"vulpinus\" show a patterning not dissimilar but generally far more rufous-toned on head, the fringes to mantle wing coverts and, especially, on the tail and the underside. The head is grey-brown with rufous tinges usually while the tail is rufous and can vary from almost unmarked to thinly dark-barred with a subterminal band. The underside can be uniformly pale to dark rufous, barred heavily or lightly with rufous or with dusky barring, usually with darker individuals showing the U as in nominate but with a rufous hue. The pale morph of the steppe buzzard is commonest in the west of its subspecies range, predominantly seen in winter and migration at the various land bridge of the Mediterranean. As in the rufous morph, the pale morph \"vulpinus\" is grey-brown above but the tail is generally marked with thin dark bars and a subterminal band, only showing rufous near the tip. The underside in the pale morph is greyish-white with dark grey-brown or somewhat streaked head to chest and barred belly and chest, occasionally showing darker flanks that can be somewhat rufous. Dark morph \"vulpinus\" tend to be found in the east and southeast of the subspecies range and are easily outnumbered by rufous morph while largely using similar migration points. Dark morph individuals vary from grey-brown to much darker blackish-brown, and have a tail that is dark grey or somewhat mixed grey and rufous, is distinctly marked with dark barring and has a broad, black subterminal band. Dark morph \"vulpinus\" have a head and underside that is mostly uniform dark, from dark brown to blackish-brown to almost pure black. Rufous morph juveniles are often distinctly paler in ground colour (ranging even to creamy-grey) than adults with distinct barring below actually increased in pale morph type juvenile. Pale and rufous morph juveniles can only be distinguished from each other in extreme cases. Dark morph juveniles are more similar to adult dark morph \"vulpinus\" but often show a little whitish streaking below, and like all other races have lighter coloured eyes and more evenly barred tails than adults. Steppe buzzards tend to appear smaller and more agile in flight than nominate whose wing beats can look slower and clumsier. In flight, rufous morph \"vulpinus\" have their whole body and underwing varying from uniform to patterned rufous (if patterning present, it is variable, but can be on chest and often thighs, sometimes flanks, pale band across median coverts), while the under-tail usually paler rufous than above. Whitish flight feathers are more prominent than in nominate and more marked contrast with the bold dark brown band along the trailing edges. Markings of pale \"vulpinus\" as seen in flight are similar to rufous morph (such as paler wing markings) but more greyish both on wings and body. In dark morph \"vulpinus\" the broad black trailing edges and colour of body make whitish areas of inner wing stand out further with an often bolder and blacker carpal patch than in other morphs. As in nominate, juvenile \"vulpinus\" (rufous/pale) tend to have much less distinct trailing edges, general streaking on body and along median underwing coverts. Dark morph \"vulpinus\" resemble adult in flight more so than other morphs.\nSimilar species.\nThe common buzzard is often confused with other raptors especially in flight or at a distance. Inexperienced and over-enthusiastic observers have even mistaken darker birds for the far larger and differently proportioned golden eagle (\"Aquila chrysaetos\") and also dark birds for western marsh harrier (\"Circus aeruginosus\") which also flies in a dihedral but is obviously relatively much longer and slenderer winged and tailed and with far different flying methods. Also buzzards may possibly be confused with dark or light morph booted eagles (\"Hieraeetus pennatus\"), which are similar in size, but the eagle flies on level, parallel-edged wings which usually appear broader, has a longer squarer tail, with no carpal patch in pale birds and all dark flight feathers but for whitish wedge on inner primaries in dark morph ones. Pale individuals are sometimes also mistaken with pale morph short-toed eagles (\"Circaetus gallicus\") which are much larger with a considerably bigger head, longer wings (which are usually held evenly in flight rather than in a dihedral) and paler underwing lacking any carpal patch or dark wing lining. More serious identification concerns lie in other \"Buteo\" species and in flight with honey buzzards, which are quite different looking when seen perched at close range. The European honey buzzard (\"Pernis apivorus\") is thought in engage in mimicry of more powerful raptors, in particular, juveniles may mimic the plumage of the more powerful common buzzard. While less individually variable in Europe, the honey buzzard is more extensive polymorphic on underparts than even the common buzzard. The most common morph of the adult European honey buzzard is heavily and rufous barred on the underside, quite different from the common buzzard, however the brownish juvenile much more resembles an intermediate common buzzard. Honey buzzards flap with distinctively slower and more even wing beats than common buzzard. The wings are also lifted higher on each upstroke, creating a more regular and mechanical effect, furthermore their wings are held slightly arched when soaring but not in a V. On the honey buzzard, the head appears smaller, the body thinner, the tail longer and the wings narrower and more parallel edged. The steppe buzzard race is particularly often mistaken for juvenile European honey buzzards, to the point where early observers of raptor migration in Israel considered distant individuals indistinguishable. However, when compared to a steppe buzzard, the honey buzzard has distinctly darker secondaries on the underwing with fewer and broader bars and more extensive black wing-tips (whole fingers) contrasting with a less extensively pale hand. Found in the same range as the steppe buzzard in some parts of southern Siberia as well as (with wintering steppes) in southwestern India, the Oriental honey buzzard (\"Pernis ptilorhynchus\") is larger than both the European honey buzzard and the common buzzard. The oriental species is with more similar in body plan to common buzzards, being relatively broader winged, shorter tailed and more amply-headed (though the head is still relatively small) relative to the European honey buzzard, but all plumages lack carpal patches.\nIn much of Europe, the common buzzard is the only type of buzzard. However, the subarctic breeding rough-legged buzzard (\"Buteo lagopus\") comes down to occupy much of the northern part of the continent during winter in the same haunts as the common buzzard. However, the rough-legged buzzard is typically larger and distinctly longer-winged with feathered legs, as well as having a white based tail with a broad subterminal band. Rough-legged buzzards have slower wing beats and hover far more frequently than do common buzzards. The carpal patch marking on the under-wing are also bolder and blacker on all paler forms of rough-legged hawk. Many pale morph rough-legged buzzards have a bold, blackish band across the belly against contrasting paler feathers, a feature which rarely appears in individual common buzzard. Usually the face also appears somewhat whitish in most pale morphs of rough-legged buzzards, which is true of only extremely pale common buzzards. Dark morph rough-legged buzzards are usually distinctly darker (ranging to almost blackish) than even extreme dark individuals of common buzzards in Europe and still have the distinct white-based tail and broad subterminal band of other roughlegs. In eastern Europe and much of the Asian range of common buzzards, the long-legged buzzard (\"Buteo rufinus\") may live alongside the common species. As in the steppe buzzard race, the long-legged buzzard has three main colour morphs that are more or less similar in hue. In both the steppe buzzard race and long-legged buzzard, the main colour is overall fairly rufous. More so than steppe buzzards, long-legged buzzards tend to have a distinctly paler head and neck compared to other feathers, and, more distinctly, a normally unbarred tail. Furthermore, the long-legged buzzard is usually a rather larger bird, often considered fairly eagle-like in appearance (although it does appear gracile and small-billed even compared to smaller true eagles), an effect enhanced by its longer tarsi, somewhat longer neck and relatively elongated wings. The flight style of the latter species is deeper, slower and more aquiline, with much more frequent hovering, showing a more protruding head and a slightly higher V held in a soar. The smaller North African and Arabian race of long-legged buzzard (\"B. r. cirtensis\") is more similar in size and nearly all colour characteristics to steppe buzzard, extending to the heavily streaked juvenile plumage, in some cases such birds can be distinguished only by their proportions and flight patterns which remain unchanged. Hybridization with the latter race (\"B. r. cirtensis\") and nominate common buzzards has been observed in the Strait of Gibraltar, a few such birds have been reported potentially in the southern Mediterranean due to mutually encroaching ranges, which are blurring possibly due to climate change.\nWintering steppe buzzards may live alongside mountain buzzards and especially with forest buzzard while wintering in Africa. The juveniles of steppe and forest buzzards are more or less indistinguishable and only told apart by proportions and flight style, the latter species being smaller, more compact, having a smaller bill, shorter legs and shorter and thinner wings than a steppe buzzard. However, size is not diagnostic unless side by side as the two buzzards overlap in this regard. Most reliable are the species wing proportions and their flight actions. Forest buzzard have more flexible wing beats interspersed with glides, additionally soaring on flatter wings and apparently never engage in hovering. Adult forest buzzards compared to the typical adult steppe buzzard (rufous morph) are also similar, but the forest typically has a whiter underside, sometimes mostly plain white, usually with heavy blotches or drop-shaped marks on abdomen, with barring on thighs, more narrow tear-shaped on chest and more spotted on leading edges of underwing, usually lacking marking on the white U across chest (which is otherwise similar but usually broader than that of \"vulpinus\"). In comparison, the mountain buzzard, which is more similar in size to the steppe buzzard and slightly larger than the forest buzzard, is usually duller brown above than a steppe buzzard and is more whitish below with distinctive heavy brown blotches from breasts to the belly, flanks and wing linings while juvenile mountain buzzard is buffy below with smaller and streakier markings. The steppe buzzard when compared to another African species, the red-necked buzzard (\"Buteo auguralis\"), which has red tail similar to \"vulpinus\", is distinct in all other plumage aspects despite their similar size. The latter buzzard has a streaky rufous head and is white below with a contrasting bold dark chest in adult plumage and, in juvenile plumage, has heavy, dark blotches on the chest and flanks with pale wing-linings. Jackal and augur buzzards (\"Buteo rufofuscus\" &amp; \"augur\"), also both rufous on the tail, are larger and bulkier than steppe buzzards and have several distinctive plumage characteristics, most notably both having their own striking, contrasting patterns of black-brown, rufous and cream.\nDistribution and habitat.\nThe common buzzard is found throughout several islands in the eastern Atlantic islands, including the Canary Islands and Azores and almost throughout Europe. It is today found in Ireland and in nearly every part of Scotland, Wales and England. In mainland Europe, remarkably, there are no substantial gaps without breeding common buzzards from Portugal and Spain to Greece, Estonia, Belarus and Ukraine, though are present mainly only in the breeding season in much of the eastern half of the latter three countries. They are also present in all larger Mediterranean islands such as Corsica, Sardinia, Sicily and Crete. Further north in Scandinavia, they are found mainly in southeastern Norway (though also some points in southwestern Norway close to the coast and one section north of Trondheim), just over the southern half of Sweden and hugging over the Gulf of Bothnia to Finland where they live as a breeding species over nearly two-thirds of the land.\nThe common buzzard reaches its northern limits as a breeder in far eastern Finland and over the border to European Russia, continuing as a breeder over to the narrowest straits of the White Sea and nearly to the Kola Peninsula. In these northern quarters, the common buzzard is present typically only in summer but is a year-around resident of a hearty bit of southern Sweden and some of southern Norway. Outside of Europe, it is a resident of northern Turkey (largely close to the Black Sea) otherwise occurring mainly as a passage migrant or winter visitor in the remainder of Turkey, Georgia, sporadically but not rarely in Azerbaijan and Armenia, northern Iran (largely hugging the Caspian Sea) to northern Turkmenistan. Further north though its absent from either side of the northern Caspian Sea, the common buzzard is found in much of western Russia (though exclusively as a breeder) including all of the Central Federal District and the Volga Federal District, all but the northernmost parts of the Northwestern and Ural Federal Districts and nearly the southern half of the Siberian Federal District, its farthest easterly occurrence as a breeder. It also found in northern Kazakhstan, Kyrgyzstan, far northwestern China (Tien Shan) and northwestern Mongolia.\nNon-breeding populations occur, either as migrants or wintering birds, in southwestern India, Israel, Lebanon, Syria, Egypt (northeastern), northern Tunisia (and far northwestern Algeria), northern Morocco, near the coasts of The Gambia, Senegal and far southwestern Mauritania and Ivory Coast (and bordering Burkina Faso). In eastern and central Africa, it is found in winter from southeastern Sudan, Eritrea, about two-thirds of Ethiopia, much of Kenya (though apparently absent from the northeast and northwest), Uganda, southern and eastern Democratic Republic of the Congo, and more or less the entirety of southern Africa from Angola across to Tanzania down the remainder of the continent (but for an apparent gap along the coast from southwestern Angola to northwestern South Africa).\nHabitat.\nThe common buzzard generally inhabits the interface of woodlands and open grounds; most typically the species lives in forest edge, small woods or shelterbelts with adjacent grassland, arables or other farmland. It acquits to open moorland as long as there is some trees for perch hunting and nesting use. The woods they inhabit may be coniferous, temperate broadleaf and mixed forests and temperate deciduous forest with occasional preferences for the local dominant tree. It is absent from treeless tundra, as well as the Subarctic where the species almost entirely gives way to the rough-legged buzzard. The common buzzard is sporadic or rare in treeless steppe but can occasionally migrate through it (despite its name, the steppe buzzard subspecies breeds primarily in the wooded fringes of the steppe). The species may be found to some extent in both in mountainous or flat country. Although adaptable to and sometimes seen in wetlands and in coastal areas, buzzards are often considered more of an upland species and neither appear to be regularly attracted to or to strongly avoid bodies of waters in non-migratory times. Buzzards in well-wooded areas of eastern Poland largely used large, mature stands of trees that were more humid, richer and denser than prevalent in surrounding area, but showed preference for those within of openings. Mostly resident buzzards live in lowlands and foothills, but they can live in timbered ridges and uplands as well as rocky coasts, sometimes nesting on cliff ledges rather than trees. Buzzards may live from sea level to elevations of , breeding mostly below but they can winter to an elevation of and migrates easily to . In the mountainous Italian Apennines, buzzard nests were at a mean elevation of and were, relative to the surrounding area, further from human developed areas (i.e. roads) and nearer to valley bottoms in rugged, irregularly topographed places, especially ones that faced northeast. Common buzzards are fairly adaptable to agricultural lands but will show can show regional declines in apparent response to agriculture. Changes to more extensive agricultural practices were shown to reduce buzzard populations in western France where reduction of \u201chedgerows, woodlots and grasslands areas\" caused a decline of buzzards and in Hampshire, England where more extensive grazing by free-range cattle and horses led to declines of buzzards, probably largely due to the seeming reduction of small mammal populations there. On the contrary, buzzards in central Poland adapted to removal of pine trees and reduction of rodent prey by changing nest sites and prey for a time with no strong change in their local numbers. Extensive urbanization seems to negatively affect buzzards, this species being generally less adaptable to urban areas than their New World counterparts, the red-tailed hawk. Although peri-urban areas can actually increase potential prey populations in a location at times, individual buzzard mortality, nest disturbances and nest site habitat degradation rises significantly in such areas. Common buzzards are fairly adaptive to rural areas as well as suburban areas with parks and large gardens, in addition to such areas if they're near farms.\nBehaviour.\nThe common buzzard is a typical \"Buteo\" in much of its behaviour. It is most often seen either soaring at varying heights or perched prominently on tree tops, bare branches, telegraph poles, fence posts, rocks or ledges, or alternately well inside tree canopies. Buzzards will also stand and forage on the ground. In resident populations, it may spend more than half of its day inactively perched. Furthermore, it has been described a \"sluggish and not very bold\" bird of prey. It is a gifted soarer once aloft and can do so for extended periods but can appear laborious and heavy in level flight, more so nominate buzzards than steppe buzzards. Particularly in migration, as was recorded in the case of steppe buzzards' movement over Israel, buzzards readily adjust their direction, tail and wing placement and flying height to adjust for the surrounding environment and wind conditions. In Israel, migrant buzzards rarely soar all that high (maximum above ground) due to the lack of mountain ridges that in other areas typically produce flyways; however tail-winds are significant and allow birds to cover a mean of .\nMigration.\nThe common buzzard is aptly described as a partial migrant. The autumn and spring movements of buzzards are subject to extensive variation, even down to the individual level, based on a region's food resources, competition (both from other buzzards and other predators), extent of human disturbance and weather conditions. Short-distance movements are the norm for juveniles and some adults in autumn and winter, but more adults in central Europe and the British Isles remain on their year-around residence than do not. Even for first year juvenile buzzards dispersal may not take them very far. In England, 96% of first-years moved in winter to less than from their natal site. Southwestern Poland was recorded to be a fairly important wintering grounds for central European buzzards in early spring that apparently travelled from somewhat farther north, in winter average density was a locally high 2.12 individual per square kilometer. Habitat and prey availability seemed to be the primary drivers of habitat selection in fall for European buzzards. In northern Germany, buzzards were recorded to show preferences in fall for areas fairly distant from nesting site, with a large quantity of vole-holes and more widely dispersed perches. In Bulgaria, the mean wintering density was 0.34 individual per square kilometer, and buzzards showed a preference for agricultural over forested areas. Similar habitat preferences were recorded in northeastern Romania, where buzzard density was 0.334\u20130.539 individuals per square kilometer. The nominate buzzards of Scandinavia are somewhat more strongly migratory than most central European populations. However, birds from Sweden show some variation in migratory behaviours. A maximum of 41,000 individuals have been recorded at one of the main migration sites within southern Sweden in Falsterbo. In southern Sweden, winter movements and migration was studied via observation of buzzard colour. White individuals were substantially more common in southern Sweden rather than further north in their Swedish range. The southern population migrates earlier than intermediate to dark buzzards, in both adults and juveniles. A larger proportion of juveniles than of adults migrate in the southern population. Especially adults in the southern population are resident to a higher degree than more northerly breeders.\nThe entire population of the steppe buzzard is strongly migratory, covering substantial distances during migration. In no part of the range do steppe buzzards use the same summering and wintering grounds. Steppe buzzards are slightly gregarious in migration, and travel in variously sized flocks. This race migrates in September to October often from Asia Minor to the Cape of Africa in about a month but does not cross water, following around the Winam Gulf of Lake Victoria rather than crossing the several kilometer wide gulf. Similarly, they will funnel along both sides of the Black Sea. Migratory behavior of steppe buzzards mirrors those of broad-winged &amp; Swainson's hawks (\"Buteo platypterus\" &amp; \"swainsoni\") in every significant way as similar long-distance migrating \"Buteos\", including trans-equatorial movements, avoidance of large bodies of waters and flocking behaviour. Migrating steppe buzzards will rise up with the morning thermals and can cover an average of hundreds of miles a day using the available currents along mountain ridges and other topographic features. The spring migration for steppe buzzards peaks around March\u2013April, but the latest \"vulpinus\" arrive in their breeding grounds by late April or early May. Distances covered by migrating steppe buzzards in one way flights from northern Europe (i.e. Finland or Sweden) to southern Africa have ranged over within a season . For the steppe buzzards from eastern and northern Europe and western Russia (which compromise a majority of all steppe buzzards), peak migratory numbers occur in differing areas in autumn, when the largest recorded movements occurs through Asia Minor such as Turkey, than in spring, when the largest recorded movement are to the south in the Middle East, especially Israel. The two migratory movements barely differ overall until they reach the Middle East and east Africa, where the largest volume of migrants in autumn occurs at the southern part of the Red Sea, around Djibouti and Yemen, while the main volume in spring is in the northernmost strait, around Egypt and Israel. In autumn, numbers of steppe buzzards recorded in migration have ranged up to 32,000 (recorded 1971) in northwestern Turkey (Bosporus) and in northeastern Turkey (Black Sea) up to 205,000 (recorded 1976). Further down in migration, autumn numbers of up to 98,000 have been recorded in passage in Djibouti. Between 150,000 and nearly 466,000 Steppe Buzzard have been recorded migrating through Israel during spring, making this not only the most abundant migratory raptor here but one of the largest raptor migrations anywhere in the world. Migratory movements of southern Africa buzzards largely occur along the major mountain ranges, such as the Drakensberg and Lebombo Mountains. Wintering steppe buzzards occur far more irregularly in Transvaal than Cape region in winter. The onset of migratory movement for steppe buzzards back to the breeding grounds in southern Africa is mainly in March, peaking in the second week. Steppe buzzard molt their feathers rapidly upon arrival at wintering grounds and seems to split their flight feather molt between breeding ground in Eurasia and wintering ground in southern Africa, the molt pausing during migration. In last 50 years, it was recorded that nominate buzzards are typically migrating shorter distances and wintering further north, possibly in response to climate change, resulting in relatively smaller numbers of them at migration sites. They are also extending their breeding range possibly reducing/supplanting steppe buzzards.\nVocalizations.\nResident populations of common buzzards tend to vocalize all year around, whereas migrants tend to vocalize only during the breeding season. Both nominate buzzards and steppe buzzards (and their numerous related subspecies within their types) tend to have similar voices. The main call of the species is a plaintive, far-carrying \"pee-yow\" or \"peee-oo\", used as both contact call and more excitedly in aerial displays. Their call is sharper, more ringing when used in aggression, tends to be more drawn-out and wavering when chasing intruders, sharper, more yelping when as warning when approaching the nest or shorter and more explosive when called in alarm. Other variations of their vocal performances include a cat-like \"mew\", uttered repeatedly on the wing or when perched, especially in display; a repeated \"mah\" has been recorded as uttered by pairs answering each other, further chuckles and croaks have also been recorded at nests. Juveniles can usually be distinguished by the discordant nature of their calls compared to those of adults.\nDietary biology.\nThe common buzzard is a generalist predator which hunts a wide variety of prey given the opportunity. Their prey spectrum extents to a wide variety of vertebrates including mammals, birds (from any age from eggs to adult birds), reptiles, amphibians and, rarely, fish, as well as to various invertebrates, mostly insects. Young animals are often attacked, largely the nidifugous young of various vertebrates. In total well over 300 prey species are known to be taken by common buzzards. Furthermore, prey size can vary from tiny beetles, caterpillars and ants to large adult grouse and rabbits up to nearly twice their body mass. Mean body mass of vertebrate prey was estimated at in Belarus. At times, they will also subsist partially on carrion, usually of dead mammals or fish. However, dietary studies have shown that they mostly prey upon small mammals, largely small rodents. Like many temperate zone raptorial birds of varied lineages, voles are an essential part of the common buzzard's diet. This bird's preference for the interface between woods and open areas frequently puts them in ideal vole habitat. Hunting in relatively open areas has been found to increase hunting success whereas more complete shrub cover lowered success. A majority of prey is taken by dropping from perch, and is normally taken on ground. Alternately, prey may be hunted in a low flight. This species tends not to hunt in a spectacular stoop but generally drops gently then gradually accelerate at bottom with wings held above the back. Sometimes, the buzzard also forages by random glides or soars over open country, wood edges or clearings. Perch hunting may be done preferentially but buzzards fairly regularly also hunt from a ground position when the habitat demands it. Outside the breeding season, as many 15\u201330 buzzards have been recorded foraging on ground in a single large field, especially juveniles. Normally the rarest foraging type is hovering. A study from Great Britain indicated that hovering does not seem to increase hunting success.\nMammals.\nA high diversity of rodents may be taken given the chance, as around 60 species of rodent have been recorded in the foods of common buzzards. It seems clear that voles are the most significant prey type for European buzzards. Nearly every study from the continent makes reference to the importance, in particular, of the two most numerous and widely distributed European voles: the common vole (\"Microtus arvalis\") and the somewhat more northerly ranging field vole (\"Microtus agrestis\"). In southern Scotland, field voles were the best-represented species in pellets, accounting for 32.1% of 581 pellets. In southern Norway, field voles were again the main food in years with peak vole numbers, accounting for 40.8% of 179 prey items in 1985 and 24.7% of 332 prey items in 1994. Altogether, rodents amount to 67.6% and 58.4% of the foods in these respective peak vole years. However, in low vole population years, the contribution of rodents to the diet was minor. As far west as the Netherlands, common voles were the most regular prey, amounting to 19.6% of 6624 prey items in a very large study. Common voles were the main foods recorded in central Slovakia, accounting for 26.5% of 606 prey items. The common vole, or other related vole species at times, were the main foods as well in Ukraine (17.2% of 146 prey items) ranging east to Russia in the Privolshky Steppe Nature Reserve (41.8% of 74 prey items) and in Samara (21.4% of 183 prey items). Other records from Russia and Ukraine show voles ranging from slightly secondary prey to as much as 42.2% of the diet. In Belarus, voles, including \"Microtus\" species and bank voles (\"Myodes glareolus\"), accounted for 34.8% of the biomass on average in 1065 prey items from different study areas over 4 years. At least 12 species of the genus \"Microtus\" are known to be hunted by common buzzards and even this is probably conservative, moreover similar species like lemmings will be taken if available.\nOther rodents are taken largely opportunistically rather than by preference. Several wood mice (\"Apodemus ssp.\") are known to be taken quite frequently but given their preference for activity in deeper woods than the field-forest interfaces preferred, they are rarely more than secondary food items. An exception was in Samara where the yellow-necked mouse (\"Apodemus flavicollis\"), one of the largest of its genus at , made up 20.9%, putting it just behind the common vole in importance. Similarly, tree squirrels are readily taken but rarely important in the foods of buzzards in Europe, as buzzards apparently prefer to avoid taking prey from trees nor do they possess the agility typically necessary to capture significant quantities of tree squirrels. All four ground squirrels that range (mostly) into eastern Europe are also known to be common buzzard prey but little quantitative analysis has gone into how significant such predator-prey relations are. Rodent prey taken have ranged in size from the Eurasian harvest mouse (\"Micromys minutus\") to the non-native, muskrat (\"Ondatra zibethicus\"). Other rodents taken either seldom or in areas where the food habits of buzzards are spottily known include flying squirrels, marmots (presumably very young if taken alive), chipmunks, spiny rats, hamsters, mole-rats, gerbils, jirds and jerboas and occasionally hearty numbers of dormice, although these are nocturnal. Surprisingly little research has gone into the diets of wintering steppe buzzards in southern Africa, considering their numerous status there. However, it has been indicated that the main prey remains consist of rodents such as the four-striped grass mouse (\"Rhabdomys pumilio\") and Cape mole-rats (\"Georychus capensis\").\nOther than rodents, two other groups of mammals can be counted as significant to the diet of common buzzards. One of these main prey types of import in the diets of common buzzards are leporids or lagomorphs, especially the European rabbit (\"Oryctolagus cuniculus\") where it is found in numbers in a wild or feral state. In all dietary studies from Scotland, rabbits were highly important to the buzzard's diet. In southern Scotland, rabbits constituted 40.8% of remains at nests and 21.6% of pellet contents, while lagomorphs (mainly rabbits but also some young hares) were present in 99% of remains in Moray, Scotland. The nutritional richness relative to the commonest prey elsewhere, such as voles, might account for the high productivity of buzzards here. For example, clutch sizes were twice as large on average where rabbits were common (Moray) than were where they were rare (Glen Urquhart). In northern Ireland, an area of interest because it is devoid of any native vole species, rabbits were again the main prey. Here, lagomorphs constituted 22.5% of prey items by number and 43.7% by biomass. While rabbits are non-native, albeit long-established, in the British Isles, in their native area of the Iberian peninsula, rabbits are similarly significant to the buzzard's diet. In Murcia, Spain, rabbits were the most common mammal in the diet, making up 16.8% of 167 prey items. In a large study from northeastern Spain, rabbits were dominant in the buzzard's foods, making up 66.5% of 598 prey items. In the Netherlands, European rabbits were second in number (19.1% of 6624 prey items) only to common voles and the largest contributor of biomass to nests (36.7%). Outside of these (at least historically) rabbit-rich areas, leverets of the common hare species found in Europe can be important supplemental prey. European hare (\"Lepus europaeus\") were the fourth most important prey species in central Poland and the third most significant prey species in Stavropol Krai, Russia. Buzzards normally attack the young of European rabbits and hares. Most of the rabbits taken by buzzard variously been estimated from , and infrequently up to in weight. Similarly, in different areas and the mean weight of brown hares taken in Finland was around . One young mountain hares (\"Lepus timidus\") taken in Norway was estimated to about . However, common buzzards are known to kill adult rabbits at times. This can be supported by remains of relatively large-sized tarsus bones of the rabbit, up to 64mm in length.\nThe other significant mammalian prey type is insectivores, among which more than 20 species are known to be taken by this species, including nearly all the species of shrew, mole and hedgehog found in Europe. Moles are taken particularly often among this order, since as is the case with \"vole-holes\", buzzards probably tend to watch molehills in fields for activity and dive quickly from their perch when one of the subterranean mammals pops up. The most widely found mole in the buzzard's northern range is the European mole (\"Talpa europaea\") and this is one of the more important non-rodent prey items for the species. This species was present in 55% of 101 remains in Glen Urquhart, Scotland and was the second most common prey species (18.6%) in 606 prey items in Slovakia. In Bari, Italy, the Roman mole (\"Talpa romana\"), of similar size to the European species, was the leading identified mammalian prey, making up 10.7% of the diet. The full-size range of insectivores may be taken by buzzards, ranging from the world's smallest mammal (by weight), the Etruscan shrew (\"Suncus etruscus\") to arguably the heaviest insectivore, the European hedgehog (\"Erinaceus europaeus\"). Mammalian prey for common buzzards other than rodents, insectivores, and lagomorphs is rarely taken. Occasionally, some weasels such as least weasel (\"Mustela nivalis\") and stoat (\"Mustela erminea\") are taken, and remains of young pine martens (\"Martes martes\") and adult european polecats (\"Mustela putorius\") was found in buzzard nest. Numerous larger mammals, including medium-sized carnivores such as dogs, cats and foxes and various ungulates, are sometimes eaten as carrion by buzzards, mainly during lean winter months. Still-borns of deer are also visited with some frequency.\nBirds.\nWhen attacking birds, common buzzards chiefly prey on nestlings and fledglings of small to medium-sized birds, largely passerines but also a variety of gamebirds, but sometimes also injured, sickly or unwary but healthy adults. While capable of overpowering birds larger than itself, the common buzzard is usually considered to lack the agility necessary to capture many adult birds, even gamebirds which would presumably be weaker fliers considering their relatively heavy bodies and small wings. The amount of fledgling and younger birds preyed upon relative to adults is variable, however. For example, in the Italian Alps, 72% of birds taken were fledglings or recently fledged juveniles, 19% were nestlings and 8% were adults. On the contrary, in southern Scotland, even though the buzzards were taking relatively large bird prey, largely red grouse (\"Lagopus lagopus scotica\"), 87% of birds taken were reportedly adults. In total, as in many raptorial birds that are far from bird-hunting specialists, birds are the most diverse group in the buzzard's prey spectrum due to the sheer number and diversity of birds, few raptors do not hunt them at least occasionally. Nearly 150 species of bird have been identified in the common buzzard's diet. In general, despite many that are taken, birds usually take a secondary position in the diet after mammals. In northern Scotland, birds were fairly numerous in the foods of buzzards. The most often recorded avian prey and 2nd and 3rd most frequent prey species (after only field voles) in Glen Urquhart, were chaffinch (\"Fringilla coelebs\") and meadow pipits (\"Anthus pratensis\"), with the buzzards taking 195 fledglings of these species against only 90 adults. This differed from Moray where the most frequent avian prey and 2nd most frequent prey species behind the rabbit was the common wood pigeon (\"Columba palumbus\") and the buzzards took four times as many adults relative to fledglings.\nBirds were the primary food for common buzzards in the Italian Alps, where they made up 46% of the diet against mammal which accounted for 29% in 146 prey items. The leading prey species here were Eurasian blackbirds (\"Turdus merula\") and Eurasian jays (\"Garrulus glandarius\"), albeit largely fledglings were taken of both. Birds could also take the leading position in years with low vole populations in southern Norway, in particular thrushes, namely the blackbird, the song thrush (\"Turdus philomelos\") and the redwing (\"Turdus iliacus\"), which were collectively 22.1% of 244 prey items in 1993. In southern Spain, birds were equal in number to mammals in the diet, both at 38.3%, but most remains were classified as \"unidentified medium-sized birds\", although the most often identified species of those that apparently could be determined were Eurasian jays and red-legged partridges (\"Alectoris rufa\"). Similarly, in northern Ireland, birds were roughly equal in import to mammals but most were unidentified corvids. In Seversky Donets, Ukraine, birds and mammals both made up 39.3% of the foods of buzzards. Common buzzards may hunt nearly 80 species passerines and nearly all available gamebirds. Like many other largish raptors, gamebirds are attractive to hunt for buzzards due to their ground-dwelling habits. Buzzards were the most frequent predator in a study of juvenile pheasants in England, accounting for 4.3% of 725 deaths (against 3.2% by foxes, 0.7% by owls and 0.5% by other mammals). They also prey on a wide size range of birds, ranging down to Europe's smallest bird, the goldcrest (\"Regulus regulus\"). Very few individual birds hunted by buzzards weigh more than . However, there have been some particularly large avian kills by buzzards, including any that weigh more or , or about the largest average size of a buzzard, have including adults of mallard (\"Anas platyrhynchos\"), black grouse (\"Tetrao tetrix\"), ring-necked pheasant (\"Phasianus colchicus\"), common raven (\"Corvus corax\") and some of the larger gulls if ambushed on their nests. The largest avian kill by a buzzard, and possibly largest known overall for the species, was an adult female western capercaillie (\"Tetrao urogallus\") that weighed an estimated . At times, buzzards will hunt the young of large birds such as herons and cranes. Other assorted avian prey has included a few species of waterfowl, most available pigeons and doves, cuckoos, swifts, grebes, rails, nearly 20 assorted shorebirds, tubenoses, hoopoes, bee-eaters and several types of woodpecker. Birds with more conspicuous or open nesting areas or habits are more likely to have fledglings or nestlings attacked, such as water birds, while those with more secluded or inaccessible nests, such as pigeons/doves and woodpeckers, adults are more likely to be hunted.\nReptiles and amphibians.\nThe common buzzard may be the most regular avian predator of reptiles and amphibians in Europe apart from the sections where they are sympatric with the largely snake-eating short-toed eagle. In total, the prey spectrum of common buzzards include nearly 50 herpetological prey species. In studies from northern and southern Spain, the leading prey numerically were both reptilian, although in Biscay (northern Spain) the leading prey (19%) was classified as \"unidentified snakes\". In Murcia, the most numerous prey was the ocellated lizard (\"Timon lepidus\"), at 32.9%. In total, at Biscay and Murcia, reptiles accounted for 30.4% and 35.9% of the prey items, respectively. Findings were similar in a separate study from northeastern Spain, where reptiles amounted to 35.9% of prey. In Bari, Italy, reptiles were the main prey, making up almost exactly half of the biomass, led by the large green whip snake (\"Hierophis viridiflavus\"), at 24.2% of food mass. In Stavropol Krai, Russia, the sand lizard (\"Lacerta agilis\") was the main prey at 23.7% of 55 prey items. The slowworm (\"Anguis fragilis\"), a legless lizard, became the most numerous prey for the buzzards of southern Norway in low vole years, amounting to 21.3% of 244 prey items in 1993 and were also common even in the peak vole year of 1994 (19% of 332 prey items). More or less any snake in Europe is potential prey and the buzzard has been known to be uncharacteristically bold in going after and overpowering large snakes such as rat snakes, ranging up to nearly in length, and healthy, large vipers despite the danger of being struck by such prey. However, in at least one case, the corpse of a female buzzard was found envenomed over the body of an adder that it had killed. In some parts of range, the common buzzard acquires the habit of taking many frogs and toads. This was the case in the Mogilev Region of Belarus where the moor frog (\"Rana arvalis\") was the major prey (28.5%) over several years, followed by other frogs and toads amounting to 39.4% of the diet over the years. In central Scotland, the common toad (\"Bufo bufo\") was the most numerous prey species, accounting for 21.7% of 263 prey items, while the common frog (\"Rana temporaria\") made up a further 14.7% of the diet. Frogs made up about 10% of the diet in central Poland as well.\nInvertebrates and other prey.\nWhen common buzzards feed on invertebrates, these are chiefly earthworms, beetles and caterpillars in Europe and largely seemed to be preyed on by juvenile buzzards with less refined hunting skills or in areas with mild winters and ample swarming or social insects. In most dietary studies, invertebrates are at best a minor supplemental contributor to the buzzard's diet. Nonetheless, roughly a dozen beetle species have found in the foods of buzzards from Ukraine alone. In winter in northeastern Spain, it was found that the buzzards switched largely from the vertebrate prey typically taken during spring and summer to a largely insect-based diet. Most of this prey was unidentified but the most frequently identified were European mantis (\"Mantis religiosa\") and European mole cricket (\"Gryllotalpa gryllotalpa\"). In Ukraine, 30.8% of the food by number was found to be insects. Especially in winter quarters such as southern Africa, common buzzards are often attracted to swarming locusts and other orthopterans. In this way the steppe buzzard may mirror a similar long-distance migrant from the Americas, the Swainson's hawk, which feeds its young largely on nutritious vertebrates but switches to a largely insect-based once the reach their distant wintering grounds in South America. In Eritrea, 18 returning migrant steppe buzzards were seen to feed together on swarms of grasshoppers. For wintering steppe buzzards in Zimbabwe, one source went so far as to refer to them as primarily insectivorous, apparently being somewhat locally specialized to feeding on termites. Stomach contents in buzzards from Malawi apparently consisted largely of grasshoppers (alternately with lizards). Fish tend to be the rarest class of prey found in the common buzzard's foods. There are a couple cases of predation of fish detected in the Netherlands, while elsewhere they have been known to have fed upon eels and carp.\nInterspecies predatory relationships.\nCommon buzzards co-occur with dozens of other raptorial birds through their breeding, resident and wintering grounds. There may be many other birds that broadly overlap in prey selection to some extent. Furthermore, their preference for interfaces of forest and field is used heavily by many birds of prey. Some of the most similar species by diet are the common kestrel (\"Falco tinniculus\"), hen harrier (\"Circus cyaenus\") and lesser spotted eagle (\"Clanga clanga\"), not to mention nearly every European species of owl, as all but two may locally prefer rodents such as voles in their diets. Diet overlap was found to be extensive between buzzards and red foxes (\"Vulpes vulpes\") in Poland, with 61.9% of prey selection overlapping by species although the dietary breadth of the fox was broader and more opportunistic. Both fox dens and buzzard roosts were found to be significantly closer to high vole areas relative to the overall environment here. The only other widely found European \"Buteo\", the rough-legged buzzard, comes to winter extensively with common buzzards. It was found in southern Sweden, habitat, hunting and prey selection often overlapped considerably. Rough-legged buzzards appear to prefer slightly more open habitat and took slightly fewer wood mice than common buzzard. Roughlegs also hover much more frequently and are more given to hunting in high winds. The two buzzards are aggressive towards one another and excluded each other from winter feeding territories in similar ways to the way they exclude conspecifics. In northern Germany, the buffer of their habitat preferences apparently accounted for the lack of effect on each other's occupancy between the two buzzard species. Despite a broad range of overlap, very little is known about the ecology of common and long-legged buzzards where they co-exist. However, it can be inferred from the long-legged species preference for predation on differing prey, such as blind mole-rats, ground squirrels, hamsters and gerbils, from the voles usually preferred by the common species, that serious competition for food is unlikely.\nA more direct negative effect has been found in buzzard's co-existence with northern goshawk (\"Accipiter gentilis\"). Despite the considerable discrepancy of the two species dietary habits, habitat selection in Europe is largely similar between buzzards and goshawks. Goshawks are slightly larger than buzzards and are more powerful, agile and generally more aggressive birds, and so they are considered dominant. In studies from Germany and Sweden, buzzards were found to be less disturbance sensitive than goshawks but were probably displaced into inferior nesting spots by the dominant goshawks. The exposure of buzzards to a dummy goshawk was found to decrease breeding success whereas there was no effect on breeding goshawks when they were exposed to a dummy buzzard. In many cases, in Germany and Sweden, goshawks displaced buzzards from their nests to take them over for themselves. In Poland, buzzards productivity was correlated to prey population variations, particularly voles which could vary from 10 to 80 per hectare, whereas goshawks were seemingly unaffected by prey variations; buzzards were found here to number 1.73 pair per against goshawk 1.63 pair per . In contrast, the slightly larger counterpart of buzzards in North America, the red-tailed hawk (which is also slightly larger than American goshawks, the latter averaging smaller than European ones) are more similar in diet to goshawks there. Redtails are not invariably dominated by goshawks and are frequently able to outcompete them by virtue of greater dietary and habitat flexibility. Furthermore, red-tailed hawks are apparently equally capable of killing goshawks as goshawks are of killing them (killings are more one-sided in buzzard-goshawk interactions in favour of the latter). Other raptorial birds, including many of similar or mildly larger size than common buzzards themselves, may dominate or displace the buzzard, especially with aims to take over their nests. Species such as the black kite (\"Milvus migrans\"), booted eagle (\"Hieraeetus pennatus\") and the lesser spotted eagle have been known to displace actively nesting buzzards, although in some cases the buzzards may attempt to defend themselves. The broad range of accipitrids that take over buzzard nests is somewhat unusual. More typically, common buzzards are victims of nest parasitism to owls and falcons, as neither of these other kinds of raptorial birds builds their own nests, but these may regularly take up occupancy on already abandoned or alternate nests rather than ones the buzzards are actively using. Even with birds not traditionally considered raptorial, such as common ravens, may compete for nesting sites with buzzards. In urban vicinities of southwestern England, it was found that peregrine falcons (\"Falco peregrinus\") were harassing buzzards so persistently, in many cases resulting in injury or death for the buzzards, the attacks tending to peak during the falcon's breeding seasons and tend to be focused on subadult buzzards. Despite often being dominated in nesting site confrontations by even similarly sized raptors, buzzards appear to be bolder in direct competition over food with other raptors outside of the context of breeding, and has even been known to displace larger birds of prey such as red kites (\"Milvus milvus\") and female buzzards may also dominate male goshawks (which are much smaller than the female goshawk) at disputed kills.\nCommon buzzards are occasionally threatened by predation by other raptorial birds. Northern goshawks have been known to have preyed upon buzzards in a few cases. Much larger raptors are known to have killed a few buzzards as well, including steppe eagles (\"Aquila nipalensis\") on migrating steppe buzzards in Israel. Further instances of predation on buzzards have involved golden, eastern imperial (\"Aquila heliaca\"), Bonelli's (\"Aquila fasciata\") and white-tailed eagles (\"Haliaeetus albicilla\") in Europe. Besides preying on adult buzzard, white-tailed eagles have been known to raise buzzards with their own young. These are most likely cases of eagles carrying off young buzzard nestlings with the intention of predation but, for unclear reasons, not killing them. Instead the mother eagle comes to brood the young buzzard. Despite the difference of the two species diets, white-tailed eagles are surprisingly successful at raising young buzzards (which are conspicuously much smaller than their own nestlings) to fledging. Studies in Lithuania of white-tailed eagle diets found that predation on common buzzards was more frequent than anticipated, with 36 buzzard remains found in 11 years of study of the summer diet of the white-tailed eagles. While nestling buzzards were multiple times more vulnerable to predation than adult buzzards in the Lithuanian data, the region's buzzards expelled considerable time and energy during the late nesting period trying to protect their nests. The most serious predator of common buzzards, however, is almost certainly the Eurasian eagle-owl (\"Bubo bubo\"). This is a very large owl with a mean body mass about three to four times greater than that of a buzzard. The eagle-owl, despite often taking small mammals that broadly overlap with those selected by buzzards, is considered a \"super-predator\" that is a major threat to nearly all co-existing raptorial birds, capably destroying whole broods of other raptorial birds and dispatching adult raptors even as large as eagles. Due to their large numbers in edge habitats, common buzzards frequently feature heavily in the eagle-owl's diet. Eagle-owls, as will some other large owls, also readily expropriate the nests of buzzards. In the Czech Republic and in Luxembourg, the buzzard was the third and fifth most frequent prey species for eagle-owls, respectively. The reintroduction of eagle-owls to sections of Germany has been found to have a slight deleterious effect on the local occupancy of common buzzards. The only sparing factor is the temporal difference (the buzzard nesting later in the year than the eagle-owl) and buzzards may locally be able to avoid nesting near an active eagle-owl family. As the ecology of the wintering population is relatively little studied, a similar very large owl at the top of the avian food chain, the Verreaux's eagle-owl (\"Bubo lacteus\"), is the only known predator of wintering steppe buzzards in southern Africa. Despite not being known predators of buzzards, other large, vole-eating owls are known to displace or to be avoided by nesting buzzards, such as great grey owls (\"Strix nebulosa\") and Ural owls (\"Strix uralensis\"). Unlike with large birds of prey, next to nothing is known of mammalian predators of common buzzards, despite up to several nestlings and fledglings being likely depredated by mammals.\nCommon buzzards themselves rarely present a threat to other raptorial birds but may occasionally kill a few of those of smaller size. The buzzard is a known predator of Eurasian sparrowhawks (\"Accipiter nisus\"), common kestrel and lesser kestrel (\"Falco naumanni\") . Perhaps surprisingly, given the nocturnal habits of this prey, the group of raptorial birds the buzzard is known to hunt most extensively is owls. Known owl prey has included Western barn owls (\"Tyto alba\"), European scops owls (\"Otus scops\"), tawny owls (\"Strix aluco\"), little owls (\"Athene noctua\"), boreal owls (\"Aegolius funereus\"), long-eared owls (\"Asio otus\") and short-eared owls (\"Asio flammeus\"). Despite their relatively large size, tawny owls are known to avoid buzzards as there are several records of them preying upon the owls.\nBreeding.\nNesting territories and density.\nHome ranges of common buzzards are generally . The size of breeding territory seem to be generally correlated with food supply. In a German study, the range was with an average of . Some of the lowest pair densities of common buzzards seem to come from Russia. For instance, in Kerzhenets Nature Reserve, the recorded density was 0.6 pairs per and the average distance of nearest neighbors was . The Snowdonia region of northern Wales held a pair per with a mean nearest neighbor distance of ; in adjacent Migneint, pair occurrence was , with a mean distance of . In the Teno massif of the Canary Islands, the average density was estimated as 23 pairs per , similar to that of a middling continental population. On another set of islands, on Crete the density of pairs was lower at 5.7 pairs per ; here buzzards tend to have an irregular distribution, some in lower intensity harvest olive groves but their occurrence actually more common in agricultural than natural areas. In the Italian Alps, it was recorded in 1993\u201396 that there were from 28 to 30 pairs per . In central Italy, density average was lower at 19.74 pairs per . Higher density areas are known than those above. Two areas of the Midlands of England showed occupancies of 81 and 22 territorial pairs per . High buzzard densities there were associated with high proportions of unimproved pasture and mature woodland within the estimated territories. Similarly high densities of common buzzards were estimated in central Slovakia using two different methods, here indicating densities of 96 to 129 pairs per . Despite claims from the study of the English midlands were the highest known territory density for the species, a number ranging from 32 to 51 pairs in wooded area of merely in Czech Republic seems to surely exceed even those densities. The Czech study hypothesized that fragmentation of forest in human management of lands for wild sheep and deer, creating exceptional concentrations of prey such as voles, and lack of appropriate habitat in surrounding regions for the exceptionally high density.\nIn the North-Estonian Neeruti landscape reserve (area 1250 ha), Marek Vahula found 9 populated nests in 1989 and 1990. One nest was found in 1982 and is apparently the oldest known nest that is still populated today.\nCommon buzzards maintain their territories through flight displays. In Europe, territorial behaviour generally starts in February. However, displays are not uncommon throughout year in resident pairs, especially by males, and can elicit similar displays by neighbors. In them, common buzzards generally engage in high circling, spiraling upward on slightly raised wings. Mutual high circling by pairs sometimes go on at length, especially during the period prior to or during breeding season. In mutual displays, a pair may follow each other at in level flight. During the mutual displays, the male may engage in exaggerated deep flapping or zig-zag tumbling, apparently in response to the female being too distant. Two or three pairs may circle together at times and as many as 14 individual adults have been recorded over established display sites. Sky-dancing by common buzzards have been recorded in spring and autumn, typically by male but sometimes by female, nearly always with much calling. Their sky-dances are of the rollercoaster type, with upward sweep until they start to stall, but sometimes embellished with loops or rolls at the top. Next in the sky-dance, they dive on more or less closed wings before spreading them and shooting up again, upward sweeps of up to , with dive drops of up to at least . These dances may be repeated in series of 10 to 20. In the climax of the sky dance, the undulations become progressive shallower, often slowing and terminating directly onto a perch. Various other aerial displays include low contour flight or weaving among trees, frequently with deep beats and exaggerated upstrokes which show underwing pattern to rivals perched below. Talon grappling and occasionally cartwheeling downward with feet interlocked has been recorded in buzzards and, as in many raptors, is likely the physical culmination of the aggressive territorial display, especially between males. Despite the highly territorial nature of buzzards and their devotion to a single mate and breeding ground each summer, there is one case of a polyandrous trio of buzzards nesting in the Canary Islands.\nNests.\nCommon buzzards tend to build a bulky nest of sticks, twigs and often heather. Commonly, nests are up to across and deep. With reuse over years, the diameter can reach or exceed and weight of nests can reach over . Active nests tend to be lined with greenery, most often this consists of broad-leafed foliage but sometimes also includes rush or seaweed locally. Nest height in trees is commonly , usually by main trunk or main crutch of the tree. In Germany, trees used for nesting consisted mostly of red beeches (\"Fagus sylvatica\") (in 337 cases), whereas a further 84 were in assorted oaks. Buzzards were recorded to nest almost exclusively in pines in Spain at a mean height of . Trees are generally used for a nesting location but they will also utilize crags or bluffs if trees are unavailable. Buzzards in one English study were surprisingly partial to nesting on well-vegetated banks and due to the rich surrounding environment habitat and prey population, were actually more productive than nests located in other locations here. Furthermore, a few ground nests were recorded in high prey-level agricultural areas in the Netherlands. In the Italian Alps, 81% of 108 nests were on cliffs. The common buzzard generally lacks the propensity of its Nearctic counterpart, the red-tailed hawk, to occasionally nest on or near manmade structures (often in heavily urbanized areas) but in Spain some pairs recorded nesting along the perimeter of abandoned buildings. Pairs often have several nests but some pairs may use one over several consecutive years. Two to four alternate nests in a territory is typical for common buzzards, especially those breeding further north in their range.\nReproduction and eggs.\nThe breeding season commences at differing times based on latitude. Common buzzard breeding seasons may fall as early as January to April but typically the breeding season is March to July in much of Palearctic. In the northern stretches of the range the breeding season may last into May\u2013August. Mating usually occurs on or near the nest and lasts about 15 seconds, typically occurring several times a day. Eggs are usually laid in 2 to 3-day intervals. The clutch size can range from to 2 to 6, a relatively large clutch for an accipitrid. More northerly and westerly buzzard usually bear larger clutches, which average nearer 3, than those further east and south. In Spain, the average clutch size is about 2 to 2.3. From 4 locations in different parts of Europe, 43% had clutch size of 2, 41% had size of 3, clutches of 1 and 4 each constituted about 8%. Laying dates are remarkably constant throughout Great Britain. There are, however, highly significant differences in clutch size between British study areas. These do not follow any latitudinal gradient and it is likely that local factors such as habitat and prey availability are more important determinants of clutch size. The eggs are white in ground colour, rather round in shape with sporadic red to brown markings sometimes lightly showing. In the nominate race, egg size is in height by in diameter with an average of in 600 eggs. In the race of \"vulpinus\", egg height is by with an average of in 303 eggs. Eggs are generally laid in late March to early April in extreme south, sometime in April in most of Europe, into May and possibly even early June in the extreme north. If eggs are lost to a predator (including humans) or fail in some other way, common buzzards do not usually lay replacement clutches but they have been recorded, even with 3 attempts of clutches by a single female. The female does most but not all of the incubating, doing so for a total of 33\u201335 days. The female remains at the nest brooding the young in the early stages with the male bringing all prey. At about 8\u201312 days, both the male and female will bring prey but the female continues to do all feeding until the young can tear up their own prey.\nDevelopment of young.\nOnce hatching commences, it may take 48 hours for the chick to chip out. Hatching may take place over 3\u20137 days, with new hatchlings averaging about in body mass. Often the youngest nestling dies from starvation, especially in broods of three or more. In nestlings, the first down replaces by longer, coarser down at about 7 days of age with the first proper feathers appearing at 12 to 15 days. The young are nearly fully feathered rather than downy at about a month of age and can start to feed themselves as well. The first attempts to leave the nest are often at about 40\u201350 days, averaging usually 40\u201345 in nominate buzzards in Europe, but more quickly on average at 40\u201342 in \"vulpinus\". Fledging occurs typically at 43\u201354 days but in extreme cases at as late 62 days. Sexual dimorphism is apparent in European fledglings, as females often scale about against in males. After leaving the nest, buzzards generally stay close by, but with migratory ones there is more definitive movement generally southbound. Full independence is generally sought 6 to 8 weeks after fledging. 1st year birds generally remain in wintering area for following summer but then return to near area of origin but then migrate south again without breeding. Radio-tracking suggests that most dispersal, even relatively early dispersals, by juvenile buzzards is undertaken independently rather than via exile by parents, as has been recorded in some other birds of prey. In common buzzards, generally speaking, siblings stay quite close to each other after dispersal from their parents and form something of a social group, although parents usually tolerate their presence on their territory until they are laying another clutch. However, the social group of siblings disbands at about a year of age. Juvenile buzzards are subordinate to adults during most encounters and tend to avoid direct confrontations and actively defended territories until they are of appropriate age (usually at least 2 years of age). This was the case as well for steppe buzzard juveniles wintering in southern Africa, although in some cases juveniles were able to successfully steal prey from adults there.\nBreeding success rates.\nNumerous factors may weigh into the breeding success of common buzzards. Chiefly among these are prey populations, habitat, disturbance and persecution levels and innerspecies competition. In Germany, intra- and interspecific competition, plumage morph, laying date, precipitation levels and anthropogenic disturbances in the breeding territory, in declining order, were deemed to be the most significant bearers of breeding success. In an accompanying study, it was found that a mere 17% of adult birds of both sexes present in a German study area produced 50% of offspring, so breeding success may be lower than perceived and many adult buzzards for unknown causes may not attempt to breed at all. High breeding success was detected in Argyll, Scotland, due likely to hearty prey populations (rabbits) but also probably a lower local rate of persecution than elsewhere in the British isles. Here, the mean number of fledglings were 1.75 against 0.82\u20131.41 in other parts of Britain. It was found in the English Midlands that breeding success both by measure of clutch size and mean number of fledglings, was relatively high thanks again to high prey populations. Breeding success was lower farther from significant stands of trees in the Midlands and most nesting failures that could be determined occurred in the incubation stage, possibly in correlation with predation of eggs by corvids. More significant than even prey, late winter-early spring was found to be likely the primary driver of breeding success in buzzards from southern Norway. Here, even in peak vole years, nesting success could be considerably hampered by heavy snow at this crucial stage. In Norway, large clutches of 3+ were expected only in years with minimal snow cover, high vole populations and lighter rains in May\u2013June. In the Italian Alps, the mean number of fledglings per pair was 1.07. 33.4% of nesting attempts were failures per a study in southwestern Germany, with an average of 1.06 of all nesting attempts and 1.61 for all successful attempt. In Germany, weather conditions and rodent populations seemed to be the primary drivers of nesting success. In Murcia part of Spain contrasted with Biscay to the north, higher levels of interspecific competition from booted eagles and northern goshawks did not appear to negatively affect breeding success due to more ample prey populations (rabbits again) in Murcia than in Biscay.\nIn the Westphalia area of Germany, it was found that intermediate colour morphs were more productive than those that were darker or lighter. For reasons that are not entirely clear, apparently fewer parasites were found to afflict broods of intermediate plumaged buzzard less so than dark and light phenotypes, in particular higher melanin levels somehow were found to be more inviting to parasitic organism that effect the health of the buzzard's offspring. The composition of habitat and its relation to human disturbance were important variables for the dark and light phenotypes but were less important to intermediate individuals. Thus selection pressures resulting from different factors did not vary much between sexes but varied between the three phenotypes in the population. Breeding success in areas with wild European rabbits was considerably effected by rabbit myxomatosis and rabbit haemorrhagic disease, both of which have heavily depleted wild rabbit population. Breeding success in formerly rabbit-rich areas were recorded to decrease from as much as 2.6 to as little as 0.9 young per pair. Age of first breeding in several radio-tagged buzzards showed only a single male breeding as early as his 2nd summer (at about a year of age). Significantly more buzzards were found to start breeding at the 3 summer but breeding attempts can be individually erratic given the availability of habitat, food and mates. The mean life expectancy was estimated at 6.3 years in the late 1950s, but this was at a time of high persecution when humans were causing 50\u201380% of buzzard deaths. In a more modern context with regionally reduced persecution rates, the lifespan expected can be higher (possibly in excess of 10 years at times) but is still widely variable due to a wide variety of factors.\nStatus.\nThe common buzzard is one of the most numerous birds of prey in its range. Almost certainly, it is the most numerous diurnal bird of prey throughout Europe. Conservative estimates put the total population at no fewer than 700,000 pairs in Europe, which are more than twice the total estimates for the next four birds of prey estimated as most common: the Eurasian sparrowhawk (more than 340,000 pairs), the common kestrel (more than 330,000 pairs) and the northern goshawk (more than 160,000 pairs). Ferguson-Lees et al. roughly estimated that the total population of the common buzzard ranges to nearly 5 million pairs but at time was including the now split-off species of eastern and Himalayan buzzards in those numbers. These numbers may be excessive but the total population of common buzzards is certain to total well over seven figures. More recently, the IUCN estimated the common buzzard (sans the Himalayan and eastern subspecies) to number somewhere between 2.1 and 3.7 million birds, which would put this buzzard one of the most numerous of all accipitrid family members (estimates for Eurasian sparrowhawks, red-tailed hawks and northern goshawks also may range over 2 million). In 1991, other than their absence in Iceland, after having been extent as breeder by 1910, buzzards recolonized Ireland sometime in the 1950s and has increased by the 1990s to 26 pairs. Supplemental feeding has reportedly helped the Irish buzzard population to rebound, especially where rabbits have decreased. Most other countries have at least four figures of breeding pairs. As of the 1990s, other countries such as Great Britain, France, Switzerland, Czech Republic, Poland, Sweden, Belarus and Ukraine all numbered pairs well into five figures, while Germany had an estimated 140,000 pairs and European Russian may have held 500,000 pairs. Between 44,000 and 61,000 pairs nested in Great Britain by 2001 with numbers gradually increasing after past persecution, habitat alteration and prey reductions, making it by far the most abundant diurnal raptor there. In Westphalia, Germany, population of Buzzards was shown to nearly triple over the last few decades. The Westphalian buzzards are possibly benefiting from increasingly warmer mean climate, which in turn is increasing vulnerability of voles. However, the rate of increase was significantly greater in males than in females, in part because of reintroduced Eurasian eagle-owls to the region preying on nests (including the brooding mother), which may in turn put undue pressure on the local buzzard population.\nAt least 238 common buzzards killed through persecution were recovered in England from 1975 to 1989, largely through poisoning. Persecution did not significantly differ at any time due this span of years nor did the persecution rates decrease, nor did it when compared to rates of last survey of this in 1981. While some persecution persists in England, it is probably slightly less common today. The buzzard was found to be the most vulnerable raptor to power-line collision fatalities in Spain probably as it is one of the most common largish birds, and together with the common raven, it accounted for nearly a third of recorded electrocutions. Given its relative abundance, the common buzzard is held as an ideal bioindicator, as they are effected by a range of pesticide and metal contamination through pollution like other raptors but are largely resilient to these at the population levels. In turn, this allows biologists to study (and harvest if needed) the buzzards intensively and their environments without affecting their overall population. The lack of affect may be due to the buzzard's adaptability as well as its relatively short, terrestrially-based food chain, which exposes them to less risk of contamination and population depletions than raptors that prey more heavily on water-based prey (such as some large eagles) or other birds (such as falcons). Common buzzards are seldom vulnerable to egg-shell thinning from DDT as are other raptors but egg-shell thinning has been recorded. Other factors that negatively effect raptors have been studied in common buzzards are helminths, avipoxvirus and assorted other viruses."}
{"id": "4194", "revid": "10274643", "url": "https://en.wikipedia.org/wiki?curid=4194", "title": "Bohrium", "text": "Bohrium is a synthetic chemical element; it has symbol Bh and atomic number 107. It is named after Danish physicist Niels Bohr. As a synthetic element, it can be created in particle accelerators but is not found in nature. All known isotopes of bohrium are highly radioactive; the most stable known isotope is 270Bh with a half-life of approximately 2.4 minutes, though the unconfirmed 278Bh may have a longer half-life of about 11.5 minutes.\nIn the periodic table, it is a d-block transactinide element. It is a member of the 7th period and belongs to the group 7 elements as the fifth member of the 6d series of transition metals. Chemistry experiments have confirmed that bohrium behaves as the heavier homologue to rhenium in group 7. The chemical properties of bohrium are characterized only partly, but they compare well with the chemistry of the other group 7 elements.\nHistory.\nDiscovery.\nTwo groups claimed discovery of the element. Evidence of bohrium was first reported in 1976 by a Soviet research team led by Yuri Oganessian, in which targets of bismuth-209 and lead-208 were bombarded with accelerated nuclei of chromium-54 and manganese-55, respectively. Two activities, one with a half-life of one to two milliseconds, and the other with an approximately five-second half-life, were seen. Since the ratio of the intensities of these two activities was constant throughout the experiment, it was proposed that the first was from the isotope bohrium-261 and that the second was from its daughter dubnium-257. Later, the dubnium isotope was corrected to dubnium-258, which indeed has a five-second half-life (dubnium-257 has a one-second half-life); however, the half-life observed for its parent is much shorter than the half-lives later observed in the definitive discovery of bohrium at Darmstadt in 1981. The IUPAC/IUPAP Transfermium Working Group (TWG) concluded that while dubnium-258 was probably seen in this experiment, the evidence for the production of its parent bohrium-262 was not convincing enough.\nIn 1981, a German research team led by Peter Armbruster and Gottfried M\u00fcnzenberg at the GSI Helmholtz Centre for Heavy Ion Research (GSI Helmholtzzentrum f\u00fcr Schwerionenforschung) in Darmstadt bombarded a target of bismuth-209 with accelerated nuclei of chromium-54 to produce 5 atoms of the isotope bohrium-262:\nThis discovery was further substantiated by their detailed measurements of the alpha decay chain of the produced bohrium atoms to previously known isotopes of fermium and californium. The IUPAC/IUPAP Transfermium Working Group (TWG) recognised the GSI collaboration as official discoverers in their 1992 report.\nProposed names.\nIn September 1992, the German group suggested the name \"nielsbohrium\" with symbol \"Ns\" to honor the Danish physicist Niels Bohr. The Soviet scientists at the Joint Institute for Nuclear Research in Dubna, Russia had suggested this name be given to element 105 (which was finally called dubnium) and the German team wished to recognise both Bohr and the fact that the Dubna team had been the first to propose the cold fusion reaction, and simultaneously help to solve the controversial problem of the naming of element 105. The Dubna team agreed with the German group's naming proposal for element 107.\nThere was an element naming controversy as to what the elements from 104 to 106 were to be called; the IUPAC adopted \"unnilseptium\" (symbol \"Uns\") as a temporary, systematic element name for this element. In 1994 a committee of IUPAC recommended that element 107 be named \"bohrium\", not \"nielsbohrium\", since there was no precedent for using a scientist's complete name in the naming of an element. This was opposed by the discoverers as there was some concern that the name might be confused with boron and in particular the distinguishing of the names of their respective oxyanions, \"bohrate\" and \"borate\". The matter was handed to the Danish branch of IUPAC which, despite this, voted in favour of the name \"bohrium\", and thus the name \"bohrium\" for element 107 was recognized internationally in 1997; the names of the respective oxyanions of boron and bohrium remain unchanged despite their homophony.\nIsotopes.\nBohrium has no stable or naturally occurring isotopes. Several radioactive isotopes have been synthesized in the laboratory, either by fusing two atoms or by observing the decay of heavier elements. Twelve different isotopes of bohrium have been reported with atomic masses 260\u2013262, 264\u2013267, 270\u2013272, 274, and 278, one of which, bohrium-262, has a known metastable state. All of these but the unconfirmed 278Bh decay only through alpha decay, although some unknown bohrium isotopes are predicted to undergo spontaneous fission.\nThe lighter isotopes usually have shorter half-lives; half-lives of under 100\u00a0ms for 260Bh, 261Bh, 262Bh, and 262mBh were observed. 264Bh, 265Bh, 266Bh, and 271Bh are more stable at around 1\u00a0s, and 267Bh and 272Bh have half-lives of about 10\u00a0s. The heaviest isotopes are the most stable, with 270Bh and 274Bh having measured half-lives of about 2.4\u00a0min and 40\u00a0s respectively, and the even heavier unconfirmed isotope 278Bh appearing to have an even longer half-life of about 11.5 minutes.\nThe most proton-rich isotopes with masses 260, 261, and 262 were directly produced by cold fusion, those with mass 262 and 264 were reported in the decay chains of meitnerium and roentgenium, while the neutron-rich isotopes with masses 265, 266, 267 were created in irradiations of actinide targets. The five most neutron-rich ones with masses 270, 271, 272, 274, and 278 (unconfirmed) appear in the decay chains of 282Nh, 287Mc, 288Mc, 294Ts, and 290Fl respectively. The half-lives of bohrium isotopes range from about ten\u00a0milliseconds for 262mBh to about one\u00a0minute for 270Bh and 274Bh, extending to about 11.5 minutes for the unconfirmed 278Bh, which may have one of the longest half-lives among reported superheavy nuclides.\nPredicted properties.\nVery few properties of bohrium or its compounds have been measured; this is due to its extremely limited and expensive production and the fact that bohrium (and its parents) decays very quickly. A few singular chemistry-related properties have been measured, but properties of bohrium metal remain unknown and only predictions are available.\nChemical.\nBohrium is the fifth member of the 6d series of transition metals and the heaviest member of group 7 in the periodic table, below manganese, technetium and rhenium. All the members of the group readily portray their group oxidation state of +7 and the state becomes more stable as the group is descended. Thus bohrium is expected to form a stable +7 state. Technetium also shows a stable +4 state whilst rhenium exhibits stable +4 and +3 states. Bohrium may therefore show these lower states as well. The higher +7 oxidation state is more likely to exist in oxyanions, such as perbohrate, , analogous to the lighter permanganate, pertechnetate, and perrhenate. Nevertheless, bohrium(VII) is likely to be unstable in aqueous solution, and would probably be easily reduced to the more stable bohrium(IV).\nThe lighter group 7 elements are known to form volatile heptoxides M2O7 (M = Mn, Tc, Re), so bohrium should also form the volatile oxide Bh2O7. The oxide should dissolve in water to form perbohric acid, HBhO4.\nRhenium and technetium form a range of oxyhalides from the halogenation of the oxide. The chlorination of the oxide forms the oxychlorides MO3Cl, so BhO3Cl should be formed in this reaction. Fluorination results in MO3F and MO2F3 for the heavier elements in addition to the rhenium compounds ReOF5 and ReF7. Therefore, oxyfluoride formation for bohrium may help to indicate eka-rhenium properties. Since the oxychlorides are asymmetrical, and they should have increasingly large dipole moments going down the group, they should become less volatile in the order TcO3Cl &gt; ReO3Cl &gt; BhO3Cl: this was experimentally confirmed in 2000 by measuring the enthalpies of adsorption of these three compounds. The values are for TcO3Cl and ReO3Cl are \u221251\u00a0kJ/mol and \u221261\u00a0kJ/mol respectively; the experimental value for BhO3Cl is \u221277.8\u00a0kJ/mol, very close to the theoretically expected value of \u221278.5\u00a0kJ/mol.\nPhysical and atomic.\nBohrium is expected to be a solid under normal conditions and assume a hexagonal close-packed crystal structure (\"c\"/\"a\"\u00a0=\u00a01.62), similar to its lighter congener rhenium. Early predictions by Fricke estimated its density at 37.1\u00a0g/cm3, but newer calculations predict a somewhat lower value of 26\u201327\u00a0g/cm3.\nThe atomic radius of bohrium is expected to be around 128\u00a0pm. Due to the relativistic stabilization of the 7s orbital and destabilization of the 6d orbital, the Bh+ ion is predicted to have an electron configuration of [Rn] 5f14 6d4 7s2, giving up a 6d electron instead of a 7s electron, which is the opposite of the behavior of its lighter homologues manganese and technetium. Rhenium, on the other hand, follows its heavier congener bohrium in giving up a 5d electron before a 6s electron, as relativistic effects have become significant by the sixth period, where they cause among other things the yellow color of gold and the low melting point of mercury. The Bh2+ ion is expected to have an electron configuration of [Rn] 5f14 6d3 7s2; in contrast, the Re2+ ion is expected to have a [Xe] 4f14 5d5 configuration, this time analogous to manganese and technetium. The ionic radius of hexacoordinate heptavalent bohrium is expected to be 58\u00a0pm (heptavalent manganese, technetium, and rhenium having values of 46, 57, and 53\u00a0pm respectively). Pentavalent bohrium should have a larger ionic radius of 83\u00a0pm.\nExperimental chemistry.\nIn 1995, the first report on attempted isolation of the element was unsuccessful, prompting new theoretical studies to investigate how best to investigate bohrium (using its lighter homologs technetium and rhenium for comparison) and removing unwanted contaminating elements such as the trivalent actinides, the group 5 elements, and polonium.\nIn 2000, it was confirmed that although relativistic effects are important, bohrium behaves like a typical group 7 element. A team at the Paul Scherrer Institute (PSI) conducted a chemistry reaction using six atoms of 267Bh produced in the reaction between 249Bk and 22Ne ions. The resulting atoms were thermalised and reacted with a HCl/O2 mixture to form a volatile oxychloride. The reaction also produced isotopes of its lighter homologues, technetium (as 108Tc) and rhenium (as 169Re). The isothermal adsorption curves were measured and gave strong evidence for the formation of a volatile oxychloride with properties similar to that of rhenium oxychloride. This placed bohrium as a typical member of group 7. The adsorption enthalpies of the oxychlorides of technetium, rhenium, and bohrium were measured in this experiment, agreeing very well with the theoretical predictions and implying a sequence of decreasing oxychloride volatility down group 7 of TcO3Cl &gt; ReO3Cl &gt; BhO3Cl.\nThe longer-lived heavy isotopes of bohrium, produced as the daughters of heavier elements, offer advantages for future radiochemical experiments. Although the heavy isotope 274Bh requires a rare and highly radioactive berkelium target for its production, the isotopes 272Bh, 271Bh, and 270Bh can be readily produced as daughters of more easily produced moscovium and nihonium isotopes."}
{"id": "4195", "revid": "1271957786", "url": "https://en.wikipedia.org/wiki?curid=4195", "title": "Barbara Olson", "text": "Barbara Kay Olson (n\u00e9e Bracher; December 27, 1955September 11, 2001) was an American lawyer and conservative television commentator who worked for CNN, Fox News Channel, and several other outlets. She was a passenger on American Airlines Flight 77 en route to a taping of Bill Maher's television show \"Politically Incorrect\" when it was flown into the Pentagon in the September 11 attacks.\nEarly life.\nOlson was born Barbara Kay Bracher in Houston, Texas, on December 27, 1955. Her older sister, Toni Bracher-Lawrence, was a member of the Houston City Council from 2004 to 2010. She graduated from Waltrip High School.\nPersonal life.\nShe married Theodore Olson in 1996, becoming his third wife.\nOlson was a frequent critic of the Bill Clinton administration and wrote a book about then\u2013First Lady Hillary Clinton, \"Hell to Pay: The Unfolding Story of Hillary Rodham Clinton\" (1999). Olson's second book, \"The Final Days: The Last, Desperate Abuses of Power by the Clinton White House\" was published posthumously.\nDeath and legacy.\nOlson was a passenger on American Airlines Flight 77, on her way to a taping of \"Politically Incorrect\" in Los Angeles, when it was flown into the Pentagon in the September 11 attacks.\nHer original plan had been to fly to California on September 10, but she waited until the next day so that she could wake up with her husband on his birthday, September 11. At the National September 11 Memorial, Olson's name is located on Panel S-70 of the South Pool, along with those of other passengers of Flight 77.\nThree months after the attacks, Olson's remains were identified. She was buried at her family's retreat in Wisconsin."}
{"id": "4196", "revid": "48184961", "url": "https://en.wikipedia.org/wiki?curid=4196", "title": "Barnard's Star", "text": "Barnard's Star is a small red dwarf star in the constellation of Ophiuchus. At a distance of from Earth, it is the fourth-nearest-known individual star to the Sun after the three components of the Alpha Centauri system, and is the closest star in the northern celestial hemisphere. Its stellar mass is about 16% of the Sun's, and it has 19% of the Sun's diameter. Despite its proximity, the star has a dim apparent visual magnitude of +9.5 and is invisible to the unaided eye; it is much brighter in the infrared than in visible light.\nThe star is named after Edward Emerson Barnard, an American astronomer who in 1916 measured its proper motion as 10.3 arcseconds per year relative to the Sun, the highest known for any star. The star had previously appeared on Harvard University photographic plates in 1888 and 1890.\nBarnard's Star is among the most studied red dwarfs because of its proximity and favorable location for observation near the celestial equator. Historically, research on Barnard's Star has focused on measuring its stellar characteristics, its astrometry, and also refining the limits of possible extrasolar planets. Although Barnard's Star is ancient, it still experiences stellar flare events, one being observed in 1998.\nBarnard's Star hosts at least one planet, Barnard's Star b, a close-orbiting sub-Earth discovered in 2024, with additional candidates suspected. Previously, it was subject to multiple claims of planets that were disproven.\nNaming.\nIn 2016, the International Astronomical Union organized a Working Group on Star Names (WGSN) to catalogue and standardize proper names for stars. The WGSN approved the name \"Barnard's Star\" for this star on 1 February 2017 and it is now included in the List of IAU-approved Star Names.\nDescription.\nBarnard's Star is a red dwarf of the dim spectral type M4 and is too faint to see without a telescope; its apparent magnitude is 9.5.\nAt 7\u201312 billion years of age, Barnard's Star is considerably older than the Sun, which is 4.5 billion years old, and it might be among the oldest stars in the Milky Way galaxy. Barnard's Star has lost a great deal of rotational energy; the periodic slight changes in its brightness indicate that it rotates once in 130 days (the Sun rotates in 25). Given its age, Barnard's Star was long assumed to be quiescent in terms of stellar activity. In 1998, astronomers observed an intense stellar flare, showing that Barnard's Star is a flare star. Barnard's Star has the variable star designation V2500 Ophiuchi. In 2003, Barnard's Star presented the first detectable change in the radial velocity of a star caused by its motion. Further variability in the radial velocity of Barnard's Star was attributed to its stellar activity.\nThe proper motion of Barnard's Star corresponds to a relative lateral speed of 90km/s. The 10.3 arcseconds it travels in a year amount to a quarter of a degree in a human lifetime, roughly half the angular diameter of the full Moon.\nThe radial velocity of Barnard's Star is , as measured from the blueshift due to its motion toward the Sun. Combined with its proper motion and distance, this gives a \"space velocity\" (actual speed relative to the Sun) of . Barnard's Star will make its closest approach to the Sun around 11,800 CE, when it will approach to within about 3.75 light-years.\nProxima Centauri is the closest star to the Sun at a position currently 4.24 light-years distant from it. However, despite Barnard's Star's even closer pass to the Sun in 11,800 CE, it will still not then be the nearest star, since by that time Proxima Centauri will have moved to a yet-nearer proximity to the Sun. At the time of the star's closest pass by the Sun, Barnard's Star will still be too dim to be seen with the naked eye, since its apparent magnitude will only have increased by one magnitude to about 8.5 by then, still being 2.5 magnitudes short of visibility to the naked eye.\nBarnard's Star has a mass of about 0.16 solar masses (), and a radius about 0.2 times that of the Sun. Thus, although Barnard's Star has roughly 150 times the mass of Jupiter (), its radius is only roughly 2 times larger, due to its much higher density. Its effective temperature is about 3,220 kelvin, and it has a luminosity of only 0.0034 solar luminosities. Barnard's Star is so faint that if it were at the same distance from Earth as the Sun is, it would appear only 100 times brighter than a full moon, comparable to the brightness of the Sun at 80 astronomical units.\nBarnard's Star has 10\u201332% of the solar metallicity. Metallicity is the proportion of stellar mass made up of elements heavier than helium and helps classify stars relative to the galactic population. Barnard's Star seems to be typical of the old, red dwarf population II stars, yet these are also generally metal-poor halo stars. While sub-solar, Barnard's Star's metallicity is higher than that of a halo star and is in keeping with the low end of the metal-rich disk star range; this, plus its high space motion, have led to the designation \"intermediate population II star\", between a halo and disk star. However, some recently published scientific papers have given much higher estimates for the metallicity of the star, very close to the Sun's level, between 75 and 125% of the solar metallicity.\nPlanetary system.\nIn August 2024, by using data from ESPRESSO spectrograph of the Very Large Telescope, the existence of an exoplanet with a minimum mass of and orbital period of 3.15 days was confirmed. This constituted the first convincing evidence for a planet orbiting Barnard's Star. Additionally, three other candidate low-mass planets were proposed in this study. All of these planets orbit closer to the star than the habitable zone. The confirmed planet is designated Barnard's Star b (or Barnard b), a re-use of the designation originally used for the refuted super-Earth candidate. An examination of TESS photometry revealed no planetary transits, implying that the system is not viewed edge-on.\nPrevious planetary claims.\nBarnard's Star has been subject to multiple claims of planets that were later disproven. From the early 1960s to the early 1970s, Peter van de Kamp argued that planets orbited Barnard's Star. His specific claims of large gas giants were refuted in the mid-1970s after much debate. In November 2018, a candidate super-Earth planetary companion was reported to orbit Barnard's Star. It was believed to have a minimum mass of and orbit at . However, work presented in July 2021 refuted the existence of this planet.\nAstrometric planetary claims.\nFor a decade from 1963 to about 1973, a substantial number of astronomers accepted a claim by Peter van de Kamp that he had detected, by using astrometry, a perturbation in the proper motion of Barnard's Star consistent with its having one or more planets comparable in mass with Jupiter. Van de Kamp had been observing the star from 1938, attempting, with colleagues at the Sproul Observatory at Swarthmore College, to find minuscule variations of one micrometre in its position on photographic plates consistent with orbital perturbations that would indicate a planetary companion; this involved as many as ten people averaging their results in looking at plates, to avoid systemic individual errors. \nVan de Kamp's initial suggestion was a planet having about at a distance of 4.4AU in a slightly eccentric orbit, and these measurements were apparently refined in a 1969 paper. Later that year, Van de Kamp suggested that there were two planets of 1.1 and .\nOther astronomers subsequently repeated Van de Kamp's measurements, and two papers in 1973 undermined the claim of a planet or planets. George Gatewood and Heinrich Eichhorn, at a different observatory and using newer plate measuring techniques, failed to verify the planetary companion. Another paper published by John L. Hershey four months earlier, also using the Swarthmore observatory, found that changes in the astrometric field of various stars correlated to the timing of adjustments and modifications that had been carried out on the refractor telescope's objective lens; the claimed planet was attributed to an artifact of maintenance and upgrade work. The affair has been discussed as part of a broader scientific review.\nVan de Kamp never acknowledged any error and published a further claim of two planets' existence as late as 1982; he died in 1995. Wulff Heintz, Van de Kamp's successor at Swarthmore and an expert on double stars, questioned his findings and began publishing criticisms from 1976 onwards. The two men were reported to have become estranged because of this.\nRefuted 2018 planetary claim.\nIn November 2018, an international team of astronomers announced the detection by radial velocity of a candidate super-Earth orbiting in relatively close proximity to Barnard's Star. Led by Ignasi Ribas of Spain their work, conducted over two decades of observation, provided strong evidence of the planet's existence. However, the existence of the planet was refuted in 2021, when the radial velocity signal was found to originate from long-term activity on the star itself, related to its rotation. Further studies in the following years confirmed this result.\nDubbed Barnard's Star b, the planet was thought to be near the stellar system's snow line, which is an ideal spot for the icy accretion of proto-planetary material. It was thought to orbit at 0.4AU every 233 days and had a proposed minimum mass of . The planet would have most likely been frigid, with an estimated surface temperature of about , and lie outside Barnard Star's presumed habitable zone. Direct imaging of the planet and its tell-tale light signature would have been possible in the decade after its discovery. Further faint and unaccounted-for perturbations in the system suggested there may be a second planetary companion even farther out.\nRefining planetary boundaries.\nFor the more than four decades between van de Kamp's rejected claim and the eventual announcement of a planet candidate, Barnard's Star was carefully studied and the mass and orbital boundaries for possible planets were slowly tightened. M dwarfs such as Barnard's Star are more easily studied than larger stars in this regard because their lower masses render perturbations more obvious.\nNull results for planetary companions continued throughout the 1980s and 1990s, including interferometric work with the Hubble Space Telescope in 1999. Gatewood was able to show in 1995 that planets with were impossible around Barnard's Star, in a paper which helped refine the negative certainty regarding planetary objects in general. In 1999, the Hubble work further excluded planetary companions of with an orbital period of less than 1,000 days (Jupiter's orbital period is 4,332 days), while Kuerster determined in 2003 that within the habitable zone around Barnard's Star, planets are not possible with an \"\"M\" sin \"i\" value greater than 7.5 times the mass of the Earth (), or with a mass greater than 3.1 times the mass of Neptune (much lower than van de Kamp's smallest suggested value).\nIn 2013, a research paper was published that further refined planet mass boundaries for the star. Using radial velocity measurements, taken over a period of 25 years, from the Lick and Keck Observatories and applying Monte Carlo analysis for both circular and eccentric orbits, upper masses for planets out to 1,000-day orbits were determined. Planets above two Earth masses in orbits of less than 10 days were excluded, and planets of more than ten Earth masses out to a two-year orbit were also confidently ruled out. It was also discovered that the habitable zone of the star seemed to be devoid of roughly Earth-mass planets or larger, save for face-on orbits.\nEven though this research greatly restricted the possible properties of planets around Barnard's Star, it did not rule them out completely as terrestrial planets were always going to be difficult to detect. NASA's Space Interferometry Mission, which was to begin searching for extrasolar Earth-like planets, was reported to have chosen Barnard's Star as an early search target, however the mission was shut down in 2010. ESA's similar Darwin interferometry mission had the same goal, but was stripped of funding in 2007.\nThe analysis of radial velocities that eventually led to the announcement of a candidate super-Earth orbiting Barnard's Star was also used to set more precise upper mass limits for possible planets, up to and within the habitable zone: a maximum of up to the inner edge and on the outer edge of the optimistic habitable zone, corresponding to orbital periods of up to 10 and 40 days respectively. Therefore, it appears that Barnard's Star indeed does not host Earth-mass planets or larger, in hot and temperate orbits, unlike other M-dwarf stars that commonly have these types of planets in close-in orbits.\nStellar flares.\n1998.\nIn 1998 a stellar flare on Barnard's Star was detected based on changes in the spectral emissions on 17 July during an unrelated search for variations in the proper motion. Four years passed before the flare was fully analyzed, at which point it was suggested that the flare's temperature was 8,000K, more than twice the normal temperature of the star. Given the essentially random nature of flares, Diane Paulson, one of the authors of that study, noted that \"the star would be fantastic for amateurs to observe\".\nThe flare was surprising because intense stellar activity is not expected in stars of such age. Flares are not completely understood, but are believed to be caused by strong magnetic fields, which suppress plasma convection and lead to sudden outbursts: strong magnetic fields occur in rapidly rotating stars, while old stars tend to rotate slowly. For Barnard's Star to undergo an event of such magnitude is thus presumed to be a rarity. Research on the star's periodicity, or changes in stellar activity over a given timescale, also suggest it ought to be quiescent; 1998 research showed weak evidence for periodic variation in the star's brightness, noting only one possible starspot over 130 days.\nStellar activity of this sort has created interest in using Barnard's Star as a proxy to understand similar stars. It is hoped that photometric studies of its X-ray and UV emissions will shed light on the large population of old M dwarfs in the galaxy. Such research has astrobiological implications: given that the habitable zones of M dwarfs are close to the star, any planet located therein would be strongly affected by solar flares, stellar winds, and plasma ejection events.\n2019.\nIn 2019, two additional ultraviolet stellar flares were detected, each with far-ultraviolet energy of 3\u00d71022 joules, together with one X-ray stellar flare with energy 1.6\u00d71022 joules. The flare rate observed to date is enough to cause loss of 87 Earth atmospheres per billion years through thermal processes and \u22483 Earth atmospheres per billion years through ion loss processes on Barnard's Star b.\nEnvironment.\nBarnard's Star shares much the same neighborhood as the Sun. The neighbors of Barnard's Star are generally of red dwarf size, the smallest and most common star type. Its closest neighbor is currently the red dwarf Ross 154, at a distance of 1.66 parsecs (5.41 light-years). The Sun (5.98 light-years) and Alpha Centauri (6.47 light-years) are, respectively, the next closest systems. From Barnard's Star, the Sun would appear on the diametrically opposite side of the sky at coordinates RA=, Dec=, in the westernmost part of the constellation Monoceros. The absolute magnitude of the Sun is 4.83, and at a distance of 1.834 parsecs, it would be a first-magnitude star, as Pollux is from the Earth.\nProposed exploration.\nProject Daedalus.\nBarnard's Star was studied as part of Project Daedalus. Undertaken between 1973 and 1978, the study suggested that rapid, uncrewed travel to another star system was possible with existing or near-future technology. Barnard's Star was chosen as a target partly because it was believed to have planets.\nThe theoretical model suggested that a nuclear pulse rocket employing nuclear fusion (specifically, electron bombardment of deuterium and helium-3) and accelerating for four years could achieve a velocity of 12% of the speed of light. The star could then be reached in 50 years, within a human lifetime. Along with detailed investigation of the star and any companions, the interstellar medium would be examined and baseline astrometric readings performed.\nThe initial Project Daedalus model sparked further theoretical research. In 1980, Robert Freitas suggested a more ambitious plan: a self-replicating spacecraft intended to search for and make contact with extraterrestrial life. Built and launched in Jupiter's orbit, it would reach Barnard's Star in 47 years under parameters similar to those of the original Project Daedalus. Once at the star, it would begin automated self-replication, constructing a factory, initially to manufacture exploratory probes and eventually to create a copy of the original spacecraft after 1,000 years."}
{"id": "4199", "revid": "1265255280", "url": "https://en.wikipedia.org/wiki?curid=4199", "title": "Bayer designation", "text": "A Bayer designation is a stellar designation in which a specific star is identified by a Greek or Latin letter followed by the genitive form of its parent constellation's Latin name. The original list of Bayer designations contained 1564 stars. The brighter stars were assigned their first systematic names by the German astronomer Johann Bayer in 1603, in his star atlas \"Uranometria\". Bayer catalogued only a few stars too far south to be seen from Germany, but later astronomers (including Nicolas-Louis de Lacaille and Benjamin Apthorp Gould) supplemented Bayer's catalog with entries for southern constellations.\nScheme.\nBayer assigned a lowercase Greek letter (alpha (\u03b1), beta (\u03b2), gamma (\u03b3), etc.) or a Latin letter (A, b, c, etc.) to each star he catalogued, combined with the Latin name of the star's parent constellation in genitive (possessive) form. The constellation name is frequently abbreviated to a standard three-letter form. For example, Aldebaran in the constellation Taurus (the Bull) is designated \"\u03b1\u00a0Tauri\" (abbreviated \"\u03b1\u00a0Tau\", pronounced \"Alpha Tauri\"), which means \"Alpha of the Bull\".\nBayer used Greek letters for the brighter stars, but the Greek alphabet has only twenty-four letters, while a single constellation may contain fifty or more stars visible to the naked eye. When the Greek letters ran out, Bayer continued with Latin letters: uppercase \"A\", followed by lowercase \"b\" through \"z\" (omitting \"j\" and \"v\", but \"o\" was included), for a total of another 24\u00a0letters.\nBayer did not label \"permanent\" stars with uppercase letters (except for \"A\", which he used instead of \"a\" to avoid confusion with \"\u03b1\"). However, a number of stars in southern constellations have uppercase letter designations, like B Centauri and G Scorpii. These letters were assigned by later astronomers, notably Lacaille in his \"Coelum Australe Stelliferum\" and Gould in his \"Uranometria Argentina\". Lacaille followed Bayer's use of Greek letters, but this was insufficient for many constellations. He used first the lowercase letters, starting with \"a\", and if needed the uppercase letters, starting with \"A\", thus deviating somewhat from Bayer's practice. Lacaille used the Latin alphabet three times over in the large constellation Argo Navis, once for each of the three areas that are now the constellations of Carina, Puppis and Vela. That was still insufficient for the number of stars, so he also used uppercase Latin letters such as N\u00a0Velorum and Q Puppis. Lacaille assigned uppercase letters between R and Z in several constellations, but these have either been dropped to allow the assignment of those letters to variable stars or have actually turned out to be variable.\nOrder by magnitude class.\nIn most constellations, Bayer assigned Greek and Latin letters to stars within a constellation in rough order of apparent brightness, from brightest to dimmest. The order is not necessarily a precise labeling from brightest to dimmest: in Bayer's day stellar brightness could not be measured precisely. Instead, stars were traditionally assigned to one of six magnitude classes (the brightest to first magnitude, the dimmest to sixth), and Bayer typically ordered stars within a constellation by class: all the first-magnitude stars (in some order), followed by all the second-magnitude stars, and so on. Within each magnitude class, Bayer made no attempt to arrange stars by relative brightness. As a result, the brightest star in each class did not always get listed first in Bayer's order\u2014and the brightest star overall did not necessarily get the designation \"Alpha\". A good example is the constellation Gemini, where Pollux is Beta Geminorum and the slightly dimmer Castor is Alpha Geminorum.\nIn addition, Bayer did not always follow the magnitude class rule; he sometimes assigned letters to stars according to their location within a constellation, or the order of their rising, or to historical or mythological details. Occasionally the order looks quite arbitrary.\nOf the 88 modern constellations, there are at least 30 in which Alpha is not the brightest star, and four of those lack a star labeled \"Alpha\" altogether. The constellations with no Alpha-designated star include Vela and Puppis\u2014both formerly part of Argo Navis, whose Greek-letter stars were split among three constellations. Canopus, the former \u03b1 Argus, is now \u03b1 Carinae in the modern constellation Carina. Norma's Alpha and Beta were reassigned to Scorpius and re-designated N and H Scorpii respectively, leaving Norma with no Alpha. Francis Baily died before designating an Alpha in Leo Minor, so it also has no Alpha. (The star 46 Leonis Minoris would have been the obvious candidate.)\nOrion as an example.\nIn Orion, Bayer first designated Betelgeuse and Rigel, the two 1st-magnitude stars (those of magnitude 1.5 or less), as Alpha and Beta from north to south, with Betelgeuse (the shoulder) coming ahead of Rigel (the foot), even though the latter is usually the brighter. (Betelgeuse is a variable star and can at its maximum occasionally outshine Rigel.) Bayer then repeated the procedure for the stars of the 2nd magnitude, labeling them from \"gamma\" through \"zeta\" in \"top-down\" (north-to-south) order. Letters as far as Latin \"p\" were used for stars of the sixth magnitude.\nBayer's miscellaneous labels.\nAlthough Bayer did not use uppercase Latin letters (except \"A\") for \"fixed stars\", he did use them to label other items shown on his charts, such as neighboring constellations, \"temporary stars\", miscellaneous astronomical objects, or reference lines like the Tropic of Cancer. In Cygnus, for example, Bayer's fixed stars run through \"g\", and on this chart Bayer employs \"H\" through \"P\" as miscellaneous labels, mostly for neighboring constellations. Bayer did not intend such labels as catalog designations, but some have survived to refer to astronomical objects: P Cygni for example is still used as a designation for Nova Cyg 1600. Tycho's Star (SN 1572), another \"temporary star\", appears as B Cassiopeiae. In charts for constellations that did not exhaust the Greek letters, Bayer sometimes used the leftover Greek letters for miscellaneous labels as well.\nRevised designations.\nPtolemy designated four stars as \"border stars\", each shared by two constellations: Alpheratz (in Andromeda and Pegasus), Elnath (in Taurus and Auriga), Nu Bo\u00f6tis (Nu1 and Nu2)(in Bo\u00f6tes and Hercules) and Fomalhaut (in Piscis Austrinus and Aquarius). Bayer assigned the first three of these stars a Greek letter from both constellations: , , and . (He catalogued Fomalhaut only once, as Alpha Piscis Austrini.) When the International Astronomical Union (IAU) assigned definite boundaries to the constellations in 1930, it declared that stars and other celestial objects can belong to only one constellation. Consequently, the redundant second designation in each pair above has dropped out of use.\nBayer assigned two stars duplicate names by mistake: (duplicated as ) and (Kappa1 and Kappa2) (duplicated as ). He corrected these in a later atlas, and the duplicate names were no longer used.\nOther cases of multiple Bayer designations arose when stars named by Bayer in one constellation were transferred by later astronomers to a different constellation. Bayer's Gamma and Omicron Scorpii, for example, were later reassigned from Scorpius to Libra and given the new names Sigma and Upsilon Librae. (To add to the confusion, the star now known as Omicron Scorpii was not named by Bayer but was assigned the designation o Scorpii (Latin lowercase 'o') by Lacaille\u2014which later astronomers misinterpreted as omicron once Bayer's omicron had been reassigned to Libra.)\nA few stars no longer lie (according to the modern constellation boundaries) within the constellation for which they are named. The proper motion of Rho Aquilae, for example, carried it across the boundary into Delphinus in 1992.\nA further complication is the use of numeric superscripts to distinguish neighboring stars that Bayer (or a later astronomer) labeled with a common letter. Usually these are double stars (mostly optical doubles rather than true binary stars), but there are some exceptions such as the chain of stars \u03c01, \u03c02, \u03c03, \u03c04, \u03c05 and \u03c06 Orionis. The most stars given the same Bayer designation but with an extra number attached to it is Psi Aurigae. (\u03c81, \u03c82, \u03c83, \u03c84, \u03c85, \u03c86, \u03c87, \u03c88, \u03c89, \u03c810, although according to the modern IAU constellation boundaries, \u03c810 lies in Lynx)."}
{"id": "4200", "revid": "3492060", "url": "https://en.wikipedia.org/wiki?curid=4200", "title": "Bo\u00f6tes", "text": "Bo\u00f6tes ( ) is a constellation in the northern sky, located between 0\u00b0 and +60\u00b0 declination, and 13 and 16 hours of right ascension on the celestial sphere. The name comes from , which comes from 'herdsman' or 'plowman' (literally, 'ox-driver'; from \"bo\u00fbs\" 'cow').\nOne of the 48 constellations described by the 2nd-century astronomer Ptolemy, Bo\u00f6tes is now one of the 88 modern constellations. It contains the fourth-brightest star in the night sky, the orange giant Arcturus. Epsilon Bo\u00f6tis, or Izar, is a colourful multiple star popular with amateur astronomers. Bo\u00f6tes is home to many other bright stars, including eight above the fourth magnitude and an additional 21 above the fifth magnitude, making a total of 29 stars easily visible to the naked eye.\nHistory and mythology.\nIn ancient Babylon, the stars of Bo\u00f6tes were known as SHU.PA. They were apparently depicted as the god Enlil, who was the leader of the Babylonian pantheon and special patron of farmers. Bo\u00f6tes may have been represented by the animal foreleg constellation in ancient Egypt, resembling that of an ox sufficiently to have been originally proposed as the \"foreleg of ox\" by Berio. \nHomer mentions Bo\u00f6tes in the \"Odyssey\" as a celestial reference for navigation, describing it as \"late-setting\" or \"slow to set\". Exactly whom Bo\u00f6tes is supposed to represent in Greek mythology is not clear. According to one version, he was a son of Demeter, Philomenus, twin brother of Plutus, a plowman who drove the oxen in the constellation Ursa Major. This agrees with the constellation's name. The ancient Greeks saw the asterism now called the \"Big Dipper\" or \"Plough\" as a cart with oxen. Some myths say that Bo\u00f6tes invented the plow and was memorialized for his ingenuity as a constellation.\nAnother myth associated with Bo\u00f6tes by Hyginus is that of Icarius, who was schooled as a grape farmer and winemaker by Dionysus. Icarius made wine so strong that those who drank it appeared poisoned, which caused shepherds to avenge their supposedly poisoned friends by killing Icarius. Maera, Icarius' dog, brought his daughter Erigone to her father's body, whereupon both she and the dog died by suicide. Zeus then chose to honor all three by placing them in the sky as constellations: Icarius as Bo\u00f6tes, Erigone as Virgo, and Maera as Canis Major or Canis Minor.\nFollowing another reading, the constellation is identified with Arcas and also referred to as Arcas and Arcturus, son of Zeus and Callisto. Arcas was brought up by his maternal grandfather Lycaon, to whom one day Zeus went and had a meal. To verify that the guest was really the king of the gods, Lycaon killed his grandson and prepared a meal made from his flesh. Zeus noticed and became very angry, transforming Lycaon into a wolf and giving life back to his son. In the meantime Callisto had been transformed into a she-bear by Zeus's wife Hera, who was angry at Zeus's infidelity. This is corroborated by the Greek name for Bo\u00f6tes, \"Arctophylax\", which means \"Bear Watcher\".\nCallisto, in the form of a bear was almost killed by her son, who was out hunting. Zeus rescued her, taking her into the sky where she became Ursa Major, \"the Great Bear\". Arcturus, the name of the constellation's brightest star, comes from the Greek word meaning \"guardian of the bear\". Sometimes Arcturus is depicted as leading the hunting dogs of nearby Canes Venatici and driving the bears of Ursa Major and Ursa Minor.\nSeveral former constellations were formed from stars now included in Bo\u00f6tes. Quadrans Muralis, the Quadrant, was a constellation created near Beta Bo\u00f6tis from faint stars. It was designated in 1795 by J\u00e9r\u00f4me Lalande, an astronomer who used a quadrant to perform detailed astronometric measurements. Lalande worked with Nicole-Reine Lepaute and others to predict the 1758 return of Halley's Comet. Quadrans Muralis was formed from the stars of eastern Bo\u00f6tes, western Hercules and Draco. It was originally called \"Le Mural\" by Jean Fortin in his 1795 \"Atlas C\u00e9leste\"; it was not given the name \"Quadrans Muralis\" until Johann Bode's 1801 \"Uranographia\". The constellation was quite faint, with its brightest stars reaching the 5th magnitude. Mons Maenalus, representing the Maenalus mountains, was created by Johannes Hevelius in 1687 at the foot of the constellation's figure. The mountain was named for the son of Lycaon, Maenalus. The mountain, one of Diana's hunting grounds, was also holy to Pan.\nNon-Western astronomy.\nThe stars of Bo\u00f6tes were incorporated into many different Chinese constellations. Arcturus was part of the most prominent of these, variously designated as the celestial king's throne (\"Tian Wang\") or the Blue Dragon's horn (\"Daijiao\"); the name \"Daijiao\", meaning \"great horn\", is more common. Arcturus was given such importance in Chinese celestial mythology because of its status marking the beginning of the lunar calendar, as well as its status as the brightest star in the northern night sky.\nTwo constellations flanked \"Daijiao\": \"Yousheti\" to the right and \"Zuosheti\" to the left; they represented companions that orchestrated the seasons. \"Zuosheti\" was formed from modern Zeta, Omicron and Pi Bo\u00f6tis, while \"Yousheti\" was formed from modern Eta, Tau and Upsilon Bo\u00f6tis. \"Dixi\", the Emperor's ceremonial banquet mat, was north of Arcturus, consisting of the stars 12, 11 and 9 Bo\u00f6tis. Another northern constellation was \"Qigong\", the Seven Dukes, which mostly straddled the Bo\u00f6tes-Hercules border. It included either Delta Bo\u00f6tis or Beta Bo\u00f6tis as its terminus.\nThe other Chinese constellations made up of the stars of Bo\u00f6tes existed in the modern constellation's north; they are all representations of weapons. \"Tianqiang\", the spear, was formed from Iota, Kappa and Theta Bo\u00f6tis; \"Genghe\", variously representing a lance or shield, was formed from Epsilon, Rho and Sigma Bo\u00f6tis.\nThere were also two weapons made up of a singular star. \"Xuange\", the halberd, was represented by Lambda Bo\u00f6tis, and \"Zhaoyao\", either the sword or the spear, was represented by Gamma Bo\u00f6tis.\nTwo Chinese constellations have an uncertain placement in Bo\u00f6tes. \"Kangchi\", the lake, was placed south of Arcturus, though its specific location is disputed. It may have been placed entirely in Bo\u00f6tes, on either side of the Bo\u00f6tes-Virgo border, or on either side of the Virgo-Libra border. The constellation \"Zhouding\", a bronze tripod-mounted container used for food, was sometimes cited as the stars 1, 2 and 6 Bo\u00f6tis. However, it has also been associated with three stars in Coma Berenices.\nBo\u00f6tes is also known to Native American cultures. In Yup'ik language, Bo\u00f6tes is \"Taluyaq\", literally \"fish trap,\" and the funnel-shaped part of the fish trap is known as \"Ilulirat.\"\nCharacteristics.\nBo\u00f6tes is a constellation bordered by Virgo to the south, Coma Berenices and Canes Venatici to the west, Ursa Major to the northwest, Draco to the northeast, and Hercules, Corona Borealis and Serpens Caput to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is \"Boo\". The official constellation boundaries, as set by Belgian astronomer Eug\u00e8ne Delporte in 1930, are defined by a polygon of 16 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates stretch from +7.36\u00b0 to +55.1\u00b0. Covering 907 square degrees, Bo\u00f6tes culminates at midnight around 2 May and ranks 13th in area.\nColloquially, its pattern of stars has been likened to a kite or ice cream cone. However, depictions of Bo\u00f6tes have varied historically. Aratus described him circling the north pole, herding the two bears. Later ancient Greek depictions, described by Ptolemy, have him holding the reins of his hunting dogs (Canes Venatici) in his left hand, with a spear, club, or staff in his right hand. After Hevelius introduced Mons Maenalus in 1681, Bo\u00f6tes was often depicted standing on the Peloponnese mountain. By 1801, when Johann Bode published his \"Uranographia\", Bo\u00f6tes had acquired a sickle, which was also held in his left hand.\nThe placement of Arcturus has also been mutable through the centuries. Traditionally, Arcturus lay between his thighs, as Ptolemy depicted him. However, Germanicus Caesar deviated from this tradition by placing Arcturus \"where his garment is fastened by a knot\".\nFeatures.\nStars.\nIn his \"Uranometria\", Johann Bayer used the Greek letters alpha through to omega and then A to k to label what he saw as the most prominent 35 stars in the constellation, with subsequent astronomers splitting Kappa, Mu, Nu and Pi as two stars each. Nu is also the same star as Psi Herculis. John Flamsteed numbered 54 stars for the constellation.\nLocated 36.7 light-years from Earth, Arcturus, or Alpha Bo\u00f6tis, is the brightest star in Bo\u00f6tes and the fourth-brightest star in the sky at an apparent magnitude of \u22120.05; It is also the brightest star north of the celestial equator, just shading out Vega and Capella. Its name comes from the Greek for \"bear-keeper\". An orange giant of spectral class K1.5III, Arcturus is an ageing star that has exhausted its core supply of hydrogen and cooled and expanded to a diameter of 27 solar diameters, equivalent to approximately 32 million kilometers. Though its mass is approximately one solar mass (), Arcturus shines with 133 times the luminosity of the Sun ().\nBayer located Arcturus above the Herdman's left knee in his \"Uranometria\". Nearby Eta Bo\u00f6tis, or Muphrid, is the uppermost star denoting the left leg. It is a 2.68-magnitude star 37 light-years distant with a spectral class of G0IV, indicating it has just exhausted its core hydrogen and is beginning to expand and cool. It is 9 times as luminous as the Sun and has 2.7 times its diameter. Analysis of its spectrum reveals that it is a spectroscopic binary. Muphrid and Arcturus lie only 3.3 light-years away from each other. Viewed from Arcturus, Muphrid would have a visual magnitude of \u22122\u00bd, while Arcturus would be around visual magnitude \u22124\u00bd when seen from Muphrid.\nMarking the herdsman's head is Beta Bo\u00f6tis, or Nekkar, a yellow giant of magnitude 3.5 and spectral type G8IIIa. Like Arcturus, it has expanded and cooled off the main sequence\u2014likely to have lived most of its stellar life as a blue-white B-type main sequence star. Its common name comes from the Arabic phrase for \"ox-driver\". It is 219 light-years away and has a luminosity of .\nLocated 86 light-years distant, Gamma Bo\u00f6tis, or Seginus, is a white giant star of spectral class A7III, with a luminosity 34 times and diameter 3.5 times that of the Sun. It is a Delta Scuti variable, ranging between magnitudes 3.02 and 3.07 every 7 hours. These stars are short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study asteroseismology.\nDelta Bo\u00f6tis is a wide double star with a primary of magnitude 3.5 and a secondary of magnitude 7.8. The primary is a yellow giant that has cooled and expanded to 10.4 times the diameter of the Sun. Of spectral class G8IV, it is around 121 light-years away, while the secondary is a yellow main sequence star of spectral type G0V. The two are thought to take 120,000 years to orbit each other.\nMu Bo\u00f6tis, known as Alkalurops, is a triple star popular with amateur astronomers. It has an overall magnitude of 4.3 and is 121 light-years away. Its name is from the Arabic phrase for \"club\" or \"staff\". The primary appears to be of magnitude 4.3 and is blue-white. The secondary appears to be of magnitude 6.5, but is actually a close double star itself with a primary of magnitude 7.0 and a secondary of magnitude 7.6. The secondary and tertiary stars have an orbital period of 260 years. The primary has an absolute magnitude of 2.6 and is of spectral class F0. The secondary and tertiary stars are separated by 2 arcseconds; the primary and secondary are separated by 109.1 arcseconds at an angle of 171 degrees.\nNu Bo\u00f6tis is an optical double star. The primary is an orange giant of magnitude 5.0 and the secondary is a white star of magnitude 5.0. The primary is 870 light-years away and the secondary is 430 light-years.\nEpsilon Bo\u00f6tis, also known as \"Izar\" or \"Pulcherrima\", is a close triple star popular with amateur astronomers and the most prominent binary star in Bo\u00f6tes. The primary is a yellow- or orange-hued magnitude 2.5 giant star, the secondary is a magnitude 4.6 blue-hued main-sequence star, and the tertiary is a magnitude 12.0 star. The system is 210 light-years away. The name \"Izar\" comes from the Arabic word for \"girdle\" or \"loincloth\", referring to its location in the constellation. The name \"Pulcherrima\" comes from the Latin phrase for \"most beautiful\", referring to its contrasting colors in a telescope. The primary and secondary stars are separated by 2.9 arcseconds at an angle of 341 degrees; the primary's spectral class is K0 and it has a luminosity of . To the naked eye, Izar has a magnitude of 2.37.\nNearby Rho and Sigma Bo\u00f6tis denote the herdsman's waist. Rho is an orange giant of spectral type K3III located around 160 light-years from Earth. It is ever so slightly variable, wavering by 0.003 of a magnitude from its average of 3.57. Sigma, a yellow-white main-sequence star of spectral type F3V, is suspected of varying in brightness from 4.45 to 4.49. It is around 52 light-years distant.\nTraditionally known as \"Aul\u0101d al Dhi\u02bcbah\" (\u0623\u0648\u0644\u0627\u062f \u0627\u0644\u0636\u0628\u0627\u0639 \u2013 \"aul\u0101d al dhi\u02bcb\"), \"the Whelps of the Hyenas\", Theta, Iota, Kappa and Lambda Bo\u00f6tis (or Xuange) are a small group of stars in the far north of the constellation. The magnitude 4.05 Theta Bo\u00f6tis has a spectral type of F7 and an absolute magnitude of 3.8. Iota Bo\u00f6tis is a triple star with a primary of magnitude 4.8 and spectral class of A7, a secondary of magnitude 7.5, and a tertiary of magnitude 12.6. The primary is 97 light-years away. The primary and secondary stars are separated by 38.5 arcseconds, at an angle of 33 degrees. The primary and tertiary stars are separated by 86.7 arcseconds at an angle of 194 degrees. Both the primary and tertiary appear white in a telescope, but the secondary appears yellow-hued.\nKappa Bo\u00f6tis is another wide double star. The primary is 155 light-years away and has a magnitude of 4.5. The secondary is 196 light-years away and has a magnitude of 6.6. The two components are separated by 13.4 arcseconds, at an angle of 236 degrees. The primary, with spectral class A7, appears white and the secondary appears bluish.\nAn apparent magnitude 4.18 type A0p star, Lambda Bo\u00f6tis is the prototype of a class of chemically peculiar stars, only some of which pulsate as Delta Scuti-type stars. The distinction between the Lambda Bo\u00f6tis stars as a class of stars with peculiar spectra, and the Delta Scuti stars whose class describes pulsation in low-overtone pressure modes, is an important one. While many Lambda Bo\u00f6tis stars pulsate and are Delta Scuti stars, not many Delta Scuti stars have Lambda Bo\u00f6tis peculiarities, since the Lambda Bo\u00f6tis stars are a much rarer class whose members can be found both inside and outside the Delta Scuti instability strip. Lambda Bo\u00f6tis stars are dwarf stars that can be either spectral class A or F. Like BL Bo\u00f6tis-type stars they are metal-poor. Scientists have had difficulty explaining the characteristics of Lambda Bo\u00f6tis stars, partly because only around 60 confirmed members exist, but also due to heterogeneity in the literature. Lambda has an absolute magnitude of 1.8.\nThere are two dimmer F-type stars, magnitude 4.83 12 Bo\u00f6tis, class F8; and magnitude 4.93 45 Bo\u00f6tis, class F5. Xi Bo\u00f6tis is a G8 yellow dwarf of magnitude 4.55, and absolute magnitude is 5.5. Two dimmer G-type stars are magnitude 4.86 31 Bo\u00f6tis, class G8, and magnitude 4.76 44 Bo\u00f6tis, class G0.\nOf apparent magnitude 4.06, Upsilon Bo\u00f6tis has a spectral class of K5 and an absolute magnitude of \u22120.3. Dimmer than Upsilon Bo\u00f6tis is magnitude 4.54 Phi Bo\u00f6tis, with a spectral class of K2 and an absolute magnitude of \u22120.1. Just slightly dimmer than Phi at magnitude 4.60 is O Bo\u00f6tis, which, like Izar, has a spectral class of K0. O Bo\u00f6tis has an absolute magnitude of 0.2. The other four dim stars are magnitude 4.91 6 Bo\u00f6tis, class K4; magnitude 4.86 20 Bo\u00f6tis, class K3; magnitude 4.81 Omega Bo\u00f6tis, class K4; and magnitude 4.83 A Bo\u00f6tis, class K1.\nThere is one bright B-class star in Bo\u00f6tes; magnitude 4.93 Pi1 Bo\u00f6tis, also called Alazal. It has a spectral class of B9 and is 40 parsecs from Earth. There is also one M-type star, magnitude 4.81 34 Bo\u00f6tis. It is of class gM0.\nMultiple stars.\nBesides Pulcherrima and Alkalurops, there are several other binary stars in Bo\u00f6tes:\n44 Bo\u00f6tis (i Bo\u00f6tis) is a double variable star 42 light-years away. It has an overall magnitude of 4.8 and appears yellow to the naked eye. The primary is of magnitude 5.3 and the secondary is of magnitude 6.1; their orbital period is 220 years. The secondary is itself an eclipsing variable star with a range of 0.6 magnitudes; its orbital period is 6.4 hours. It is a W Ursae Majoris variable that ranges in magnitude from a minimum of 7.1 to a maximum of 6.5 every 0.27 days. Both stars are G-type stars. Another eclipsing binary star is ZZ Bo\u00f6tis, which has two F2-type components of almost equal mass, and ranges in magnitude from a minimum of 6.79 to a maximum of 7.44 over a period of 5.0 days.\nVariable stars.\nTwo of the brighter Mira-type variable stars in the constellation are R and S Bo\u00f6tis. Both are red giants that range greatly in magnitude\u2014from 6.2 to 13.1 over 223.4 days, and 7.8 to 13.8 over a period of 270.7 days, respectively. Also red giants, V and W Bo\u00f6tis are semi-regular variable stars that range in magnitude from 7.0 to 12.0 over a period of 258 days, and magnitude 4.7 to 5.4 over 450 days, respectively.\nBL Bo\u00f6tis is the prototype of its class of pulsating variable stars, the anomalous Cepheids. These stars are somewhat similar to Cepheid variables, but they do not have the same relationship between their period and luminosity. Their periods are similar to RRAB variables; however, they are far brighter than these stars. BL Bo\u00f6tis is a member of the cluster NGC 5466. Anomalous Cepheids are metal poor and have masses not much larger than the Sun's, on average, . BL Bo\u00f6tis type stars are a subtype of RR Lyrae variables.\nT Bo\u00f6tis was a nova observed in April 1860 at a magnitude of 9.7. It has never been observed since, but that does not preclude the possibility of it being a highly irregular variable star or a recurrent nova.\nStars with planetary systems.\nExtrasolar planets have been discovered encircling ten stars in Bo\u00f6tes as of 2012. Tau Bo\u00f6tis is orbited by a large planet, discovered in 1999. The host star itself is a magnitude 4.5 star of type F7V, 15.6 parsecs from Earth. It has a mass of and a radius of 1.331 solar radii (); a companion, GJ527B, orbits at a distance of 240 AU. Tau Bo\u00f6tis b, the sole planet discovered in the system, orbits at a distance of 0.046 AU every 3.31 days. Discovered through radial velocity measurements, it has a mass of 5.95 Jupiter masses (). This makes it a hot Jupiter. The host star and planet are tidally locked, meaning that the planet's orbit and the star's particularly high rotation are synchronized. Furthermore, a slight variability in the host star's light may be caused by magnetic interactions with the planet. Carbon monoxide is present in the planet's atmosphere. Tau Bo\u00f6tis b does not transit its star, rather, its orbit is inclined 46 degrees.\nLike Tau Bo\u00f6tis b, HAT-P-4b is also a hot Jupiter. It is noted for orbiting a particularly metal-rich host star and being of low density. Discovered in 2007, HAT-P-4 b has a mass of and a radius of . It orbits every 3.05 days at a distance of 0.04 AU. HAT-P-4, the host star, is an F-type star of magnitude 11.2, 310 parsecs from Earth. It is larger than the Sun, with a mass of and a radius of .\nBo\u00f6tes is also home to multiple-planet systems. HD 128311 is the host star for a two-planet system, consisting of HD 128311 b and HD 128311 c, discovered in 2002 and 2005, respectively. HD 128311 b is the smaller planet, with a mass of ; it was discovered through radial velocity observations. It orbits at almost the same distance as Earth, at 1.099 AU; however, its orbital period is significantly longer at 448.6 days.\nThe larger of the two, HD 128311 c, has a mass of and was discovered in the same manner. It orbits every 919 days inclined at 50\u00b0, and is 1.76 AU from the host star. The host star, HD 128311, is a K0V-type star located 16.6 parsecs from Earth. It is smaller than the Sun, with a mass of and a radius of ; it also appears below the threshold of naked-eye visibility at an apparent magnitude of 7.51.\nThere are several single-planet systems in Bo\u00f6tes. HD 132406 is a Sun-like star of spectral type G0V with an apparent magnitude of 8.45, 231.5 light-years from Earth. It has a mass of and a radius of . The star is orbited by a gas giant, HD 132406 b, discovered in 2007. HD 132406 orbits 1.98 AU from its host star with a period of 974 days and has a mass of . The planet was discovered by the radial velocity method.\nWASP-23 is a star with one orbiting planet, WASP-23 b. The planet, discovered by the transit method in 2010, orbits every 2.944 days very close to its Sun, at 0.0376 AU. It is smaller than Jupiter, at and . Its star is a K1V-type star of apparent magnitude 12.7, far below naked-eye visibility, and smaller than the Sun at and .\nHD 131496 is also encircled by one planet, HD 131496 b. The star is of type K0 and is located 110 parsecs from Earth; it appears at a visual magnitude of 7.96. It is significantly larger than the Sun, with a mass of and a radius of 4.6 solar radii. Its one planet, discovered in 2011 by the radial velocity method, has a mass of ; its radius is as yet undetermined. HD 131496 b orbits at a distance of 2.09 AU with a period of 883 days.\nAnother single planetary system in Bo\u00f6tes is the HD 132563 system, a triple star system. The parent star, technically HD 132563B, is a star of magnitude 9.47, 96 parsecs from Earth. It is almost exactly the size of the Sun, with the same radius and a mass only 1% greater. Its planet, HD 132563B b, was discovered in 2011 by the radial velocity method. , it orbits 2.62 AU from its star with a period of 1544 days. Its orbit is somewhat elliptical, with an eccentricity of 0.22. HD 132563B b is one of very few planets found in triple star systems; it orbits the isolated member of the system, which is separated from the other components, a spectroscopic binary, by 400 AU.\nAlso discovered through the radial velocity method, albeit a year earlier, is HD 136418 b, a two-Jupiter-mass planet that orbits the star HD 136418 at a distance of 1.32 AU with a period of 464.3 days. Its host star is a magnitude 7.88 G5-type star, 98.2 parsecs from Earth. It has a radius of and a mass of .\nWASP-14 b is one of the most massive and dense exoplanets known, with a mass of and a radius of . Discovered via the transit method, it orbits 0.036 AU from its host star with a period of 2.24 days. WASP-14 b has a density of 4.6 grams per cubic centimeter, making it one of the densest exoplanets known. Its host star, WASP-14, is an F5V-type star of magnitude 9.75, 160 parsecs from Earth. It has a radius of and a mass of . It also has a very high proportion of lithium.\nDeep-sky objects.\nBo\u00f6tes is in a part of the celestial sphere facing away from the plane of our home Milky Way galaxy, and so does not have open clusters or nebulae. Instead, it has one bright globular cluster and many faint galaxies. The globular cluster NGC 5466 has an overall magnitude of 9.1 and a diameter of 11 arcminutes. It is a very loose globular cluster with fairly few stars and may appear as a rich, concentrated open cluster in a telescope. NGC 5466 is classified as a Shapley\u2013Sawyer Concentration Class 12 cluster, reflecting its sparsity. Its fairly large diameter means that it has a low surface brightness, so it appears far dimmer than the catalogued magnitude of 9.1 and requires a large amateur telescope to view. Only approximately 12 stars are resolved by an amateur instrument.\nBo\u00f6tes has two bright galaxies. NGC 5248 (Caldwell 45) is a type Sc galaxy (a variety of spiral galaxy) of magnitude 10.2. It measures 6.5 by 4.9 arcminutes. Fifty million light-years from Earth, NGC 5248 is a member of the Virgo Cluster of galaxies; it has dim outer arms and obvious H II regions, dust lanes and young star clusters. NGC 5676 is another type Sc galaxy of magnitude 10.9. It measures 3.9 by 2.0 arcminutes. Other galaxies include NGC 5008, a type Sc emission-line galaxy, NGC 5548, a type S Seyfert galaxy, NGC 5653, a type S HII galaxy, NGC 5778 (also classified as NGC 5825), a type E galaxy that is the brightest of its cluster, NGC 5886, and NGC 5888, a type SBb galaxy. NGC 5698 is a barred spiral galaxy, notable for being the host of the 2005 supernova SN 2005bc, which peaked at magnitude 15.3.\nFurther away lies the 250-million-light-year-diameter Bo\u00f6tes void, a huge space largely empty of galaxies. Discovered by Robert Kirshner and colleagues in 1981, it is roughly 700 million light-years from Earth. Beyond it and within the bounds of the constellation, lie two superclusters at around 830 million and 1 billion light-years distant.\nThe Hercules\u2013Corona Borealis Great Wall, the largest-known structure in the Universe, covers a significant part of Bo\u00f6tes.\nMeteor showers.\nBo\u00f6tes is home to the Quadrantid meteor shower, the most prolific annual meteor shower. It was discovered in January 1835 and named in 1864 by Alexander Herschel. The radiant is located in northern Bo\u00f6tes near Kappa Bo\u00f6tis, in its namesake former constellation of Quadrans Muralis. Quadrantid meteors are dim, but have a peak visible hourly rate of approximately 100 per hour on January 3\u20134. The zenithal hourly rate of the Quadrantids is approximately 130 meteors per hour at their peak; it is also a very narrow shower.\nThe Quadrantids are notoriously difficult to observe because of a low radiant and often inclement weather. The parent body of the meteor shower has been disputed for decades; however, Peter Jenniskens has proposed 2003 EH1, a minor planet, as the parent. 2003 EH1 may be linked to C/1490 Y1, a comet previously thought to be a potential parent body for the Quadrantids.\n2003 EH1 is a short-period comet of the Jupiter family; 500 years ago, it experienced a catastrophic breakup event. It is now dormant. The Quadrantids had notable displays in 1982, 1985 and 2004. Meteors from this shower often appear to have a blue hue and travel at a moderate speed of 41.5\u201343 kilometers per second.\nOn April 28, 1984, a remarkable outburst of the normally placid Alpha Bootids was observed by visual observer Frank Witte from 00:00 to 2:30 UTC. In a 6\u00a0cm telescope, he observed 433 meteors in a field of view near Arcturus with a diameter of less than 1\u00b0. Peter Jenniskens comments that this outburst resembled a \"typical dust trail crossing\". The Alpha Bootids normally begin on April 14, peaking on April 27 and 28, and finishing on May 12. Its meteors are slow-moving, with a velocity of 20.9 kilometers per second. They may be related to Comet 73P/Schwassmann\u2013Wachmann 3, but this connection is only theorized.\nThe June Bootids, also known as the Iota Draconids, is a meteor shower associated with the comet 7P/Pons\u2013Winnecke, first recognized on May 27, 1916, by William F. Denning. The shower, with its slow meteors, was not observed prior to 1916 because Earth did not cross the comet's dust trail until Jupiter perturbed Pons\u2013Winnecke's orbit, causing it to come within of Earth's orbit the first year the June Bootids were observed.\nIn 1982, E. A. Reznikov discovered that the 1916 outburst was caused by material released from the comet in 1819. Another outburst of the June Bootids was not observed until 1998, because Comet Pons\u2013Winnecke's orbit was not in a favorable position. However, on June 27, 1998, an outburst of meteors radiating from Bo\u00f6tes, later confirmed to be associated with Pons-Winnecke, was observed. They were incredibly long-lived, with trails of the brightest meteors lasting several seconds at times. Many fireballs, green-hued trails, and even some meteors that cast shadows were observed throughout the outburst, which had a maximum zenithal hourly rate of 200\u2013300 meteors per hour.\nTwo Russian astronomers determined in 2002 that material ejected from the comet in 1825 was responsible for the 1998 outburst. Ejecta from the comet dating to 1819, 1825 and 1830 was predicted to enter Earth's atmosphere on June 23, 2004. The predictions of a shower less spectacular than the 1998 showing were borne out in a display that had a maximum zenithal hourly rate of 16\u201320 meteors per hour that night. The June Bootids are not expected to have another outburst in the next 50 years.\nTypically, only 1\u20132 dim, very slow meteors are visible per hour; the average June Bootid has a magnitude of 5.0. It is related to the Alpha Draconids and the Bootids-Draconids. The shower lasts from June 27 to July 5, with a peak on the night of June 28. The June Bootids are classified as a class III shower (variable), and has an average entry velocity of 18 kilometers per second. Its radiant is located 7 degrees north of Beta Bo\u00f6tis.\nThe Beta Bootids is a weak shower that begins on January 5, peaks on January 16, and ends on January 18. Its meteors travel at 43\u00a0km/s. The January Bootids is a short, young meteor shower that begins on January 9, peaks from January 16 to January 18, and ends on January 18.\nThe Phi Bootids is another weak shower radiating from Bo\u00f6tes. It begins on April 16, peaks on April 30 and May 1, and ends on May 12. Its meteors are slow-moving, with a velocity of 15.1\u00a0km/s. They were discovered in 2006. The shower's peak hourly rate can be as high as six meteors per hour. Though named for a star in Bo\u00f6tes, the Phi Bootid radiant has moved into Hercules. The meteor stream is associated with three different asteroids: 1620 Geographos, 2062 Aten and 1978 CA.\nThe Lambda Bootids, part of the Bootid-Coronae Borealid Complex, are a weak annual shower with moderately fast meteors; 41.75\u00a0km/s. The complex includes the Lambda Bootids, as well as the Theta Coronae Borealids and Xi Coronae Borealids. All of the Bootid-Coronae Borealid showers are Jupiter family comet showers; the streams in the complex have highly inclined orbits.\nThere are several minor showers in Bo\u00f6tes, some of whose existence is yet to be verified. The Rho Bootids radiate from near the namesake star, and were hypothesized in 2010. The average Rho Bootid has an entry velocity of 43\u00a0km/s. It peaks in November and lasts for three days.\nThe Rho Bootid shower is part of the SMA complex, a group of meteor showers related to the Taurids, which is in turn linked to the comet 2P/Encke. However, the link to the Taurid shower remains unconfirmed and may be a chance correlation. Another such shower is the Gamma Bootids, which were hypothesized in 2006. Gamma Bootids have an entry velocity of 50.3\u00a0km/s. The Nu Bootids, hypothesized in 2012, have faster meteors, with an entry velocity of 62.8\u00a0km/s.\nReferences.\nCitations\nReferences"}
{"id": "4201", "revid": "4928500", "url": "https://en.wikipedia.org/wiki?curid=4201", "title": "Borromini, Francesco", "text": ""}
{"id": "4203", "revid": "1544984", "url": "https://en.wikipedia.org/wiki?curid=4203", "title": "Bernardino Ochino", "text": "Bernardino Ochino (1487\u20131564) was an Italian, who was raised a Roman Catholic and later turned to Protestantism and became a Protestant reformer.\nBiography.\nBernardino Ochino was born in Siena, the son of the barber Domenico Ochino, and at the age of 7 or 8, in around 1504, was entrusted to the order of Franciscan Friars. From 1510 he studied medicine at Perugia.\nTransfer to the Capuchins.\nAt the age of 38, Ochino transferred himself in 1534 to the newly founded Order of Friars Minor Capuchin. By then he was the close friend of Juan de Vald\u00e9s, Pietro Bembo, Vittoria Colonna, Pietro Martire, Carnesecchi. In 1538 he was elected vicar-general of his order. In 1539, urged by Bembo, he visited Venice and delivered a course of sermons showing a sympathy with justification by faith, which appeared more clearly in his \"Dialogues\" published the same year. He was suspected and denounced, but nothing ensued until the establishment of the Inquisition in Rome in June 1542, at the instigation of Cardinal Giovanni Pietro Carafa. Ochino received a citation to Rome, and set out to obey it about the middle of August. According to his own statement, he was deterred from presenting himself at Rome by the warnings of Cardinal Contarini, whom he found at Bologna, dying of poison administered by the reactionary party.\nEscape to Geneva.\nOchino turned aside to Florence, and after some hesitation went across the Alps to Geneva. He was cordially received by John Calvin, and published within two years several volumes of \"Prediche\", controversial tracts rationalizing his change of religion. He also addressed replies to marchioness Vittoria Colonna, Claudio Tolomei, and other Italian sympathizers who were reluctant to go to the same length as himself. His own breach with the Roman Catholic Church was final.\nAugsburg and England.\nIn 1545 Ochino became minister of the Italian Protestant congregation at Augsburg. From this time dates his contact with Caspar Schwenckfeld. In 1546 he participated in the anti-Trinitarian Collegia Vicentina. He was compelled to flee from Augsburg when, in January 1547, the city was occupied by the imperial forces for the Diet of Augsburg.\nOchino found asylum in England, where he was made a prebendary of Canterbury Cathedral, received a pension from Edward VI's privy purse, and composed his major work, the \"Tragoedie or Dialoge of the unjuste usurped primacie of the Bishop of Rome\". This text, originally written in Latin, is extant only in the 1549 translation of Bishop John Ponet. The form is a series of dialogues. Lucifer, enraged at the spread of Jesus's kingdom, convokes the fiends in council, and resolves to set up the pope as antichrist. The state, represented by the emperor Phocas, is persuaded to connive at the pope's assumption of spiritual authority; the other churches are intimidated into acquiescence; Lucifer's projects seem fully accomplished, when Heaven raises up Henry VIII of England and his son for their overthrow.\nSeveral of Ochino's \"Prediche\" were translated into English by Anna Cooke; and he published numerous controversial treatises on the Continent. Ochino's \"Che Cosa \u00e8 Christo\" was translated into Latin and English by the future Queen Elizabeth I of England in 1547.\nZ\u00fcrich.\nIn 1553 the accession of Mary I drove Ochino from England. He went to Basel, where Lelio Sozzini and the lawyer Martino Muralto were sent to secure Ochino as pastor of the Italian church at Zurich, which Ochino accepted. The Italian congregation there was composed mainly of refugees from Locarno. There for 10 years Ochino wrote books which gave increasing evidence of his alienation from the orthodoxy around him. The most important of these was the \"Labyrinth\", a discussion of the freedom of the will, covertly undermining the Calvinistic doctrine of predestination.\nIn 1563 a long simmering storm burst on Ochino with the publication of his \"Thirty Dialogues\", in one of which his adversaries maintained that he had justified polygamy under the disguise of a pretended refutation. His dialogues on divorce and against the Trinity were also considered heretical.\nPoland, and death.\nOchino was not given opportunity to defend himself, and was banished from Z\u00fcrich. After being refused admission by other Protestant cities, he directed his steps towards Poland, at that time the most tolerant state in Europe. He had not resided there long when an edict appeared (August 8, 1564) banishing all foreign dissidents. Fleeing the country, he encountered the plague at Pi\u0144cz\u00f3w; three of his four children were carried off; and he himself, worn out by misfortune, died in solitude and obscurity at Slavkov in Moravia, about the end of 1564.\nLegacy.\nOchino's reputation among Protestants was low. He was charged by Thomas Browne in 1643 with the authorship of the legendary-apocryphal heretical treatise \"De tribus Impostoribus\", as well as with having carried his alleged approval of polygamy into practice.\nHis biographer Karl Benrath justified him, representing him as a fervent evangelist and at the same time as a speculative thinker with a passion for free inquiry. The picture is of Ochino always learning and unlearning and arguing out difficult questions with himself in his dialogues, frequently without attaining to any absolute conviction."}
{"id": "4204", "revid": "43059617", "url": "https://en.wikipedia.org/wiki?curid=4204", "title": "Bay of Quinte", "text": "The Bay of Quinte () is a long, narrow bay shaped like the letter \"Z\" on the northern shore of Lake Ontario in the province of Ontario, Canada. It is just west of the head of the Saint Lawrence River that drains the Great Lakes into the Gulf of Saint Lawrence. It is located about east of Toronto and west of Montreal.\nThe name \"Quinte\" is derived from \"Kent\u00e9\" or Kentio, an Iroquoian village located near the south shore of the Bay. Later on, an early French Catholic mission was built at Kent\u00e9, located on the north shore of what is now Prince Edward County, leading to the Bay being named after the Mission. Officially, in the Mohawk language, the community is called , which means \"the place of the bay\". The Cayuga name is or , \"land of two logs.\"\nThe Bay, as it is known locally, provides some of the best trophy walleye angling in North America as well as most sport fish common to the great lakes. The bay is subject to algal blooms in late summer. Zebra mussels as well as the other invasive species found in the Great Lakes are present.\nThe Quinte area played a vital role in bootlegging during prohibition in the United States, with large volumes of liquor being produced in the area, and shipped via boat on the bay to Lake Ontario finally arriving in New York State where it was distributed. Prohibition-era illegal sales of liquor accounted for many fortunes made in and around Belleville.\nTourism in the area is significant, especially in the summer months due to the Bay of Quinte and its fishing, local golf courses, provincial parks, and wineries.\nGeography.\nThe northern side of the bay is defined by Ontario's mainland, while the southern side follows the shore of the Prince Edward County headland. Beginning in the east with the outlet to Lake Ontario, the bay runs west-southwest for to Picton (although this section is also called Adolphus Reach), where it turns north-northwest for another as far as Deseronto. From there it turns south-southwest again for another , running past Big Island on the south and Belleville on the north. The width of the bay rarely exceeds . The bay ends at Trenton (Quinte West) and the Trent River, both also on the north side. The Murray Canal has been cut through the \"Carrying Place\", the few kilometres separating the end of the bay and Lake Ontario on the west side. The Trent River is part of the Trent-Severn Waterway, a canal connecting Lake Ontario to Lake Simcoe and then Georgian Bay on Lake Huron.\nThere are several sub-bays off the Bay of Quinte, including Hay Bay, Big Bay, and Muscote Bay.\nBay of Quinte Region.\nQuinte is also a region comprising several communities situated along the Bay of Quinte, including Quinte West, Brighton and the City of Belleville, which is the largest city in the Quinte Region, and represents a midpoint between Montreal, Ottawa, and Toronto.\nThe Greater Bay of Quinte area includes the municipalities of Brighton, Quinte West, Belleville, Prince Edward County, and Greater Napanee as well as the Native Tyendinaga Mohawk Territory. Overall population of the area exceeds 200,000.\nMohawks of the Bay of Quinte.\nThe Mohawks of the Bay of Quinte (Kenht\u00e8:ke Kanyen'keh\u00e1:ka) live on traditional Tyendinaga Mohawk Territory. Their reserve Band number 244, their current land base, is on the Bay of Quinte in southeastern Ontario east of Belleville and immediately to the west of Deseronto.\nThe community takes its name from a variant spelling of Mohawk leader Joseph Brant's traditional Mohawk name, Thayendanegea (standardized spelling Thayentin\u00e9:ken), which means 'two pieces of fire wood beside each other'. Officially, in the Mohawk language, the community is called \"Kenht\u00e8:ke\" (Tyendinaga), which means \"on the bay\", and was the birthplace of Tekanaw\u00ed:ta. The Cayuga name is Tyendinaga, \"Tay\u0119da:ne:g\u0119\u02c0 or Detgay\u0119:da:neg\u0119\u02c0\", \"land of two logs.\"\nEducation.\nThe Quinte Region, specifically the City of Belleville, is home to Loyalist College of Applied Arts and Technology. Other post-secondary schools in the region include Maxwell College of Advanced Technology, CDI College, and Quinte Literacy. Secondary schools in the region include Albert College (private school) and Sir James Whitney (a school for the deaf and severely hearing-impaired).\nIndustry and employment.\nThe Bay of Quinte region is a hub for industry in eastern Ontario. The region is home to a diverse cluster of domestic and multi-national manufacturing and logistics companies. Sectors include; food processing, auto-parts, plastics and packaging, consumer goods, and more. The region's close proximity to North American markets, strong labour force and start-up and operating costs have attracted attention and new investment from companies all over the globe. Industry in the Bay of Quinte region is supported by a workforce of over 11,000.\nInvestment attraction and industrial retention are supported regionally by the Quinte Economic Development Commission.\nJust a few of over 350 industries located in the Bay of Quinte Region include:"}
{"id": "4207", "revid": "1273072067", "url": "https://en.wikipedia.org/wiki?curid=4207", "title": "Bassoon", "text": "The bassoon is a musical instrument in the woodwind family, which plays in the tenor and bass ranges. It is composed of six pieces, and is usually made of wood. It is known for its distinctive tone color, wide range, versatility, and virtuosity. It is a non-transposing instrument and typically its music is written in the bass and tenor clefs, and sometimes in the treble. There are two forms of modern bassoon: the Buffet (or French) and Heckel (or German) systems. It is typically played while sitting using a seat strap, but can be played while standing if the player has a harness to hold the instrument. Sound is produced by rolling both lips over the reed and blowing direct air pressure to cause the reed to vibrate. Its fingering system can be quite complex when compared to those of other instruments. Appearing in its modern form in the 19th century, the bassoon figures prominently in orchestral, concert band, and chamber music literature, and is occasionally heard in pop, rock, and jazz settings as well. One who plays a bassoon is called a bassoonist.\nEtymology.\nThe word bassoon comes from French and from Italian ( with the augmentative suffix ). However, the Italian name for the same instrument is , in Spanish, Dutch, Danish, Czech, Polish, Serbo-Croatian and Romanian it is , in German it is and in Portuguese it is . Fagot is an Old French word meaning a bundle of sticks.\nThe dulcian came to be known as fagotto in Italy. However, the usual etymology that equates fagotto with \"bundle of sticks\" is somewhat misleading, as the latter term did not come into general use until later. However an early English variation, \"faget\", was used as early as 1450 to refer to firewood, which is 100 years before the earliest recorded use of the dulcian (1550). Further citation is needed to prove the lack of relation between the meaning \"bundle of sticks\" and \"fagotto\" (Italian) or variants. Some think that it may resemble the Roman fasces, a standard of bound sticks with an axe. A further discrepancy lies in the fact that the dulcian was carved out of a single block of wood\u2014in other words, a single \"stick\" and not a bundle.\nCharacteristics.\nRange.\nThe range of the bassoon begins at B1 (the first one below the bass staff) and extends upward over three octaves, roughly to the G above the treble staff (G5). However, most writing for bassoon rarely calls for notes above C5 or D5; even Stravinsky's opening solo in \"The Rite of Spring\" only ascends to D5. Notes higher than this are possible, but seldom written, as they are difficult to produce (often requiring specific reed design features to ensure reliability), and at any rate are quite homogeneous in timbre to the same pitches on cor anglais, which can produce them with relative ease. French bassoon has greater facility in the extreme high register, and so repertoire written for it is somewhat likelier to include very high notes, although repertoire for French system can be executed on German system without alterations and vice versa.\nThe extensive high register of the bassoon and its frequent role as a lyric tenor have meant that tenor clef is very commonly employed in its literature after the Baroque, partly to avoid excessive ledger lines, and, beginning in the 20th century, treble clef is also seen for similar reasons.\nLike other woodwind instruments, the lowest note is fixed, but A1 is possible with a special extension to the instrument\u2014see \"Extended techniques\" below.\nAlthough the primary tone hole pitches are a pitched perfect 5th lower than other non-transposing Western woodwinds (effectively an octave beneath English horn) the bassoon is non-transposing, meaning that notes sounded match the written pitch.\nConstruction.\nThe bassoon disassembles into six main pieces, including the reed. The bell (6), extending upward; the bass joint (or long joint) (5), connecting the bell and the boot; the boot (or butt) (4), at the bottom of the instrument and folding over on itself; the wing joint (or tenor joint) (3), which extends from boot to bocal; and the bocal (or crook) (2), a crooked metal tube that attaches the wing joint to a reed (1) ().\nStructure.\nThe bore of the bassoon is conical, like that of the oboe and the saxophone, and the two adjoining bores of the boot joint are connected at the bottom of the instrument with a U-shaped metal connector. Both bore and tone holes are precision-machined, and each instrument is finished by hand for proper tuning. The walls of the bassoon are thicker at various points along the bore; here, the tone holes are drilled at an angle to the axis of the bore, which reduces the distance between the holes on the exterior. This ensures coverage by the fingers of the average adult hand. Playing is facilitated by closing the distance between the widely spaced holes with a complex system of key work, which extends throughout nearly the entire length of the instrument. The overall height of the bassoon stretches to tall, but the total sounding length is considering that the tube is doubled back on itself. There are also short-reach bassoons made for the benefit of young or petite players.\nMaterials.\nA modern beginner's bassoon is generally made of maple, with medium-hardness types such as sycamore maple and sugar maple preferred. Less-expensive models are also made of materials such as polypropylene and ebonite, primarily for student and outdoor use. Metal bassoons were made in the past but have not been produced by any major manufacturer since 1889.\nDouble Reeds.\nThe art of reed-making has been practiced for several hundred years, some of the earliest known reeds having been made for the dulcian, a predecessor of the bassoon. Current methods of reed-making consist of a set of basic methods; however, individual bassoonists' playing styles vary greatly and thus require that reeds be customized to best suit their respective bassoonist. Advanced players usually make their own reeds to this end. With regards to commercially made reeds, many companies and individuals offer pre-made reeds for sale, but players often find that such reeds still require adjustments to suit their particular playing style.\nModern bassoon reeds, made of \"Arundo donax\" cane, are often made by the players themselves, although beginner bassoonists tend to buy their reeds from professional reed makers or use reeds made by their teachers. Reeds begin with a length of tube cane that is split into three or four pieces using a tool called a cane splitter. The cane is then trimmed and \"gouged\" to the desired thickness, leaving the bark attached. After soaking, the gouged cane is cut to the proper shape and milled to the desired thickness, or \"profiled\", by removing material from the bark side. This can be done by hand with a file; more frequently it is done with a machine or tool designed for the purpose. After the profiled cane has soaked once again it is folded over in the middle. Prior to soaking, the reed maker will have lightly scored the bark with parallel lines with a knife; this ensures that the cane will assume a cylindrical shape during the forming stage.\nOn the bark portion, the reed maker binds on one, two, or three coils or loops of brass wire to aid in the final forming process. The exact placement of these loops can vary somewhat depending on the reed maker. The bound reed blank is then wrapped with thick cotton or linen thread to protect it, and a conical steel mandrel (which sometimes has been heated in a flame) is quickly inserted in between the blades. Using a special pair of pliers, the reed maker presses down the cane, making it conform to the shape of the mandrel. (The steam generated by the heated mandrel causes the cane to permanently assume the shape of the mandrel.) The upper portion of the cavity thus created is called the \"throat\", and its shape has an influence on the final playing characteristics of the reed. The lower, mostly cylindrical portion will be reamed out with a special tool called a reamer, allowing the reed to fit on the bocal.\nAfter the reed has dried, the wires are tightened around the reed, which has shrunk after drying, or replaced completely. The lower part is sealed (a nitrocellulose-based cement such as Duco may be used) and then wrapped with thread to ensure both that no air leaks out through the bottom of the reed and that the reed maintains its shape. The wrapping itself is often sealed with Duco or clear nail varnish (polish). Electrical tape can also be used as a wrapping for amateur reed makers. The bulge in the wrapping is sometimes referred to as the \"Turk's head\"\u2014it serves as a convenient handle when inserting the reed on the bocal. Alternatively, hot glue, epoxy, or heat shrink wrap may be used to seal the tube of the reed. The thread wrapping (commonly known as a \"Turban\" due to the criss-crossing fabric) is still more common in commercially sold reeds.\nTo finish the reed, the end of the reed blank, originally at the center of the unfolded piece of cane, is cut off, creating an opening. The blades above the first wire are now roughly long. For the reed to play, a slight bevel must be created at the tip with a knife, although there is also a machine that can perform this function. Other adjustments with the reed knife may be necessary, depending on the hardness, the profile of the cane, and the requirements of the player. The reed opening may also need to be adjusted by squeezing either the first or second wire with the pliers. Additional material may be removed from the sides (the \"channels\") or tip to balance the reed. Additionally, if the \"e\" in the bass clef staff is sagging in pitch, it may be necessary to \"clip\" the reed by removing from its length using a pair of very sharp scissors or the equivalent.\nHistory.\nOrigin.\nMusic historians generally consider the dulcian to be the forerunner of the modern bassoon, as the two instruments share many characteristics: a double reed fitted to a metal crook, obliquely drilled tone holes and a conical bore that doubles back on itself. The origins of the dulcian are obscure, but by the mid-16th century it was available in as many as eight different sizes, from soprano to great bass. A full consort of dulcians was a rarity; its primary function seems to have been to provide the bass in the typical wind band of the time, either loud (shawms) or soft (recorders), indicating a remarkable ability to vary dynamics to suit the need. Otherwise, dulcian technique was rather primitive, with eight finger holes and two keys, indicating that it could play in only a limited number of key signatures.\nCircumstantial evidence indicates that the baroque bassoon was a newly invented instrument, rather than a simple modification of the old dulcian. The dulcian was not immediately supplanted, but continued to be used well into the 18th century by Bach and others; and, presumably for reasons of interchangeability, repertoire from this time is very unlikely to go beyond the smaller compass of the dulcian. The man most likely responsible for developing the true bassoon was Martin Hotteterre (1712), who may also have invented the three-piece \"fl\u00fbte traversi\u00e8re\" (transverse flute) and the \"hautbois\" (baroque oboe). Some historians believe that sometime in the 1650s, Hotteterre conceived the bassoon in four sections (bell, bass joint, boot and wing joint), an arrangement that allowed greater accuracy in machining the bore compared to the one-piece dulcian. He also extended the compass down to B by adding two keys. An alternate view maintains Hotteterre was one of several craftsmen responsible for the development of the early bassoon. These may have included additional members of the Hotteterre family, as well as other French makers active around the same time. No original French bassoon from this period survives, but if it did, it would most likely resemble the earliest extant bassoons of Johann Christoph Denner and Richard Haka from the 1680s. Sometime around 1700, a fourth key (G\u266f) was added, and it was for this type of instrument that composers such as Antonio Vivaldi, Bach, and Georg Philipp Telemann wrote their demanding music. A fifth key, for the low E, was added during the first half of the 18th century. Notable makers of the 4-key and 5-key baroque bassoon include J.H. Eichentopf (), J. Poerschmann (1680\u20131757), Thomas Stanesby Jr. (1668\u20131734), G.H. Scherer (1703\u20131778), and Prudent Thieriot (1732\u20131786).\nModern configuration.\nIncreasing demands on capabilities of instruments and players in the 19th century\u2014particularly larger concert halls requiring greater volume and the rise of virtuoso composer-performers\u2014spurred further refinement. Increased sophistication, both in manufacturing techniques and acoustical knowledge, made possible great improvements in the instrument's playability.\nThe modern bassoon exists in two distinct primary forms, the Buffet (or \"French\") system and the Heckel (\"German\") system. Most of the world plays the Heckel system, while the Buffet system is primarily played in France, Belgium, and parts of Latin America. A number of other types of bassoons have been constructed by various instrument makers, such as the rare Galandronome. Owing to the ubiquity of the Heckel system in English-speaking countries, references in English to the contemporary bassoon always mean the Heckel system, with the Buffet system being explicitly qualified where it appears.\nHeckel (German) system.\nThe design of the modern bassoon owes a great deal to the performer, teacher, and composer Carl Almenr\u00e4der. Assisted by the German acoustic researcher Gottfried Weber, he developed the 17-key bassoon with a range spanning four octaves. Almenr\u00e4der's improvements to the bassoon began with an 1823 treatise describing ways of improving intonation, response, and technical ease of playing by augmenting and rearranging the keywork. Subsequent articles further developed his ideas. His employment at Schott gave him the freedom to construct and test instruments according to these new designs, and he published the results in \"Caecilia\", Schott's house journal. Almenr\u00e4der continued publishing and building instruments until his death in 1846, and Ludwig van Beethoven himself requested one of the newly made instruments after hearing of the papers. In 1831, Almenr\u00e4der left Schott to start his own factory with a partner, Johann Adam Heckel.\nHeckel and two generations of descendants continued to refine the bassoon, and their instruments became the standard, with other makers following. Because of their superior singing tone quality (an improvement upon one of the main drawbacks of the Almenr\u00e4der instruments), the Heckel instruments competed for prominence with the reformed Wiener system, a Boehm-style bassoon, and a completely keyed instrument devised by Charles-Joseph Sax, father of Adolphe Sax. F.W. Kruspe implemented a latecomer attempt in 1893 to reform the fingering system, but it failed to catch on. Other attempts to improve the instrument included a 24-keyed model and a single-reed mouthpiece, but both these had adverse effects on tone and were abandoned.\nComing into the 20th century, the Heckel-style German model of bassoon dominated the field. Heckel himself had made over 1,100 instruments by the turn of the 20th century (serial numbers begin at 3,000), and the British makers' instruments were no longer desirable for the changing pitch requirements of the symphony orchestra, remaining primarily in military band use.\nExcept for a brief 1940s wartime conversion to ball bearing manufacture, the Heckel concern has produced instruments continuously to the present day. Heckel bassoons are considered by many to be the best, although a range of Heckel-style instruments is available from several other manufacturers, all with slightly different playing characteristics.\nBecause its mechanism is primitive compared to most modern woodwinds, makers have occasionally attempted to \"reinvent\" the bassoon. In the 1960s, Giles Brindley began to develop what he called the \"logical bassoon\", which aimed to improve intonation and evenness of tone through use of an electrically activated mechanism, making possible key combinations too complex for the human hand to manage. Brindley's logical bassoon was never marketed.\nBuffet (French) system.\nThe Buffet system bassoon achieved its basic acoustical properties somewhat earlier than the Heckel. Thereafter, it continued to develop in a more conservative manner. While the early history of the Heckel bassoon included a complete overhaul of the instrument in both acoustics and key work, the development of the Buffet system consisted primarily of incremental improvements to the key work. This minimalist approach of the Buffet deprived it of improved consistency of intonation, ease of operation, and increased power, which is found in Heckel bassoons, but the Buffet is considered by some to have a more vocal and expressive quality. The conductor John Foulds lamented in 1934 the dominance of the Heckel-style bassoon, considering them too homogeneous in sound with the horn. The modern Buffet system has 22 keys with its range being the same as the Heckel; although Buffet instruments have greater facility in the upper registers, reaching E5 and F5 with far greater ease and less air resistance.\nCompared to the Heckel bassoon, Buffet system bassoons have a narrower bore and simpler mechanism, requiring different, and often more complex fingerings for many notes. Switching between Heckel and Buffet, or vice versa, requires extensive retraining. French woodwind instruments' tone in general exhibits a certain amount of \"edge\", with more of a vocal quality than is usual elsewhere, and the Buffet bassoon is no exception. This sound has been utilised effectively in writing for Buffet bassoon, but is less inclined to blend than the tone of the Heckel bassoon. As with all bassoons, the tone varies considerably, depending on individual instrument, reed, and performer. In the hands of a lesser player, the Heckel bassoon can sound flat and woody, but good players succeed in producing a vibrant, singing tone. Conversely, a poorly played Buffet can sound buzzy and nasal, but good players succeed in producing a warm, expressive sound.\nThough the United Kingdom once favored the French system, Buffet-system instruments are no longer made there and the last prominent British player of the French system retired in the 1980s. However, with continued use in some regions and its distinctive tone, the Buffet continues to have a place in modern bassoon playing, particularly in France, where it originated. Buffet-model bassoons are currently made in Paris by Buffet Crampon and the atelier Ducasse (Romainville, France). The Selmer Company stopped fabrication of French system bassoons around the year 2012. Some players, for example the late Gerald Corey in Canada, have learned to play both types and will alternate between them depending on the repertoire.\nUse in ensembles.\nEnsembles prior to the 20th century.\nPre-1760.\nPrior to 1760, the early ancestor of the bassoon was the dulcian. It was used to reinforce the bass line in wind ensembles called consorts. However, its use in concert orchestras was sporadic until the late 17th century when double reeds began to make their way into standard instrumentation. Increasing use of the dulcian as a \"basso continuo\" instrument meant that it began to be included in opera orchestras, in works such as those by Reinhard Keiser and Jean-Baptiste Lully. Meanwhile, as the dulcian advanced technologically and was able to achieve more virtuosity, composers such as Joseph Bodin de Boismortier, Johann Ernst Galliard, Johann Friedrich Fasch and Georg Philipp Telemann wrote demanding solo and ensemble music for the instrument. Antonio Vivaldi brought it to prominence by featuring it in thirty-nine concerti.\nc. 1760\u20131830.\nWhile the bassoon was still often used to give clarity to the bassline due to its sonorous low register, the capabilities of wind instruments grew as technology advanced during the Classical era. This allowed the instrument to play in more keys than the dulcian. Joseph Haydn took advantage of this in his Symphony No. 45 (\"Farewell Symphony\"), in which the bassoon plays in F-sharp minor. Following with these advances, composers also began to exploit the bassoon for its unique color, flexibility, and virtuosic ability, rather than for its perfunctory ability to double the bass line. Those who did this include Ludwig van Beethoven in his three Duos for Clarinet and Bassoon (WoO 27) for clarinet and bassoon and Niccolo Paganini in his duets for violin and bassoon. In his Bassoon Concerto in B-flat major, K. 191, W. A. Mozart utilized all aspects of the bassoon's expressiveness with its contrasts in register, staccato playing, and expressive sound, and was especially noted for its singing quality in the second movement. This concerto is often considered one of the most important works in all of the bassoon's repertoire, even today.\nThe bassoon's similarity to the human voice, in addition to its newfound virtuosic ability, was another quality many composers took advantage of during the classical era. After 1730, the German bassoon's range expended up to B\u266d4, and much higher with the French instrument. Technological advances also caused the bassoon's tenor register sound to become more resonant, and playing in this register grew in popularity, especially in the Austro-Germanic musical world. Pedagogues such as Josef Frohlich instructed students to practice scales, thirds, and fourths as vocal students would. In 1829, he wrote that the bassoon was capable of expressing \"the worthy, the virile, the solemn, the great, the sublime, composure, mildness, intimacy, emotion, longing, heartfulness, reverence, and soulful ardour.\" In G.F. Brandt's performance of Carl Maria von Weber's Concerto for Bassoon in F Major, Op. 75 (J. 127) it was also likened to the human voice. In France, Pierre Cugnier described the bassoon's role as encompassing not only the bass part, but also to accompany the voice and harp, play in pairs with clarinets and horns in Harmonie, and to play in \"nearly all types of music,\" including concerti, which were much more common than the sonatas of the previous era. Both Cugnier and \u00c9tienne Ozi emphasized the importance of the bassoon's similarity to the singing voice.\nThe role of the bassoon in the orchestra varied depending on the country. In the Viennese orchestra the instrument offered a three-dimensional sound to the ensemble by doubling other instruments such as violins, as heard in Mozart's overture to \"The Marriage of Figaro\", K 492. where it plays a rather technical part alongside the strings. He also wrote for the bassoon to change its timbre depending on which instrument it was paired with; warmer with clarinets, hollow with flutes, and dark and dignified with violins. In Germany and Scandinavian countries, orchestras typically featured only two bassoons. But in France, orchestras increased the number to four in the latter half of the nineteenth century. In England, the bassoonist's role varied depending on the ensemble. Johann Christian Bach wrote two concertos for solo bassoon, and it also appeared in more supportive roles such as accompanying church choirs after the Puritan revolution destroyed most church organs. In the American colonies, the bassoon was typically seen in a chamber setting. After the Revolutionary War, bassoonists were found in wind bands that gave public performances. By 1800, there was at least one bassoon in the United States Marine Band. In South America, the bassoon also appeared in small orchestras, bands, and military musique (similar to Harmonie ensembles).\nc. 1830\u20131900.\nThe role of the bassoon during the Romantic era varied between a role as a supportive bass instrument and a role as a virtuosic, expressive, solo instrument. In fact, it was very much considered an instrument that could be used in almost any circumstance. The comparison of the bassoon's sound to the human voice continued on during this time, as much of the pedagogy surrounded emulating this sound. Giuseppe Verdi used the instrument's lyrical, singing voice to evoke emotion in pieces such as his \"Messa da Requiem\". Eugene Jancourt compared the use of vibrato on the bassoon to that of singers, and Luigi Orselli wrote that the bassoon blended well with human voice. He also noted the function of the bassoon in the French orchestra at the time, which served to support the sound of the viola, reinforce staccato sound, and double the bass, clarinet, flute, and oboe. Emphasis also began to be placed on the unique sound of the bassoon's staccato, which might be described as quite short and aggressive, such as in Hector Berlioz's \"Symphonie fantastique, Op. 14\" in the fifth movement. Paul Dukas utilized the staccato to depict the image of two brooms coming to life in \"The Sorcerer's Apprentice.\"\nIt was common for there to be only two bassoons in German orchestras. Austrian and British military bands also only carried two bassoons, and were mainly used for accompaniment and offbeat playing. In France, Hector Berlioz also made it fashionable to use more than two bassoons; he often scored for three or four, and at time wrote for up to eight such as in his \"l'Imp\u00e9riale\".\nAt this point, composers expected bassoons to be as virtuosic as the other wind instruments, as they often wrote solos challenging the range and technique of the instrument. Examples of this include Nikolai Rimsky-Korsakov's bassoon solo and cadenza following the clarinet in \"Sheherazade,\" Op. 35 and in Richard Wagner's \"Tannh\u00e4user\", which required the bassoonist to triple tongue and also play up to the top of its range at an E5. Wagner also used the bassoon for its staccato ability in his work, and often wrote his three bassoon parts in thirds to evoke a darker sound with noticeable tone color. In Modest Mussorgsky's \"Night on Bald Mountain\", the bassoons play fortissimo alongside other bass instruments in order to evoke \"the voice of the Devil.\"\n20th and 21st century ensembles.\nAt this point in time, the development of the bassoon slowed. Rather than making large leaps in technological improvements, tiny imperfections in the instrument's function were corrected. The instrument became quite versatile throughout the twentieth century; the instrument was at this point able to play three octaves, a variety of different trills, and maintained stable intonation across all registers and dynamic levels. The pedagogy among bassoonists varied among different countries, and so the overall instrument itself played a variety of roles. As was a common theme in previous eras, the bassoon was valued by composers for its unique voice, and its use rose higher in pitch. A famous example of this is the beginning of Igor Stravinsky's \"Rite of Spring\" in which the bassoon plays in its highest register in order to mimic the Ukrainian Dentsivka. Composers also wrote for the bassoon's middle register, such as in Stravinsky's \"Berceuse\" in The \"Firebird\" and Symphony No. 5 in E-flat major, Op. 82 by Jean Sibelius. They also continued to highlight the staccato sound of the bassoon, as heard in Sergei Prokofiev's \"Humorous Scherzo\". In Sergei Prokofiev's Peter and the Wolf, the part of the grandfather is played by the bassoon.\nIn orchestral settings, most orchestras from the beginning of the twentieth century to the present have three or four bassoonists, with the fourth typically covering contrabassoon as well. Greater emphasis on the use of timbre, vibrato, and phrasing began to appear in bassoon pedagogy, and many followed Marcel Tabuteau's philosophy on musical phrasing. Vibrato began to be used in ensemble playing, depending on the phrasing of the music. The bassoon was, and currently is, expected to be fluent with other woodwinds in terms of virtuosity and technique. Examples of this include the cadenza for bassoons in Maurice Ravel's \"Rapsodie espagnole\" and the multi-finger trills used in Stravinsky's Octet.\nIn the twentieth century, the bassoon was less of a concerto soloist, and when it was, the accompanying ensemble was made softer and quieter. In addition, it was no longer used in marching bands, though still existed in concert bands with one or two of them. Orchestral repertoire remained very much the same Austro-Germanic tradition throughout most Western countries. It mostly appeared in solo, chamber, and symphonic settings. By the mid-1900s, broadcasting and recording grew in popularity, allowing for new opportunities for bassoonists, and leading to a slow decline of live performances. Much of the new music for bassoon in the late twentieth and early twenty-first centuries, often included extended techniques and was written for solo or chamber settings. One piece that included extended techniques was Luciano Berio's \"Sequenza XII\", which called for microtonal fingerings, glissandos, and timbral trills. Double and triple tonguing, flutter tonguing, multiphonics, quarter-tones, and singing are all utilized in Bruno Bartolozzi's \"Concertazioni.\" There were also a variety of concerti and bassoon and piano pieces written, such as John Williams's \"Five Sacred Trees\" and Andr\u00e9 Previn's \"Sonata for bassoon and piano\". There were also \"performance\" pieces such as Peter Schickele's \"Sonata Abassoonata\", which required the bassoonist to be both a musician and an actor. The bassoon quartet became prominent at this time, with pieces such as Daniel Dorff's \"It Takes Four to Tango\".\nJazz.\nThe bassoon is infrequently used as a jazz instrument and rarely seen in a jazz ensemble. It first began appearing in the 1920s, when Garvin Bushell began incorporating the bassoon in his performances. Specific calls for its use occurred in Paul Whiteman's group, the unusual octets of Alec Wilder, and a few other session appearances. The next few decades saw the instrument used only sporadically, as symphonic jazz fell out of favor, but the 1960s saw artists such as Yusef Lateef and Chick Corea incorporate bassoon into their recordings. Lateef's diverse and eclectic instrumentation saw the bassoon as a natural addition (see, e.g., \"The Centaur and the Phoenix\" (1960) which features bassoon as part of a 6-man horn section, including a few solos) while Corea employed the bassoon in combination with flautist Hubert Laws.\nMore recently, Illinois Jacquet, Ray Pizzi, Frank Tiberi, and Marshall Allen have both doubled on bassoon in addition to their saxophone performances. Bassoonist Karen Borca, a performer of free jazz, is one of the few jazz musicians to play only bassoon; Michael Rabinowitz, the Spanish bassoonist Javier Abad, and James Lassen, an American resident in Bergen, Norway, are others. Katherine Young plays the bassoon in the ensembles of Anthony Braxton. Lindsay Cooper, Paul Hanson, the Brazilian bassoonist Alexandre Silv\u00e9rio, Trent Jacobs and Daniel Smith are also currently using the bassoon in jazz. French bassoonists Jean-Jacques Decreux and Alexandre Ouzounoff have both recorded jazz, exploiting the flexibility of the Buffet system instrument to good effect.\nPopular music.\nIn conjunction with the use of electronic pickups and amplification, the instrument began to be used more somewhat in jazz and rock settings. However, the bassoon is still quite rare as a regular member of rock bands. Several 1960s pop music hits feature the bassoon, including \"The Tears of a Clown\" by Smokey Robinson and the Miracles (the bassoonist was Charles R. Sirard), \"Jennifer Juniper\" by Donovan, \"59th Street Bridge Song\" by Harpers Bizarre, and the oompah bassoon underlying The New Vaudeville Band's \"Winchester Cathedral\". From 1974 to 1978, the bassoon was played by Lindsay Cooper in the British avant-garde band Henry Cow. The Leonard Nimoy song \"The Ballad of Bilbo Baggins\" features the bassoon. In the 1970s it was played, in the British medieval/progressive rock band Gryphon, by Brian Gulland, as well as by the American band Ambrosia, where it was played by drummer Burleigh Drummond. The Belgian Rock in Opposition-band Univers Zero is also known for its use of the bassoon.\nMore recently, These New Puritans's 2010 album \"Hidden\" makes heavy use of the instrument throughout; their principal songwriter, Jack Barnett, claimed repeatedly to be \"writing a lot of music for bassoon\" in the run-up to its recording. The rock band Better Than Ezra took their name from a passage in Ernest Hemingway's \"A Moveable Feast\" in which the author comments that listening to an annoyingly talkative person is still \"better than Ezra learning how to play the bassoon\", referring to Ezra Pound.\nBritish psychedelic/progressive rock band Knifeworld features the bassoon playing of Chloe Herrington, who also plays for experimental chamber rock orchestra Chrome Hoof.\nFiona Apple featured the bassoon in the opening track of her 2004 album \"Extraordinary Machine\".\nIn 2016, the bassoon was featured on the album \"Gang Signs and Prayers\" by UK \"grime\" artist Stormzy. Played by UK bassoonist Louise Watson, the bassoon is heard in the tracks \"Cold\" and \"Mr Skeng\" as a complement to the electronic synthesizer bass lines typically found in this genre.\nAppearance in Television.\nThe Cartoon Network animated series \"Over the Garden Wall\" features a bassoon in episode 6 entitled \"Lullaby in Frogland\", where the main character is encouraged to play the bassoon to impress a group of frogs.\nThe character Jan Bellows in the Hulu series \"Only Murders in the Building\" is a professional bassoonist.\nTechnique.\nThe bassoon is held diagonally in front of the player, but unlike the flute, oboe and clarinet, it cannot be easily supported by the player's hands alone. Some means of additional support is usually required; the most common ones are a seat strap attached to the base of the boot joint, which is laid across the chair seat prior to sitting down, or a neck strap or shoulder harness attached to the top of the boot joint. Occasionally a spike similar to those used for the cello or the bass clarinet is attached to the bottom of the boot joint and rests on the floor. It is possible to play while standing up if the player uses a neck strap or similar harness, or if the seat strap is tied to the belt. Sometimes a device called a \"balance hanger\" is used when playing in a standing position. This is installed between the instrument and the neck strap, and shifts the point of support closer to the center of gravity, adjusting the distribution of weight between the two hands.\nThe bassoon is played with both hands in a stationary position, the left above the right, with five main finger holes on the front of the instrument (nearest the audience) plus a sixth that is activated by an open-standing key. Five additional keys on the front are controlled by the little fingers of each hand. The back of the instrument (nearest the player) has twelve or more keys to be controlled by the thumbs, the exact number varying depending on model.\nTo stabilize the right hand, many bassoonists use an adjustable comma-shaped apparatus called a \"crutch\", or a hand rest, which mounts to the boot joint. The crutch is secured with a thumb screw, which also allows the distance that it protrudes from the bassoon to be adjusted. Players rest the curve of the right hand where the thumb joins the palm against the crutch. The crutch also keeps the right hand from tiring and enables the player to keep the finger pads flat on the finger holes and keys.\nAn aspect of bassoon technique not found on any other woodwind is called \"flicking\". It involves the left hand thumb momentarily pressing, or \"flicking\" the high A, C and D keys at the beginning of certain notes in the middle octave to achieve a clean slur from a lower note. This eliminates cracking, or brief multiphonics that happens without the use of this technique. Alternatively, a similar method is called \"venting\", which requires that the register key be used as part of the full fingering as opposed to being open momentarily at the start of the note. This is sometimes called the \"European style\"; venting raises the intonation of the notes slightly, and it can be advantageous when tuning to higher frequencies. Some bassoonists flick A and B when tongued, for clarity of articulation, but flicking (or venting) is practically ubiquitous for slurs.\nWhile flicking is used to slur up to higher notes, the whisper key is used for lower notes. From the A right below middle C and lower, the whisper key is pressed with the left thumb and held for the duration of the note. This prevents cracking, as low notes can sometimes crack into a higher octave. Both flicking and using the whisper key is especially important to ensure notes speak properly during slurring between high and low registers.\nWhile bassoons are usually critically tuned at the factory, the player nonetheless has a great degree of flexibility of pitch control through the use of breath support, embouchure, and reed profile. Players can also use alternate fingerings to adjust the pitch of many notes. Similar to other woodwind instruments, the length of the bassoon can be increased to lower pitch or decreased to raise pitch. On the bassoon, this is done preferably by changing the bocal to one of a different length, (lengths are denoted by a number on the bocal, usually starting at 0 for the shortest length, and 3 for the longest, but there are some manufacturers who will use other numbers) but it is possible to push the bocal in or out slightly to grossly adjust the pitch.\nEmbouchure and sound production.\nThe bassoon embouchure is a very important aspect of producing a full, round, and rich sound on the instrument. The lips are both rolled over the teeth, often with the upper lip further along in an \"overbite\". The lips provide micromuscular pressure on the entire circumference of the reed, which grossly controls intonation and harmonic excitement, and thus must be constantly modulated with every change of note. How far along the reed the lips are placed affects both tone (with less reed in the mouth making the sound more edged or \"reedy\", and more reed making it smooth and less projectile) and the way the reed will respond to pressure.\nThe musculature employed in a bassoon embouchure is primarily around the lips, which pressure the reed into the shapes needed for the desired sound. The jaw is raised or lowered to adjust the oral cavity for better reed control, but the jaw muscles are used much less for upward vertical pressure than in single reeds, only being substantially employed in the very high register. However, double reed students often \"bite\" the reed with these muscles because the control and tone of the labial and other muscles is still developing, but this generally makes the sound sharp and \"choked\" as it contracts the aperture of the reed and stifles the vibration of its blades.\nApart from the embouchure proper, students must also develop substantial muscle tone and control in the diaphragm, throat, neck and upper chest, which are all employed to increase and direct air pressure. Air pressure is a very important aspect of the tone, intonation and projection of double reed instruments, affecting these qualities as much, or more than the embouchure does.\nAttacking a note on the bassoon with imprecise amounts of muscle or air pressure for the desired pitch will result in poor intonation, cracking or multiphonics, accidentally producing the incorrect partial, or the reed not speaking at all. These problems are compounded by the individual qualities of reeds, which are categorically inconsistent in behaviour for inherent and exherent reasons.\nThe muscle requirements and variability of reeds mean it takes some time for bassoonists (and oboists) to develop an embouchure that exhibits consistent control across all reeds, dynamics and playing environments.\nModern fingering.\nThe fingering technique of the bassoon varies more between players, by a wide margin, than that of any other orchestral woodwind. The complex mechanism and acoustics mean the bassoon lacks simple fingerings of good sound quality or intonation for some notes (especially in the higher range), but, conversely, there is a great variety of superior, but generally more complicated, fingerings for them. Typically, the simpler fingerings for such notes are used as alternate or trill fingerings, and the bassoonist will use as \"full fingering\" one or several of the more complex executions possible, for optimal sound quality. The fingerings used are at the discretion of the bassoonist, and, for particular passages, he or she may experiment to find new alternate fingerings that are thus idiomatic to the player.\nThese elements have resulted in both \"full\" and alternate fingerings differing extensively between bassoonists, and are further informed by factors such as cultural difference in what sound is sought, how reeds are made, and regional variation in tuning frequencies (necessitating sharper or flatter fingerings). Regional enclaves of bassoonists tend to have some uniformity in technique, but on a global scale, technique differs such that two given bassoonists may share no fingerings for certain notes. Owing to these factors, ubiquitous bassoon technique can only be partially notated.\nThe left thumb operates nine keys: B1, B1, C2, D2, D5, C5 (also B4), two keys when combined create A4, and the whisper key. The whisper key should be held down for notes between and including F2 and G3 and certain other notes; it can be omitted, but the pitch will destabilise. Additional notes can be created with the left thumb keys; the D2 and bottom key above the whisper key on the tenor joint (C key) together create both C3 and C4. The same bottom tenor-joint key is also used, with additional fingering, to create E5 and F5. D5 and C5 together create C5. When the two keys on the tenor joint to create A4 are used with slightly altered fingering on the boot joint, B4 is created. The whisper key may also be used at certain points throughout the instrument's high register, along with other fingerings, to alter sound quality as desired.\nThe right thumb operates four keys. The uppermost key is used to produce B2 and B3, and may be used in B4,F4, C5, D5, F5, and E5. The large circular key, otherwise known as the \"pancake key\", is held down for all the lowest notes from E2 down to B1. It is also used, like the whisper key, in additional fingerings for muting the sound. For example, in Ravel's \"Bol\u00e9ro\", the bassoon is asked to play the ostinato on G4. This is easy to perform with the normal fingering for G4, but Ravel directs that the player should also depress the E2 key (pancake key) to mute the sound (this being written with Buffet system in mind; the G fingering on which involves the Bb key\u00a0\u2013 sometimes called \"French\" G on Heckel). The next key operated by the right thumb is known as the \"spatula key\": its primary use is to produce F2 and F3. The lowermost key is used less often: it is used to produce A2 (G2) and A3 (G3), in a manner that avoids sliding the right fourth finger from another note.\nThe four fingers of the left hand can each be used in two different positions. The key normally operated by the index finger is primarily used for E5, also serving for trills in the lower register. Its main assignment is the upper tone hole. This hole can be closed fully, or partially by rolling down the finger. This half-holing technique is used to overblow F3, G3 and G3. The middle finger typically stays on the centre hole on the tenor joint. It can also move to a lever used for E5, also a trill key. The ring finger operates, on most models, one key. Some bassoons have an alternate E key above the tone hole, predominantly for trills, but many do not. The smallest finger operates two side keys on the bass joint. The lower key is typically used for C2, but can be used for muting or flattening notes in the tenor register. The upper key is used for E2, E4, F4, F4, A4, B4, B4, C5, C5, and D5; it flattens G3 and is the standard fingering for it in many places that tune to lower Hertz levels such as A440.\nThe four fingers of the right hand have at least one assignment each. The index finger stays over one hole, except that when E5 is played a side key at the top of the boot is used (this key also provides a C3 trill, albeit sharp on D). The middle finger remains stationary over the hole with a ring around it, and this ring and other pads are lifted when the smallest finger on the right hand pushes a lever. The ring finger typically remains stationary on the lower ring-finger key. However, the upper ring-finger key can be used, typically for B2 and B3, in place of the top thumb key on the front of the boot joint; this key comes from the oboe, and some bassoons do not have it because the thumb fingering is practically universal. The smallest finger operates three keys. The backmost one, closest to the bassoonist, is held down throughout most of the bass register. F4 may be created with this key, as well as G4, B4, B4, and C5 (the latter three employing solely it to flatten and stabilise the pitch). The lowest key for the smallest finger on the right hand is primarily used for A2 (G2) and A3 (G3) but can be used to improve D5, E5, and F5. The frontmost key is used, in addition to the thumb key, to create G2 and G3; on many bassoons this key operates a different tone hole to the thumb key and produces a slightly flatter F (\"duplicated F\"); some techniques use one as standard for both octaves and the other for utility, but others use the thumb key for the lower and the fourth finger for the higher.\nExtended techniques.\nMany extended techniques can be performed on the bassoon, such as multiphonics, flutter-tonguing, circular breathing, double tonguing, and harmonics. In the case of the bassoon, flutter-tonguing may be accomplished by \"gargling\" in the back of the throat as well as by the conventional method of rolling Rs. Multiphonics on the bassoon are plentiful, and can be achieved by using particular alternative fingerings, but are generally heavily influenced by embouchure position. Also, again using certain fingerings, notes may be produced on the instrument that sound lower pitches than the actual range of the instrument. These notes tend to sound very gravelly and out of tune, but technically sound below the low B.\nThe bassoonist may also produce lower notes than the bottom B by extending the length of bell. This can be achieved by inserting a specially made \"low A extension\" into the bell, but may also be achieved with a small paper or rubber tube or a clarinet/cor anglais bell sitting inside the bassoon bell (although the note may tend sharp). The effect of this is to convert the lower B into a lower note, almost always A natural; this broadly lowers the pitch of the instrument (most noticeably in the lower register) and will often accordingly convert the lowest B to B (and render the neighbouring C very flat). The idea of using low A was begun by Richard Wagner, who wanted to extend the range of the bassoon. Many passages in his later operas require the low A as well as the B-flat immediately above it; this is possible on a normal bassoon using an extension which also flattens low B to B, but all extensions to the bell have significant effects on intonation and sound quality in the bottom register of the instrument, and passages such as this are more often realised with comparative ease by the contrabassoon.\nSome bassoons have been specially made to allow bassoonists to realize similar passages. These bassoons are made with a \"Wagner bell\" which is an extended bell with a key for both the low A and the low B-flat, but they are not widespread; bassoons with Wagner bells suffer similar intonational problems as a bassoon with an ordinary A extension, and a bassoon must be constructed specifically to accommodate one, making the extension option far less complicated. Extending the bassoon's range even lower than the A, though possible, would have even stronger effects on pitch and make the instrument effectively unusable.\nDespite the logistic difficulties of the note, Wagner was not the only composer to write the low A. Another composer who has required the bassoon to be chromatic down to low A is Gustav Mahler. Richard Strauss also calls for the low A in his opera \"Intermezzo\". Some works have optional low As, as in Carl Nielsen's Wind Quintet, op. 43, which includes an optional low A for the final cadence of the work.\nLearning the bassoon.\nThe complex fingering system and the expense and lack of access to quality bassoon reeds can make the bassoon more of a challenge to learn than some of the other woodwind instruments. Cost is another factor in a person's decision to pursue the bassoon. Prices may range from US$7,000 to over $45,000 for a high-quality instrument. In North America, schoolchildren may take up bassoon only after starting on another reed instrument, such as clarinet or saxophone.\nStudents in America often begin to pursue the study of bassoon performance and technique in the middle years of their music education, often in association with their school band program. Students are often provided with a school instrument and encouraged to pursue lessons with private instructors. Students typically receive instruction in proper posture, hand position, embouchure, repertoire, and tone production."}
{"id": "4210", "revid": "1152308", "url": "https://en.wikipedia.org/wiki?curid=4210", "title": "Bipedalism", "text": "Bipedalism is a form of terrestrial locomotion where an animal moves by means of its two rear (or lower) limbs or legs. An animal or machine that usually moves in a bipedal manner is known as a biped , meaning 'two feet' (from Latin \"bis\" 'double' and \"pes\" 'foot'). Types of bipedal movement include walking or running (a bipedal gait) and hopping.\nSeveral groups of modern species are habitual bipeds whose normal method of locomotion is two-legged. In the Triassic period some groups of archosaurs (a group that includes crocodiles and dinosaurs) developed bipedalism; among the dinosaurs, all the early forms and many later groups were habitual or exclusive bipeds; the birds are members of a clade of exclusively bipedal dinosaurs, the theropods. Within mammals, habitual bipedalism has evolved multiple times, with the macropods, kangaroo rats and mice, springhare, hopping mice, pangolins and hominin apes (australopithecines, including humans) as well as various other extinct groups evolving the trait independently.\nA larger number of modern species intermittently or briefly use a bipedal gait. Several lizard species move bipedally when running, usually to escape from threats. Many primate and bear species will adopt a bipedal gait in order to reach food or explore their environment, though there are a few cases where they walk on their hind limbs only. Several arboreal primate species, such as gibbons and indriids, exclusively walk on two legs during the brief periods they spend on the ground. Many animals rear up on their hind legs while fighting or copulating. Some animals commonly stand on their hind legs to reach food, keep watch, threaten a competitor or predator, or pose in courtship, but do not move bipedally.\nEtymology.\nThe word is derived from the Latin words \"bi(s)\" 'two' and \"ped-\" 'foot', as contrasted with quadruped 'four feet'.\nAdvantages.\nLimited and exclusive bipedalism can offer a species several advantages. Bipedalism raises the head; this allows a greater field of vision with improved detection of distant dangers or resources, access to deeper water for wading animals and allows the animals to reach higher food sources with their mouths. While upright, non-locomotory limbs become free for other uses, including manipulation (in primates and rodents), flight (in birds), digging (in the giant pangolin), combat (in bears, great apes and the large monitor lizard) or camouflage.\nThe maximum bipedal speed appears slower than the maximum speed of quadrupedal movement with a flexible backbone \u2013 both the ostrich and the red kangaroo can reach speeds of , while the cheetah can exceed . Even though bipedalism is slower at first, over long distances, it has allowed humans to outrun most other animals according to the endurance running hypothesis. Bipedality in kangaroo rats has been hypothesized to improve locomotor performance, which could aid in escaping from predators.\nFacultative and obligate bipedalism.\nZoologists often label behaviors, including bipedalism, as \"facultative\" (i.e. optional) or \"obligate\" (the animal has no reasonable alternative). Even this distinction is not completely clear-cut \u2014 for example, humans other than infants normally walk and run in biped fashion, but almost all can crawl on hands and knees when necessary. There are even reports of humans who normally walk on all fours with their feet but not their knees on the ground, but these cases are a result of conditions such as Uner Tan syndrome \u2014 very rare genetic neurological disorders rather than normal behavior. Even if one ignores exceptions caused by some kind of injury or illness, there are many unclear cases, including the fact that \"normal\" humans can crawl on hands and knees. This article therefore avoids the terms \"facultative\" and \"obligate\", and focuses on the range of styles of locomotion \"normally\" used by various groups of animals. Normal humans may be considered \"obligate\" bipeds because the alternatives are very uncomfortable and usually only resorted to when walking is impossible.\nMovement.\nThere are a number of states of movement commonly associated with bipedalism.\nBipedal animals.\nThe great majority of living terrestrial vertebrates are quadrupeds, with bipedalism exhibited by only a handful of living groups. Humans, gibbons and large birds walk by raising one foot at a time. On the other hand, most macropods, smaller birds, lemurs and bipedal rodents move by hopping on both legs simultaneously. Tree kangaroos are able to walk or hop, most commonly alternating feet when moving arboreally and hopping on both feet simultaneously when on the ground.\nExtant reptiles.\nMany species of lizards become bipedal during high-speed, sprint locomotion, including the world's fastest lizard, the spiny-tailed iguana (genus \"Ctenosaura\").\nEarly reptiles and lizards.\nThe first known biped is the bolosaurid \"Eudibamus\" whose fossils date from 290 million years ago. Its long hind-legs, short forelegs, and distinctive joints all suggest bipedalism. The species became extinct in the early Permian.\nArchosaurs (includes crocodilians and dinosaurs).\nBirds.\nAll birds are bipeds, as is the case for all theropod dinosaurs. However, hoatzin chicks have claws on their wings which they use for climbing.\nOther archosaurs.\nBipedalism evolved more than once in archosaurs, the group that includes both dinosaurs and crocodilians. All dinosaurs are thought to be descended from a fully bipedal ancestor, perhaps similar to \"Eoraptor\".\nDinosaurs diverged from their archosaur ancestors approximately 230 million years ago during the Middle to Late Triassic period, roughly 20 million years after the Permian-Triassic extinction event wiped out an estimated 95 percent of all life on Earth. Radiometric dating of fossils from the early dinosaur genus \"Eoraptor\" establishes its presence in the fossil record at this time. Paleontologists suspect \"Eoraptor\" resembles the common ancestor of all dinosaurs; if this is true, its traits suggest that the first dinosaurs were small, bipedal predators. The discovery of primitive, dinosaur-like ornithodirans such as \"Marasuchus\" and \"Lagerpeton\" in Argentinian Middle Triassic strata supports this view; analysis of recovered fossils suggests that these animals were indeed small, bipedal predators.\nBipedal movement also re-evolved in a number of other dinosaur lineages such as the iguanodonts. Some extinct members of Pseudosuchia, a sister group to the avemetatarsalians (the group including dinosaurs and relatives), also evolved bipedal forms \u2013 a poposauroid from the Triassic, \"Effigia okeeffeae\", is thought to have been bipedal. Pterosaurs were previously thought to have been bipedal, but recent trackways have all shown quadrupedal locomotion.\nMammals.\nA number of groups of extant mammals have independently evolved bipedalism as their main form of locomotion - for example humans, ground pangolins, the extinct giant ground sloths, numerous species of jumping rodents and macropods. Humans, as their bipedalism has been extensively studied, are documented in the next section. Macropods are believed to have evolved bipedal hopping only once in their evolution, at some time no later than 45 million years ago.\nBipedal movement is less common among mammals, most of which are quadrupedal. All primates possess some bipedal ability, though most species primarily use quadrupedal locomotion on land. Primates aside, the macropods (kangaroos, wallabies and their relatives), kangaroo rats and mice, hopping mice and springhare move bipedally by hopping. Very few non-primate mammals commonly move bipedally with an alternating leg gait. Exceptions are the ground pangolin and in some circumstances the tree kangaroo. One black bear, Pedals, became famous locally and on the internet for having a frequent bipedal gait, although this is attributed to injuries on the bear's front paws. A two-legged fox was filmed in a Derbyshire garden in 2023, most likely having been born that way.\nPrimates.\nMost bipedal animals move with their backs close to horizontal, using a long tail to balance the weight of their bodies. The primate version of bipedalism is unusual because the back is close to upright (completely upright in humans), and the tail may be absent entirely. Many primates can stand upright on their hind legs without any support. \nChimpanzees, bonobos, gorillas, gibbons and baboons exhibit forms of bipedalism. On the ground sifakas move like all indrids with bipedal sideways hopping movements of the hind legs, holding their forelimbs up for balance. Geladas, although usually quadrupedal, will sometimes move between adjacent feeding patches with a squatting, shuffling bipedal form of locomotion. However, they can only do so for brief amounts, as their bodies are not adapted for constant bipedal locomotion.\nHumans are the only primates who are normally biped, due to an extra curve in the spine which stabilizes the upright position, as well as shorter arms relative to the legs than is the case for the nonhuman great apes. The evolution of human bipedalism began in primates about four million years ago, or as early as seven million years ago with \"Sahelanthropus\" or about 12 million years ago with \"Danuvius guggenmosi\". One hypothesis for human bipedalism is that it evolved as a result of differentially successful survival from carrying food to share with group members, although there are alternative hypotheses.\nInjured chimpanzees and bonobos have been capable of sustained bipedalism.\nThree captive primates, one macaque Natasha and two chimps, Oliver and Poko (chimpanzee), were found to move bipedally. Natasha switched to exclusive bipedalism after an illness, while Poko was discovered in captivity in a tall, narrow cage. Oliver reverted to knuckle-walking after developing arthritis. Non-human primates often use bipedal locomotion when carrying food, or while moving through shallow water.\nLimited bipedalism.\nLimited bipedalism in mammals.\nOther mammals engage in limited, non-locomotory, bipedalism. A number of other animals, such as rats, raccoons, and beavers will squat on their hindlegs to manipulate some objects but revert to four limbs when moving (the beaver will move bipedally if transporting wood for their dams, as will the raccoon when holding food). Bears will fight in a bipedal stance to use their forelegs as weapons. A number of mammals will adopt a bipedal stance in specific situations such as for feeding or fighting. Ground squirrels and meerkats will stand on hind legs to survey their surroundings, but will not walk bipedally. Dogs (e.g. Faith) can stand or move on two legs if trained, or if birth defect or injury precludes quadrupedalism. The gerenuk antelope stands on its hind legs while eating from trees, as did the extinct giant ground sloth and chalicotheres. The spotted skunk will walk on its front legs when threatened, rearing up on its front legs while facing the attacker so that its anal glands, capable of spraying an offensive oil, face its attacker.\nLimited bipedalism in non-mammals (and non-birds).\nBipedalism is unknown among the amphibians. Among the non-archosaur reptiles bipedalism is rare, but it is found in the \"reared-up\" running of lizards such as agamids and monitor lizards. Many reptile species will also temporarily adopt bipedalism while fighting. One genus of basilisk lizard can run bipedally across the surface of water for some distance. Among arthropods, cockroaches are known to move bipedally at high speeds. Bipedalism is rarely found outside terrestrial animals, though at least two species of octopus walk bipedally on the sea floor using two of their arms, allowing the remaining arms to be used to camouflage the octopus as a mat of algae or a floating coconut.\nEvolution of human bipedalism.\nThere are at least twelve distinct hypotheses as to how and why bipedalism evolved in humans, and also some debate as to when. Bipedalism evolved well before the large human brain or the development of stone tools. Bipedal specializations are found in \"Australopithecus\" fossils from 4.2 to 3.9 million years ago and recent studies have suggested that obligate bipedal hominid species were present as early as 7 million years ago. Nonetheless, the evolution of bipedalism was accompanied by significant evolutions in the spine including the forward movement in position of the foramen magnum, where the spinal cord leaves the cranium. Recent evidence regarding modern human sexual dimorphism (physical differences between male and female) in the lumbar spine has been seen in pre-modern primates such as \"Australopithecus africanus\". This dimorphism has been seen as an evolutionary adaptation of females to bear lumbar load better during pregnancy, an adaptation that non-bipedal primates would not need to make. Adapting bipedalism would have required less shoulder stability, which allowed the shoulder and other limbs to become more independent of each other and adapt for specific suspensory behaviors. In addition to the change in shoulder stability, changing locomotion would have increased the demand for shoulder mobility, which would have propelled the evolution of bipedalism forward. The different hypotheses are not necessarily mutually exclusive and a number of selective forces may have acted together to lead to human bipedalism. It is important to distinguish between adaptations for bipedalism and adaptations for running, which came later still.\nThe form and function of modern-day humans' upper bodies appear to have evolved from living in a more forested setting. Living in this kind of environment would have made it so that being able to travel arboreally would have been advantageous at the time. Although different to human walking, bipedal locomotion in trees was thought to be advantageous. It has also been proposed that, like some modern-day apes, early hominins had undergone a knuckle-walking stage prior to adapting the back limbs for bipedality while retaining forearms capable of grasping. Numerous causes for the evolution of human bipedalism involve freeing the hands for carrying and using tools, sexual dimorphism in provisioning, changes in climate and environment (from jungle to savanna) that favored a more elevated eye-position, and to reduce the amount of skin exposed to the tropical sun. It is possible that bipedalism provided a variety of benefits to the hominin species, and scientists have suggested multiple reasons for evolution of human bipedalism. There is also not only the question of why the earliest hominins were partially bipedal but also why hominins became more bipedal over time. For example, the postural feeding hypothesis describes how the earliest hominins became bipedal for the benefit of reaching food in trees while the savanna-based theory describes how the late hominins that started to settle on the ground became increasingly bipedal.\nMultiple factors.\nNapier (1963) argued that it is unlikely that a single factor drove the evolution of bipedalism. He stated \"It seems unlikely that any single factor was responsible for such a dramatic change in behaviour. In addition to the advantages of accruing from ability to carry objects \u2013 food or otherwise \u2013 the improvement of the visual range and the freeing of the hands for purposes of defence and offence may equally have played their part as catalysts.\" Sigmon (1971) demonstrated that chimpanzees exhibit bipedalism in different contexts, and one single factor should be used to explain bipedalism: preadaptation for human bipedalism. Day (1986) emphasized three major pressures that drove evolution of bipedalism: food acquisition, predator avoidance, and reproductive success. Ko (2015) stated that there are two main questions regarding bipedalism 1. Why were the earliest hominins partially bipedal? and 2. Why did hominins become more bipedal over time? He argued that these questions can be answered with combination of prominent theories such as Savanna-based, Postural feeding, and Provisioning.\nSavannah-based theory.\nAccording to the Savanna-based theory, hominines came down from the tree's branches and adapted to life on the savanna by walking erect on two feet. The theory suggests that early hominids were forced to adapt to bipedal locomotion on the open savanna after they left the trees. One of the proposed mechanisms was the knuckle-walking hypothesis, which states that human ancestors used quadrupedal locomotion on the savanna, as evidenced by morphological characteristics found in \"Australopithecus anamensis\" and \"Australopithecus afarensis\" forelimbs, and that it is less parsimonious to assume that knuckle walking developed twice in genera \"Pan\" and \"Gorilla\" instead of evolving it once as synapomorphy for \"Pan\" and \"Gorilla\" before losing it in Australopithecus. The evolution of an orthograde posture would have been very helpful on a savanna as it would allow the ability to look over tall grasses in order to watch out for predators, or terrestrially hunt and sneak up on prey. It was also suggested in P. E. Wheeler's \"The evolution of bipedality and loss of functional body hair in hominids\", that a possible advantage of bipedalism in the savanna was reducing the amount of surface area of the body exposed to the sun, helping regulate body temperature. In fact, Elizabeth Vrba's turnover pulse hypothesis supports the savanna-based theory by explaining the shrinking of forested areas due to global warming and cooling, which forced animals out into the open grasslands and caused the need for hominids to acquire bipedality.\nOthers state hominines had already achieved the bipedal adaptation that was used in the savanna. The fossil evidence reveals that early bipedal hominins were still adapted to climbing trees at the time they were also walking upright. It is possible that bipedalism evolved in the trees, and was later applied to the savanna as a vestigial trait. Humans and orangutans are both unique to a bipedal reactive adaptation when climbing on thin branches, in which they have increased hip and knee extension in relation to the diameter of the branch, which can increase an arboreal feeding range and can be attributed to a convergent evolution of bipedalism evolving in arboreal environments. Hominine fossils found in dry grassland environments led anthropologists to believe hominines lived, slept, walked upright, and died only in those environments because no hominine fossils were found in forested areas. However, fossilization is a rare occurrence\u2014the conditions must be just right in order for an organism that dies to become fossilized for somebody to find later, which is also a rare occurrence. The fact that no hominine fossils were found in forests does not ultimately lead to the conclusion that no hominines ever died there. The convenience of the savanna-based theory caused this point to be overlooked for over a hundred years.\nSome of the fossils found actually showed that there was still an adaptation to arboreal life. For example, Lucy, the famous \"Australopithecus afarensis\", found in Hadar in Ethiopia, which may have been forested at the time of Lucy's death, had curved fingers that would still give her the ability to grasp tree branches, but she walked bipedally. \"Little Foot\", a nearly-complete specimen of \"Australopithecus africanus\", has a divergent big toe as well as the ankle strength to walk upright. \"Little Foot\" could grasp things using his feet like an ape, perhaps tree branches, and he was bipedal. Ancient pollen found in the soil in the locations in which these fossils were found suggest that the area used to be much more wet and covered in thick vegetation and has only recently become the arid desert it is now.\nTraveling efficiency hypothesis.\nAn alternative explanation is that the mixture of savanna and scattered forests increased terrestrial travel by proto-humans between clusters of trees, and bipedalism offered greater efficiency for long-distance travel between these clusters than quadrupedalism. In an experiment monitoring chimpanzee metabolic rate via oxygen consumption, it was found that the quadrupedal and bipedal energy costs were very similar, implying that this transition in early ape-like ancestors would not have been very difficult or energetically costing. This increased travel efficiency is likely to have been selected for as it assisted foraging across widely dispersed resources.\nPostural feeding hypothesis.\nThe postural feeding hypothesis has been recently supported by Dr. Kevin Hunt, a professor at Indiana University. This hypothesis asserts that chimpanzees were only bipedal when they eat. While on the ground, they would reach up for fruit hanging from small trees and while in trees, bipedalism was used to reach up to grab for an overhead branch. These bipedal movements may have evolved into regular habits because they were so convenient in obtaining food. Also, Hunt's hypotheses states that these movements coevolved with chimpanzee arm-hanging, as this movement was very effective and efficient in harvesting food. When analyzing fossil anatomy, \"Australopithecus afarensis\" has very similar features of the hand and shoulder to the chimpanzee, which indicates hanging arms. Also, the \"Australopithecus\" hip and hind limb very clearly indicate bipedalism, but these fossils also indicate very inefficient locomotive movement when compared to humans. For this reason, Hunt argues that bipedalism evolved more as a terrestrial feeding posture than as a walking posture.\nA related study conducted by University of Birmingham, Professor Susannah Thorpe examined the most arboreal great ape, the orangutan, holding onto supporting branches in order to navigate branches that were too flexible or unstable otherwise. In more than 75 percent of observations, the orangutans used their forelimbs to stabilize themselves while navigating thinner branches. Increased fragmentation of forests where A. afarensis as well as other ancestors of modern humans and other apes resided could have contributed to this increase of bipedalism in order to navigate the diminishing forests. Findings also could shed light on discrepancies observed in the anatomy of A. afarensis, such as the ankle joint, which allowed it to \"wobble\" and long, highly flexible forelimbs. If bipedalism started from upright navigation in trees, it could explain both increased flexibility in the ankle as well as long forelimbs which grab hold of branches.\nProvisioning model.\nOne theory on the origin of bipedalism is the behavioral model presented by C. Owen Lovejoy, known as \"male provisioning\". Lovejoy theorizes that the evolution of bipedalism was linked to monogamy. In the face of long inter-birth intervals and low reproductive rates typical of the apes, early hominids engaged in pair-bonding that enabled greater parental effort directed towards rearing offspring. Lovejoy proposes that male provisioning of food would improve the offspring survivorship and increase the pair's reproductive rate. Thus the male would leave his mate and offspring to search for food and return carrying the food in his arms walking on his legs. This model is supported by the reduction (\"feminization\") of the male canine teeth in early hominids such as \"Sahelanthropus tchadensis\" and \"Ardipithecus ramidus\", which along with low body size dimorphism in \"Ardipithecus\" and \"Australopithecus\", suggests a reduction in inter-male antagonistic behavior in early hominids. In addition, this model is supported by a number of modern human traits associated with concealed ovulation (permanently enlarged breasts, lack of sexual swelling) and low sperm competition (moderate sized testes, low sperm mid-piece volume) that argues against recent adaptation to a polygynous reproductive system.\nHowever, this model has been debated, as others have argued that early bipedal hominids were instead polygynous. Among most monogamous primates, males and females are about the same size. That is sexual dimorphism is minimal, and other studies have suggested that \"Australopithecus afarensis\" males were nearly twice the weight of females. However, Lovejoy's model posits that the larger range a provisioning male would have to cover (to avoid competing with the female for resources she could attain herself) would select for increased male body size to limit predation risk. Furthermore, as the species became more bipedal, specialized feet would prevent the infant from conveniently clinging to the mother - hampering the mother's freedom and thus make her and her offspring more dependent on resources collected by others. Modern monogamous primates such as gibbons tend to be also territorial, but fossil evidence indicates that \"Australopithecus afarensis\" lived in large groups. However, while both gibbons and hominids have reduced canine sexual dimorphism, female gibbons enlarge ('masculinize') their canines so they can actively share in the defense of their home territory. Instead, the reduction of the male hominid canine is consistent with reduced inter-male aggression in a pair-bonded though group living primate.\nEarly bipedalism in homininae model.\nRecent studies of 4.4 million years old \"Ardipithecus ramidus\" suggest bipedalism. It is thus possible that bipedalism evolved very early in homininae and was reduced in chimpanzee and gorilla when they became more specialized. Other recent studies of the foot structure of \"Ardipithecus ramidus\" suggest that the species was closely related to African-ape ancestors. This possibly provides a species close to the true connection between fully bipedal hominins and quadruped apes. According to Richard Dawkins in his book \"The Ancestor's Tale\", chimps and bonobos are descended from \"Australopithecus\" gracile type species while gorillas are descended from \"Paranthropus\". These apes may have once been bipedal, but then lost this ability when they were forced back into an arboreal habitat, presumably by those australopithecines from whom eventually evolved hominins. Early hominines such as \"Ardipithecus ramidus\" may have possessed an arboreal type of bipedalism that later independently evolved towards knuckle-walking in chimpanzees and gorillas and towards efficient walking and running in modern humans (see figure). It is also proposed that one cause of Neanderthal extinction was a less efficient running.\nWarning display (aposematic) model.\nJoseph Jordania from the University of Melbourne recently (2011) suggested that bipedalism was one of the central elements of the general defense strategy of early hominids, based on aposematism, or warning display and intimidation of potential predators and competitors with exaggerated visual and audio signals. According to this model, hominids were trying to stay as visible and as loud as possible all the time. Several morphological and behavioral developments were employed to achieve this goal: upright bipedal posture, longer legs, long tightly coiled hair on the top of the head, body painting, threatening synchronous body movements, loud voice and extremely loud rhythmic singing/stomping/drumming on external subjects. Slow locomotion and strong body odor (both characteristic for hominids and humans) are other features often employed by aposematic species to advertise their non-profitability for potential predators.\nOther behavioural models.\nThere are a variety of ideas which promote a specific change in behaviour as the key driver for the evolution of hominid bipedalism. For example, Wescott (1967) and later Jablonski &amp; Chaplin (1993) suggest that bipedal threat displays could have been the transitional behaviour which led to some groups of apes beginning to adopt bipedal postures more often. Others (e.g. Dart 1925) have offered the idea that the need for more vigilance against predators could have provided the initial motivation. Dawkins (e.g. 2004) has argued that it could have begun as a kind of fashion that just caught on and then escalated through sexual selection. And it has even been suggested (e.g. Tanner 1981:165) that male phallic display could have been the initial incentive, as well as increased sexual signaling in upright female posture.\nThermoregulatory model.\nThe thermoregulatory model explaining the origin of bipedalism is one of the simplest theories so far advanced, but it is a viable explanation. Dr. Peter Wheeler, a professor of evolutionary biology, proposes that bipedalism raises the amount of body surface area higher above the ground which results in a reduction in heat gain and helps heat dissipation. When a hominid is higher above the ground, the organism accesses more favorable wind speeds and temperatures. During heat seasons, greater wind flow results in a higher heat loss, which makes the organism more comfortable. Also, Wheeler explains that a vertical posture minimizes the direct exposure to the sun whereas quadrupedalism exposes more of the body to direct exposure. Analysis and interpretations of Ardipithecus reveal that this hypothesis needs modification to consider that the forest and woodland environmental preadaptation of early-stage hominid bipedalism preceded further refinement of bipedalism by the pressure of natural selection. This then allowed for the more efficient exploitation of the hotter conditions ecological niche, rather than the hotter conditions being hypothetically bipedalism's initial stimulus. A feedback mechanism from the advantages of bipedality in hot and open habitats would then in turn make a forest preadaptation solidify as a permanent state.\nCarrying models.\nCharles Darwin wrote that \"Man could not have attained his present dominant position in the world without the use of his hands, which are so admirably adapted to the act of obedience of his will\". Darwin (1871:52) and many models on bipedal origins are based on this line of thought. Gordon Hewes (1961) suggested that the carrying of meat \"over considerable distances\" (Hewes 1961:689) was the key factor. Isaac (1978) and Sinclair et al. (1986) offered modifications of this idea, as indeed did Lovejoy (1981) with his \"provisioning model\" described above. Others, such as Nancy Tanner (1981), have suggested that infant carrying was key, while others again have suggested stone tools and weapons drove the change. This stone-tools theory is very unlikely, as though ancient humans were known to hunt, the discovery of tools was not discovered for thousands of years after the origin of bipedalism, chronologically precluding it from being a driving force of evolution. (Wooden tools and spears fossilize poorly and therefore it is difficult to make a judgment about their potential usage.)\nWading models.\nThe observation that large primates, including especially the great apes, that predominantly move quadrupedally on dry land, tend to switch to bipedal locomotion in waist deep water, has led to the idea that the origin of human bipedalism may have been influenced by waterside environments. This idea, labelled \"the wading hypothesis\", was originally suggested by the Oxford marine biologist Alister Hardy who said: \"It seems to me likely that Man learnt to stand erect first in water and then, as his balance improved, he found he became better equipped for standing up on the shore when he came out, and indeed also for running.\" It was then promoted by Elaine Morgan, as part of the aquatic ape hypothesis, who cited bipedalism among a cluster of other human traits unique among primates, including voluntary control of breathing, hairlessness and subcutaneous fat. The \"aquatic ape hypothesis\", as originally formulated, has not been accepted or considered a serious theory within the anthropological scholarly community. Others, however, have sought to promote wading as a factor in the origin of human bipedalism without referring to further (\"aquatic ape\" related) factors. Since 2000 Carsten Niemitz has published a series of papers and a book on a variant of the wading hypothesis, which he calls the \"amphibian generalist theory\" ().\nOther theories have been proposed that suggest wading and the exploitation of aquatic food sources (providing essential nutrients for human brain evolution or critical fallback foods) may have exerted evolutionary pressures on human ancestors promoting adaptations which later assisted full-time bipedalism. It has also been thought that consistent water-based food sources had developed early hominid dependency and facilitated dispersal along seas and rivers.\nConsequences.\nPrehistoric fossil records show that early hominins first developed bipedalism before being followed by an increase in brain size. The consequences of these two changes in particular resulted in painful and difficult labor due to the increased favor of a narrow pelvis for bipedalism being countered by larger heads passing through the constricted birth canal. This phenomenon is commonly known as the obstetrical dilemma.\nNon-human primates habitually deliver their young on their own, but the same cannot be said for modern-day humans. Isolated birth appears to be rare and actively avoided cross-culturally, even if birthing methods may differ between said cultures. This is due to the fact that the narrowing of the hips and the change in the pelvic angle caused a discrepancy in the ratio of the size of the head to the birth canal. The result of this is that there is greater difficulty in birthing for hominins in general, let alone to be doing it by oneself.\nPhysiology.\nBipedal movement occurs in a number of ways and requires many mechanical and neurological adaptations. Some of these are described below.\nBiomechanics.\nStanding.\nEnergy-efficient means of standing bipedally involve constant adjustment of balance, and of course these must avoid overcorrection. The difficulties associated with simple standing in upright humans are highlighted by the greatly increased risk of falling present in the elderly, even with minimal reductions in control system effectiveness.\nShoulder stability.\nShoulder stability would decrease with the evolution of bipedalism. Shoulder mobility would increase because the need for a stable shoulder is only present in arboreal habitats. Shoulder mobility would support suspensory locomotion behaviors which are present in human bipedalism. The forelimbs are freed from weight-bearing requirements, which makes the shoulder a place of evidence for the evolution of bipedalism.\nWalking.\nUnlike non-human apes that are able to practice bipedality such as \"Pan\" and \"Gorilla\", hominins have the ability to move bipedally without the utilization of a bent-hip-bent-knee (BHBK) gait, which requires the engagement of both the hip and the knee joints. This human ability to walk is made possible by the spinal curvature humans have that non-human apes do not. Rather, walking is characterized by an \"inverted pendulum\" movement in which the center of gravity vaults over a stiff leg with each step. Force plates can be used to quantify the whole-body kinetic &amp; potential energy, with walking displaying an out-of-phase relationship indicating exchange between the two. This model applies to all walking organisms regardless of the number of legs, and thus bipedal locomotion does not differ in terms of whole-body kinetics.\nIn humans, walking is composed of several separate processes:\nRunning.\nEarly hominins underwent post-cranial changes in order to better adapt to bipedality, especially running. One of these changes is having longer hindlimbs proportional to the forelimbs and their effects. As previously mentioned, longer hindlimbs assist in thermoregulation by reducing the total surface area exposed to direct sunlight while simultaneously allowing for more space for cooling winds. Additionally, having longer limbs is more energy-efficient, since longer limbs mean that overall muscle strain is lessened. Better energy efficiency, in turn, means higher endurance, particularly when running long distances.\nRunning is characterized by a spring-mass movement. Kinetic and potential energy are in phase, and the energy is stored &amp; released from a spring-like limb during foot contact, achieved by the plantar arch and the Achilles tendon in the foot and leg, respectively. Again, the whole-body kinetics are similar to animals with more limbs.\nMusculature.\nBipedalism requires strong leg muscles, particularly in the thighs. Contrast in domesticated poultry the well muscled legs, against the small and bony wings. Likewise in humans, the quadriceps and hamstring muscles of the thigh are both so crucial to bipedal activities that each alone is much larger than the well-developed biceps of the arms. In addition to the leg muscles, the increased size of the gluteus maximus in humans is an important adaptation as it provides support and stability to the trunk and lessens the amount of stress on the joints when running.\nRespiration.\nQuadrupeds, have more restrictive breathing respire while moving than do bipedal humans. \"Quadrupedal species normally synchronize the locomotor and respiratory cycles at a constant ratio of 1:1 (strides per breath) in both the trot and gallop. Human runners differ from quadrupeds in that while running they employ several phase-locked patterns (4:1, 3:1, 2:1, 1:1, 5:2, and 3:2), although a 2:1 coupling ratio appears to be favored. Even though the evolution of bipedal gait has reduced the mechanical constraints on respiration in man, thereby permitting greater flexibility in breathing pattern, it has seemingly not eliminated the need for the synchronization of respiration and body motion during sustained running.\"\nRespiration through bipedality means that there is better breath control in bipeds, which can be associated with brain growth. The modern brain utilizes approximately 20% of energy input gained through breathing and eating, as opposed to species like chimpanzees who use up twice as much energy as humans for the same amount of movement. This excess energy, leading to brain growth, also leads to the development of verbal communication. This is because breath control means that the muscles associated with breathing can be manipulated into creating sounds. This means that the onset of bipedality, leading to more efficient breathing, may be related to the origin of verbal language.\nBipedal robots.\nFor nearly the whole of the 20th century, bipedal robots were very difficult to construct and robot locomotion involved only wheels, treads, or multiple legs. Recent cheap and compact computing power has made two-legged robots more feasible. Some notable biped robots are ASIMO, HUBO, MABEL and QRIO. Recently, spurred by the success of creating a fully passive, un-powered bipedal walking robot, those working on such machines have begun using principles gleaned from the study of human and animal locomotion, which often relies on passive mechanisms to minimize power consumption."}
{"id": "4211", "revid": "31516478", "url": "https://en.wikipedia.org/wiki?curid=4211", "title": "Bootstrapping", "text": "In general, bootstrapping usually refers to a self-starting process that is supposed to continue or grow without external input. Many analytical techniques are often called bootstrap methods in reference to their self-starting or self-supporting implementation, such as bootstrapping (statistics), bootstrapping (finance), or bootstrapping (linguistics).\nEtymology.\nTall boots may have a tab, loop or handle at the top known as a bootstrap, allowing one to use fingers or a boot hook tool to help pull the boots on. The saying \"to \" was already in use during the 19th century as an example of an impossible task. The idiom dates at least to 1834, when it appeared in the \"Workingman's Advocate\": \"It is conjectured that Mr. Murphee will now be enabled to hand himself over the Cumberland river or a barn yard fence by the straps of his boots.\" In 1860 it appeared in a comment on philosophy of mind: \"The attempt of the mind to analyze itself [is] an effort analogous to one who would lift himself by his own bootstraps.\" Bootstrap as a metaphor, meaning to better oneself by one's own unaided efforts, was in use in 1922. This metaphor spawned additional metaphors for a series of self-sustaining processes that proceed without external help.\nThe term is sometimes attributed to a story in Rudolf Erich Raspe's \"\", but in that story Baron Munchausen pulls himself (and his horse) out of a swamp by his hair (specifically, his pigtail), not by his bootstraps and no explicit reference to bootstraps has been found elsewhere in the various versions of the Munchausen tales.\nOriginally meant to attempt something ludicrously far-fetched or even impossible, the phrase \"Pull yourself up by your bootstraps!\" has since been utilized as a narrative for economic mobility or a cure for depression. That idea is believed to have been popularized by American writer Horatio Alger in the 19th century. To request that someone \"bootstrap\" is to suggest that they might overcome great difficulty by sheer force of will.\nCritics have observed that the phrase is used to portray unfair situations as far more meritocratic than they really are. A 2009 study found that 77% of Americans believe that wealth is often the result of hard work. Various studies have found that the main predictor of future wealth is not IQ or hard work, but initial wealth.\nApplications.\nComputing.\nIn computer technology, the term bootstrapping refers to language compilers that are able to be coded in the same language. (For example, a C compiler is now written in the C language. Once the basic compiler is written, improvements can be iteratively made, thus pulling the language up by its bootstraps). Also, booting usually refers to the process of loading the basic software into the memory of a computer after power-on or general reset, the kernel will load the operating system which will then take care of loading other device drivers and software as needed.\nSoftware loading and execution.\nBooting is the process of starting a computer, specifically with regard to starting its software. The process involves a chain of stages, in which at each stage, a relatively small and simple program loads and then executes the larger, more complicated program of the next stage. It is in this sense that the computer \"pulls itself up by its bootstraps\"; i.e., it improves itself by its own efforts. Booting is a chain of events that starts with execution of hardware-based procedures and may then hand off to firmware and software which is loaded into main memory. Booting often involves processes such as performing self-tests, loading configuration settings, loading a BIOS, resident monitors, a hypervisor, an operating system, or utility software.\nThe computer term bootstrap began as a metaphor in the 1950s. In computers, pressing a bootstrap button caused a hardwired program to read a bootstrap program from an input unit. The computer would then execute the bootstrap program, which caused it to read more program instructions. It became a self-sustaining process that proceeded without external help from manually entered instructions. As a computing term, bootstrap has been used since at least 1953.\nSoftware development.\nBootstrapping can also refer to the development of successively more complex, faster programming environments. The simplest environment will be, perhaps, a very basic text editor (\"e.g.\", ed) and an assembler program. Using these tools, one can write a more complex text editor, and a simple compiler for a higher-level language and so on, until one can have a graphical IDE and an extremely high-level programming language.\nHistorically, bootstrapping also refers to an early technique for computer program development on new hardware. The technique described in this paragraph has been replaced by the use of a cross compiler executed by a pre-existing computer. Bootstrapping in program development began during the 1950s when each program was constructed on paper in decimal code or in binary code, bit by bit (1s and 0s), because there was no high-level computer language, no compiler, no assembler, and no linker. A tiny assembler program was hand-coded for a new computer (for example the IBM 650) which converted a few instructions into binary or decimal code: A1. This simple assembler program was then rewritten in its just-defined assembly language but with extensions that would enable the use of some additional mnemonics for more complex operation codes. The enhanced assembler's source program was then assembled by its predecessor's executable (A1) into binary or decimal code to give A2, and the cycle repeated (now with those enhancements available), until the entire instruction set was coded, branch addresses were automatically calculated, and other conveniences (such as conditional assembly, macros, optimisations, etc.) established. This was how the early Symbolic Optimal Assembly Program (SOAP) was developed. Compilers, linkers, loaders, and utilities were then coded in assembly language, further continuing the bootstrapping process of developing complex software systems by using simpler software.\nThe term was also championed by Doug Engelbart to refer to his belief that organizations could better evolve by improving the process they use for improvement (thus obtaining a compounding effect over time). His SRI team that developed the NLS hypertext system applied this strategy by using the tool they had developed to improve the tool.\nCompilers.\nThe development of compilers for new programming languages first developed in an existing language but then rewritten in the new language and compiled by itself, is another example of the bootstrapping notion.\nInstallers.\nDuring the installation of computer programs, it is sometimes necessary to update the installer or package manager itself. The common pattern for this is to use a small executable bootstrapper file (\"e.g.,\" setup.exe) which updates the installer and starts the real installation after the update. Sometimes the bootstrapper also installs other prerequisites for the software during the bootstrapping process.\nOverlay networks.\nA bootstrapping node, also known as a rendezvous host, is a node in an overlay network that provides initial configuration information to newly joining nodes so that they may successfully join the overlay network.\nDiscrete-event simulation.\nA type of computer simulation called discrete-event simulation represents the operation of a system as a chronological sequence of events. A technique called \"bootstrapping the simulation model\" is used, which bootstraps initial data points using a pseudorandom number generator to schedule an initial set of pending events, which schedule additional events, and with time, the distribution of event times approaches its steady state\u2014the bootstrapping behavior is overwhelmed by steady-state behavior.\nArtificial intelligence and machine learning.\nBootstrapping is a technique used to iteratively improve a classifier's performance. Typically, multiple classifiers will be trained on different sets of the input data, and on prediction tasks the output of the different classifiers will be combined.\nSeed AI is a hypothesized type of artificial intelligence capable of recursive self-improvement. Having improved itself, it would become better at improving itself, potentially leading to an exponential increase in intelligence. No such AI is known to exist, but it remains an active field of research. Seed AI is a significant part of some theories about the technological singularity: proponents believe that the development of seed AI will rapidly yield ever-smarter intelligence (via bootstrapping) and thus a new era.\nStatistics.\nBootstrapping is a resampling technique used to obtain estimates of summary statistics.\nBusiness.\nBootstrapping in business means starting a business without external help or working capital. Entrepreneurs in the startup development phase of their company survive through internal cash flow and are very cautious with their expenses. Generally at the start of a venture, a small amount of money will be set aside for the bootstrap process. Bootstrapping can also be a supplement for econometric models. Bootstrapping was also expanded upon in the book \"Bootstrap Business\" by Richard Christiansen, the Harvard Business Review article \"The Art of Bootstrapping\" and the follow-up book \"The Origin and Evolution of New Businesses\" by Amar Bhide. There is also an entire bible written on how to properly bootstrap by Seth Godin.\nExperts have noted that several common stages exist for bootstrapping a business venture:\nThere are many types of companies that are eligible for bootstrapping. Early-stage companies that do not necessarily require large influxes of capital (particularly from outside sources) qualify. This would specifically allow for flexibility for the business and time to grow. Serial entrepreneur companies could also possibly reap the benefits of bootstrapping. These are organizations whereby the founder has money from the sale of a previous companies they can use to invest.\nThere are different methods of bootstrapping. Future business owners aspiring to use bootstrapping as way of launching their product or service often use the following methods:\nBootstrapping is often considered successful. When taking into account statistics provided by Fundera, approximately 77% of small business rely on some sort of personal investment and or savings in order to fund their startup ventures. The average small business venture requires approximately $10,000 in startup capital with a third of small business launching with less than $5,000 bootstrapped.\nBased on startup data presented by Entrepreneur.com, in comparison other methods of funding, bootstrapping is more commonly used than others. \"0.91% of startups are funded by angel investors, while 0.05% are funded by VCs. In contrast, 57 percent of startups are funded by personal loans and credit, while 38 percent receive funding from family and friends.\"\nSome examples of successful entrepreneurs that have used bootstrapping in order to finance their businesses include serial entrepreneur Mark Cuban. He has publicly endorsed bootstrapping claiming that \"If you can start on your own \u2026 do it by [yourself] without having to go out and raise money.\" When asked why he believed this approach was most necessary, he replied, \"I think the biggest mistake people make is once they have an idea and the goal of starting a business, they think they have to raise money. And once you raise money, that's not an accomplishment, that's an obligation\" because \"now, you're reporting to whoever you raised money from.\"\nBootstrapped companies such as Apple Inc. (APPL), eBay Inc. (EBAY) and Coca-Cola Co. have also claimed that they attribute some of their success to the fact that this method of funding enables them to remain highly focused on a specific array of profitable product.\nStartups can grow by reinvesting profits in its own growth if bootstrapping costs are low and return on investment is high. This financing approach allows owners to maintain control of their business and forces them to spend with discipline. In addition, bootstrapping allows startups to focus on customers rather than investors, thereby increasing the likelihood of creating a profitable business. This leaves startups with a better exit strategy with greater returns. \nLeveraged buyouts, or highly leveraged or \"bootstrap\" transactions, occur when an investor acquires a controlling interest in a company's equity and where a significant percentage of the purchase price is financed through leverage, i.e.\u00a0borrowing by the acquired company. \nOperation Bootstrap (\"Operaci\u00f3n Manos a la Obra\") refers to the ambitious projects that industrialized Puerto Rico in the mid-20th century.\nBiology.\nRichard Dawkins in his book \"River Out of Eden\" used the computer bootstrapping concept to explain how biological cells differentiate: \"Different cells receive different combinations of chemicals, which switch on different combinations of genes, and some genes work to switch other genes on or off. And so the bootstrapping continues, until we have the full repertoire of different kinds of cells.\"\nPhylogenetics.\nBootstrapping analysis gives a way to judge the strength of support for clades on phylogenetic trees. A number is written by a node, which reflects the percentage of bootstrap trees which also resolve the clade at the endpoints of that branch.\nLaw.\nBootstrapping is a rule preventing the admission of hearsay evidence in conspiracy cases.\nLinguistics.\nBootstrapping is a theory of language acquisition.\nPhysics.\nFlatness.\nWhitworth's three plates method does not rely other flat reference surfaces or other precision instruments, and thus solves the problem of how to create a better precise flat surface.\nQuantum theory.\nBootstrapping is using very general consistency criteria to determine the form of a quantum theory from some assumptions on the spectrum of particles or operators.\nMagnetically confined fusion plasmas.\nIn tokamak fusion devices, bootstrapping refers to the process in which a bootstrap current is self-generated by the plasma, which reduces or eliminates the need for an external current driver. Maximising the bootstrap current is a major goal of advanced tokamak designs.\nInertially confined fusion plasmas.\nBootstrapping in inertial confinement fusion refers to the alpha particles produced in the fusion reaction providing further heating to the plasma. This heating leads to ignition and an overall energy gain.\nElectronics.\nBootstrapping is a form of positive feedback in analog circuit design.\nElectric power grid.\nAn electric power grid is almost never brought down intentionally. Generators and power stations are started and shut down as necessary. A typical power station requires power for start up prior to being able to generate power. This power is obtained from the grid, so if the entire grid is down these stations cannot be started.\nTherefore, to get a grid started, there must be at least a small number of power stations that can start entirely on their own. A black start is the process of restoring a power station to operation without relying on external power. In the absence of grid power, one or more black starts are used to bootstrap the grid.\nNuclear power.\nA nuclear power plant always needs to have a way to remove decay heat, which is usually done with electrical cooling pumps. But in the rare case of a complete loss of electrical power, this can still be achieved by booting a turbine generator. As steam builds up in the steam generator, it can be used to power the turbine generator (initially with no oil pumps, circ water pumps, or condensation pumps). Once the turbine generator is producing electricity, the auxiliary pumps can be powered on, and the reactor cooling pumps can be run momentarily. Eventually the steam pressure will become insufficient to power the turbine generator, and the process can be shut down in reverse order. The process can be repeated until no longer needed. This can cause great damage to the turbine generator, but more importantly, it saves the nuclear reactor.\nCellular networks.\nA Bootstrapping Server Function (BSF) is an intermediary element in cellular networks which provides application independent functions for mutual authentication of user equipment and servers unknown to each other and for 'bootstrapping' the exchange of secret session keys afterwards. The term 'bootstrapping' is related to building a security relation with a previously unknown device first and to allow installing security elements (keys) in the device and the BSF afterwards."}
{"id": "4212", "revid": "44062", "url": "https://en.wikipedia.org/wiki?curid=4212", "title": "Bolshevik", "text": ""}
{"id": "4213", "revid": "48988249", "url": "https://en.wikipedia.org/wiki?curid=4213", "title": "Baltic languages", "text": "The Baltic languages are a branch of the Indo-European language family spoken natively or as a second language by a population of about 6.5\u20137.0 million people mainly in areas extending east and southeast of the Baltic Sea in Europe. Together with the Slavic languages, they form the Balto-Slavic branch of the Indo-European family.\nScholars usually regard them as a single subgroup divided into two branches: West Baltic (containing only extinct languages) and East Baltic (containing at least two living languages, Lithuanian, Latvian, and by some counts including Latgalian and Samogitian as separate languages rather than dialects of those two). The range of the East Baltic linguistic influence once possibly reached as far as the Ural Mountains, but this hypothesis has been questioned.\nOld Prussian, a Western Baltic language that became extinct in the 18th century, had possibly conserved the greatest number of properties from Proto-Baltic.\nAlthough related, Lithuanian, Latvian, and particularly Old Prussian have lexicons that differ substantially from one another and so the languages are not mutually intelligible. Relatively low mutual interaction for neighbouring languages historically led to gradual erosion of mutual intelligibility, and development of their respective linguistic innovations that did not exist in shared Proto-Baltic. The substantial number of false friends and various uses and sources of loanwords from their surrounding languages are considered to be the major reasons for poor mutual intelligibility today.\nBranches.\nWithin Indo-European, the Baltic languages are generally classified as forming a single family with two branches: Eastern and Western Baltic. But these two branches are sometimes classified as independent branches of Balto-Slavic itself.\nHistory.\nIt is believed that the Baltic languages are among the most conservative of the currently remaining Indo-European languages, despite their late attestation.\nAlthough the Baltic Aesti tribe was mentioned by ancient historians such as Tacitus as early as 98 CE, the first attestation of a Baltic language was 1369, in a Basel epigram of two lines written in Old Prussian. Lithuanian was first attested in a printed book, which is a Catechism by Martynas Ma\u017evydas published in 1547. Latvian appeared in a printed Catechism in 1585.\nOne reason for the late attestation is that the Baltic peoples resisted Christianization longer than any other Europeans, which delayed the introduction of writing and isolated their languages from outside influence.\nWith the establishment of a German state in Prussia, and the mass influx of Germanic (and to a lesser degree Slavic-speaking) settlers, the Prussians began to be assimilated, and by the end of the 17th century, the Prussian language had become extinct.\nAfter the Partitions of Polish-Lithuanian Commonwealth, most of the Baltic lands were under the rule of the Russian Empire, where the native languages or alphabets were sometimes prohibited from being written down or used publicly in a Russification effort (see Lithuanian press ban for the ban in force from 1864 to 1904).\nGeographic distribution.\nSpeakers of modern Baltic languages are generally concentrated within the borders of Lithuania and Latvia, and in emigrant communities in the United States, Canada, Australia and the countries within the former borders of the Soviet Union.\nHistorically the languages were spoken over a larger area: west to the mouth of the Vistula river in present-day Poland, at least as far east as the Dniepr river in present-day Belarus, perhaps even to Moscow, and perhaps as far south as Kyiv. Key evidence of Baltic language presence in these regions is found in hydronyms (names of bodies of water) that are characteristically Baltic. The use of hydronyms is generally accepted to determine the extent of a culture's influence, but \"not\" the date of such influence.\nThe eventual expansion of the use of Slavic languages in the south and east, and Germanic languages in the west, reduced the geographic distribution of Baltic languages to a fraction of the area that they formerly covered. The Russian geneticist Oleg Balanovsky speculated that there is a predominance of the assimilated pre-Slavic substrate in the genetics of East and West Slavic populations, according to him the common genetic structure which contrasts East Slavs and Balts from other populations may suggest that the pre-Slavic substrate of the East Slavs consists most significantly of Baltic-speakers, which predated the Slavs in the cultures of the Eurasian steppe according to archaeological references he cites.\nContact with Uralic languages.\nThough Estonia is geopolitically included among the Baltic states due to its location, Estonian is a Finnic language of the Uralic language family and is not related to the Baltic languages, which are Indo-European.\nThe Mordvinic languages, spoken mainly along western tributaries of the Volga, show several dozen loanwords from one or more Baltic languages. These may have been mediated by contacts with the Eastern Balts along the river Oka. In regards to the same geographical location, Asko Parpola, in a 2013 article, suggested that the Baltic presence in this area, dated to \u2013600 CE, is due to an \"elite superstratum\". However, linguist argued that the Volga-Oka is a \"secondary\" Baltic-speaking area, expanding from East Baltic, due to a large number of Baltic loanwords in Finnic and Saami.\nFinnish scholars also indicate that Latvian had extensive contacts with Livonian, and, to a lesser extent, to Estonian and South Estonian. Therefore, this contact accounts for the number of Finnic hydronyms in Lithuania and Latvia that increase in a northwards direction.\nParpola, in the same article, supposed the existence of a Baltic substratum for Finnic, in Estonia and coastal Finland. In the same vein, Kallio argues for the existence of a lost \"North Baltic language\" that would account for loanwords during the evolution of the Finnic branch.\nComparative linguistics.\nGenetic relatedness.\nThe Baltic languages are of particular interest to linguists because they retain many archaic features, which are thought to have been present in the early stages of the Proto-Indo-European language. However, linguists have had a hard time establishing the precise relationship of the Baltic languages to other languages in the Indo-European family. Several of the extinct Baltic languages have a limited or nonexistent written record, their existence being known only from the records of ancient historians and personal or place names. All of the languages in the Baltic group (including the living ones) were first written down relatively late in their probable existence as distinct languages. These two factors combined with others have obscured the history of the Baltic languages, leading to a number of theories regarding their position in the Indo-European family.\nThe Baltic languages show a close relationship with the Slavic languages, and are grouped with them in a Balto-Slavic family by most scholars. This family is considered to have developed from a common ancestor, Proto-Balto-Slavic. Later on, several lexical, phonological and morphological dialectisms developed, separating the various Balto-Slavic languages from each other. Although it is generally agreed that the Slavic languages developed from a single more-or-less unified dialect (Proto-Slavic) that split off from common Balto-Slavic, there is more disagreement about the relationship between the Baltic languages.\nThe traditional view is that the Balto-Slavic languages split into two branches, Baltic and Slavic, with each branch developing as a single common language (Proto-Baltic and Proto-Slavic) for some time afterwards. Proto-Baltic is then thought to have split into East Baltic and West Baltic branches. However, more recent scholarship has suggested that there was no unified Proto-Baltic stage, but that Proto-Balto-Slavic split directly into three groups: Slavic, East Baltic and West Baltic. Under this view, the Baltic family is paraphyletic, and consists of all Balto-Slavic languages that are not Slavic. In the 1960s Vladimir Toporov and Vyacheslav Ivanov made the following conclusions about the relationship between the Baltic and Slavic languages: \nThese scholars' theses do not contradict the close relationship between Baltic and Slavic languages and, from a historical perspective, specify the Baltic-Slavic languages' evolution \u2013 the terms 'Baltic' and 'Slavic' are relevant only from the point of view of the present time, meaning diachronic changes, and the oldest stage of the language development could be called both Baltic and Slavic; this concept does not contradict the traditional thesis that the Proto-Slavic and Proto-Baltic languages coexisted for a long time after their formation \u2013 between the 2nd millennium BC and circa the 5th century BC \u2013 the Proto-Slavic language was a continuum of the Proto-Baltic dialects, more rather, the Proto-Slavic language should have been localized in the peripheral circle of Proto-Baltic dialects.\nFinally, a minority of scholars argue that Baltic descended directly from Proto-Indo-European, without an intermediate common Balto-Slavic stage. They argue that the many similarities and shared innovations between Baltic and Slavic are caused by several millennia of contact between the groups, rather than a shared heritage.\nThracian hypothesis.\nThe Baltic-speaking peoples likely encompassed an area in eastern Europe much larger than their modern range. As in the case of the Celtic languages of Western Europe, they were reduced by invasion, extermination and assimilation. Studies in comparative linguistics point to genetic relationship between the languages of the Baltic family and the following extinct languages:\nThe Baltic classification of Dacian and Thracian has been proposed by the Lithuanian scientist Jonas Basanavi\u010dius, who insisted this is the most important work of his life and listed 600 identical words of Balts and Thracians. His theory included Phrygian in the related group, but this did not find support and was disapproved among other authors, such as , whose own analysis found Phrygian completely lacking parallels in either Thracian or Baltic languages.\nThe Bulgarian linguist Ivan Duridanov, who improved the most extensive list of toponyms, in his first publication claimed that Thracian is genetically linked to the Baltic languages and in the next one he made the following classification: \"The Thracian language formed a close group with the Baltic, the Dacian and the \"Pelasgian\" languages. More distant were its relations with the other Indo-European languages, and especially with Greek, the Italic and Celtic languages, which exhibit only isolated phonetic similarities with Thracian; the Tokharian and the Hittite were also distant. \" Of about 200 reconstructed Thracian words by Duridanov most cognates (138) appear in the Baltic languages, mostly in Lithuanian, followed by Germanic (61), Indo-Aryan (41), Greek (36), Bulgarian (23), Latin (10) and Albanian (8). The cognates of the reconstructed Dacian words in his publication are found mostly in the Baltic languages, followed by Albanian. Parallels have enabled linguists, using the techniques of comparative linguistics, to decipher the meanings of several Dacian and Thracian placenames with, they claim, a high degree of probability. Of 74 Dacian placenames attested in primary sources and considered by Duridanov, a total of 62 have Baltic cognates, most of which were rated \"certain\" by Duridanov. For a big number of 300 Thracian geographic names most parallels were found between Thracian and Baltic geographic names in the study of Duridanov. According to him the most important impression make the geographic cognates of Baltic and Thracian \"the similarity of these parallels stretching frequently on the main element and the suffix simultaneously, which makes a strong impression\".\nRomanian linguist Sorin Paliga, analysing and criticizing Harvey Mayer's study, did admit \"great likeness\" between Thracian, the substrate of Romanian, and \"some Baltic forms\"."}
{"id": "4214", "revid": "49085933", "url": "https://en.wikipedia.org/wiki?curid=4214", "title": "Bioinformatics", "text": "Bioinformatics () is an interdisciplinary field of science that develops methods and software tools for understanding biological data, especially when the data sets are large and complex. Bioinformatics uses biology, chemistry, physics, computer science, data science, computer programming, information engineering, mathematics and statistics to analyze and interpret biological data. The process of analyzing and interpreting data can sometimes be referred to as computational biology, however this distinction between the two terms is often disputed. To some, the term \"computational biology\" refers to building and using models of biological systems.\nComputational, statistical, and computer programming techniques have been used for computer simulation analyses of biological queries. They include reused specific analysis \"pipelines\", particularly in the field of genomics, such as by the identification of genes and single nucleotide polymorphisms (SNPs). These pipelines are used to better understand the genetic basis of disease, unique adaptations, desirable properties (especially in agricultural species), or differences between populations. Bioinformatics also includes proteomics, which tries to understand the organizational principles within nucleic acid and protein sequences.\nImage and signal processing allow extraction of useful results from large amounts of raw data. In the field of genetics, it aids in sequencing and annotating genomes and their observed mutations. Bioinformatics includes text mining of biological literature and the development of biological and gene ontologies to organize and query biological data. It also plays a role in the analysis of gene and protein expression and regulation. Bioinformatics tools aid in comparing, analyzing and interpreting genetic and genomic data and more generally in the understanding of evolutionary aspects of molecular biology. At a more integrative level, it helps analyze and catalogue the biological pathways and networks that are an important part of systems biology. In structural biology, it aids in the simulation and modeling of DNA, RNA, proteins as well as biomolecular interactions.\nHistory.\nThe first definition of the term \"bioinformatics\" was coined by Paulien Hogeweg and Ben Hesper in 1970, to refer to the study of information processes in biotic systems. This definition placed bioinformatics as a field parallel to biochemistry (the study of chemical processes in biological systems).\nBioinformatics and computational biology involved the analysis of biological data, particularly DNA, RNA, and protein sequences. The field of bioinformatics experienced explosive growth starting in the mid-1990s, driven largely by the Human Genome Project and by rapid advances in DNA sequencing technology.\nAnalyzing biological data to produce meaningful information involves writing and running software programs that use algorithms from graph theory, artificial intelligence, soft computing, data mining, image processing, and computer simulation. The algorithms in turn depend on theoretical foundations such as discrete mathematics, control theory, system theory, information theory, and statistics.\nSequences.\nThere has been a tremendous advance in speed and cost reduction since the completion of the Human Genome Project, with some labs able to sequence over 100,000 billion bases each year, and a full genome can be sequenced for $1,000 or less.\nComputers became essential in molecular biology when protein sequences became available after Frederick Sanger determined the sequence of insulin in the early 1950s. Comparing multiple sequences manually turned out to be impractical. Margaret Oakley Dayhoff, a pioneer in the field, compiled one of the first protein sequence databases, initially published as books as well as methods of sequence alignment and molecular evolution. Another early contributor to bioinformatics was Elvin A. Kabat, who pioneered biological sequence analysis in 1970 with his comprehensive volumes of antibody sequences released online with Tai Te Wu between 1980 and 1991.\nIn the 1970s, new techniques for sequencing DNA were applied to bacteriophage MS2 and \u00f8X174, and the extended nucleotide sequences were then parsed with informational and statistical algorithms. These studies illustrated that well known features, such as the coding segments and the triplet code, are revealed in straightforward statistical analyses and were the proof of the concept that bioinformatics would be insightful.\nGoals.\nIn order to study how normal cellular activities are altered in different disease states, raw biological data must be combined to form a comprehensive picture of these activities. Therefore, the field of bioinformatics has evolved such that the most pressing task now involves the analysis and interpretation of various types of data. This also includes nucleotide and amino acid sequences, protein domains, and protein structures.\nImportant sub-disciplines within bioinformatics and computational biology include:\nThe primary goal of bioinformatics is to increase the understanding of biological processes. What sets it apart from other approaches is its focus on developing and applying computationally intensive techniques to achieve this goal. Examples include: pattern recognition, data mining, machine learning algorithms, and visualization. Major research efforts in the field include sequence alignment, gene finding, genome assembly, drug design, drug discovery, protein structure alignment, protein structure prediction, prediction of gene expression and protein\u2013protein interactions, genome-wide association studies, the modeling of evolution and cell division/mitosis.\nBioinformatics entails the creation and advancement of databases, algorithms, computational and statistical techniques, and theory to solve formal and practical problems arising from the management and analysis of biological data.\nOver the past few decades, rapid developments in genomic and other molecular research technologies and developments in information technologies have combined to produce a tremendous amount of information related to molecular biology. Bioinformatics is the name given to these mathematical and computing approaches used to glean understanding of biological processes.\nCommon activities in bioinformatics include mapping and analyzing DNA and protein sequences, aligning DNA and protein sequences to compare them, and creating and viewing 3-D models of protein structures.\nSequence analysis.\nSince the bacteriophage Phage \u03a6-X174 was sequenced in 1977, the DNA sequences of thousands of organisms have been decoded and stored in databases. This sequence information is analyzed to determine genes that encode proteins, RNA genes, regulatory sequences, structural motifs, and repetitive sequences. A comparison of genes within a species or between different species can show similarities between protein functions, or relations between species (the use of molecular systematics to construct phylogenetic trees). With the growing amount of data, it long ago became impractical to analyze DNA sequences manually. Computer programs such as BLAST are used routinely to search sequences\u2014as of 2008, from more than 260,000 organisms, containing over 190 billion nucleotides.\nDNA sequencing.\nBefore sequences can be analyzed, they are obtained from a data storage bank, such as GenBank. DNA sequencing is still a non-trivial problem as the raw data may be noisy or affected by weak signals. Algorithms have been developed for base calling for the various experimental approaches to DNA sequencing.\nSequence assembly.\nMost DNA sequencing techniques produce short fragments of sequence that need to be assembled to obtain complete gene or genome sequences. The shotgun sequencing technique (used by The Institute for Genomic Research (TIGR) to sequence the first bacterial genome, \"Haemophilus influenzae\") generates the sequences of many thousands of small DNA fragments (ranging from 35 to 900 nucleotides long, depending on the sequencing technology). The ends of these fragments overlap and, when aligned properly by a genome assembly program, can be used to reconstruct the complete genome. Shotgun sequencing yields sequence data quickly, but the task of assembling the fragments can be quite complicated for larger genomes. For a genome as large as the human genome, it may take many days of CPU time on large-memory, multiprocessor computers to assemble the fragments, and the resulting assembly usually contains numerous gaps that must be filled in later. Shotgun sequencing is the method of choice for virtually all genomes sequenced (rather than chain-termination or chemical degradation methods), and genome assembly algorithms are a critical area of bioinformatics research.\nGenome annotation.\nIn genomics, annotation refers to the process of marking the stop and start regions of genes and other biological features in a sequenced DNA sequence. Many genomes are too large to be annotated by hand. As the rate of sequencing exceeds the rate of genome annotation, genome annotation has become the new bottleneck in bioinformatics.\nGenome annotation can be classified into three levels: the nucleotide, protein, and process levels.\nGene finding is a chief aspect of nucleotide-level annotation. For complex genomes, a combination of ab initio gene prediction and sequence comparison with expressed sequence databases and other organisms can be successful. Nucleotide-level annotation also allows the integration of genome sequence with other genetic and physical maps of the genome.\nThe principal aim of protein-level annotation is to assign function to the protein products of the genome. Databases of protein sequences and functional domains and motifs are used for this type of annotation. About half of the predicted proteins in a new genome sequence tend to have no obvious function.\nUnderstanding the function of genes and their products in the context of cellular and organismal physiology is the goal of process-level annotation. An obstacle of process-level annotation has been the inconsistency of terms used by different model systems. The Gene Ontology Consortium is helping to solve this problem.\nThe first description of a comprehensive annotation system was published in 1995 by The Institute for Genomic Research, which performed the first complete sequencing and analysis of the genome of a free-living (non-symbiotic) organism, the bacterium \"Haemophilus influenzae\". The system identifies the genes encoding all proteins, transfer RNAs, ribosomal RNAs, in order to make initial functional assignments. The GeneMark program trained to find protein-coding genes in \"Haemophilus influenzae\" is constantly changing and improving.\nFollowing the goals that the Human Genome Project left to achieve after its closure in 2003, the ENCODE project was developed by the National Human Genome Research Institute. This project is a collaborative data collection of the functional elements of the human genome that uses next-generation DNA-sequencing technologies and genomic tiling arrays, technologies able to automatically generate large amounts of data at a dramatically reduced per-base cost but with the same accuracy (base call error) and fidelity (assembly error).\nGene function prediction.\nWhile genome annotation is primarily based on sequence similarity (and thus homology), other properties of sequences can be used to predict the function of genes. In fact, most \"gene\" function prediction methods focus on \"protein\" sequences as they are more informative and more feature-rich. For instance, the distribution of hydrophobic amino acids predicts transmembrane segments in proteins. However, protein function prediction can also use external information such as gene (or protein) expression data, protein structure, or protein-protein interactions.\nComputational evolutionary biology.\nEvolutionary biology is the study of the origin and descent of species, as well as their change over time. Informatics has assisted evolutionary biologists by enabling researchers to:\nFuture work endeavours to reconstruct the now more complex tree of life.\nComparative genomics.\nThe core of comparative genome analysis is the establishment of the correspondence between genes (orthology analysis) or other genomic features in different organisms. Intergenomic maps are made to trace the evolutionary processes responsible for the divergence of two genomes. A multitude of evolutionary events acting at various organizational levels shape genome evolution. At the lowest level, point mutations affect individual nucleotides. At a higher level, large chromosomal segments undergo duplication, lateral transfer, inversion, transposition, deletion and insertion. Entire genomes are involved in processes of hybridization, polyploidization and endosymbiosis that lead to rapid speciation. The complexity of genome evolution poses many exciting challenges to developers of mathematical models and algorithms, who have recourse to a spectrum of algorithmic, statistical and mathematical techniques, ranging from exact, heuristics, fixed parameter and approximation algorithms for problems based on parsimony models to Markov chain Monte Carlo algorithms for Bayesian analysis of problems based on probabilistic models.\nMany of these studies are based on the detection of sequence homology to assign sequences to protein families.\nPan genomics.\nPan genomics is a concept introduced in 2005 by Tettelin and Medini. Pan genome is the complete gene repertoire of a particular monophyletic taxonomic group. Although initially applied to closely related strains of a species, it can be applied to a larger context like genus, phylum, etc. It is divided in two parts: the Core genome, a set of genes common to all the genomes under study (often housekeeping genes vital for survival), and the Dispensable/Flexible genome: a set of genes not present in all but one or some genomes under study. A bioinformatics tool BPGA can be used to characterize the Pan Genome of bacterial species.\nGenetics of disease.\nAs of 2013, the existence of efficient high-throughput next-generation sequencing technology allows for the identification of cause many different human disorders. Simple Mendelian inheritance has been observed for over 3,000 disorders that have been identified at the Online Mendelian Inheritance in Man database, but complex diseases are more difficult. Association studies have found many individual genetic regions that individually are weakly associated with complex diseases (such as infertility, breast cancer and Alzheimer's disease), rather than a single cause. There are currently many challenges to using genes for diagnosis and treatment, such as how we don't know which genes are important, or how stable the choices an algorithm provides.\nGenome-wide association studies have successfully identified thousands of common genetic variants for complex diseases and traits; however, these common variants only explain a small fraction of heritability. Rare variants may account for some of the missing heritability. Large-scale whole genome sequencing studies have rapidly sequenced millions of whole genomes, and such studies have identified hundreds of millions of rare variants. Functional annotations predict the effect or function of a genetic variant and help to prioritize rare functional variants, and incorporating these annotations can effectively boost the power of genetic association of rare variants analysis of whole genome sequencing studies. Some tools have been developed to provide all-in-one rare variant association analysis for whole-genome sequencing data, including integration of genotype data and their functional annotations, association analysis, result summary and visualization. Meta-analysis of whole genome sequencing studies provides an attractive solution to the problem of collecting large sample sizes for discovering rare variants associated with complex phenotypes.\nAnalysis of mutations in cancer.\nIn cancer, the genomes of affected cells are rearranged in complex or unpredictable ways. In addition to single-nucleotide polymorphism arrays identifying point mutations that cause cancer, oligonucleotide microarrays can be used to identify chromosomal gains and losses (called comparative genomic hybridization). These detection methods generate terabytes of data per experiment. The data is often found to contain considerable variability, or noise, and thus Hidden Markov model and change-point analysis methods are being developed to infer real copy number changes.\nTwo important principles can be used to identify cancer by mutations in the exome. First, cancer is a disease of accumulated somatic mutations in genes. Second, cancer contains driver mutations which need to be distinguished from passengers.\nFurther improvements in bioinformatics could allow for classifying types of cancer by analysis of cancer driven mutations in the genome. Furthermore, tracking of patients while the disease progresses may be possible in the future with the sequence of cancer samples. Another type of data that requires novel informatics development is the analysis of lesions found to be recurrent among many tumors.\nGene and protein expression.\nAnalysis of gene expression.\nThe expression of many genes can be determined by measuring mRNA levels with multiple techniques including microarrays, expressed cDNA sequence tag (EST) sequencing, serial analysis of gene expression (SAGE) tag sequencing, massively parallel signature sequencing (MPSS), RNA-Seq, also known as \"Whole Transcriptome Shotgun Sequencing\" (WTSS), or various applications of multiplexed in-situ hybridization. All of these techniques are extremely noise-prone and/or subject to bias in the biological measurement, and a major research area in computational biology involves developing statistical tools to separate signal from noise in high-throughput gene expression studies. Such studies are often used to determine the genes implicated in a disorder: one might compare microarray data from cancerous epithelial cells to data from non-cancerous cells to determine the transcripts that are up-regulated and down-regulated in a particular population of cancer cells.\nAnalysis of protein expression.\nProtein microarrays and high throughput (HT) mass spectrometry (MS) can provide a snapshot of the proteins present in a biological sample. The former approach faces similar problems as with microarrays targeted at mRNA, the latter involves the problem of matching large amounts of mass data against predicted masses from protein sequence databases, and the complicated statistical analysis of samples when multiple incomplete peptides from each protein are detected. Cellular protein localization in a tissue context can be achieved through affinity proteomics displayed as spatial data based on immunohistochemistry and tissue microarrays.\nAnalysis of regulation.\nGene regulation is a complex process where a signal, such as an extracellular signal such as a hormone, eventually leads to an increase or decrease in the activity of one or more proteins. Bioinformatics techniques have been applied to explore various steps in this process.\nFor example, gene expression can be regulated by nearby elements in the genome. Promoter analysis involves the identification and study of sequence motifs in the DNA surrounding the protein-coding region of a gene. These motifs influence the extent to which that region is transcribed into mRNA. Enhancer elements far away from the promoter can also regulate gene expression, through three-dimensional looping interactions. These interactions can be determined by bioinformatic analysis of chromosome conformation capture experiments.\nExpression data can be used to infer gene regulation: one might compare microarray data from a wide variety of states of an organism to form hypotheses about the genes involved in each state. In a single-cell organism, one might compare stages of the cell cycle, along with various stress conditions (heat shock, starvation, etc.). Clustering algorithms can be then applied to expression data to determine which genes are co-expressed. For example, the upstream regions (promoters) of co-expressed genes can be searched for over-represented regulatory elements. Examples of clustering algorithms applied in gene clustering are k-means clustering, self-organizing maps (SOMs), hierarchical clustering, and consensus clustering methods.\nAnalysis of cellular organization.\nSeveral approaches have been developed to analyze the location of organelles, genes, proteins, and other components within cells. A gene ontology category, \"cellular component\", has been devised to capture subcellular localization in many biological databases.\nMicroscopy and image analysis.\nMicroscopic pictures allow for the location of organelles as well as molecules, which may be the source of abnormalities in diseases.\nProtein localization.\nFinding the location of proteins allows us to predict what they do. This is called protein function prediction. For instance, if a protein is found in the nucleus it may be involved in gene regulation or splicing. By contrast, if a protein is found in mitochondria, it may be involved in respiration or other metabolic processes. There are well developed protein subcellular localization prediction resources available, including protein subcellular location databases, and prediction tools.\nNuclear organization of chromatin.\nData from high-throughput chromosome conformation capture experiments, such as Hi-C (experiment) and ChIA-PET, can provide information on the three-dimensional structure and nuclear organization of chromatin. Bioinformatic challenges in this field include partitioning the genome into domains, such as Topologically Associating Domains (TADs), that are organised together in three-dimensional space.\nStructural bioinformatics.\nFinding the structure of proteins is an important application of bioinformatics. The Critical Assessment of Protein Structure Prediction (CASP) is an open competition where worldwide research groups submit protein models for evaluating unknown protein models.\nAmino acid sequence.\nThe linear amino acid sequence of a protein is called the primary structure. The primary structure can be easily determined from the sequence of codons on the DNA gene that codes for it. In most proteins, the primary structure uniquely determines the 3-dimensional structure of a protein in its native environment. An exception is the misfolded protein involved in bovine spongiform encephalopathy. This structure is linked to the function of the protein. Additional structural information includes the \"secondary\", \"tertiary\" and \"quaternary\" structure. A viable general solution to the prediction of the function of a protein remains an open problem. Most efforts have so far been directed towards heuristics that work most of the time.\nHomology.\nIn the genomic branch of bioinformatics, homology is used to predict the function of a gene: if the sequence of gene \"A\", whose function is known, is homologous to the sequence of gene \"B,\" whose function is unknown, one could infer that B may share A's function. In structural bioinformatics, homology is used to determine which parts of a protein are important in structure formation and interaction with other proteins. Homology modeling is used to predict the structure of an unknown protein from existing homologous proteins.\nOne example of this is hemoglobin in humans and the hemoglobin in legumes (leghemoglobin), which are distant relatives from the same protein superfamily. Both serve the same purpose of transporting oxygen in the organism. Although both of these proteins have completely different amino acid sequences, their protein structures are virtually identical, which reflects their near identical purposes and shared ancestor.\nOther techniques for predicting protein structure include protein threading and \"de novo\" (from scratch) physics-based modeling.\nAnother aspect of structural bioinformatics include the use of protein structures for Virtual Screening models such as Quantitative Structure-Activity Relationship models and proteochemometric models (PCM). Furthermore, a protein's crystal structure can be used in simulation of for example ligand-binding studies and \"in silico\" mutagenesis studies.\nA 2021 deep-learning algorithms-based software called AlphaFold, developed by Google's DeepMind, greatly outperforms all other prediction software methods, and has released predicted structures for hundreds of millions of proteins in the AlphaFold protein structure database.\nNetwork and systems biology.\n\"Network analysis\" seeks to understand the relationships within biological networks such as metabolic or protein\u2013protein interaction networks. Although biological networks can be constructed from a single type of molecule or entity (such as genes), network biology often attempts to integrate many different data types, such as proteins, small molecules, gene expression data, and others, which are all connected physically, functionally, or both.\n\"Systems biology\" involves the use of computer simulations of cellular subsystems (such as the networks of metabolites and enzymes that comprise metabolism, signal transduction pathways and gene regulatory networks) to both analyze and visualize the complex connections of these cellular processes. Artificial life or virtual evolution attempts to understand evolutionary processes via the computer simulation of simple (artificial) life forms.\nMolecular interaction networks.\nTens of thousands of three-dimensional protein structures have been determined by X-ray crystallography and protein nuclear magnetic resonance spectroscopy (protein NMR) and a central question in structural bioinformatics is whether it is practical to predict possible protein\u2013protein interactions only based on these 3D shapes, without performing protein\u2013protein interaction experiments. A variety of methods have been developed to tackle the protein\u2013protein docking problem, though it seems that there is still much work to be done in this field.\nOther interactions encountered in the field include Protein\u2013ligand (including drug) and protein\u2013peptide. Molecular dynamic simulation of movement of atoms about rotatable bonds is the fundamental principle behind computational algorithms, termed docking algorithms, for studying molecular interactions.\nBiodiversity informatics.\nBiodiversity informatics deals with the collection and analysis of biodiversity data, such as taxonomic databases, or microbiome data. Examples of such analyses include phylogenetics, niche modelling, species richness mapping, DNA barcoding, or species identification tools. A growing area is also macro-ecology, i.e. the study of how biodiversity is connected to ecology and human impact, such as climate change.\nOthers.\nLiterature analysis.\nThe enormous number of published literature makes it virtually impossible for individuals to read every paper, resulting in disjointed sub-fields of research. Literature analysis aims to employ computational and statistical linguistics to mine this growing library of text resources. For example:\nThe area of research draws from statistics and computational linguistics.\nHigh-throughput image analysis.\nComputational technologies are used to automate the processing, quantification and analysis of large amounts of high-information-content biomedical imagery. Modern image analysis systems can improve an observer's accuracy, objectivity, or speed. Image analysis is important for both diagnostics and research. Some examples are:\nHigh-throughput single cell data analysis.\nComputational techniques are used to analyse high-throughput, low-measurement single cell data, such as that obtained from flow cytometry. These methods typically involve finding populations of cells that are relevant to a particular disease state or experimental condition.\nOntologies and data integration.\nBiological ontologies are directed acyclic graphs of controlled vocabularies. They create categories for biological concepts and descriptions so they can be easily analyzed with computers. When categorised in this way, it is possible to gain added value from holistic and integrated analysis.\nThe OBO Foundry was an effort to standardise certain ontologies. One of the most widespread is the Gene ontology which describes gene function. There are also ontologies which describe phenotypes.\nDatabases.\nDatabases are essential for bioinformatics research and applications. Databases exist for many different information types, including DNA and protein sequences, molecular structures, phenotypes and biodiversity. Databases can contain both empirical data (obtained directly from experiments) and predicted data (obtained from analysis of existing data). They may be specific to a particular organism, pathway or molecule of interest. Alternatively, they can incorporate data compiled from multiple other databases. Databases can have different formats, access mechanisms, and be public or private.\nSome of the most commonly used databases are listed below:\nSoftware and tools.\nSoftware tools for bioinformatics include simple command-line tools, more complex graphical programs, and standalone web-services. They are made by bioinformatics companies or by public institutions.\nOpen-source bioinformatics software.\nMany free and open-source software tools have existed and continued to grow since the 1980s. The combination of a continued need for new algorithms for the analysis of emerging types of biological readouts, the potential for innovative \"in silico\" experiments, and freely available open code bases have created opportunities for research groups to contribute to both bioinformatics regardless of funding. The open source tools often act as incubators of ideas, or community-supported plug-ins in commercial applications. They may also provide \"de facto\" standards and shared object models for assisting with the challenge of bioinformation integration.\nOpen-source bioinformatics software includes Bioconductor, BioPerl, Biopython, BioJava, BioJS, BioRuby, Bioclipse, EMBOSS, .NET Bio, Orange with its bioinformatics add-on, Apache Taverna, UGENE and GenoCAD.\nThe non-profit Open Bioinformatics Foundation and the annual Bioinformatics Open Source Conference promote open-source bioinformatics software.\nWeb services in bioinformatics.\nSOAP- and REST-based interfaces have been developed to allow client computers to use algorithms, data and computing resources from servers in other parts of the world. The main advantage are that end users do not have to deal with software and database maintenance overheads.\nBasic bioinformatics services are classified by the EBI into three categories: SSS (Sequence Search Services), MSA (Multiple Sequence Alignment), and BSA (Biological Sequence Analysis). The availability of these service-oriented bioinformatics resources demonstrate the applicability of web-based bioinformatics solutions, and range from a collection of standalone tools with a common data format under a single web-based interface, to integrative, distributed and extensible bioinformatics workflow management systems.\nBioinformatics workflow management systems.\nA bioinformatics workflow management system is a specialized form of a workflow management system designed specifically to compose and execute a series of computational or data manipulation steps, or a workflow, in a Bioinformatics application. Such systems are designed to\nSome of the platforms giving this service: Galaxy, Kepler, Taverna, UGENE, Anduril, HIVE.\nBioCompute and BioCompute Objects.\nIn 2014, the US Food and Drug Administration sponsored a conference held at the National Institutes of Health Bethesda Campus to discuss reproducibility in bioinformatics. Over the next three years, a consortium of stakeholders met regularly to discuss what would become BioCompute paradigm. These stakeholders included representatives from government, industry, and academic entities. Session leaders represented numerous branches of the FDA and NIH Institutes and Centers, non-profit entities including the Human Variome Project and the European Federation for Medical Informatics, and research institutions including Stanford, the New York Genome Center, and the George Washington University.\nIt was decided that the BioCompute paradigm would be in the form of digital 'lab notebooks' which allow for the reproducibility, replication, review, and reuse, of bioinformatics protocols. This was proposed to enable greater continuity within a research group over the course of normal personnel flux while furthering the exchange of ideas between groups. The US FDA funded this work so that information on pipelines would be more transparent and accessible to their regulatory staff.\nIn 2016, the group reconvened at the NIH in Bethesda and discussed the potential for a BioCompute Object, an instance of the BioCompute paradigm. This work was copied as both a \"standard trial use\" document and a preprint paper uploaded to bioRxiv. The BioCompute object allows for the JSON-ized record to be shared among employees, collaborators, and regulators.\nEducation platforms.\nBioinformatics is not only taught as in-person master's degree at many universities. The computational nature of bioinformatics lends it to computer-aided and online learning. Software platforms designed to teach bioinformatics concepts and methods include Rosalind and online courses offered through the Swiss Institute of Bioinformatics Training Portal. The Canadian Bioinformatics Workshops provides videos and slides from training workshops on their website under a Creative Commons license. The 4273\u03c0 project or 4273pi project also offers open source educational materials for free. The course runs on low cost Raspberry Pi computers and has been used to teach adults and school pupils. 4273 is actively developed by a consortium of academics and research staff who have run research level bioinformatics using Raspberry Pi computers and the 4273\u03c0 operating system.\nMOOC platforms also provide online certifications in bioinformatics and related disciplines, including Coursera's Bioinformatics Specialization at the University of California, San Diego, Genomic Data Science Specialization at Johns Hopkins University, and EdX's Data Analysis for Life Sciences XSeries at Harvard University.\nConferences.\nThere are several large conferences that are concerned with bioinformatics. Some of the most notable examples are Intelligent Systems for Molecular Biology (ISMB), European Conference on Computational Biology (ECCB), and Research in Computational Molecular Biology (RECOMB)."}
{"id": "4215", "revid": "9784415", "url": "https://en.wikipedia.org/wiki?curid=4215", "title": "Brian de Palma", "text": ""}
{"id": "4216", "revid": "1267002592", "url": "https://en.wikipedia.org/wiki?curid=4216", "title": "Brian De Palma", "text": "Brian Russell De Palma (; born September 11, 1940) is an American film director and screenwriter. With a career spanning over 50 years, he is best known for work in the suspense, crime and psychological thriller genres. De Palma was a leading member of the New Hollywood generation.\n\"Carrie\" (1976), his adaptation of Stephen King's novel of the same name, put him on the map. He enjoyed commercial success with \"Dressed to Kill\" (1980), \"The Untouchables\" (1987) and (1996) and made cult classics such as \"Sisters\" (1972), \"Phantom of the Paradise\" (1974) and \"The Fury\" (1978).\nAs a young director, De Palma dreamed of being the \"American Godard\". His style is allusive; he paid homage to Alfred Hitchcock in \"Obsession\" (1976) and \"Body Double\" (1984); \"Blow Out\" (1981) is based on Michelangelo Antonioni's \"Blowup\" (1966) and \"Scarface\" (1983), his remake of Howard Hawks's 1932 film, is dedicated to Hawks and Ben Hecht. His work has been criticized for its violence and sexual content but has also been championed by American critics such as Roger Ebert and Pauline Kael. In 2015, he was interviewed about his work in a well-received documentary by Noah Baumbach.\nEarly life and education.\nDe Palma was born on September 11, 1940, in Newark, New Jersey, the youngest of three boys. His Italian-American parents were Vivienne DePalma (n\u00e9e Muti), and Anthony F. DePalma, an orthopedic surgeon who was the son of immigrants from Alberona, Province of Foggia. He was raised in Philadelphia, Pennsylvania and New Hampshire, and attended various Protestant and Quaker schools, eventually graduating from Friends' Central School. He had a poor relationship with his father, and would secretly follow him to record his adulterous behavior; this would eventually inspire the teenage character in De Palma's \"Dressed to Kill\" (1980). When he was in high school, he built computers. He won a regional science-fair prize for his project \"An Analog Computer to Solve Differential Equations\".\nEnrolled at Columbia University as a physics student, De Palma became enraptured with filmmaking after seeing Orson Welles's \"Citizen Kane\" (1941) and Alfred Hitchcock's \"Vertigo\" (1958). After receiving his undergraduate degree in 1962, De Palma enrolled at the newly coed Sarah Lawrence College as a graduate student in their theater department, earning an M.A. in the discipline in 1964 and becoming one of the first male students among a female population. Once there, influences as various as drama teacher Wilford Leach, the Maysles brothers, Michelangelo Antonioni, Andy Warhol and Jean-Luc Godard, impressed upon De Palma the many styles and themes that would shape his work in the coming decades.\nCareer.\n1963\u20131976: Rise to prominence.\nAn early association with a young Robert De Niro resulted in \"The Wedding Party\". The film, co-directed with Wilford Leach and producer Cynthia Munroe, had been shot in 1963 but remained unreleased until 1969, when De Palma's star had risen sufficiently in the Greenwich Village filmmaking scene. De Niro was unknown at the time; the credits mistakenly display his name as \"Robert \". The film is noteworthy for its invocation of silent film techniques and use of the jump-cut. De Palma followed this style with various small films for the NAACP and the Treasury Department.\nDuring the 1960s, De Palma began making a living producing documentaries, notably \"The Responsive Eye\" (1966), about \"The Responsive Eye\" op-art exhibit curated by William Seitz for MoMA in 1965. In an interview with Joseph Gelmis from 1969, De Palma described the film as \"very good and very successful. It's distributed by Pathe Contemporary and makes lots of money. I shot it in four hours, with synched sound. I had two other guys shooting people's reactions to the paintings, and the paintings themselves.\"\n\"Dionysus in '69\" (1969) was De Palma's other major documentary from this period. The film records the Performance Group's performance of Euripides's \"The Bacchae\", starring, amongst others, De Palma regular William Finley. The play is noted for breaking traditional barriers between performers and audience. The film's most striking quality is its extensive use of the split-screen. De Palma recalls that he was \"floored\" by this performance upon first sight, and in 1973 recounts how he \"began to try and figure out a way to capture it on film. I came up with the idea of split-screen, to be able to show the actual audience involvement, to trace the life of the audience and that of the play as they merge in and out of each other.\"\nDe Palma's most significant features from this decade are \"Greetings\" (1968) and \"Hi, Mom!\" (1970). Both films star De Niro and espouse a leftist revolutionary viewpoint in the spirit of the time. \"Greetings\" was entered into the 19th Berlin International Film Festival, where it won a Silver Bear award. His other major film from this period is the slasher comedy \"Murder a la Mod\" (1968). Each of these films experiments with narrative and intertextuality, reflecting De Palma's stated intention to become the \"American Godard\".\nIn 1970, De Palma left New York for Hollywood at age thirty to make \"Get to Know Your Rabbit\" (1972), starring Orson Welles and Tommy Smothers. Making the film was a crushing experience for De Palma, as Smothers did not like many of De Palma's ideas. Here he made several small, studio and independently released films. Among them were the horror film \"Sisters\" (1972), the rock musical \"Phantom of the Paradise\" (1974) and \"Obsession\" (1976), a variation on theme of Alfred Hitchcock's \"Vertigo\" (1958) scored by Hitchcock's frequent collaborator Bernard Herrmann.\n1976\u20131979: Breakthrough.\nIn November 1976, De Palma released an adaptation of Stephen King's novel \"Carrie\". Though some see the psychic thriller as De Palma's bid for a blockbuster, the project was in fact small, underfunded by United Artists, and well under the cultural radar during the early months of production, as King's novel had yet to climb the bestseller list. De Palma gravitated toward the project and changed crucial plot elements based upon his own predilections. The cast was mostly young and relatively new, though Sissy Spacek and John Travolta had gained attention for previous work in, respectively, film and sitcoms. \"Carrie\" became De Palma's first genuine box-office success, garnering Spacek and Piper Laurie Oscar nominations for their performances. Pre-production for the film had coincided with the casting process for George Lucas's \"Star Wars\", and many of the actors cast in De Palma's film had been earmarked as contenders for Lucas's movie, and vice versa. Its suspense sequences are buttressed by teen comedy tropes, and its use of split-screen, split-diopter and slow motion shots tell the story visually rather than through dialogue. As for Lucas's project, De Palma complained in an early viewing of \"Star Wars\" that the opening text crawl was poorly written and volunteered to help edit the text to a more concise and engaging form.\nThe financial and critical success of \"Carrie\" allowed De Palma to pursue more personal material. Alfred Bester's novel \"The Demolished Man\" had fascinated De Palma since the late 1950s and appealed to his background in mathematics and avant-garde storytelling. Its unconventional unfolding of plot (exemplified in its mathematical layout of dialogue) and its stress on perception have analogs in De Palma's filmmaking. He sought to adapt it numerous times, though the project would carry a substantial price tag, and has yet to appear on-screen (Steven Spielberg's 2002 adaptation of Philip K. Dick's \"Minority Report\" bears striking similarities to De Palma's visual style and some of the themes of \"The Demolished Man\"). The result of his experience with adapting \"The Demolished Man\" was the 1978 science fiction psychic thriller \"The Fury\", starring Kirk Douglas, Carrie Snodgress, John Cassavetes and Amy Irving. The film was admired by Jean-Luc Godard, who featured a clip in his mammoth \"Histoire(s) du cin\u00e9ma\", and Pauline Kael, who championed both \"The Fury\" and De Palma. The film boasted a larger budget than \"Carrie\", though the consensus view at the time was that De Palma was repeating himself, with diminishing returns.\n1980\u20131996: Established career.\nThe 1980s were marked by some of De Palma's best known films, including the erotic thriller \"Dressed to Kill\" (1980) starring Michael Caine and Angie Dickinson. Although the film received critical acclaim, it caused controversy for its negative depiction of the transgender community. The following year he directed \"Blow Out\" (1981), a variation on Michelangelo Antonioni's \"Blow-Up\" (1966) and Francis Ford Coppola's \"The Conversation\" (1974) starring John Travolta, Nancy Allen and John Lithgow. The film received critical acclaim. Kael wrote: \"De Palma has sprung to the place that Robert Altman achieved with films such as \"McCabe &amp; Mrs. Miller\" and \"Nashville\" and that Francis Ford Coppola reached with \"The Godfather\" films\u2014that is, to the place where genre is transcended and what we're moved by is an artist's vision. It's a great movie.\" \nDe Palma directed \"Scarface\" (1983), a remake of Howard Hawks's 1932 film, starring Al Pacino and Michelle Pfeiffer with a screenplay by Oliver Stone. The film received mixed reviews with its negative depictions of ethnic stereotypes, as well as its violence and profanity. It has since been re-evaluated and became a cult classic. The following year he made another erotic thriller, \"Body Double\" (1984), starring Craig Wasson and Melanie Griffith. The film also received mixed reviews but has since had a reassessment and found acclaim. De Palma directed the music video for Bruce Springsteen's single \"Dancing in the Dark\" the same year.\nIn 1987, De Palma directed the crime film \"The Untouchables\", loosely based on the book of the same name and adapted by David Mamet. The film stars Kevin Costner, Andy Garcia, Robert De Niro and Sean Connery, the latter of whom won the Academy Award for Best Supporting Actor for the film. It received critical acclaim and box-office success. De Palma's Vietnam War film \"Casualties of War\" (1989) won critical praise but performed poorly in theatres and \"The Bonfire of the Vanities\" (1990) was a notorious failure with both critics and audiences. De Palma then had subsequent successes with \"Raising Cain\" (1992) and \"Carlito's Way\" (1993). \"\" (1996) was his highest-grossing film and started \".\"\n1998\u2013present: Career slump.\nDe Palma's work after \"Mission: Impossible\" has been less well received. His ensuing films \"Snake Eyes\" (1998), \"Mission to Mars\" (2000), and \"Femme Fatale\" (2002) all failed at the box office and received generally poor reviews, though \"Femme Fatale\" has since been revived in the eyes of many film critics and became a cult classic. His 2006 adaptation of \"The Black Dahlia\" was also unsuccessful and is currently the last movie De Palma has directed with backing from Hollywood.\nA political controversy erupted over the portrayal of US soldiers in De Palma's 2007 film \"Redacted\". Loosely based on the 2006 Mahmudiyah killings by American soldiers in Iraq, the film echoes themes that appeared in \"Casualties of War\". \"Redacted\" received a limited release in the United States and grossed less than $1 million against a $5 million budget.\nDe Palma's output has slowed since the release of \"Redacted\", with subsequent projects often falling into development hell, due mostly to creative differences. In 2012, his film \"Passion\" starring Rachel McAdams and Noomi Rapace was selected to compete for the Golden Lion at the 69th Venice International Film Festival but received mixed reviews and was financially unsuccessful.\nDe Palma's next project was the thriller \"Domino\" (2019), released two years after the film began production. It received generally negative reviews and was released direct-to-VOD in the United States, grossing less than half a million dollars internationally. De Palma has also expressed dissatisfaction with both the production of the film and the final result; \"I never experienced such a horrible movie set.\"\nIn 2018, De Palma published his debut novel in France, \"Les serpents sont-ils n\u00e9cessaires?\" (English translation: \"Are Snakes Necessary?\"), co-written with Susan Lehman. It was published in the U.S. in 2020. De Palma and Lehman also wrote a second book, currently unpublished, called \"Terry\", based on one of De Palma's passion projects about a French film production making an adaptation of \"Th\u00e9r\u00e8se Raquin\".\nDespite rumors of his supposed retirement after having two projects, \"Sweet Vengeance\" and \"Catch and Kill\", fall through, De Palma revealed to \"Vulture\" in September 2024 that he had \"one other\" undisclosed film he was planning to make, and that he was in the process of trying to cast it.\nFilmmaking style, techniques and trademarks.\nDe Palma's films can fall into two categories, his thriller films (\"Sisters\", \"Body Double\", \"Obsession\", \"Dressed to Kill\", \"Blow Out\", \"Raising Cain\") and his mainly commercial films ( \"The Untouchables\", \"Carlito's Way\", and \"Mission: Impossible\"). He has often produced \"De Palma\" films one after the other before going on to direct a different genre, but would always return to his familiar territory. Because of the subject matter and graphic violence of some of De Palma's films, such as \"Dressed to Kill\", \"Scarface\" and \"Body Double\", they are often at the center of controversy with the Motion Picture Association of America, film critics and the viewing public.\nInspirations.\nDe Palma frequently quotes and references other directors' work. His early work was inspired by the films of Jean-Luc Godard. Michelangelo Antonioni's \"Blowup\" and Francis Ford Coppola's \"The Conversation\" plots were used for the basis of \"Blow Out\". \"The Untouchables\" finale shoot out in the train station is a clear borrowing from the Odessa Steps sequence in Sergei Eisenstein's \"The Battleship Potemkin\". The main plot from \"Rear Window\" was used for \"Body Double\", while it also used elements of \"Vertigo\". \"Vertigo\" was also the basis for \"Obsession\". \"Dressed to Kill\" was a note-for-note homage to Hitchcock's \"Psycho\", including such moments as the surprise death of the lead actress and the exposition scene by the psychiatrist at the end.\nCamera shots.\nFilm critics have often noted De Palma's penchant for unusual camera angles and compositions. He often frames characters against the background using a canted angle shot. Split-screen techniques have been used to show two separate events happening simultaneously. To emphasize the dramatic impact of a certain scene De Palma has employed a 360-degree camera pan. Slow sweeping, panning and tracking shots are often used throughout his films, often through precisely-choreographed long takes lasting for minutes without cutting. Split focus shots, often referred to as \"di-opt\", are used by De Palma to emphasize the foreground person/object while simultaneously keeping a background person/object in focus. Slow-motion is frequently used in his films to increase suspense.\nPersonal life.\nDe Palma has been married and divorced three times, to actress Nancy Allen (1979\u20131983), producer Gale Anne Hurd (1991\u20131993), and Darnell Gregorio (1995\u20131997). He has one daughter from his marriage to Hurd, and one daughter from his marriage to Gregorio. He resides in Manhattan, New York.\nReception and legacy.\nDe Palma is often cited as a leading member of the New Hollywood generation of film directors, a distinct pedigree who either emerged from film schools or are overtly cine-literate. His contemporaries include Martin Scorsese, Paul Schrader, John Milius, George Lucas, Francis Ford Coppola, Steven Spielberg, John Carpenter, and Ridley Scott. His artistry in directing and use of cinematography and suspense in several of his films has often been compared to the work of Alfred Hitchcock. Psychologists have been intrigued by De Palma's fascination with pathology, by the aberrant behavior aroused in characters who find themselves manipulated by others.\nDe Palma has encouraged and fostered the filmmaking careers of directors such as Mark Romanek and Keith Gordon, the latter of whom collaborated with him twice as an actor, both in 1979's \"Home Movies\" and 1980's \"Dressed to Kill\". Filmmakers influenced by De Palma include Terrence Malick, Quentin Tarantino, Ronny Yu, Don Mancini, Nacho Vigalondo, and Jack Thomas Smith. During an interview with De Palma, Quentin Tarantino said that \"Blow Out\" is one of his all-time favorite films, and that after watching \"Scarface\" he knew how to make his own film. John Travolta's performance as Jack Terry in \"Blow Out\" even resulted in Tarantino casting him as Vincent Vega in his 1994 film \"Pulp Fiction\", which would go on to reinvigorate Travolta's then-declining career. Tarantino also placed \"Carrie\" at number eight in a list of his favorite films.\nCritics who frequently admire De Palma's work include Pauline Kael and Roger Ebert. Kael wrote in her review of \"Blow Out\", \"At forty, Brian De Palma has more than twenty years of moviemaking behind him, and he has been growing better and better. Each time a new film of his opens, everything he has done before seems to have been preparation for it.\" In his review of \"Femme Fatale\", Roger Ebert wrote about the director: \"De Palma deserves more honor as a director. Consider also these titles: \"Sisters\", \"Blow Out\", \"The Fury\", \"Dressed to Kill\", \"Carrie\", \"Scarface\", \"Wise Guys\", \"Casualties of War\", \"Carlito's Way\", \"Mission: Impossible\". Yes, there are a few failures along the way (\"Snake Eyes\", \"Mission to Mars\", \"The Bonfire of the Vanities\"), but look at the range here, and reflect that these movies contain treasure for those who admire the craft as well as the story, who sense the glee with which De Palma manipulates images and characters for the simple joy of being good at it. It's not just that he sometimes works in the style of Hitchcock, but that he has the nerve to.\"\nThe influential French film magazine \"Cahiers du Cin\u00e9ma\" has placed five of De Palma's films (\"Carlito's Way\", \"\", \"Snake Eyes\", \"Mission to Mars\", and \"Redacted\") on their annual top ten list, with \"Redacted\" placing first on the 2008 list. The magazine also listed \"Carlito's Way\" as the greatest film of the 1990s.\nJulie Salamon has written that critics have accused De Palma of being \"a perverse misogynist\", to which De Palma has responded with, \"I'm always attacked for having an erotic, sexist approach chopping up women, putting women in peril. I'm making suspense movies! What else is going to happen to them?\"\nHis films have also been interpreted as feminist and examined for their perceived queer affinities. In \"Film Comment\" \"Queer and Now and Then\" column on \"Femme Fatale\", film critic Michael Koresky writes that \"De Palma's films radiate an undeniable queer energy\" and notes the \"intense appeal\" De Palma's films have for gay critics. In her book \"The Erotic Thriller in Contemporary Cinema\", Linda Ruth Williams writes that \"De Palma understood the cinematic potency of dangerous fucking, perhaps earlier than his feminist detractors\".\nRobin Wood considered \"Sisters\" an overtly feminist film, writing that \"one can define the monster of \"Sisters\" as women's liberation; adding only that the film follows the time-honored horror film tradition of making the monster emerge as the most sympathetic character and its emotional center.\" Pauline Kael's review of \"Casualties of War\", \"A Wounded Apparition\", describes the film as \"feminist\" and notes that \"De Palma was always involved in examining (and sometimes satirizing) victimization, but he was often accused of being a victimizer\". Helen Grace, in a piece for \"Lola\", writes that upon seeing \"Dressed to Kill\" amidst calls for a boycott from feminist groups Women Against Violence Against Women and Women Against Pornography, that the film \"seemed to say more about masculine anxiety than about the fears that women were expressing in relation to the film\". De Palma has also expressed contrition for the depiction of a transgender murderer in the film, saying in a 2016 interview \"I don't know what the transgender community would think [of the film now]... Obviously I realize that it's not good for their image to be transgender and also be a psychopathic murderer. But I think that [perception] passes with time. We're in a different time.\" In the same interview, he said he was \"glad\" that the film had become a \"a favorite of the gay community\".\nDavid Thomson wrote in his entry for De Palma, \"There is a self-conscious cunning in De Palma's work, ready to control everything except his own cruelty and indifference.\" Matt Zoller Seitz objected to this characterisation, writing that there are films from the director which can be seen as \"straightforwardly empathetic and/or moralistic\".\nHis life and career in his own words was the subject of the 2015 documentary \"De Palma,\" directed by Noah Baumbach and Jake Paltrow."}
{"id": "4218", "revid": "5450916", "url": "https://en.wikipedia.org/wiki?curid=4218", "title": "North American B-25 Mitchell", "text": "The North American B-25 Mitchell is an American medium bomber that was introduced in 1941 and named in honor of Brigadier General William \"Billy\" Mitchell, a pioneer of U.S. military aviation. Used by many Allied air forces, the B-25 served in every theater of World War II, and after the war ended, many remained in service, operating across four decades. Produced in numerous variants, nearly 10,000 B-25s were built. It was the most-produced American medium bomber and the third most-produced American bomber overall. These included several limited models such as the F-10 reconnaissance aircraft, the AT-24 crew trainers, and the United States Marine Corps' PBJ-1 patrol bomber.\nDesign and development.\nIn March 1939, the US Army Air Corps issued a specification for a medium bomber that was capable of carrying a payload of over at . North American Aviation (NAA) used its NA-40B design to develop the NA-62, which competed for the medium bomber contract. No YB-25 was available for prototype service tests. In September 1939, the Air Corps ordered the NA-62 into production as the B-25, along with the other new Air Corps medium bomber, the Martin B-26 Marauder \"off the drawing board\".\nEarly into B-25 production, NAA incorporated a significant redesign to the wing dihedral. The first nine aircraft had a constant-dihedral, meaning the wing had a consistent, upward angle from the fuselage to the wingtip. This design caused stability problems. \"Flattening\" the outer wing panels just outboard of the engine nacelles nullified the problem and gave the B-25 its gull wing configuration. Less noticeable changes during this period included an increase in the size of the tail fins and a decrease in their inward tilt at their tops.\nNAA continued design and development in 1940 and 1941. Both the B-25A and B-25B series entered USAAF service. The B-25B was operational in 1942. Combat requirements led to further developments. Before the year was over, NAA was producing the B-25C and B-25D series at different plants. Also in 1942, the manufacturer began design work on the cannon-armed B-25G series. The NA-100 of 1943 and 1944 was an interim armament development at the Kansas City complex known as the B-25D2. Similar armament upgrades by U.S-based commercial modification centers involved about half of the B-25G series. Further development led to the B-25H, B-25J, and B-25J2. The gunship design concept dates to late 1942 and NAA sent a field technical representative to the SWPA. The factory-produced B-25G entered production during the NA-96 order followed by the redesigned B-25H gunship. The B-25J reverted to the bomber role, but it, too, could be outfitted as a strafer.\nNAA manufactured the greatest number of aircraft in World War II, the first time a company had produced trainers, bombers, and fighters simultaneously (the AT-6/SNJ Texan/Harvard, B-25 Mitchell, and the P-51 Mustang). It produced B-25s at both its Inglewood main plant and an additional 6,608 aircraft at its Kansas City, Kansas, plant at Fairfax Airport.\nAfter the war, the USAF placed a contract for the TB-25L trainer in 1952. This was a modification program by Hayes of Birmingham, Alabama. Its primary role was reciprocating engine pilot training.\nA development of the B-25 was the North American XB-28 Dragon, designed as a high-altitude bomber. Two prototypes were built with the second prototype, the XB-28A, evaluated as a photo-reconnaissance platform, but the aircraft did not enter production.\nFlight characteristics.\nThe B-25 was a safe and forgiving aircraft to fly. With one engine out, 60\u00b0 banking turns into the dead engine were possible, and control could be easily maintained down to 145\u00a0mph (230\u00a0km/h). The pilot had to remember to maintain engine-out directional control at low speeds after takeoff with rudder; if this maneuver were attempted with ailerons, the aircraft could snap out of control. The tricycle landing gear made for excellent visibility while taxiing. The only significant complaint about the B-25 was its extremely noisy engines; as a result, many pilots eventually suffered from some degree of hearing loss.\nThe high noise level was due to design and space restrictions in the engine cowlings, which resulted in the exhaust \"stacks\" protruding directly from the cowling ring and partly covered by a small triangular fairing. This arrangement directed exhaust and noise directly at the pilot and crew compartments.\nDurability.\nThe Mitchell was exceptionally sturdy and could withstand tremendous punishment. One B-25C of the 321st Bomb Group was nicknamed \"Patches\" because its crew chief painted all the aircraft's flak hole patches with bright yellow zinc chromate primer. By the end of the war, this aircraft had completed over 300 missions, had been belly-landed six times, and had over 400 patched holes. The airframe of \"Patches\" was so distorted from battle damage that straight-and-level flight required 8\u00b0 of left aileron trim and 6\u00b0 of right rudder, causing the aircraft to \"crab\" sideways across the sky.\nOperational history.\nAsia-Pacific.\nMost B-25s in American service were used in the war against Japan in Asia and the Pacific. The Mitchell fought from the Northern Pacific to the South Pacific and the Far East. These areas included the campaigns in the Aleutian Islands, Papua New Guinea, the Solomon Islands, New Britain, China, Burma and the island hopping campaign in the Central Pacific, as well as in the Doolittle Raid. The aircraft's potential as a ground-attack aircraft emerged during the Pacific war. The jungle environment reduced the usefulness of medium-level bombing, and made low-level attack the best tactic. Using similar mast height level tactics and skip bombing, the B-25 proved itself to be a capable anti-shipping weapon and sank many enemy sea vessels. An ever-increasing number of forward firing guns made the B-25 a formidable strafing aircraft for island warfare. The strafer models were the B-25C1/D1, the B-25J1 and with the NAA strafer nose, the J2 subseries.\nIn Burma, the B-25 was used to attack Japanese communication links, especially bridges in central Burma. It also helped supply the besieged troops at Imphal in 1944. The China Air Task Force, the Chinese American Composite Wing, the First Air Commando Group, the 341st Bomb Group, and eventually, the relocated 12th Bomb Group, all operated the B-25 in the China Burma India Theater. Many of these missions involved battle-field isolation, interdiction, and close air support.\nLater in the war, as the USAAF acquired bases in other parts of the Pacific, the Mitchell could strike targets in Indochina, Formosa, and Kyushu, increasing the usefulness of the B-25. It was also used in some of the shortest raids of the Pacific War, striking from Saipan against Guam and Tinian. The 41st Bomb Group used it against Japanese-occupied islands that had been bypassed by the main campaign, such as the Marshall Islands.\nMiddle East and Italy.\nThe first B-25s arrived in Egypt and were carrying out independent operations by October 1942. Operations there against Axis airfields and motorized vehicle columns supported the ground actions of the Second Battle of El Alamein. Thereafter, the aircraft took part in the rest of the campaign in North Africa, the invasion of Sicily, and the advance up Italy. In the Strait of Messina to the Aegean Sea, the B-25 conducted sea sweeps as part of the coastal air forces. In Italy, the B-25 was used in the ground attack role, concentrating on attacks against road and rail links in Italy, Austria, and the Balkans. The B-25 had a longer range than the Douglas A-20 Havoc and Douglas A-26 Invader, allowing it to reach further into occupied Europe. The five bombardment groups \u2013 20 squadrons \u2013 of the Ninth and Twelfth Air Forces that used the B-25 in the Mediterranean Theater of Operations were the only U.S. units to employ the B-25 in Europe.\nEurope.\nThe RAF received nearly 900 Mitchells, using them to replace Douglas Bostons, Lockheed Venturas, and Vickers Wellington bombers. The Mitchell entered active RAF service on 22 January 1943. At first, it was used to bomb targets in occupied Europe. After the Normandy invasion, the RAF and France used Mitchells in support of the Allies in Europe. Several squadrons moved to forward airbases on the continent. The USAAF used the B-25 in combat in the Mediterranean Theater of Operations.\nUS Army Air Forces.\nThe B-25B found fame as the bomber used in the 18 April 1942 Doolittle Raid, in which 15 B-25Bs led by Lieutenant Colonel Jimmy Doolittle attacked mainland Japan, four months after the Japanese attack on Pearl Harbor (a 16th plane which participated was forced to abort, landing in Russia, where it and the crew were initially interned). The mission gave a much-needed lift in morale to the Americans and alarmed the Japanese, who had believed their home islands to be inviolable by enemy forces. Although the amount of actual damage done was relatively minor, it forced the Japanese to divert troops for home defense for the remainder of the war.\nThe raiders took off from the carrier and bombed Tokyo and four other Japanese cities. Fifteen of the bombers subsequently crash-landed en route to recovery fields in eastern China. The losses resulted from the task force being spotted by a Japanese vessel, which forced the bombers to take off early, fuel exhaustion, stormy nighttime conditions with zero visibility, and the failure to activate electronic homing aids at the recovery bases. Only one B-25 bomber landed intact, in Vladivostok, where its five-man crew was interned and the aircraft confiscated. Of the 80 aircrew members, 69 survived their historic mission and eventually made it back to American lines.\nFollowing additional modifications, including the addition of a Plexiglas dome for navigational sightings to replace the overhead window for the navigator, and heavier nose armament, de-icing and anti-icing equipment, the B-25C entered USAAF operations. Through block 20, the B-25C and B-25D differed only in the location of manufacture: C series at Inglewood, California, and D series at Kansas City, Kansas. After block 20, some NA-96s began the transition to the G series, while some NA-87s acquired interim modifications eventually produced as the B-25D2 and ordered as the NA-100. NAA built a total of 3,915 B-25Cs and Ds during World War II.\nAlthough the B-25 was designed to bomb from medium altitudes in level flight, it was frequently used in the Southwest Pacific theatre in treetop-level strafing and missions with parachute-retarded fragmentation bombs against Japanese airfields in New Guinea and the Philippines. These heavily armed Mitchells were field-modified at Townsville, Australia, under the direction of Major Paul I. \"Pappy\" Gunn and North American technical representative Jack Fox. These \"commerce destroyers\" were also used on strafing and skip bombing missions against Japanese shipping trying to resupply their armies.\nUnder the leadership of Lieutenant General George C. Kenney, Mitchells of the Far East Air Forces and its existing components, the Fifth and Thirteenth Air Forces, devastated Japanese targets in the Southwest Pacific Theater during 1944 to 1945. The USAAF played a significant role in pushing the Japanese back to their home islands. The type operated with great effect in the Central Pacific, Alaska, North Africa, Mediterranean, and China-Burma-India theaters.\nThe USAAF Antisubmarine Command made great use of the B-25 in 1942 and 1943. Some of the earliest B-25 bomb groups also flew the Mitchell on coastal patrols after the Pearl Harbor attack, prior to the AAFAC organization. Many of the two dozen or so antisubmarine squadrons flew the B-25C, D, and G series in the American Theater antisubmarine campaign, often in the distinctive, white sea-search camouflage.\nCombat developments.\nUse as a gunship.\nIn anti-shipping operations, the USAAF had an urgent need for hard-hitting aircraft, and North American responded with the B-25G. In this series, the transparent nose and bombardier/navigator position was changed for a shorter, hatched nose with two fixed .50\u00a0in (12.7\u00a0mm) machine guns and a manually loaded 75\u00a0mm (2.95\u00a0in) M4 cannon, one of the largest weapons fitted to an aircraft, similar to the British 57\u00a0mm gun-armed Mosquito Mk. XVIII and the autoloading German 75\u00a0mm long-barrel \"Bordkanone BK 7,5\" heavy-caliber ordnance fitted to both the Henschel Hs 129B-3 and Junkers Ju 88P-1. The B-25G's shorter nose placed the cannon breech behind the pilot, where it could be manually loaded and serviced by the navigator; his crew station was moved to a position just behind the pilot. The navigator signaled the pilot when the gun was ready and the pilot fired the weapon using a button on his control wheel.\nThe Royal Air Force, U.S. Navy, and Soviet VVS each conducted trials with this series, but none adopted it. The G series comprised one prototype, five preproduction C conversions, 58 C series modifications, and 400 production aircraft for a total of 464 B-25Gs. In its final version, the G-12, an interim armament modification, eliminated the lower Bendix turret and added a starboard dual gun pack, waist guns, and a canopy for the tail gunner to improve the view when firing the single tail gun. In April 1945, the air depots in Hawaii refurbished about two dozen of these and included the eight-gun nose and rocket launchers in the upgrade.\nThe B-25H series continued the development of the gunship version. NAA Inglewood produced 1000. The H had even more firepower. Most replaced the M4 gun with the lighter T13E1, designed specifically for the aircraft, but 20-odd H-1 block aircraft completed by the Republic Aviation modification center at Evansville had the M4 and two-machine-gun nose armament. The 75\u00a0mm (2.95\u00a0in) gun fired at a muzzle velocity of . Due to its slow rate of fire (about four rounds could be fired in a single strafing run), relative ineffectiveness against ground targets, and the substantial recoil, the 75\u00a0mm gun was sometimes removed from both G and H models and replaced with two additional .50\u00a0in (12.7\u00a0mm) machine guns as a field modification. In the new FEAF, these were redesignated the G1 and H1 series, respectively.\nThe H series normally came from the factory mounting four fixed, forward-firing .50\u00a0in (12.7\u00a0mm) machine guns in the nose; four in a pair of under-cockpit conformal flank-mount gun pod packages (two guns per side); two more in the manned dorsal turret, relocated forward to a position just behind the cockpit (which became standard for the J-model); one each in a pair of new waist positions, introduced simultaneously with the forward-relocated dorsal turret; and lastly, a pair of guns in a new tail-gunner's position. Company promotional material bragged that the B-25H could \"bring to bear 10 machine guns coming and four going, in addition to the 75\u00a0mm cannon, eight rockets, and 3,000\u00a0lb (1,360\u00a0kg) of bombs.\"\nThe H had a modified cockpit with single flight controls operated by the pilot. The co-pilot's station and controls were removed and replaced by a smaller seat used by the navigator/cannoneer, The radio operator crew position was aft of the bomb bay with access to the waist guns. Factory production totals were 405 B-25Gs and 1,000 B-25Hs, with 248 of the latter being used by the Navy as PBJ-1Hs. Elimination of the co-pilot saved weight, and moving the dorsal turret forward partially counterbalanced the waist guns and the manned rear turret.\nReturn to medium bomber.\nFollowing the two-gunship series, NAA again produced the medium bomber configuration with the B-25J series. It optimized the mix of the interim NA-100 and the H series, having both the bombardier's station and fixed guns of the D and the forward turret and refined armament of the H series. NAA also produced a strafer nose-first shipped to air depots as kits, then introduced on the production line in alternating blocks with the bombardier nose. The solid metal \"strafer\" nose housed eight centerline Browning M2 .50 caliber machine guns. The remainder of the armament was as in the H-5. NAA also supplied kits to mount eight underwing 5 inch High Velocity Airborne Rockets just outside the propeller arcs. These were mounted on zero-length launch rails, four per wing.\nThe final, and most numerous, series of the Mitchell, the B-25J, looked less like earlier series apart from the well-glazed bombardier's nose of nearly identical appearance to the earliest B-25 subtypes. Instead, the J followed the overall configuration of the H series from the cockpit aft. It had the forward dorsal turret and other armament and airframe advancements. All J models included four .50\u00a0in (12.7\u00a0mm) light-barrel Browning AN/M2 guns in a pair of \"fuselage packages\", conformal gun pods each flanking the lower cockpit, each pod containing two Browning M2s. By 1945, however, combat squadrons removed these. The J series restored the co-pilot's seat and dual flight controls. The factory-made kits available to the Air Depot system to create the strafer-nose B-25J-2. This configuration carried a total of 18 .50\u00a0in (12.7\u00a0mm) light-barrel AN/M2 Browning M2 machine guns: eight in the nose, four in the flank-mount conformal gun pod packages, two in the dorsal turret, one each in the pair of waist positions, and a pair in the tail \u2013 with 14 of the guns either aimed directly forward or aimed to fire directly forward for strafing missions. Some aircraft had eight 5-inch (130\u00a0mm) high-velocity aircraft rockets. NAA introduced the J-2 into production in alternating blocks at the J-22. Total J series production was 4,318.\nPostwar (USAF) use.\nIn 1947, legislation created an independent United States Air Force and by that time, the B-25 inventory numbered only a few hundred. Some B-25s continued in service into the 1950s in training, reconnaissance, and support roles. The principal use during this period was undergraduate training of multiengine aircraft pilots slated for reciprocating engine or turboprop cargo, aerial refueling, or reconnaissance aircraft. Others were assigned to units of the Air National Guard in training roles in support of Northrop F-89 Scorpion and Lockheed F-94 Starfire operations. \nDuring its USAF tenure, many B-25s received the so-called \"Hayes modification\" and as a result, surviving B-25s often have exhaust systems with a semi collector ring that splits emissions into two different systems. The upper seven cylinders are collected by a ring, while the other cylinders remain directed to individual ports.\nTB-25J-25-NC Mitchell, \"44-30854\", the last B-25 in the USAF inventory, assigned at March AFB, California, as of March 1960, was flown to Eglin AFB, Florida, from Turner Air Force Base, Georgia, on 21 May 1960, the last flight by a USAF B-25. It was presented by Brigadier General A. J. Russell, Commander of SAC's 822d Air Division at Turner AFB, to the Air Proving Ground Center Commander, Brigadier General Robert H. Warren. He in turn presented the bomber to Valparaiso, Florida, Mayor Randall Roberts on behalf of the Niceville-Valparaiso Chamber of Commerce. Four of the original Tokyo Raiders were present for the ceremony, Colonel (later Major General) David Jones, Colonel Jack Simms, Lieutenant Colonel Joseph Manske, and retired Master Sergeant Edwin W. Horton. It was donated back to the Air Force Armament Museum c. 1974 and marked as Doolittle's \"40-2344\".\nU.S. Navy and USMC.\nThe U.S. Navy designation for the Mitchell was the PBJ-1 and apart from increased use of radar, it was configured like its Army Air Forces counterparts. Under the pre-1962 USN/USMC/USCG aircraft designation system, PBJ-1 stood for Patrol (P) Bomber (B) built by North American Aviation (J), first variant (-1) under the existing American naval aircraft designation system of the era. The PBJ had its origin in an inter-service agreement of mid-1942 between the Navy and the USAAF exchanging the Boeing Renton plant for the Kansas plant for B-29 Superfortress production. The Boeing XPBB Sea Ranger flying boat, competing for B-29 engines, was cancelled in exchange for part of the Kansas City Mitchell production. Other terms included the interservice transfer of 50 B-25Cs and 152 B-25Ds to the Navy. The bombers carried Navy bureau numbers (BuNos), beginning with BuNo 34998. The first PBJ-1 arrived in February 1943, and nearly all reached Marine Corps squadrons, beginning with Marine Bombing Squadron 413 (VMB-413). Following the AAFAC format, the Marine Mitchells had search radar in a retractable radome replacing the remotely operated ventral turret. Later D and J series had nose-mounted APS-3 radar; and later still, J and H series mounted radar in the starboard wingtip. The large quantities of B-25H and J series became known as PBJ-1H and PBJ-1J, respectively. These aircraft often operated along with earlier PBJ series in Marine squadrons.\nThe PBJs were operated almost exclusively by the Marine Corps as land-based bombers. The U.S. Marine Corps established Marine bomber squadrons (VMB), beginning with VMB-413, in March 1943 at MCAS Cherry Point, North Carolina. Eight VMB squadrons were flying PBJs by the end of 1943 as the initial Marine medium bombardment group. Four more squadrons were in the process of formation in late 1945, but had not yet deployed by the time the war ended.\nOperations of the Marine Corps PBJ-1s began in March 1944. The Marine PBJs flew from the Philippines, Saipan, Iwo Jima, and Okinawa during the last few months of the Pacific war. Their primary mission was the long-range interdiction of enemy shipping trying to run the blockade, which was strangling Japan. The weapon of choice during these missions was usually the five-inch HVAR rocket, eight of which could be carried. Some VMB-612 intruder PBJ-1D and J series planes flew without top turrets to save weight and increase range on night patrols, especially towards the end of the war when air superiority had been achieved. \nDuring the war, the Navy tested the cannon-armed G series and conducted carrier trials with an H equipped with arresting gear. After World War II, some PBJs stationed at the Navy's rocket laboratory in Inyokern, California, site of the present-day Naval Air Weapons Station China Lake, tested air-to-ground rockets and arrangements. One arrangement was a twin-barrel nose that could fire 10 spin-stabilized five-inch rockets in one salvo.\nRoyal Air Force.\nThe Royal Air Force (RAF) was an early customer for the B-25 via Lend-Lease. The first Mitchells were given the service name Mitchell I by the RAF and were delivered in August 1941, to No. 111 Operational Training Unit based in the Bahamas. These bombers were used exclusively for training and familiarization and never became operational. The B-25Cs and Ds were designated Mitchell II. Altogether, 167 B-25Cs and 371 B-25Ds were delivered to the RAF. The RAF tested the cannon-armed G series but did not adopt the series nor the follow-on H series.\nBy the end of 1942, the RAF had taken delivery of 93 Mitchells, marks I and II. Some served with squadrons of No. 2 Group RAF, the RAF's tactical medium-bomber force, including No. 139 Wing RAF at RAF Dunsfold. The first RAF operation with the Mitchell II took place on 22 January 1943, when six aircraft from No. 180 Squadron RAF attacked oil installations at Ghent. After the invasion of Europe (by which point 2 Group was part of Second Tactical Air Force), all four Mitchell squadrons moved to bases in France and Belgium (Melsbroek) to support Allied ground forces. The British Mitchell squadrons were joined by No. 342 (Lorraine) Squadron of the French Air Force in April 1945.\nAs part of its move from Bomber Command, No 305 (Polish) Squadron flew Mitchell IIs from September to December 1943 before converting to the de Havilland Mosquito. In addition to No. 2 Group, the B-25 was used by various second-line RAF units in the UK and abroad. In the Far East, No. 3 PRU, which consisted of Nos. 681 and 684 Squadrons, flew the Mitchell (primarily Mk IIs) on photographic reconnaissance sorties.\nRoyal Canadian Air Force.\nThe Royal Canadian Air Force (RCAF) used the B-25 Mitchell for training during the war. Postwar use continued operations with most of the 162 Mitchells received. The first B-25s had been diverted to Canada from RAF orders. These included one Mitchell I, 42 Mitchell IIs, and 19 Mitchell IIIs. No 13 (P) Squadron was formed unofficially at RCAF Rockcliffe in May 1944 and used Mitchell IIs on high-altitude aerial photography sorties. No. 5 Operational Training Unit at Boundary Bay, British Columbia and Abbotsford, British Columbia, operated the B-25D Mitchell in the training role together with B-24 Liberators for Heavy Conversion as part of the BCATP. The RCAF retained the Mitchell until October 1963.\nNo 418 (Auxiliary) Squadron received its first Mitchell IIs in January 1947. It was followed by No 406 (auxiliary), which flew Mitchell IIs and IIIs from April 1947 to June 1958. No 418 operated a mix of IIs and IIIs until March 1958. No 12 Squadron of Air Transport Command also flew Mitchell IIIs along with other types from September 1956 to November 1960. In 1951, the RCAF received an additional 75 B-25Js from USAF stocks to make up for attrition and to equip various second-line units.\nRoyal Australian Air Force.\nThe Australians received Mitchells by the spring of 1944. The joint Australian-Dutch No. 18 (Netherlands East Indies) Squadron RAAF had more than enough Mitchells for one squadron, so the surplus went to re-equip the RAAF's No. 2 Squadron, replacing their Beauforts.\nDutch Air Force.\nDuring World War II, the Mitchell served in fairly large numbers with the Air Force of the Dutch government-in-exile. They participated in combat in the East Indies, as well as on the European front. On 30 June 1941, the Netherlands Purchasing Commission, acting on behalf of the Dutch government-in-exile in London, signed a contract with North American Aviation for 162 B-25C aircraft. The bombers were to be delivered to the Netherlands East Indies to help deter any Japanese aggression into the region.\nIn February 1942, the British Overseas Airways Corporation agreed to ferry 20 Dutch B-25s from Florida to Australia travelling via Africa and India, and an additional 10 via the South Pacific route from California. During March, five of the bombers on the Dutch order had reached Bangalore, India, and 12 had reached Archerfield in Australia. The B-25s in Australia were used as the nucleus of a new squadron, No. 18. This squadron was staffed jointly by Australian and Dutch aircrews plus a smattering of aircrews from other nations and operated under Royal Australian Air Force command for the remainder of the war.\nThe B-25s of No. 18 Squadron were painted with the Dutch national insignia (at that time a rectangular Netherlands flag) and carried NEIAF serials. Discounting the ten \"temporary\" B-25s delivered to 18 Squadron in early 1942, a total of 150 Mitchells were taken on strength by the NEIAF, 19 in 1942, 16 in 1943, 87 in 1944, and 28 in 1945. They flew bombing raids against Japanese targets in the East Indies. In 1944, the more capable B-25J Mitchells replaced most of the earlier C and D models.\nIn June 1940, No. 320 (Netherlands) Squadron RAF had been formed from personnel formerly serving with the Royal Dutch Naval Air Service, who had escaped to England after the German occupation of the Netherlands. Equipped with various British aircraft, No. 320 Squadron flew antisubmarine patrols, convoy escort missions, and performed air-sea rescue duties. They acquired the Mitchell II in September 1943, performing operations over Europe against gun emplacements, railway yards, bridges, troops, and other tactical targets. They moved to Belgium in October 1944, and transitioned to the Mitchell III in 1945. No. 320 Squadron was disbanded in August 1945. Following the war, B-25s were used by Dutch forces during the Indonesian National Revolution.\nSoviet Air Force.\nThe USSR received 862 B-25s (B, C, D, G, and J types) from the United States under Lend-Lease during World War II via the Alaska\u2013Siberia ALSIB ferry route. A total of 870 B-25s were sent to the Soviets, meaning that 8 aircraft were lost during transportation.\nOther damaged B-25s arrived or crashed in the Far East of Russia, and one Doolittle Raid aircraft landed there short of fuel after attacking Japan. This lone airworthy Doolittle Raid aircraft to reach the Soviet Union was lost in a hangar fire in the early 1950s while undergoing routine maintenance. In general, the B-25 was operated as a ground-support and tactical day bomber (as similar Douglas A-20 Havocs were used). It saw action in fights from Stalingrad (with B/C/D models) to the German surrender during May 1945 (with G/J types).\nThe B-25s that remained in Soviet Air Force service after the war were assigned the NATO reporting name \"Bank\".\nChina.\nWell over 100 B-25Cs and Ds were supplied to the Nationalist Chinese during the Second Sino-Japanese War. In addition, a total of 131 B-25Js were supplied to China under Lend-Lease.\nThe four squadrons of the 1st BG (1st, 2nd, 3rd, and 4th) of the 1st Medium Bomber Group were formed during the war. They formerly operated Russian-built Tupolev SB bombers, then transferred to the B-25. The 1st BG was under the command of Chinese-American Composite Wing while operating B-25s. Following the end of the war in the Pacific, these four bombardment squadrons were established to fight against the Communist insurgency that was rapidly spreading throughout the country. During the Chinese Civil War, Chinese Mitchells fought alongside de Havilland Mosquitos.\nIn December 1948, the Nationalists were forced to retreat to the island of Taiwan, taking many of their Mitchells with them. However, some B-25s were left behind and were pressed into service with the air force of the new People's Republic of China.\nBrazilian Air Force.\nDuring the war, the For\u00e7a A\u00e9rea Brasileira received a few B-25s under Lend-Lease. Brazil declared war against the Axis powers in August 1942 and participated in the war against the U-boats in the southern Atlantic. The last Brazilian B-25 was finally declared surplus in 1970.\nFree French.\nThe Royal Air Force issued at least 21 Mitchell IIIs to No 342 Squadron, which was made up primarily of Free French aircrews. Following the liberation of France, this squadron transferred to the newly formed French Air Force (\"Arm\u00e9e de l'Air\") as GB I/20 Lorraine. The aircraft continued in operation after the war, with some being converted into fast VIP transports. They were struck off charge in June 1947.\nBiafra.\nIn October 1967, during the Nigerian Civil War, Biafra bought two Mitchells. After a few bombings in November, they were put out of action in December.\nIndonesia.\nIndonesia received 42 Mitchells after the Round Table Conference, one was used for strafing runs against a Dutch warship while two others were used in Maluku.\nVariants.\nTrainer variants.\nMost models of the B-25 were used at some point as training aircraft.\nAccidents and incidents.\nEmpire State Building crash.\nAt 9:40 on 28 July 1945, a USAAF B-25D crashed in thick fog into the north side of the Empire State Building between the 79th and 80th floors. Fourteen people died\u00a0\u2014 11 in the building and the three occupants of the aircraft, including the pilot, Colonel William F. Smith. Betty Lou Oliver, an elevator attendant, survived the impact and the subsequent fall of the elevator cage 75 stories to the basement.\nFrench general Philippe Leclerc was aboard his North American B-25 Mitchell, Tailly II, when it crashed near Colomb-B\u00e9char in French Algeria on 28 November 1947, killing everyone on board.\nLake Erie skydiving disaster.\nA bit after 16:00 on 27 August 1967, a converted civilian B-25 mistakenly dropped eighteen skydivers over Lake Erie, four or five nautical miles (7.5\u20139.3\u00a0km) from Huron, Ohio. The air traffic controller had confused the B-25 with a Cessna 180 Skywagon that was trailing it to take photographs, causing the B-25 pilot to think he was over the intended drop site at Ortner Airport. Sixteen of the jumpers drowned, while two were rescued. A National Transportation Safety Board report faulted the pilot, and to a lesser extent the skydivers, for executing a jump when they could not see the ground, and faulted the controller for the misidentification. The United States was subsequently held liable for the controller's negligence.\nTraining Mission Incident.\nOn Nov. 1, 1941, just one month before the Japanese attack on Pearl Harbor, a B-25 bomber on a training mission flying out of Wright-Patterson Air Force Base, crashed near Benton Ridge, Ohio.\nSurviving aircraft.\nMany B-25s are currently kept in airworthy condition by air museums and collectors."}
{"id": "4219", "revid": "14493457", "url": "https://en.wikipedia.org/wiki?curid=4219", "title": "British Open (disambiguation)", "text": "The British Open often refers to the Open Championship men's golf tournament.\nBritish Open may also refer to:"}
{"id": "4221", "revid": "1306352", "url": "https://en.wikipedia.org/wiki?curid=4221", "title": "B-25", "text": ""}
{"id": "4222", "revid": "15902509", "url": "https://en.wikipedia.org/wiki?curid=4222", "title": "Bernthia Perkins", "text": ""}
